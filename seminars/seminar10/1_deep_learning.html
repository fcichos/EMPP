<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.34">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Neural Networks ‚Äì Einf√ºhrung in die Modellierung Physikalischer Prozesse</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-c8ad9e5dbd60b7b70b38521ab19b7da4.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-9344fb9851b4da3cab95007ef9d770dc.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script src="../../site_libs/quarto-contrib/live-runtime/live-runtime.js" type="module"></script>
<link href="../../site_libs/quarto-contrib/live-runtime/live-runtime.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script type="module" src="../../site_libs/quarto-ojs/quarto-ojs-runtime.js"></script>
<link href="../../site_libs/quarto-ojs/quarto-ojs.css" rel="stylesheet">
<script defer="" data-domain="fcichos.github.io/EMPP" src="https://plausible.io/js/script.js"></script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-sidebar floating nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Einf√ºhrung in die Modellierung Physikalischer Prozesse</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item">Neural Networks</li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Home</span></a>
  </div>
</li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">üìã Course Info</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../course-info/intructors.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Vorlesender</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../course-info/resources.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Ressourcen</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../course-info/assignments.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">√úbungsaufgaben</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../course-info/exam.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Pr√ºfungen</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">üöÄ Week 1: Your First Physics Code</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/lecture01/01-lecture01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Setup: Jupyter Notebooks</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/lecture01/01-plotting-basics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Quick Win: Plotting Your First Graph</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">üéØ Week 2: Python Building Blocks</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/lecture01/02-lecture01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Variables &amp; Numbers (What You Just Used)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/lecture02/3_datatypes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Datatypes for Physics</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">üåü Week 3: Modeling Motion</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/lecture02/01-lecture02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Functions: Reusable Physics Equations</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/lecture02/4_brownian_motion_simple.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Application: Brownian Motion (Simple)</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true">
 <span class="menu-text">‚ö° Week 4: Classical Mechanics 1</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/lecture02/4_brownian_motion_simple.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Application: Brownian Motion (Simple)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/lecture03/1_numpy.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Arrays with Numpy</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true">
 <span class="menu-text">‚ö° Week 5: Numerical Methods Toolkit</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/lecture07/1_differentiation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Numerical Differentiation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/lecture08/3_solving_ODEs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Tool: Solving ODEs</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true">
 <span class="menu-text">üåü Week 6: Classical Mechanics Applications</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/lecture10/2_planetary_motion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Planetary Motion</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/lecture10/1_spring_pendulum.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Spring Pendulum &amp; Chaos</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="true">
 <span class="menu-text">üîß Week 7: Code Organization</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/lecture05/1_classes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Classes &amp; Objects</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="true">
 <span class="menu-text">üåä Week 8: Oscillations &amp; Files</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-9" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/lecture05/2_brownian_motion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Advanced: Brownian Motion with OOP</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/lecture06/1_input_output.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Input, Output, Data Files</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/lecture09/2_coupled_pendula.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Coupled Pendula</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="true">
 <span class="menu-text">üåä Week 9: Fourier Analysis &amp; Waves</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-10" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/lecture09/3_fourier_analysis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Fourier Analysis</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/lecture13/1_plane_waves.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Plane Waves</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/lecture13/2_spherical_waves.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Spherical Waves</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/lecture14/3_huygens_principle.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Huygens Principle</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" role="navigation" aria-expanded="true">
 <span class="menu-text">üìä Week 10: Analyzing Experiments</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-11" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/lecture07/1_curve_fitting.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Curve Fitting to Data</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-12" role="navigation" aria-expanded="true">
 <span class="menu-text">üéì Week 11: Review</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-12" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-12" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/lecture11/1_repetition.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Repetition: Core Concepts</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/lecture11/1_repetition_slides.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Repetition: Core Concepts Slides</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/lecture15/lecture15a.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Repetition: ODE Review</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/lecture15/lecture15a_slides.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Repetition: ODE Review Slides</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-13" role="navigation" aria-expanded="true">
 <span class="menu-text">üéì Week 12: Review</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-13" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-13" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/lecture13/4_repetition.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Repetition: Meshgrid &amp; Arrays</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/lecture13/4_repetition_slides.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Repetition: Meshgrid &amp; Arrays Slides</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/lecture12/3_diffusion_equation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Diffusion Equation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lectures/lecture12/3_diffusion_equation_slides.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Diffusion Equation Slides</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-14" role="navigation" aria-expanded="true">
 <span class="menu-text">üõ†Ô∏è Hands-On Seminars</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-14" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-14" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-15" role="navigation" aria-expanded="false">
 <span class="menu-text">Advanced Topics</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-15" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-15" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../seminars/seminar01/2_reinforcement_learning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Advanced: Reinforcement Learning</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../seminars/seminar01/1_deep_learning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Advanced: Deep Learning</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-16" role="navigation" aria-expanded="false">
 <span class="menu-text">Other Seminar Topics</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-16" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-16" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../seminars/seminar06/25_publication_ready_figures.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Publication-Ready Figures</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../seminars/seminar07/seminar7_curve_fitting.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Curve Fitting</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-17" role="navigation" aria-expanded="false">
 <span class="menu-text">Recap: Projectile Motion</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-17" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-17" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../seminars/seminar11/seminar11_projectile.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Projectile with Air Resistance</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#the-mnist-data-set" id="toc-the-mnist-data-set" class="nav-link active" data-scroll-target="#the-mnist-data-set">The MNIST Data Set</a>
  <ul class="collapse">
  <li><a href="#load-the-data" id="toc-load-the-data" class="nav-link" data-scroll-target="#load-the-data">Load the data</a></li>
  <li><a href="#normalize-the-data" id="toc-normalize-the-data" class="nav-link" data-scroll-target="#normalize-the-data">Normalize the data</a></li>
  <li><a href="#preparing-training-and-testing-data" id="toc-preparing-training-and-testing-data" class="nav-link" data-scroll-target="#preparing-training-and-testing-data">Preparing training and testing data</a></li>
  </ul></li>
  <li><a href="#a-single-neuron" id="toc-a-single-neuron" class="nav-link" data-scroll-target="#a-single-neuron">A Single Neuron</a>
  <ul class="collapse">
  <li><a href="#forward-propogation" id="toc-forward-propogation" class="nav-link" data-scroll-target="#forward-propogation">Forward Propogation</a></li>
  <li><a href="#loss-function" id="toc-loss-function" class="nav-link" data-scroll-target="#loss-function">Loss Function</a></li>
  </ul></li>
  <li><a href="#trainging-the-network" id="toc-trainging-the-network" class="nav-link" data-scroll-target="#trainging-the-network">Trainging the Network</a>
  <ul class="collapse">
  <li><a href="#backward-propagation" id="toc-backward-propagation" class="nav-link" data-scroll-target="#backward-propagation">Backward Propagation</a></li>
  <li><a href="#stochastic-gradient-descent" id="toc-stochastic-gradient-descent" class="nav-link" data-scroll-target="#stochastic-gradient-descent">Stochastic Gradient Descent</a></li>
  <li><a href="#build-an-train" id="toc-build-an-train" class="nav-link" data-scroll-target="#build-an-train">Build an Train</a></li>
  <li><a href="#testing-our-model" id="toc-testing-our-model" class="nav-link" data-scroll-target="#testing-our-model">Testing our model</a></li>
  </ul></li>
  <li><a href="#network-with-hidden-layers" id="toc-network-with-hidden-layers" class="nav-link" data-scroll-target="#network-with-hidden-layers">Network with Hidden Layers</a></li>
  <li><a href="#multiclass-network" id="toc-multiclass-network" class="nav-link" data-scroll-target="#multiclass-network">Multiclass Network</a>
  <ul class="collapse">
  <li><a href="#changes-to-the-model" id="toc-changes-to-the-model" class="nav-link" data-scroll-target="#changes-to-the-model">Changes to the model</a></li>
  <li><a href="#build-and-train" id="toc-build-and-train" class="nav-link" data-scroll-target="#build-and-train">Build and Train</a></li>
  </ul></li>
  <li><a href="#test-the-model" id="toc-test-the-model" class="nav-link" data-scroll-target="#test-the-model">Test the model</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Neural Networks</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>Neural networks are one of the most commonly used machine learning objects nowadays. Mostly these systems are known as <strong>deep neural networks</strong>, which just says something about how many layers in which neurons are arranged exist. We will in this lecture have a look at the basic unit, the neuron, and how to connect and train a network. We will do all ourselves, that means, we will not use one of the many existing python modules, that simplifies the task. This notebook has been largely developed by <strong>Martin Fr√§nzl</strong>.</p>
<div id="6da70ff8" class="cell" data-tags="[]" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>matplotlib inline</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>config InlineBackend.figure_format <span class="op">=</span> <span class="st">'retina'</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>plt.rcParams.update({<span class="st">'font.size'</span>: <span class="dv">18</span>,</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>                     <span class="st">'axes.titlesize'</span>: <span class="dv">20</span>,</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>                     <span class="st">'axes.labelsize'</span>: <span class="dv">20</span>,</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>                     <span class="st">'axes.labelpad'</span>: <span class="dv">1</span>,</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>                     <span class="st">'lines.linewidth'</span>: <span class="dv">2</span>,</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>                     <span class="st">'lines.markersize'</span>: <span class="dv">10</span>,</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>                     <span class="st">'xtick.labelsize'</span> : <span class="dv">18</span>,</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>                     <span class="st">'ytick.labelsize'</span> : <span class="dv">18</span>,</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>                     <span class="st">'xtick.top'</span> : <span class="va">True</span>,</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>                     <span class="st">'xtick.direction'</span> : <span class="st">'in'</span>,</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>                     <span class="st">'ytick.right'</span> : <span class="va">True</span>,</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>                     <span class="st">'ytick.direction'</span> : <span class="st">'in'</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>                    })</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>In this lecture we are going to build a neural network from scratch using Python and NumPy (The high-level libaries like Keras and TensorFlow will be covered in Part 2). We will build a network to recognize hand-written digits, using the famous MNIST data set.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="MNIST.png" class="img-fluid figure-img"></p>
<figcaption>MNIS</figcaption>
</figure>
</div>
<p>We will start with the simplest possible ‚Äúnetwork‚Äù: A single node that recognizes just the digit 0. This is actually just an implementation of logistic regression, but it will help us understand some of the key components before things get more complicated. Then we‚Äôll extend that into a network with one hidden layer, still recognizing just 0. Finally, we will extend the network to recognize all the digits 0 through 9. That will give us a 92% accurate digit-recognizer.</p>
<section id="the-mnist-data-set" class="level2">
<h2 class="anchored" data-anchor-id="the-mnist-data-set">The MNIST Data Set</h2>
<p>The MNIST data set contains 70,000 images of hand-written digits, each 28 x 28 pixels, in greyscale with pixel-values from 0 to 255. We could download and preprocess the data ourselves, but the makers of the module <code>sklearn</code> already did that for us:</p>
<section id="load-the-data" class="level3">
<h3 class="anchored" data-anchor-id="load-the-data">Load the data</h3>
<div id="bdb37c42" class="cell" data-tags="[]" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> fetch_openml</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> fetch_openml(<span class="st">'mnist_784'</span>, version<span class="op">=</span><span class="dv">1</span>, return_X_y<span class="op">=</span><span class="va">True</span>,as_frame<span class="op">=</span><span class="va">False</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The images are now contained in the array <code>X</code>, while the labels (so which number it is) are contained in <code>y</code>. Let‚Äôs have a look at a random image and label.</p>
<div id="dc25f316" class="cell" data-tags="[]" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>i <span class="op">=</span> <span class="dv">33419</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>plt.imshow(np.array(X)[i].reshape(<span class="dv">28</span>, <span class="dv">28</span>), cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>plt.colorbar()</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'label: '</span>,y[i])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="1_deep_learning_files/figure-html/cell-4-output-1.png" width="519" height="420" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>label:  8</code></pre>
</div>
</div>
</section>
<section id="normalize-the-data" class="level3">
<h3 class="anchored" data-anchor-id="normalize-the-data">Normalize the data</h3>
<p>To use data in neural networks as training data, it is always useful to normalize the data to the interval [0, 1].</p>
<div id="44af4818" class="cell" data-tags="[]" data-execution_count="4">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> X<span class="op">/</span><span class="dv">255</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="preparing-training-and-testing-data" class="level3">
<h3 class="anchored" data-anchor-id="preparing-training-and-testing-data">Preparing training and testing data</h3>
<p>The default MNIST labels say ‚Äò1‚Äô for an image of a one, ‚Äò2‚Äô for an image of a two, etc., but we are just building a zero classifier for now. So we want our labels to say 1 when we have a zero, and 0 otherwise. So we overwrite the labels accordingly:</p>
<div id="2db6e593" class="cell" data-tags="[]" data-execution_count="5">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>y_new <span class="op">=</span> np.zeros(y.shape)</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>y_new[np.where(y <span class="op">==</span> <span class="st">'0'</span>)[<span class="dv">0</span>]] <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> y_new</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We now split the data in a train and test set. The MNIST images are pre-arranged so that the first 60,000 can be used for training, and the last 10,000 for testing. We‚Äôll also transform the data into the shape we want, with each example in a column (instead of a row):</p>
<div id="51b01d97" class="cell" data-tags="[]" data-execution_count="6">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>m <span class="op">=</span> <span class="dv">60000</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>m_test <span class="op">=</span> X.shape[<span class="dv">0</span>] <span class="op">-</span> m</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>X_train, X_test <span class="op">=</span> X[:m].T, X[m:].T</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>y_train, y_test <span class="op">=</span> y[:m].reshape(<span class="dv">1</span>,m), y[m:].reshape(<span class="dv">1</span>, m_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Finally, we shuffle the training set:</p>
<div id="8f3218d0" class="cell" data-tags="[]" data-execution_count="7">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">1</span>)</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>shuffle_index <span class="op">=</span> np.random.permutation(m)</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>X_train, y_train <span class="op">=</span> X_train[:,shuffle_index], y_train[:,shuffle_index]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Let‚Äôs again have a look at random image and label just to check</p>
<div id="6c6de298" class="cell" data-tags="[]" data-execution_count="8">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>i <span class="op">=</span> <span class="dv">39</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>plt.imshow(X_train[:,i].reshape(<span class="dv">28</span>, <span class="dv">28</span>), cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>plt.colorbar()</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(y_train[:,i])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="1_deep_learning_files/figure-html/cell-9-output-1.png" width="511" height="426" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>[0.]</code></pre>
</div>
</div>
<p>Try to find a zero to check whether the corresponding label is a 1.</p>
</section>
</section>
<section id="a-single-neuron" class="level2">
<h2 class="anchored" data-anchor-id="a-single-neuron">A Single Neuron</h2>
<p>The basic unit of a neural network is a neuron. A neuron takes inputs, does some math with them, and produces one output. The neuron below does that with two inputs.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/neuron.png" class="img-fluid figure-img"></p>
<figcaption>image</figcaption>
</figure>
</div>
<section id="forward-propogation" class="level3">
<h3 class="anchored" data-anchor-id="forward-propogation">Forward Propogation</h3>
<p>The neuron does now three things.</p>
<ol type="1">
<li>Take input values and multipy by weights</li>
</ol>
<p><span class="math display">\[\begin{eqnarray}
x_{1}\rightarrow x_{1} w_{1}\\
x_{2}\rightarrow x_{2} w_{2}
\end{eqnarray}\]</span></p>
<ol start="2" type="1">
<li>All the weighted inputs are the added to a bias value <span class="math inline">\(b\)</span></li>
</ol>
<p><span class="math display">\[\begin{equation}
x_{1} w_{1}+ x_{2} w_{2}+b
\end{equation}\]</span></p>
<ol start="3" type="1">
<li>The output is generated by applying a function <span class="math inline">\(\sigma()\)</span> <span class="math display">\[\begin{equation}
y=\sigma( x_{1} w_{1}+ x_{2} w_{2}+b)
\end{equation}\]</span></li>
</ol>
<p>This function is called activation function. The activation function is used to turn an unbounded input value into a bounded output value with a predictable range. A commonly used activation function is the <code>sigmoid function</code>.</p>
<p>For a single input dataset <span class="math inline">\(x\)</span> a more compact writing of the math above is</p>
<p><span class="math display">\[\begin{equation*}
\hat{y} = \sigma(w^{\rm T} x + b)\ .
\end{equation*}\]</span></p>
<p>Here <span class="math inline">\(\sigma\)</span> is the sigmoid function: <span class="math display">\[\begin{equation*}
\sigma(z) = \frac{1}{1+{\rm e}^{-z}}\ .
\end{equation*}\]</span></p>
<p>The sigmoid function is something we can already define and plot.</p>
<div id="5aae71bc" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> sigmoid(z):</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="dv">1</span><span class="op">/</span>(<span class="dv">1</span> <span class="op">+</span> np.exp(<span class="op">-</span>z))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="192f8bb1" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>x<span class="op">=</span>np.linspace(<span class="op">-</span><span class="dv">5</span>,<span class="dv">5</span>,<span class="dv">100</span>)</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">5</span>,<span class="dv">3</span>))</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>plt.plot(x,sigmoid(x))</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'input'</span>)</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'output'</span>)</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>plt.grid()</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="1_deep_learning_files/figure-html/cell-11-output-1.png" width="464" height="297" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>If we now have this kind of two input neuron with the weights <span class="math inline">\(w\)</span> and the bias value <span class="math inline">\(b\)</span></p>
<p><span class="math display">\[\begin{eqnarray}
w=[0,1]\\
b=4
\end{eqnarray}\]</span></p>
<p>we may supply and input</p>
<p><span class="math display">\[\begin{eqnarray}
x=[2,3]
\end{eqnarray}\]</span></p>
<p>which gives writing it a s a dot product</p>
<p><span class="math display">\[\begin{equation}
y=f(w\cdot x+b)=f(7)=0.999
\end{equation}\]</span></p>
<p>This procedure of propagating the input values to obtain and output value is called <strong>feedforward</strong> or <strong>forward propagation</strong>. Our first goal is now to create a network with a single neuron with 784 inputs (28 x 28), and a single sigmoid unit generating the output.</p>
<p>The above examples can be written and executed more efficiently in a vectorized form. Generating the output We‚Äôll vectorize by stacking examples side-by-side, so that our input matrix <span class="math inline">\(X\)</span> has an example in each column. The vectorized form of the forward pass is then</p>
<p><span class="math display">\[\begin{equation*}
\hat{y} = \sigma(w^{\rm T} X + b)\ .
\end{equation*}\]</span></p>
<p>Note that <span class="math inline">\(\hat{y}\)</span> is now a vector, not a scalar as it was in the previous equation.</p>
<p>In our code we will compute this in two stages: <code>Z = np.matmul(W.T, X) + b</code> and then <code>A = sigmoid(Z)</code> (<code>A</code> for Activation). Breaking things up into stages like this is just for clarity - It will make our forward pass computations mirror the steps in our backward propagation computation.</p>
</section>
<section id="loss-function" class="level3">
<h3 class="anchored" data-anchor-id="loss-function">Loss Function</h3>
<p>Since we have now data and we also know how to propagate (at least in principle) the input through the single neuron here, we also need to define a measure for how far the output deviates from the input. This measure is called <strong>loss</strong>. The many different ways of defining a suitable loss. The <code>mean squared error</code>, as it appeared already during our fitting lecture, could be a suitable loss function</p>
<p><span class="math display">\[\begin{equation}
MSE(y,\hat{y})=\frac{1}{n}\sum_{i=1}^{n}(y-\hat{y})^2
\end{equation}\]</span></p>
<p>for a number of <span class="math inline">\(n\)</span> datasets. Here <span class="math inline">\(\hat{y}\)</span> is the data that is predicted by the network and <span class="math inline">\(y\)</span> is the value which represents the so called ground truth, i.e.&nbsp;the data provided by the training set.</p>
<p>We will not use the mean squared error bu the <code>cross-entropy</code> for our loss function. The formula for a single training example (one input image) is:</p>
<p><span class="math display">\[\begin{equation*}
L(y,\hat{y}) = -y\log(\hat{y})-(1-y)\log(1-\hat{y})\ .
\end{equation*}\]</span></p>
<p>This error definition comes from the Shannon entropy definition, which you may look up in the web if you are interested. Averaging over a training set of <span class="math inline">\(m\)</span> examples we then have:</p>
<p><span class="math display">\[\begin{equation*}
L(Y,\hat{Y}) = -\frac{1}{m}\sum_{i = 0}^{m}y^{(i)}\log(\hat{y}^{(i)})-(1-y^{(i)})\log(1-\hat{y}^{(i)})\ .
\end{equation*}\]</span></p>
<p>In Python code, this looks like</p>
<div id="78b57e8d" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_loss(Y, Y_hat):</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>    m <span class="op">=</span> Y.shape[<span class="dv">1</span>]</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>    L <span class="op">=</span> <span class="op">-</span>(<span class="fl">1.</span><span class="op">/</span>m)<span class="op">*</span>(np.<span class="bu">sum</span>(np.multiply(np.log(Y_hat), Y)) <span class="op">+</span> np.<span class="bu">sum</span>(np.multiply(np.log(<span class="dv">1</span> <span class="op">-</span> Y_hat), (<span class="dv">1</span> <span class="op">-</span> Y))))</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> L</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="trainging-the-network" class="level2">
<h2 class="anchored" data-anchor-id="trainging-the-network">Trainging the Network</h2>
<p>The goal of all neural network training procedures is to minimize the loss and we have to find a way to minimize that loss. This is not so much different from our fitting of function values before.</p>
<section id="backward-propagation" class="level3">
<h3 class="anchored" data-anchor-id="backward-propagation">Backward Propagation</h3>
<p>The output of the network is determined by the input values and how we have distributed the weights <span class="math inline">\(w\)</span> and the biases <span class="math inline">\(b\)</span>. We can write the loss function therefore as a function of the weights and losses</p>
<p><span class="math display">\[
L(w_{1},w_{2},w_{3},\ldots ,b_{1},b_{2},b_{3},\ldots)
\]</span></p>
<p>To train the network, we would now try to find out, by how much the output values change if we do change a specific weight <span class="math inline">\(w_j\)</span>. This can be expressed by the partial derivative</p>
<p><span class="math display">\[
\frac{\partial L}{\partial w_j}
\]</span></p>
<p>We may then take a tiny step and correct the current value of <span class="math inline">\(w_j\)</span> such that the network yields a new output. This way back from the current output of the network and its current loss to a correction of the weights to yield a smaller loss is called <strong>back propagation</strong>.</p>
<p><strong>Calculating derivatives</strong></p>
<p>Focusing on a single input image will make it easier to derive the formulas we need. Holding all values except <span class="math inline">\(w_j\)</span> fixed, we can think of <span class="math inline">\(L\)</span> as being computed in three steps: <span class="math inline">\(w_j\rightarrow z \rightarrow \hat{y} \rightarrow L\)</span>. The formulas for these steps are: <span class="math display">\[\begin{align*}
z &amp;= w^{\rm T} x + b\ , \\
\hat{y} &amp;= \sigma(z)\ , \\
L(y,\hat{y}) &amp;= -y\log(\hat{y})-(1-y)\log(1-\hat{y})\ .
\end{align*}\]</span></p>
<p>The change of the loss function with the weights can then be split up by the chain rule into</p>
<p><span class="math display">\[\begin{align*}
\frac{\partial L}{\partial w_j} = \frac{\partial L}{\partial \hat{y}}\frac{\partial \hat{y}}{\partial z}\frac{\partial z}{\partial w_j}
\end{align*}\]</span> <br></p>
<p>There we have a product of three individual partial derivatives, which are a bit tedius to write down, but not to complicated. The read like</p>
<p><span class="math inline">\(\partial L/\partial\hat{y}\)</span>: <span class="math display">\[\begin{align*}
\frac{\partial L}{\partial\hat{y}} &amp;= \frac{\partial}{\partial\hat{y}}\left(-y\log(\hat{y})-(1-y)\log(1-\hat{y})\right) \\
&amp;= -y\frac{\partial}{\partial\hat{y}}\log(\hat{y})-(1-y)\frac{\partial}{\partial\hat{y}}\log(1-\hat{y}) \\
&amp;= -\frac{y}{\hat{y}} +\frac{(1 - y)}{1-\hat{y}} \\
&amp;= \frac{\hat{y} - y}{\hat{y}(1-\hat{y})}
\end{align*}\]</span></p>
<p><span class="math inline">\(\partial \hat{y}/\partial z\)</span>: <span class="math display">\[\begin{align*}
\frac{\partial }{\partial z}\sigma(z)
&amp;= \frac{\partial }{\partial z}\left(\frac{1}{1 + {\rm e}^{-z}}\right) \\
&amp;= \frac{1}{(1 + {\rm e}^{-z})^2}\frac{\partial }{\partial z}(1 + {\rm e}^{-z}) \\
&amp;= \frac{{\rm e}^{-z}}{(1 + {\rm e}^{-z})^2} \\
&amp;= \frac{1}{1 + {\rm e}^{-z}}\frac{{\rm e}^{-z}}{1 + {\rm e}^{-z}} \\
&amp;= \frac{1}{1 + {\rm e}^{-z}}\left(1 - \frac{1}{1 + {\rm e}^{-z}}\right) \\
&amp;= \sigma(z)(1-\sigma(z)) \\
&amp;= \hat{y}(1-\hat{y})
\end{align*}\]</span></p>
<p><span class="math inline">\(\partial z/\partial w_j\)</span>: <span class="math display">\[\begin{align*}
\frac{\partial }{\partial w_j}(w^{\rm T} x + b) &amp;= \frac{\partial }{\partial w_j}(w_0x_0 + \dots + w_nx_n + b) \\
&amp;= x_j
\end{align*}\]</span></p>
<p>Substituting back into the chain rule yields: <span class="math display">\[\begin{align*}
\frac{\partial L}{\partial w_j}
&amp;= \frac{\partial L}{\partial \hat{y}}\frac{\partial \hat{y}}{\partial z}\frac{\partial z}{\partial w_j} \\
&amp;= \frac{\hat{y} - y}{\hat{y}(1-\hat{y})}\hat{y}(1-\hat{y}) x_j \\
&amp;= (\hat{y} - y)x_j\ .
\end{align*}\]</span></p>
<p>which does not look that unfriendly anymore.</p>
<p>In vectorized form with <span class="math inline">\(m\)</span> training examples this gives us <span class="math display">\[\begin{align*}
\frac{\partial L}{\partial w} = \frac{1}{m} X(\hat{y} - y)^{\rm T}\ .
\end{align*}\]</span></p>
<p>A very similar derivation of <span class="math inline">\(\partial L/\partial b\)</span> yields, for a single example: <span class="math display">\[\begin{align*}
\frac{\partial L}{\partial b} = (\hat{y} - y)\ .
\end{align*}\]</span></p>
<p>In vectorized form we get <span class="math display">\[\begin{align*}
\frac{\partial L}{\partial b} = \frac{1}{m}\sum_{i=1}^{m}{(\hat{y}^{(i)} - y^{(i)})}\ .
\end{align*}\]</span></p>
<p>In our code we label these gradients according to their denominators, as <code>dW</code> and <code>db</code>. So for backpropagation we compute <code>dW = (1/m) * np.matmul(X, (A-Y).T)</code> and <code>db = (1/m)*np.sum(A-Y, axis=1, keepdims=True)</code>.</p>
</section>
<section id="stochastic-gradient-descent" class="level3">
<h3 class="anchored" data-anchor-id="stochastic-gradient-descent">Stochastic Gradient Descent</h3>
<p>We have all the tools we need to train a neural network now! We‚Äôll use an optimization algorithm called stochastic gradient descent (SGD) that tells us how to change our weights and biases to minimize loss. It is a simple umpdate of the weights and biases, which would read for the weights like</p>
<p><span class="math display">\[
w\leftarrow w-\eta\frac{\partial L}{\partial w}
\]</span></p>
<p>where <span class="math inline">\(\eta\)</span> is a constant called the learning rate that controls how fast we train. All we‚Äôre doing is subtracting <span class="math inline">\(\eta \partial L/\partial w\)</span> from <span class="math inline">\(w\)</span></p>
<ul>
<li>If <span class="math inline">\(\partial L/\partial w\)</span> is positive, <span class="math inline">\(w\)</span> will decrease, which makes L decrease.</li>
<li>If <span class="math inline">\(\partial L/\partial w\)</span> is negative, <span class="math inline">\(w\)</span> will increase, which makes L decrease.</li>
</ul>
<p>The equations look equivalent for the bias <span class="math inline">\(b\)</span>. Our back propagation procedure will do that for as many steps we want, i.e.&nbsp;until we feel that the output is close enough to the ground truth. Each back propagation step is called and <code>epoch</code>.</p>
</section>
<section id="build-an-train" class="level3">
<h3 class="anchored" data-anchor-id="build-an-train">Build an Train</h3>
<p>Now we have all things together to create a single neuron network doing the analysis of the MNIST numbers. This type of data processing is called logistic regression based on the sigmoid function, which is a logistic function. So let‚Äôs create all in python code and train the network for 100 epochs.</p>
<div id="9626d6a7" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>learning_rate <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.array(X_train)</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>Y <span class="op">=</span> np.array(y_train)</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>n_x <span class="op">=</span> X.shape[<span class="dv">0</span>]</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>m <span class="op">=</span> X.shape[<span class="dv">1</span>]</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>W <span class="op">=</span> np.random.randn(n_x, <span class="dv">1</span>) <span class="op">*</span> <span class="fl">0.01</span></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> np.zeros((<span class="dv">1</span>, <span class="dv">1</span>))</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">200</span>):</span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>    Z <span class="op">=</span> np.matmul(W.T, X) <span class="op">+</span> b</span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>    A <span class="op">=</span> sigmoid(Z)</span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> compute_loss(Y, A)</span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a>    dW <span class="op">=</span> (<span class="dv">1</span><span class="op">/</span>m)<span class="op">*</span>np.matmul(X, (A<span class="op">-</span>Y).T)</span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a>    db <span class="op">=</span> (<span class="dv">1</span><span class="op">/</span>m)<span class="op">*</span>np.<span class="bu">sum</span>(A<span class="op">-</span>Y, axis<span class="op">=</span><span class="dv">1</span>, keepdims<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a>    W <span class="op">=</span> W <span class="op">-</span> learning_rate <span class="op">*</span> dW</span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a>    b <span class="op">=</span> b <span class="op">-</span> learning_rate <span class="op">*</span> db</span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> i <span class="op">%</span> <span class="dv">10</span> <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb14-25"><a href="#cb14-25" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"Epoch"</span>, i, <span class="st">" loss: "</span>, loss)</span>
<span id="cb14-26"><a href="#cb14-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-27"><a href="#cb14-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Final loss:"</span>, loss)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 0  loss:  0.7471125121616977
Epoch 10  loss:  0.07308269582929021
Epoch 20  loss:  0.061318323546277226</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/var/folders/t4/_9qps8wj56jc60nwkr3nrcr00000gn/T/ipykernel_44637/1534748172.py:13: RuntimeWarning: divide by zero encountered in matmul
  Z = np.matmul(W.T, X) + b
/var/folders/t4/_9qps8wj56jc60nwkr3nrcr00000gn/T/ipykernel_44637/1534748172.py:13: RuntimeWarning: overflow encountered in matmul
  Z = np.matmul(W.T, X) + b
/var/folders/t4/_9qps8wj56jc60nwkr3nrcr00000gn/T/ipykernel_44637/1534748172.py:13: RuntimeWarning: invalid value encountered in matmul
  Z = np.matmul(W.T, X) + b
/var/folders/t4/_9qps8wj56jc60nwkr3nrcr00000gn/T/ipykernel_44637/1534748172.py:18: RuntimeWarning: divide by zero encountered in matmul
  dW = (1/m)*np.matmul(X, (A-Y).T)
/var/folders/t4/_9qps8wj56jc60nwkr3nrcr00000gn/T/ipykernel_44637/1534748172.py:18: RuntimeWarning: overflow encountered in matmul
  dW = (1/m)*np.matmul(X, (A-Y).T)
/var/folders/t4/_9qps8wj56jc60nwkr3nrcr00000gn/T/ipykernel_44637/1534748172.py:18: RuntimeWarning: invalid value encountered in matmul
  dW = (1/m)*np.matmul(X, (A-Y).T)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 30  loss:  0.055230119812005714
Epoch 40  loss:  0.051324320236142515
Epoch 50  loss:  0.048540041963711845
Epoch 60  loss:  0.04642485272904433
Epoch 70  loss:  0.04474722082574825
Epoch 80  loss:  0.043374333931969114
Epoch 90  loss:  0.04222371551840797
Epoch 100  loss:  0.041241045998320916
Epoch 110  loss:  0.040388886511106684
Epoch 120  loss:  0.03964048057966332
Epoch 130  loss:  0.0389761317586134
Epoch 140  loss:  0.03838097920656846
Epoch 150  loss:  0.03784357458020544
Epoch 160  loss:  0.037354939644815115
Epoch 170  loss:  0.03690792357698068
Epoch 180  loss:  0.03649675336766015
Epoch 190  loss:  0.03611671225524699
Final loss: 0.03579805734492837</code></pre>
</div>
</div>
<p>We do not really now how to judge the quality of our trained network. At least we saw that the loss is decreasing, which is good. We may judge the quality of our trained network by calculating the so-called <strong>confusion matrix</strong>. The confusion matrix is creating a matrix giving reports the actual values in the rows and the predicted values in the columns.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="confusion_matrix.png" class="img-fluid figure-img"></p>
<figcaption>confusion_matrix</figcaption>
</figure>
</div>
<p>The entries in the matrix are called <strong>true positives</strong> (TP), <strong>false positives</strong> (FP), <strong>false negatives</strong> (FN), and <strong>true negatives</strong> (TN). Fortunately we can use a method of the <code>sklearn</code> module to calculate the confusion matrix. We just have to supply the predictions and the actual labels to it. To do so, we use the testing data set <code>X_test</code> which we have splitted earlier.</p>
<div id="830fe466" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix, classification_report</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>Z <span class="op">=</span> np.matmul(W.T,X_test) <span class="op">+</span> b</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>A <span class="op">=</span> sigmoid(Z)</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>predictions <span class="op">=</span> (A<span class="op">&gt;</span><span class="fl">.5</span>)[<span class="dv">0</span>,:]</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> (y_test <span class="op">==</span> <span class="dv">1</span>)[<span class="dv">0</span>,:]</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(confusion_matrix(predictions, labels))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[[8973   33]
 [  47  947]]</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/var/folders/t4/_9qps8wj56jc60nwkr3nrcr00000gn/T/ipykernel_44637/2374582204.py:3: RuntimeWarning: divide by zero encountered in matmul
  Z = np.matmul(W.T,X_test) + b
/var/folders/t4/_9qps8wj56jc60nwkr3nrcr00000gn/T/ipykernel_44637/2374582204.py:3: RuntimeWarning: overflow encountered in matmul
  Z = np.matmul(W.T,X_test) + b
/var/folders/t4/_9qps8wj56jc60nwkr3nrcr00000gn/T/ipykernel_44637/2374582204.py:3: RuntimeWarning: invalid value encountered in matmul
  Z = np.matmul(W.T,X_test) + b</code></pre>
</div>
</div>
<div id="1577e06a" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(predictions, labels))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>              precision    recall  f1-score   support

       False       0.99      1.00      1.00      9006
        True       0.97      0.95      0.96       994

    accuracy                           0.99     10000
   macro avg       0.98      0.97      0.98     10000
weighted avg       0.99      0.99      0.99     10000
</code></pre>
</div>
</div>
</section>
<section id="testing-our-model" class="level3">
<h3 class="anchored" data-anchor-id="testing-our-model">Testing our model</h3>
<p>We can check a single image of our testing data with the following line. If the output number is bigger than 0.5, our number is likely a 0.</p>
<div id="9903ef17" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>i<span class="op">=</span><span class="dv">200</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="bu">bool</span>(sigmoid(np.matmul(W.T, np.array(X_test)[:,i])<span class="op">+</span>b)<span class="op">&gt;</span><span class="fl">0.5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="15">
<pre><code>False</code></pre>
</div>
</div>
<div id="9a10cb6f" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>plt.imshow(np.array(X_test)[:,i].reshape(<span class="dv">28</span>,<span class="dv">28</span>),cmap<span class="op">=</span><span class="st">'gray'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="1_deep_learning_files/figure-html/cell-17-output-1.png" width="424" height="420" class="figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="network-with-hidden-layers" class="level2">
<h2 class="anchored" data-anchor-id="network-with-hidden-layers">Network with Hidden Layers</h2>
<p>In our example above, we just had an input layer and a single output neuron. More complex neural networks are containing many layers between the input layer and the output layer. These inbetween layers are called hidden layers. Here is a simple example of a neural network with a single hidden layer.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="image.png" class="img-fluid figure-img"></p>
<figcaption>hidden</figcaption>
</figure>
</div>
<p>So we have now and input layer with 784 inputs that are connected to 64 units in the hidden layer and 1 neuron in the output layer. We will not go through the derivations of all the formulas for the forward and backward passes this time. The code is a simple extension of what we did before and I hope easy to read.</p>
<div id="bbad6eba" class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> X_train</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>Y <span class="op">=</span> y_train</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>n_x <span class="op">=</span> X.shape[<span class="dv">0</span>]</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>n_h <span class="op">=</span> <span class="dv">64</span></span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>learning_rate <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a>W1 <span class="op">=</span> np.random.randn(n_h, n_x)</span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a>b1 <span class="op">=</span> np.zeros((n_h, <span class="dv">1</span>))</span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a>W2 <span class="op">=</span> np.random.randn(<span class="dv">1</span>, n_h)</span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a>b2 <span class="op">=</span> np.zeros((<span class="dv">1</span>, <span class="dv">1</span>))</span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-13"><a href="#cb26-13" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">100</span>):</span>
<span id="cb26-14"><a href="#cb26-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-15"><a href="#cb26-15" aria-hidden="true" tabindex="-1"></a>    Z1 <span class="op">=</span> np.matmul(W1, X) <span class="op">+</span> b1</span>
<span id="cb26-16"><a href="#cb26-16" aria-hidden="true" tabindex="-1"></a>    A1 <span class="op">=</span> sigmoid(Z1)</span>
<span id="cb26-17"><a href="#cb26-17" aria-hidden="true" tabindex="-1"></a>    Z2 <span class="op">=</span> np.matmul(W2, A1) <span class="op">+</span> b2</span>
<span id="cb26-18"><a href="#cb26-18" aria-hidden="true" tabindex="-1"></a>    A2 <span class="op">=</span> sigmoid(Z2)</span>
<span id="cb26-19"><a href="#cb26-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-20"><a href="#cb26-20" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> compute_loss(Y, A2)</span>
<span id="cb26-21"><a href="#cb26-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-22"><a href="#cb26-22" aria-hidden="true" tabindex="-1"></a>    dZ2 <span class="op">=</span> A2<span class="op">-</span>Y</span>
<span id="cb26-23"><a href="#cb26-23" aria-hidden="true" tabindex="-1"></a>    dW2 <span class="op">=</span> (<span class="fl">1.</span><span class="op">/</span>m) <span class="op">*</span> np.matmul(dZ2, A1.T)</span>
<span id="cb26-24"><a href="#cb26-24" aria-hidden="true" tabindex="-1"></a>    db2 <span class="op">=</span> (<span class="fl">1.</span><span class="op">/</span>m) <span class="op">*</span> np.<span class="bu">sum</span>(dZ2, axis<span class="op">=</span><span class="dv">1</span>, keepdims<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb26-25"><a href="#cb26-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-26"><a href="#cb26-26" aria-hidden="true" tabindex="-1"></a>    dA1 <span class="op">=</span> np.matmul(W2.T, dZ2)</span>
<span id="cb26-27"><a href="#cb26-27" aria-hidden="true" tabindex="-1"></a>    dZ1 <span class="op">=</span> dA1 <span class="op">*</span> sigmoid(Z1) <span class="op">*</span> (<span class="dv">1</span> <span class="op">-</span> sigmoid(Z1))</span>
<span id="cb26-28"><a href="#cb26-28" aria-hidden="true" tabindex="-1"></a>    dW1 <span class="op">=</span> (<span class="fl">1.</span><span class="op">/</span>m) <span class="op">*</span> np.matmul(dZ1, X.T)</span>
<span id="cb26-29"><a href="#cb26-29" aria-hidden="true" tabindex="-1"></a>    db1 <span class="op">=</span> (<span class="fl">1.</span><span class="op">/</span>m) <span class="op">*</span> np.<span class="bu">sum</span>(dZ1, axis<span class="op">=</span><span class="dv">1</span>, keepdims<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb26-30"><a href="#cb26-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-31"><a href="#cb26-31" aria-hidden="true" tabindex="-1"></a>    W2 <span class="op">=</span> W2 <span class="op">-</span> learning_rate <span class="op">*</span> dW2</span>
<span id="cb26-32"><a href="#cb26-32" aria-hidden="true" tabindex="-1"></a>    b2 <span class="op">=</span> b2 <span class="op">-</span> learning_rate <span class="op">*</span> db2</span>
<span id="cb26-33"><a href="#cb26-33" aria-hidden="true" tabindex="-1"></a>    W1 <span class="op">=</span> W1 <span class="op">-</span> learning_rate <span class="op">*</span> dW1</span>
<span id="cb26-34"><a href="#cb26-34" aria-hidden="true" tabindex="-1"></a>    b1 <span class="op">=</span> b1 <span class="op">-</span> learning_rate <span class="op">*</span> db1</span>
<span id="cb26-35"><a href="#cb26-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-36"><a href="#cb26-36" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> i <span class="op">%</span> <span class="dv">10</span> <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb26-37"><a href="#cb26-37" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"Epoch"</span>, i, <span class="st">"loss: "</span>, loss)</span>
<span id="cb26-38"><a href="#cb26-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-39"><a href="#cb26-39" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Final loss:"</span>, loss)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/var/folders/t4/_9qps8wj56jc60nwkr3nrcr00000gn/T/ipykernel_44637/1376930165.py:15: RuntimeWarning: divide by zero encountered in matmul
  Z1 = np.matmul(W1, X) + b1
/var/folders/t4/_9qps8wj56jc60nwkr3nrcr00000gn/T/ipykernel_44637/1376930165.py:15: RuntimeWarning: overflow encountered in matmul
  Z1 = np.matmul(W1, X) + b1
/var/folders/t4/_9qps8wj56jc60nwkr3nrcr00000gn/T/ipykernel_44637/1376930165.py:15: RuntimeWarning: invalid value encountered in matmul
  Z1 = np.matmul(W1, X) + b1
/var/folders/t4/_9qps8wj56jc60nwkr3nrcr00000gn/T/ipykernel_44637/1376930165.py:17: RuntimeWarning: divide by zero encountered in matmul
  Z2 = np.matmul(W2, A1) + b2
/var/folders/t4/_9qps8wj56jc60nwkr3nrcr00000gn/T/ipykernel_44637/1376930165.py:17: RuntimeWarning: overflow encountered in matmul
  Z2 = np.matmul(W2, A1) + b2
/var/folders/t4/_9qps8wj56jc60nwkr3nrcr00000gn/T/ipykernel_44637/1376930165.py:17: RuntimeWarning: invalid value encountered in matmul
  Z2 = np.matmul(W2, A1) + b2
/var/folders/t4/_9qps8wj56jc60nwkr3nrcr00000gn/T/ipykernel_44637/1376930165.py:23: RuntimeWarning: divide by zero encountered in matmul
  dW2 = (1./m) * np.matmul(dZ2, A1.T)
/var/folders/t4/_9qps8wj56jc60nwkr3nrcr00000gn/T/ipykernel_44637/1376930165.py:23: RuntimeWarning: overflow encountered in matmul
  dW2 = (1./m) * np.matmul(dZ2, A1.T)
/var/folders/t4/_9qps8wj56jc60nwkr3nrcr00000gn/T/ipykernel_44637/1376930165.py:23: RuntimeWarning: invalid value encountered in matmul
  dW2 = (1./m) * np.matmul(dZ2, A1.T)
/var/folders/t4/_9qps8wj56jc60nwkr3nrcr00000gn/T/ipykernel_44637/1376930165.py:28: RuntimeWarning: divide by zero encountered in matmul
  dW1 = (1./m) * np.matmul(dZ1, X.T)
/var/folders/t4/_9qps8wj56jc60nwkr3nrcr00000gn/T/ipykernel_44637/1376930165.py:28: RuntimeWarning: overflow encountered in matmul
  dW1 = (1./m) * np.matmul(dZ1, X.T)
/var/folders/t4/_9qps8wj56jc60nwkr3nrcr00000gn/T/ipykernel_44637/1376930165.py:28: RuntimeWarning: invalid value encountered in matmul
  dW1 = (1./m) * np.matmul(dZ1, X.T)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 0 loss:  2.395166635058746
Epoch 10 loss:  0.22074168759268956
Epoch 20 loss:  0.1660154822272753
Epoch 30 loss:  0.13990677867922954
Epoch 40 loss:  0.12390102523919129
Epoch 50 loss:  0.11269161497108851
Epoch 60 loss:  0.10421329497723458
Epoch 70 loss:  0.09747959072905935
Epoch 80 loss:  0.09194898313097832
Epoch 90 loss:  0.0872943606401609
Final loss: 0.08367740628296327</code></pre>
</div>
</div>
<p>To judge the newtork quality we do use again the confusion matrix.</p>
<div id="6347bc6a" class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>Z1 <span class="op">=</span> np.matmul(W1, X_test) <span class="op">+</span> b1</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>A1 <span class="op">=</span> sigmoid(Z1)</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>Z2 <span class="op">=</span> np.matmul(W2, A1) <span class="op">+</span> b2</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>A2 <span class="op">=</span> sigmoid(Z2)</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>predictions <span class="op">=</span> (A2<span class="op">&gt;</span><span class="fl">.5</span>)[<span class="dv">0</span>,:]</span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> (y_test <span class="op">==</span> <span class="dv">1</span>)[<span class="dv">0</span>,:]</span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(confusion_matrix(predictions, labels))</span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(predictions, labels))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[[8905  178]
 [ 115  802]]
              precision    recall  f1-score   support

       False       0.99      0.98      0.98      9083
        True       0.82      0.87      0.85       917

    accuracy                           0.97     10000
   macro avg       0.90      0.93      0.91     10000
weighted avg       0.97      0.97      0.97     10000
</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/var/folders/t4/_9qps8wj56jc60nwkr3nrcr00000gn/T/ipykernel_44637/3572825488.py:1: RuntimeWarning: divide by zero encountered in matmul
  Z1 = np.matmul(W1, X_test) + b1
/var/folders/t4/_9qps8wj56jc60nwkr3nrcr00000gn/T/ipykernel_44637/3572825488.py:1: RuntimeWarning: overflow encountered in matmul
  Z1 = np.matmul(W1, X_test) + b1
/var/folders/t4/_9qps8wj56jc60nwkr3nrcr00000gn/T/ipykernel_44637/3572825488.py:1: RuntimeWarning: invalid value encountered in matmul
  Z1 = np.matmul(W1, X_test) + b1
/var/folders/t4/_9qps8wj56jc60nwkr3nrcr00000gn/T/ipykernel_44637/3572825488.py:3: RuntimeWarning: divide by zero encountered in matmul
  Z2 = np.matmul(W2, A1) + b2
/var/folders/t4/_9qps8wj56jc60nwkr3nrcr00000gn/T/ipykernel_44637/3572825488.py:3: RuntimeWarning: overflow encountered in matmul
  Z2 = np.matmul(W2, A1) + b2
/var/folders/t4/_9qps8wj56jc60nwkr3nrcr00000gn/T/ipykernel_44637/3572825488.py:3: RuntimeWarning: invalid value encountered in matmul
  Z2 = np.matmul(W2, A1) + b2</code></pre>
</div>
</div>
</section>
<section id="multiclass-network" class="level2">
<h2 class="anchored" data-anchor-id="multiclass-network">Multiclass Network</h2>
<p>So far we did only classify if the number we feed to the network is just a 0 or not. We would like to recognize the different number now and therefore need a multiclass network. Each number is then a class and per class, we have multiple realizations of handwritten numbers. We therefore have to create an output layer, which is not only containing a single neuron, but 10 neurons. Each of these neuron can output a value between 0 and 1. Whenever the output is 1, the index of the neuron represents the number predicted.</p>
<p>The output array</p>
<pre><code>[0,1,0,0,0,0,0,0,0,0]</code></pre>
<p>would therefore correspond to the value 1.</p>
<p>For this purpose, we need to reload the right labels.</p>
<div id="45e60d50" class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> fetch_openml</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> fetch_openml(<span class="st">'mnist_784'</span>, version<span class="op">=</span><span class="dv">1</span>, return_X_y<span class="op">=</span><span class="va">True</span>,as_frame<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> X <span class="op">/</span> <span class="dv">255</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Then we‚Äôll one-hot encode MNIST‚Äôs labels, to get a 10 x 70,000 array.</p>
<div id="679b393c" class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>digits <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>examples <span class="op">=</span> y.shape[<span class="dv">0</span>]</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> y.reshape(<span class="dv">1</span>, examples)</span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a>Y_new <span class="op">=</span> np.eye(digits)[y.astype(<span class="st">'int32'</span>)]</span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a>Y_new <span class="op">=</span> Y_new.T.reshape(digits, examples)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="86904c27" class="cell" data-tags="[]" data-execution_count="21">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>Y_new.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="21">
<pre><code>(10, 70000)</code></pre>
</div>
</div>
<p>We also seperate into trainging and testing data</p>
<div id="765a485a" class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>m <span class="op">=</span> <span class="dv">60000</span></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>m_test <span class="op">=</span> X.shape[<span class="dv">0</span>] <span class="op">-</span> m</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a>X_train, X_test <span class="op">=</span> X[:m].T, X[m:].T</span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a>Y_train, Y_test <span class="op">=</span> Y_new[:,:m], Y_new[:,m:]</span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a>shuffle_index <span class="op">=</span> np.random.permutation(m)</span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a>X_train, Y_train <span class="op">=</span> X_train[:, shuffle_index], Y_train[:, shuffle_index]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="16c27cff" class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>i <span class="op">=</span> <span class="dv">58</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>plt.imshow(X_train[:,i].reshape(<span class="dv">28</span>,<span class="dv">28</span>), cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>plt.colorbar()</span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a>Y_train[:,i]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="1_deep_learning_files/figure-html/cell-24-output-1.png" width="511" height="426" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display" data-execution_count="23">
<pre><code>array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])</code></pre>
</div>
</div>
<section id="changes-to-the-model" class="level3">
<h3 class="anchored" data-anchor-id="changes-to-the-model">Changes to the model</h3>
<p>OK, so let‚Äôs consider what changes we need to make to the model itself.</p>
<section id="forward-pass" class="level4">
<h4 class="anchored" data-anchor-id="forward-pass">Forward Pass</h4>
<p>Only the last layer of our network is changing. To add the softmax, we have to replace our lone, final node with a 10 unit layer. Its final activations are the exponentials of its z-values, normalized across all ten such exponentials. So instead of just computing <span class="math inline">\(\sigma(z)\)</span>, we compute the activation for each unit <span class="math inline">\(i\)</span> using the softmax function: <span class="math display">\[\begin{align*}
\sigma(z)_i = \frac{{\rm e}^{z_i}}{\sum_{j=0}^9{\rm e}^{z_i}}\ .
\end{align*}\]</span></p>
<p>So, in our vectorized code, the last line of forward propagation will be <code>A2 = np.exp(Z2) / np.sum(np.exp(Z2), axis=0)</code>.</p>
</section>
<section id="loss-function-1" class="level4">
<h4 class="anchored" data-anchor-id="loss-function-1">Loss Function</h4>
<p>Our loss function now has to generalize to more than two classes. The general formula for <span class="math inline">\(n\)</span> classes is: <span class="math display">\[\begin{align*}
L(y,\hat{y}) = -\sum_{i=0}^n y_i\log(\hat{y}_i)\ .
\end{align*}\]</span> Averaging over <span class="math inline">\(m\)</span> training examples this becomes: <span class="math display">\[\begin{align*}
L(y,\hat{y}) = -\frac{1}{m}\sum_{j=0}^m\sum_{i=0}^n y_i^{(i)}\log(\hat{y}_i^{(i)})\ .
\end{align*}\]</span></p>
<p>So let‚Äôs define:</p>
<div id="555140f2" class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_multiclass_loss(Y, Y_hat):</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>    L_sum <span class="op">=</span> np.<span class="bu">sum</span>(np.multiply(Y, np.log(Y_hat)))</span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>    m <span class="op">=</span> Y.shape[<span class="dv">1</span>]</span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a>    L <span class="op">=</span> <span class="op">-</span>(<span class="dv">1</span><span class="op">/</span>m) <span class="op">*</span> L_sum</span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> L</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="back-propagation" class="level4">
<h4 class="anchored" data-anchor-id="back-propagation">Back Propagation</h4>
<p>Luckily it turns out that back propagation isn‚Äôt really affected by the switch to a softmax. A softmax generalizes the sigmoid activiation we‚Äôve been using, and in such a way that the code we wrote earlier still works. We could verify this by deriving: <span class="math display">\[\begin{align*}
\frac{\partial L}{\partial z_i} = \hat{y}_i - y_i\ .
\end{align*}\]</span></p>
<p>But we won‚Äôt walk through the steps here. Let‚Äôs just go ahead and build our final network.</p>
</section>
</section>
<section id="build-and-train" class="level3">
<h3 class="anchored" data-anchor-id="build-and-train">Build and Train</h3>
<p>As we have now more weights and classes, the training takes longer and we actually need also more episodes to achieve a good accuracy.</p>
<div id="b48cd21e" class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>n_x <span class="op">=</span> X_train.shape[<span class="dv">0</span>]</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>n_h <span class="op">=</span> <span class="dv">64</span></span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>learning_rate <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a>W1 <span class="op">=</span> np.random.randn(n_h, n_x)</span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a>b1 <span class="op">=</span> np.zeros((n_h, <span class="dv">1</span>))</span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a>W2 <span class="op">=</span> np.random.randn(digits, n_h)</span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a>b2 <span class="op">=</span> np.zeros((digits, <span class="dv">1</span>))</span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-10"><a href="#cb41-10" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> X_train</span>
<span id="cb41-11"><a href="#cb41-11" aria-hidden="true" tabindex="-1"></a>Y <span class="op">=</span> Y_train</span>
<span id="cb41-12"><a href="#cb41-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-13"><a href="#cb41-13" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">200</span>):</span>
<span id="cb41-14"><a href="#cb41-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-15"><a href="#cb41-15" aria-hidden="true" tabindex="-1"></a>    Z1 <span class="op">=</span> np.matmul(W1,X) <span class="op">+</span> b1</span>
<span id="cb41-16"><a href="#cb41-16" aria-hidden="true" tabindex="-1"></a>    A1 <span class="op">=</span> sigmoid(Z1)</span>
<span id="cb41-17"><a href="#cb41-17" aria-hidden="true" tabindex="-1"></a>    Z2 <span class="op">=</span> np.matmul(W2,A1) <span class="op">+</span> b2</span>
<span id="cb41-18"><a href="#cb41-18" aria-hidden="true" tabindex="-1"></a>    A2 <span class="op">=</span> np.exp(Z2) <span class="op">/</span> np.<span class="bu">sum</span>(np.exp(Z2), axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb41-19"><a href="#cb41-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-20"><a href="#cb41-20" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> compute_multiclass_loss(Y, A2)</span>
<span id="cb41-21"><a href="#cb41-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-22"><a href="#cb41-22" aria-hidden="true" tabindex="-1"></a>    dZ2 <span class="op">=</span> A2<span class="op">-</span>Y</span>
<span id="cb41-23"><a href="#cb41-23" aria-hidden="true" tabindex="-1"></a>    dW2 <span class="op">=</span> (<span class="fl">1.</span><span class="op">/</span>m) <span class="op">*</span> np.matmul(dZ2, A1.T)</span>
<span id="cb41-24"><a href="#cb41-24" aria-hidden="true" tabindex="-1"></a>    db2 <span class="op">=</span> (<span class="fl">1.</span><span class="op">/</span>m) <span class="op">*</span> np.<span class="bu">sum</span>(dZ2, axis<span class="op">=</span><span class="dv">1</span>, keepdims<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb41-25"><a href="#cb41-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-26"><a href="#cb41-26" aria-hidden="true" tabindex="-1"></a>    dA1 <span class="op">=</span> np.matmul(W2.T, dZ2)</span>
<span id="cb41-27"><a href="#cb41-27" aria-hidden="true" tabindex="-1"></a>    dZ1 <span class="op">=</span> dA1 <span class="op">*</span> sigmoid(Z1) <span class="op">*</span> (<span class="dv">1</span> <span class="op">-</span> sigmoid(Z1))</span>
<span id="cb41-28"><a href="#cb41-28" aria-hidden="true" tabindex="-1"></a>    dW1 <span class="op">=</span> (<span class="fl">1.</span><span class="op">/</span>m) <span class="op">*</span> np.matmul(dZ1, X.T)</span>
<span id="cb41-29"><a href="#cb41-29" aria-hidden="true" tabindex="-1"></a>    db1 <span class="op">=</span> (<span class="fl">1.</span><span class="op">/</span>m) <span class="op">*</span> np.<span class="bu">sum</span>(dZ1, axis<span class="op">=</span><span class="dv">1</span>, keepdims<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb41-30"><a href="#cb41-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-31"><a href="#cb41-31" aria-hidden="true" tabindex="-1"></a>    W2 <span class="op">=</span> W2 <span class="op">-</span> learning_rate <span class="op">*</span> dW2</span>
<span id="cb41-32"><a href="#cb41-32" aria-hidden="true" tabindex="-1"></a>    b2 <span class="op">=</span> b2 <span class="op">-</span> learning_rate <span class="op">*</span> db2</span>
<span id="cb41-33"><a href="#cb41-33" aria-hidden="true" tabindex="-1"></a>    W1 <span class="op">=</span> W1 <span class="op">-</span> learning_rate <span class="op">*</span> dW1</span>
<span id="cb41-34"><a href="#cb41-34" aria-hidden="true" tabindex="-1"></a>    b1 <span class="op">=</span> b1 <span class="op">-</span> learning_rate <span class="op">*</span> db1</span>
<span id="cb41-35"><a href="#cb41-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-36"><a href="#cb41-36" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (i <span class="op">%</span> <span class="dv">10</span> <span class="op">==</span> <span class="dv">0</span>):</span>
<span id="cb41-37"><a href="#cb41-37" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"Epoch"</span>, i, <span class="st">"loss: "</span>, loss)</span>
<span id="cb41-38"><a href="#cb41-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-39"><a href="#cb41-39" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Final loss:"</span>, loss)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/var/folders/t4/_9qps8wj56jc60nwkr3nrcr00000gn/T/ipykernel_44637/1725216505.py:15: RuntimeWarning: divide by zero encountered in matmul
  Z1 = np.matmul(W1,X) + b1
/var/folders/t4/_9qps8wj56jc60nwkr3nrcr00000gn/T/ipykernel_44637/1725216505.py:15: RuntimeWarning: overflow encountered in matmul
  Z1 = np.matmul(W1,X) + b1
/var/folders/t4/_9qps8wj56jc60nwkr3nrcr00000gn/T/ipykernel_44637/1725216505.py:15: RuntimeWarning: invalid value encountered in matmul
  Z1 = np.matmul(W1,X) + b1
/var/folders/t4/_9qps8wj56jc60nwkr3nrcr00000gn/T/ipykernel_44637/1725216505.py:17: RuntimeWarning: divide by zero encountered in matmul
  Z2 = np.matmul(W2,A1) + b2
/var/folders/t4/_9qps8wj56jc60nwkr3nrcr00000gn/T/ipykernel_44637/1725216505.py:17: RuntimeWarning: overflow encountered in matmul
  Z2 = np.matmul(W2,A1) + b2
/var/folders/t4/_9qps8wj56jc60nwkr3nrcr00000gn/T/ipykernel_44637/1725216505.py:17: RuntimeWarning: invalid value encountered in matmul
  Z2 = np.matmul(W2,A1) + b2
/var/folders/t4/_9qps8wj56jc60nwkr3nrcr00000gn/T/ipykernel_44637/1725216505.py:23: RuntimeWarning: divide by zero encountered in matmul
  dW2 = (1./m) * np.matmul(dZ2, A1.T)
/var/folders/t4/_9qps8wj56jc60nwkr3nrcr00000gn/T/ipykernel_44637/1725216505.py:23: RuntimeWarning: overflow encountered in matmul
  dW2 = (1./m) * np.matmul(dZ2, A1.T)
/var/folders/t4/_9qps8wj56jc60nwkr3nrcr00000gn/T/ipykernel_44637/1725216505.py:23: RuntimeWarning: invalid value encountered in matmul
  dW2 = (1./m) * np.matmul(dZ2, A1.T)
/var/folders/t4/_9qps8wj56jc60nwkr3nrcr00000gn/T/ipykernel_44637/1725216505.py:26: RuntimeWarning: divide by zero encountered in matmul
  dA1 = np.matmul(W2.T, dZ2)
/var/folders/t4/_9qps8wj56jc60nwkr3nrcr00000gn/T/ipykernel_44637/1725216505.py:26: RuntimeWarning: overflow encountered in matmul
  dA1 = np.matmul(W2.T, dZ2)
/var/folders/t4/_9qps8wj56jc60nwkr3nrcr00000gn/T/ipykernel_44637/1725216505.py:26: RuntimeWarning: invalid value encountered in matmul
  dA1 = np.matmul(W2.T, dZ2)
/var/folders/t4/_9qps8wj56jc60nwkr3nrcr00000gn/T/ipykernel_44637/1725216505.py:28: RuntimeWarning: divide by zero encountered in matmul
  dW1 = (1./m) * np.matmul(dZ1, X.T)
/var/folders/t4/_9qps8wj56jc60nwkr3nrcr00000gn/T/ipykernel_44637/1725216505.py:28: RuntimeWarning: overflow encountered in matmul
  dW1 = (1./m) * np.matmul(dZ1, X.T)
/var/folders/t4/_9qps8wj56jc60nwkr3nrcr00000gn/T/ipykernel_44637/1725216505.py:28: RuntimeWarning: invalid value encountered in matmul
  dW1 = (1./m) * np.matmul(dZ1, X.T)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 0 loss:  9.359409945262724
Epoch 10 loss:  2.480915410750769
Epoch 20 loss:  1.6744327642277674
Epoch 30 loss:  1.3330104308788544
Epoch 40 loss:  1.1447842302497118
Epoch 50 loss:  1.0230964725181804
Epoch 60 loss:  0.9368747323694274
Epoch 70 loss:  0.8719573894048428
Epoch 80 loss:  0.8208795576102073
Epoch 90 loss:  0.7793325725168159
Epoch 100 loss:  0.7446649543545801
Epoch 110 loss:  0.7151537041535515
Epoch 120 loss:  0.6896258244540622
Epoch 130 loss:  0.6672519100025255
Epoch 140 loss:  0.6474268213495037
Epoch 150 loss:  0.6296970416913454
Epoch 160 loss:  0.6137147676333654
Epoch 170 loss:  0.5992079750548168
Epoch 180 loss:  0.5859603076597459
Epoch 190 loss:  0.5737971945414018
Final loss: 0.5636592880338956</code></pre>
</div>
</div>
<p>Let‚Äôs see how we did:</p>
<div id="a461ad41" class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a>Z1 <span class="op">=</span> np.matmul(W1, X_test) <span class="op">+</span> b1</span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>A1 <span class="op">=</span> sigmoid(Z1)</span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a>Z2 <span class="op">=</span> np.matmul(W2, A1) <span class="op">+</span> b2</span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a>A2 <span class="op">=</span> np.exp(Z2) <span class="op">/</span> np.<span class="bu">sum</span>(np.exp(Z2), axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-6"><a href="#cb44-6" aria-hidden="true" tabindex="-1"></a>predictions <span class="op">=</span> np.argmax(A2, axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb44-7"><a href="#cb44-7" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> np.argmax(Y_test, axis<span class="op">=</span><span class="dv">0</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/var/folders/t4/_9qps8wj56jc60nwkr3nrcr00000gn/T/ipykernel_44637/3032217627.py:1: RuntimeWarning: divide by zero encountered in matmul
  Z1 = np.matmul(W1, X_test) + b1
/var/folders/t4/_9qps8wj56jc60nwkr3nrcr00000gn/T/ipykernel_44637/3032217627.py:1: RuntimeWarning: overflow encountered in matmul
  Z1 = np.matmul(W1, X_test) + b1
/var/folders/t4/_9qps8wj56jc60nwkr3nrcr00000gn/T/ipykernel_44637/3032217627.py:1: RuntimeWarning: invalid value encountered in matmul
  Z1 = np.matmul(W1, X_test) + b1
/var/folders/t4/_9qps8wj56jc60nwkr3nrcr00000gn/T/ipykernel_44637/3032217627.py:3: RuntimeWarning: divide by zero encountered in matmul
  Z2 = np.matmul(W2, A1) + b2
/var/folders/t4/_9qps8wj56jc60nwkr3nrcr00000gn/T/ipykernel_44637/3032217627.py:3: RuntimeWarning: overflow encountered in matmul
  Z2 = np.matmul(W2, A1) + b2
/var/folders/t4/_9qps8wj56jc60nwkr3nrcr00000gn/T/ipykernel_44637/3032217627.py:3: RuntimeWarning: invalid value encountered in matmul
  Z2 = np.matmul(W2, A1) + b2</code></pre>
</div>
</div>
<section id="model-performance" class="level4">
<h4 class="anchored" data-anchor-id="model-performance">Model performance</h4>
<div id="0d6817f4" class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(confusion_matrix(predictions, labels))</span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(predictions, labels))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[[ 896    0   26    8    8   22   30    4   14   10]
 [   0 1076   15    6    2    7    3    6   14    2]
 [  14   13  815   30   10   13   23   33   24   13]
 [  10   12   47  820    4   60    5   18   40   17]
 [   0    1   17    0  790   22   30   17   14  106]
 [  27    4    7   56    5  669   23    6   58   16]
 [  13    5   30    7   23   28  822    0   21    1]
 [   6    2   18   25   12   10    3  866   18   37]
 [  12   22   47   42   19   44   16   15  739   28]
 [   2    0   10   16  109   17    3   63   32  779]]
              precision    recall  f1-score   support

           0       0.91      0.88      0.90      1018
           1       0.95      0.95      0.95      1131
           2       0.79      0.82      0.81       988
           3       0.81      0.79      0.80      1033
           4       0.80      0.79      0.80       997
           5       0.75      0.77      0.76       871
           6       0.86      0.87      0.86       950
           7       0.84      0.87      0.86       997
           8       0.76      0.75      0.75       984
           9       0.77      0.76      0.76      1031

    accuracy                           0.83     10000
   macro avg       0.82      0.83      0.82     10000
weighted avg       0.83      0.83      0.83     10000
</code></pre>
</div>
</div>
<p>We are at 84% accuray across all digits, which could be of course better. We may now plot image and the corresponding prediction.</p>
</section>
</section>
</section>
<section id="test-the-model" class="level2">
<h2 class="anchored" data-anchor-id="test-the-model">Test the model</h2>
<div id="e7ef7e2b" class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a>i<span class="op">=</span><span class="dv">2003</span></span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a>plt.imshow(X_test[:,i].reshape(<span class="dv">28</span>,<span class="dv">28</span>), cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a>predictions[i]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="28">
<pre><code>np.int64(5)</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="1_deep_learning_files/figure-html/cell-29-output-2.png" width="424" height="420" class="figure-img"></p>
</figure>
</div>
</div>
</div>


<script type="ojs-module-contents">
eyJjb250ZW50cyI6W119
</script>
<div id="exercise-loading-indicator" class="exercise-loading-indicator d-none d-flex align-items-center gap-2">
<div id="exercise-loading-status" class="d-flex gap-2">

</div>
<div class="spinner-grow spinner-grow-sm">

</div>
</div>
<script type="vfs-file">
W10=
</script>
</section>

</main> <!-- /main -->
<script type="ojs-module-contents">
eyJjb250ZW50cyI6W119
</script>
<script type="module">
if (window.location.protocol === "file:") { alert("The OJS runtime does not work with file:// URLs. Please use a web server to view this document."); }
window._ojs.paths.runtimeToDoc = "../../seminars/seminar10";
window._ojs.paths.runtimeToRoot = "../..";
window._ojs.paths.docToRoot = "../..";
window._ojs.selfContained = false;
window._ojs.runtime.interpretFromScriptTags();
</script>
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "Óßã";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/fcichos\.github\.io\/EMPP24\/");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>