[
  {
    "objectID": "Assignment 4.html",
    "href": "Assignment 4.html",
    "title": "Assignment 3",
    "section": "",
    "text": "Problem 1\nThere are two files with a list of integers a.txt and b.txt. Calculate the greatest common divisors of each pair of values from these files and store them in the file result.txt. Check out the numpy function np.gcd() for this purpose.¬†\nAufgabenstellung klarer!\n\nimport numpy as np\n\nwith open('a.txt', 'r') as file_1, open('b.txt', 'r') as file_2, open('result.txt', 'w') as result:\n    for a, b in zip(file_1, file_2):\n        result.write(f\"{np.gcd(int(a),int(b))}\\n\")\n\n\nfile=open('a.txt','r')\nfile1=open('b.txt','r')\n\n\na=file.readlines()\nb=file1.readlines()\n\n\nlist(zip(a,b))\n\n[('12\\n', '5\\n'),\n ('2\\n', '8\\n'),\n ('4\\n', '4\\n'),\n ('3\\n', '6\\n'),\n ('4', '87\\n')]\n\n\nProblem 2\nAssign the 100 numbers between -10 and 10 including -10 and 10 to the variable x using the linspace function of numpy. Assign the function values ( x¬≤-20 ) to the variable y. Store the paired values in the file named ‚Äúdata.txt‚Äù in the form ‚Äúx, y‚Äù (e.g.¬†-10, 80) for each line of the file.\nLeerzeichen war die Falle!\n\nimport numpy as np\n\nx=np.linspace(-10,10,100)\ny=x**2-20\n\nwith open('data.txt', 'w') as file:\n    for x, y in zip(x, y):\n        file.write(f\"{x}, {y}\\n\")\n\nProblem 3\nWrite a Python function projectile_motion(v0, theta, dt)¬†that simulates the projectile motion of an object launched at an initial velocity v0 (in m/s) and angle theta (in degrees). The function should return a tuple containing:\nThe maximum height reached by the object (in meters). The total time of flight (in seconds). The horizontal range (in meters).\nUse a time step dt (in seconds) for the simulation. Advance the time inside the function with a loop. Note that calling the function is not required for the task! Can be done only with the math module.¬†\nWhat if one of the arguments is 0?\nAufgabenstellung klarer!\n\nimport math\n\ndef projectile_motion(v0, theta, dt):\n    if(v0 == 0 or theta == 0 or dt == 0): return (0,0,0)\n    \n    theta_rad = math.radians(theta)\n    \n    v0x = v0 * math.cos(theta_rad)\n    v0y = v0 * math.sin(theta_rad)\n    \n    x_points = []\n    y_points = []\n    \n    x = 0\n    y = 0\n    t = 0\n    \n    while y &gt;= 0:\n        x = v0x * t\n        y = v0y * t - 0.5 * 9.81 * t**2\n        x_points.append(x)\n        y_points.append(y)\n        t += dt\n    \n    max_height = max(y_points)\n    total_time = t - dt\n    horizontal_range = x_points[-1]\n    \n    return (max_height, total_time, horizontal_range)\n\n\nx=np.linspace(0,10,100)-5\ny=np.linspace(0,10,100)-5\n\n\nX,Y=np.meshgrid(x,y)\n\n\nr=np.sqrt(X**2+Y**2)\n\n\n\nimport matplotlib.pyplot as plt\n\n\nplt.contour(r)"
  },
  {
    "objectID": "lectures/lecture13/1_plane_waves.html",
    "href": "lectures/lecture13/1_plane_waves.html",
    "title": "Electromagnetic Waves",
    "section": "",
    "text": "In the previous parts we have dealt with mechanics essentially. Even if we have described Brownian motion, this has been done by a particular type of Newtons equation of motion, it is much like mechanics. Now we would like to have a look at some examples from electromagnetic waves. We will not solve the wave equation but look at some solution using the complex notion of the electric field. This shall train our use of complex numbers. The special solutions are the plane wave and the spherical wave and we will be able to simulate a number of things especially with the spherical waves as they are part of Huuygens principle."
  },
  {
    "objectID": "lectures/lecture13/1_plane_waves.html#plane-waves",
    "href": "lectures/lecture13/1_plane_waves.html#plane-waves",
    "title": "Electromagnetic Waves",
    "section": "Plane waves",
    "text": "Plane waves\nWe will start with plane waves. Plane waves are solutions of the homogeneous wave equation and are the simplest solutions of the wave equation. They are also the basis for the description of more complicated waves. We will have a look at the electric field of a plane wave and its propagation in space and time.\n\nEquations\nA plane wave is a solution of the homogeneous wave equation and is given in its complex form by\n\\[\\begin{equation}\nE=E_{0}e^{i\\vec{k}\\cdot \\vec{r}}e^{-i\\omega t}\n\\end{equation}\\]\nwhere the two exponentials contain a spatial and a temporal phase. \\(E_{0}\\) denotes the amplitude of the plane wave. The plane is defined by the shape of the wavefront which is given by \\(\\vec{k}\\cdot \\vec{r}=const\\), which is just the definition of a plane perpendicular to \\(\\vec{k}\\).\nA wave is a physical quantity which oscillates in space and time. Its energy current density is related to the square magnitude of the amplitude. We will include in the following the spatial and the temporal phase. For plotting just the spatial variation of the electric field, you may just use the spatial part of the equation\n\\[\\begin{equation}\nE=E_{0}e^{i\\vec{k}\\cdot \\vec{r}}\n\\end{equation}\\]\nBut since we also want to see the wave propagate, we will directly include also the temporal dependence in our function. In all of the examples below we set the amplitude of the wave \\(E_{0}=1\\).\nThe propagation of the wave is defined by wavevector \\(\\vec{k}\\). In vacuum, the wavevector is just real valued\n\\[\\begin{equation}\n\\vec{k}_{0}=\n\\begin{pmatrix}\nk_{0x} \\\\\nk_{0y}\\\\\nk_{0z}\\\\\n\\end{pmatrix}\n\\end{equation}\\]\nThe wavevector is providing the direction in which the wavefronts propagate. It is also proportional to the momentum of the wave, which will be important if we consider the refraction process a bit later. The magnitude of the wavevector is related to the wavelength \\(\\lambda\\).\n\\[\\begin{equation}\nk_{0}=\\frac{2\\pi}{\\lambda_{0}}=\\frac{\\omega}{c_{0}}\n\\end{equation}\\]\nAt the same time, its magnitude is also given by the angular frequency divided by the speed of light. The latter is called a dispersion relation.\nIn a medium, the wavevector is by a factor of \\(n\\) longer, where n is the refractive index. Since the refractive index may be a complex number, e.g.¬†\\(n=\\eta+i\\kappa\\), the wavevector can be complex as well. It is then given by\n\\[\\begin{equation}\n\\vec{k}=n\\vec{k}_{0}=\n\\begin{pmatrix}\nk_{x}^{\\prime}+ik_{x}^{\\prime\\prime} \\\\\nk_{y}^{\\prime}+ik_{y}^{\\prime\\prime} \\\\\nk_{z}^{\\prime}+ik_{z}^{\\prime\\prime} \\\\\n\\end{pmatrix}\n\\end{equation}\\]\nThe complex refractive index means that there is some damping of the electromagnetic wave due to absorption, for example.\nThe wavelength is then related to\n\\[\\begin{equation}\n\\Re(k)=\\eta \\frac{2\\pi}{\\lambda_{0}}\n\\end{equation}\\]\nand the imaginary part gives the damping\n\\[\\begin{equation}\n\\Im(k)=\\kappa \\frac{2\\pi}{\\lambda_{0}}\n\\end{equation}\\]\n\n\nElectric field\n\n\n\n\n\n\nLets have a look at waves and wave propagation. We want to create a wave, which has a wavelength of 532 nm in vacuum.\n\n\n\n\n\n\nIt shall propagate along the z-direction and we wull have a look at the x-z plane.\n\n\n\n\n\n\nWe can plot the electric field in the x-z plane by defining a grid of points (x,z). This is done by the meshgrid function of numpy. The meshgrid returns a 2-dimensional array for each coordinate. Have a look at the values in the meshgrid.\n\n\n\n\n\n\nIn the last lines, we defined an array of X,0,Z, where X and Z are already 2-dimensional array. This finally gives an array 3D vectors, which we can use to calculate the electric field at any point in space. If we want to plot the electric field, we have to calculate the real part of the complex values, as the electric field is a physical quantity, which is always real. There is not much to see for a plane wave in the intensity plot, as the intensity of a plane wave is constant in space. Yet, if you want to plot it, you have to calculate the magnitude square of the electric field, e.g.\n\\[\\begin{equation}\nI\\propto |E|^{2}\n\\end{equation}\\]\n\n\n\n\n\n\n\n\nPlane wave propagation\nThe above graph shows a static snapshot of the plane wave at a time \\(t=0\\). We know, however, that a plane wave is propagating in space and time. Since we know how to animate things, we may do that using the ipycanvas module.\n\nx=np.linspace(-2.5e-6,2.5e-6,300)\nz=np.linspace(0,5e-6,300)\n\nX,Z=np.meshgrid(x,z)\nr=np.array([X,0,Z],dtype=object)\ncanvas = Canvas(width=300, height=300,sync_image_data=False)\ndisplay(canvas)\nTo do the animation I use a little trick to get the same color map as in the matplotlib plotting. The function below uses the matplotlib color map seismic and the corresponding mapping of values with a given minimum vmin and maximum vmax value. The mapping is done in the animation function with c=m.to_rgba(tmp).\n\n#normalize the color map to a certain value range\nnorm = mpl.colors.Normalize(vmin=-1, vmax=1)\n\ncmap = cm.seismic\n\n# do the mapping of values to color values.\nm = cm.ScalarMappable(norm=norm, cmap=cmap)\nThis is our animation function, where I provide time and the wavevector as arguments, such that we may change both parameters easily.\ndef animate(k,time):\n    for t in time:\n        field=plane_wave(k,omega0,r,t)\n        tmp=np.real(field.transpose())\n        c=m.to_rgba(tmp)\n        with hold_canvas(canvas):\n            canvas.put_image_data(c[:,:,:3]*255,0,0)\n            #canvas.put_image_data(data*255,0,0)\n        sleep(0.02)\nWith the call below, you may animate the wave now with different refractive indices.\n\neta=1.\nkappa=0.0\nn=eta+kappa*1j\n\nk=n*k0*vec\ntime= np.linspace(0,5e-14,500)\nanimate(k,time)\n\n\nImaginary wave vector\nIf we now create a material, which has an imaginary part of the refractive index, we see that the amplitude decays and the wave fades.\n\n\n\n\n\n\nThe above plots show the electric field amplitude in the x-z plane. We may also have a look the field amplitude and intensity as a function of the z-position by chosing a single x-value. In the plot below, you may notice two things. The first is, that the wave decays exponentially with distance \\(z\\). Intensity and field decay with different decay length. The field decays with \\(\\exp(-\\kappa*k_{0}z)\\) while the intensity of cause decays twice as fast \\(\\exp(-2\\kappa*k_{0}z)\\) due to the fact the the intensity is the square of the electric field.\n\n\n\n\n\n\n\n\nAnimation\nOf course, we should not miss the animation.\ndisplay(canvas)\nk=n*k0*vec\ntime= np.linspace(0,5e-14,500)\nanimate(k,time)\n\n\nInterference of two plane waves\nIt is not very difficult to calculate from the definitions we did above now the interference of two plane waves, which have different directions of the wavevector. The total field in space is then just the sum of the two fields\n\\[\\begin{equation}\n\\vec{E}=\\vec{E}_{1}+\\vec{E}_{2}\n\\end{equation}\\]\nThe interesting thing is now to look at the intensity which\n\\[\\begin{equation}\nI\\propto |\\vec{E}|^2=|\\vec{E}_{1}|^2+|\\vec{E}_{2}|^2 + \\vec{E}_{1}^{*} \\vec{E}_{2}+\\vec{E}_{2}^{*}\\vec{E}_{1}\n\\end{equation}\\]\n\n\n\n\n\n\nWhile the field pattern still looks complicated, the intensity pattern is just a set of bright lines.\n\n\n\n\n\n\n\n\n\n\n\n\nAdvanced Topics: Plane wave at a boundary\n\n\n\n\n\nWe want to go a bit further now and have a look at the wave at a boundary between vaccum and glass for example. At this boundary, the electromagnetic wave is reflected and refracted such that two new wavevectors arise. These are easily calculated by the law of reflection and the law of refraction. Besides that, also the amplitude of the waves change. To calculate the field we need the so-called Fresnel equations.\n\nFresnel equations\nWhen electromagnetic waves hit a boundary, they will be reflected and refracted. The amplitude of the reflected and refracted wave is determined by the refractive index of the two materials, the angles and the polarizations. For the latter we differentiate between a polarization in the incident plane (the p-polarization) and perpendicular to the incident plane (s-polarization).\n\n\n\nFresnel\n\n\nFor each of the polarization we in general obtain a coeffcient for the reflection and one for the refraction. To make our calculation a bit simpler, we will assume only s-polarization. Then the two Fresnel coefficients are calculated as\n\\[\\begin{equation}\n\\left( \\frac{E_{0t}}{E_{0e}} \\right)_s = t_s =\\frac{2n_1 \\cos{\\alpha}}{n_1\\cos{\\alpha}+n_2\\cos{\\beta}}\n\\end{equation}\\]\n\\[\\begin{equation}\n\\left( \\frac{E_{0r}}{E_{0e}} \\right)_s = r_s =\\frac{n_1\\cos{\\alpha}-n_2\\cos{\\beta}}{n_1\\cos{\\alpha}+n_2\\cos{\\beta}}\n\\end{equation}\\]\nwhere \\(\\alpha\\) and \\(\\beta\\) are the incident and refraction angles, respectively. Note that the Fresnel coefficients are for the amplitudes and can be negative to account for a phase jump by \\(\\pi\\). To obtain the coefficients for the intensities, one has to square the Fresnel coefficients.\nTo bring everything correctly together, we therefore have to define a number of things. We will need a function calculating the outgoing angle from Snells law. And we need at least two functions calculating the reflection and transmission coefficient for one polarization. We use the s-polarization, where the electric field is always parallel to the interface.\n\n\n\n\n\n\nWith the definition of the Fresnel coefficients, we may now plot the reflection and the transmission coefficients. Note that the sum of reflection and transmission coefficients for the intensities have to add up to one if there is no absorption.\n\n\n\n\n\n\n\n\nIncident wave\nWe want to study the electric fields and the intensities at various angles. The most interesting one, is a case where we have total internal reflection. This happens, if light is propagating from the higher refractive index to a lower refractive index. If we start in glass (\\(n_1=1.5\\)) and transmit to vacuum \\(n_2=1\\), then at all angles above \\(\\theta_{c}=\\sin^{-1}(n_2/n_1)=41.810314895778596\\) are total internally reflected.\n\n\n\n\n\n\nWe may now specify or calculate the corresponding wavevectors for an incident angle of \\(45^{\\circ}\\). In general all waves (reflect, refracted) have to match with their phase at the boundary. If the boundary is along the x-direction, we therefore have\n\\[\\begin{equation}\nk_{x,in}=k_{x,r}=k_{x,t}\n\\end{equation}\\]\nThis fixes one component of all wavevectors in the plane. What is then missing, is the z-component of the wavevectors. The incident wavevector is providing \\(k_{z,in}\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReflected wave\nFor the reflected wave the z-component of the wavevector is just flipped in sign, e.g.¬†\\(k_{z,r}=-k_{z,in}\\).\n\n\n\n\n\n\n\n\nRefracted wave\nThe magnitude of the z-component of the transmitted wave can be obtained from the conservation of momentum. The momentum of the wave is proportional to the magnitude of the wavevector on both sides.\n\\[\\begin{equation}\nk_{1}^2=k_{2}^{2}\n\\end{equation}\\]\nwhich is, due to \\(k=nk_{0}\\) the same as\n\\[\\begin{equation}\nn_{1}^2(k_{0x,in}^2+k_{0z,in}^{2})=n_2^2 (k_{0x,t}^{2}+k_{0z,t}^2)\n\\end{equation}\\]\nfrom which we get\n\\[\\begin{equation}\nk_{0z,t}=\\pm \\frac{1}{n_{1}}\\sqrt{n_2^2 k_{0z,in}^2 -(n_{1}^2-n_{2}^2)k_{0x}^{2}}\n\\end{equation}\\]\nIf we go from a medium with high refrective index to a lower one, the second term in the root may surpass the first one and the whole solution will become imaginary. The wave in the lower refractive index medium \\(n_{2}\\) is then evanescent.\n\n\n\n\n\n\nThe total field thus containes three components. In medium 1, the field consists of the incident and the reflected wave. In medium 2, we just have the transmitted wave, with a possible evanescent solution.\n\n\n\n\n\n\nThe plots below show the electric field on the left side and the intensity on the right side. Interestingly, the intensity is that of a standing wave in medium 1, while it is just decaying in medium 2. Note that the electric field is oscillating along the interface in medium 2 but not at all in z-direction. This means that there is no energy transport along the z-direction anymore.\n\n\n\n\n\n\nWe will also have a look ath the propagation of the wave yb defining our animation.\ncanvas = Canvas(width=500, height=500,sync_image_data=True)\ndisplay(canvas)\n\ndef animate(k,time):\n    for t in time:\n        field=np.zeros([500,500],dtype=complex)\n        field1=plane_wave(k1,omega0,r1,t)\n        field2=plane_wave(k2,omega0,r1,t)\n        field3=plane_wave(k3,omega0,r2,t)\n\n        beta=snell(n1,n2,alpha)\n        r=rs(n1,n2,alpha,beta)\n        t=ts(n1,n2,alpha,beta)\n\n        field[0:250,:]=field1+r*field2\n        field[250:,:]=t*field3\n        tmp=np.real(field.transpose())\n\n        c=m.to_rgba(tmp)\n        with hold_canvas(canvas):\n            canvas.put_image_data(c[:,:,:3]*255,0,0)\n        sleep(0.02)\n\ntime= np.linspace(0,1e-14,100)\nanimate(k,time)\nAs it is apparent from our simulation, the wave is longitudinal in medium 2 at this angle. Try to modify the incident angles yourself to see if the wave becomes propagating in medium 2.\nIn the last plot, we will have a look at the intensity in medium 1 and medium 2. What is nicely visible, is that the intensity decays in medium 2 with increasing distance. As compared to the absorbing case, there is not oscillation of the field in the z-direction, hence no energy transfer. Convince yourself that this is indeed an exponential decay by using the appropriate semilog plot."
  },
  {
    "objectID": "lectures/lecture13/2_spherical_waves.html",
    "href": "lectures/lecture13/2_spherical_waves.html",
    "title": "Spherical waves",
    "section": "",
    "text": "After we have had a look at plane waves, we can explore a second solution of the homogeneous wave equation - Spherical Waves. Spherical waves are elementary waves that are for example considered in Huygens principle. So if we develop some code to visualize spherical waves, we may also verify Huygens principle later."
  },
  {
    "objectID": "lectures/lecture13/2_spherical_waves.html#equations",
    "href": "lectures/lecture13/2_spherical_waves.html#equations",
    "title": "Spherical waves",
    "section": "Equations",
    "text": "Equations\nA spherical wave is as well described by two exponentials containing the spatial and temporal dependence of the wave. The only difference is, that the wavefronts shall describe spheres instead of planes. We therefore need \\(|\\vec{k}||\\vec{r}|=k r=const\\). The product of the magntitudes of the wavevector and the distance from the source are constant. If we further generalize the position of the source to \\(\\vec{r}_{0}\\) we can write a spherical wave by\n\\[\\begin{equation}\nE=\\frac{E_{0}}{|\\vec{r}-\\vec{r}_{0}|}e^{i k|\\vec{r}-\\vec{r}_{0}|} e^{-i\\omega t}\n\\end{equation}\\]\nNote that we have to introduce an additional scaling of the amplitude with the inverse distance of the source. This is due to energy conservation, as we require that all the energy that flows through all spheres around the source is constant."
  },
  {
    "objectID": "lectures/lecture13/2_spherical_waves.html#electric-field",
    "href": "lectures/lecture13/2_spherical_waves.html#electric-field",
    "title": "Spherical waves",
    "section": "Electric field",
    "text": "Electric field\nLets have a look at the electric field of the spherical wave. Below is some code plotting the electric field is space. The source is at the origin and the plot nicely shows, that the amplitude decays with the distance.\n\n\n\n\n\n\nThe line plots below show that the field amplitude rapidly decays and the intensity follows a \\(1/r^2\\) law as expected. The slight deiviation at small distances is an artifact from our discretization. We used the image above to extract the line plot and therefore never exactly hit \\(r=0\\)."
  },
  {
    "objectID": "lectures/lecture13/2_spherical_waves.html#animation",
    "href": "lectures/lecture13/2_spherical_waves.html#animation",
    "title": "Spherical waves",
    "section": "Animation",
    "text": "Animation\nWe can also visualize the animation our spherical wave to check for the direction of the wave propagation.\nnorm = mpl.colors.Normalize(vmin=-5e6, vmax=5e6)\ncmap = cm.seismic\nm = cm.ScalarMappable(norm=norm, cmap=cmap)\ncanvas = Canvas(width=300, height=300,sync_image_data=True)\ndisplay(canvas)\ndef animate(k,time):\n    for t in time:\n        field=spherical_wave(k,omega0,r,r0,t)\n        data=np.zeros([300,300,3])\n        tmp=np.real(field.transpose())\n        c=m.to_rgba(tmp)\n        with hold_canvas(canvas):\n            canvas.put_image_data(c[:,:,:3]*255,0,0)\n        sleep(0.02)\ntime= np.linspace(0,1e-14,200)\nanimate(k,time)"
  },
  {
    "objectID": "lectures/lecture13/2_spherical_waves.html#plot-the-intensity-in-an-image-plane",
    "href": "lectures/lecture13/2_spherical_waves.html#plot-the-intensity-in-an-image-plane",
    "title": "Spherical waves",
    "section": "Plot the intensity in an image plane",
    "text": "Plot the intensity in an image plane\nAs we have now the electric field in space, wqe may also chose an arbitrary plane in space to record the intensity of that wave in space. Here we want to know the intensity in a plane at 10 ¬µm distance from the source, which is again at the origin. The intensity cross section at the screen is a Lorentzian function."
  },
  {
    "objectID": "lectures/lecture13/2_spherical_waves.html#interference-between-a-spherical-and-a-plane-wave",
    "href": "lectures/lecture13/2_spherical_waves.html#interference-between-a-spherical-and-a-plane-wave",
    "title": "Spherical waves",
    "section": "Interference between a spherical and a plane wave",
    "text": "Interference between a spherical and a plane wave\nIn the section on plane waves, we had a look at the interference pattern of plane waves in space. We now have a look at the interference of a plane wave and a spherical wave. The plane wave thereby probes the distortion of the spherical wavefronts and the interference pattern stores this information on the shape of the spherical wavefronts. This is exactly what is done in holography. Taking this interference pattern as a ‚Äúdiffraction grating‚Äù will allow you to restore information on the spherical wavefonts."
  },
  {
    "objectID": "lectures/lecture15/lecture15.html",
    "href": "lectures/lecture15/lecture15.html",
    "title": "Repetiion",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\n\n# Set plotting style\n#plt.style.use('seaborn')"
  },
  {
    "objectID": "lectures/lecture15/lecture15.html#setup",
    "href": "lectures/lecture15/lecture15.html#setup",
    "title": "Repetiion",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\n\n# Set plotting style\n#plt.style.use('seaborn')"
  },
  {
    "objectID": "lectures/lecture15/lecture15.html#introduction-neural-networks-as-physical-systems",
    "href": "lectures/lecture15/lecture15.html#introduction-neural-networks-as-physical-systems",
    "title": "Repetiion",
    "section": "Introduction: Neural Networks as Physical Systems",
    "text": "Introduction: Neural Networks as Physical Systems\nNeural networks might seem complicated, but we can understand them using physics concepts you already know! Let‚Äôs explore how these computational tools are similar to physical systems we‚Äôve studied."
  },
  {
    "objectID": "lectures/lecture15/lecture15.html#neural-networks-as-energy-flow",
    "href": "lectures/lecture15/lecture15.html#neural-networks-as-energy-flow",
    "title": "Repetiion",
    "section": "1. Neural Networks as Energy Flow",
    "text": "1. Neural Networks as Energy Flow\nJust like we study energy flow through physical systems, a neural network processes information flowing through it:\n\nInput values: Like initial energy\nWeights: Like how efficiently energy transfers (think spring constants)\nBias: Like a baseline energy level\nOutput: Like final energy state\n\n\n# Simple example\ninput_value = 2    # Like initial energy\nweight = 0.5       # Like energy transfer efficiency\nbias = 1          # Like baseline energy level\noutput = weight * input_value + bias\n\nprint(f\"Input energy: {input_value}\")\nprint(f\"Transfer efficiency: {weight}\")\nprint(f\"Baseline: {bias}\")\nprint(f\"Final state: {output}\")\n\nInput energy: 2\nTransfer efficiency: 0.5\nBaseline: 1\nFinal state: 2.0"
  },
  {
    "objectID": "lectures/lecture15/lecture15.html#the-sigmoid-function-natures-barrier",
    "href": "lectures/lecture15/lecture15.html#the-sigmoid-function-natures-barrier",
    "title": "Repetiion",
    "section": "2. The Sigmoid Function: Nature‚Äôs Barrier",
    "text": "2. The Sigmoid Function: Nature‚Äôs Barrier\nMany physical systems have natural limits. Think about: - Terminal velocity in air resistance - Saturation in magnetic materials - Maximum compression of a spring\nNeural networks use a similar concept called the sigmoid function:\n\ndef sigmoid(x):\n    return 1/(1 + np.exp(-x))\n\nx = np.linspace(-10, 10, 100)\nplt.figure(figsize=(8, 5))\nplt.plot(x, sigmoid(x))\nplt.title('Sigmoid Function: Like a Physical Barrier')\nplt.xlabel('Input (like force)')\nplt.ylabel('Output (like displacement)')\nplt.grid(True)\nplt.show()"
  },
  {
    "objectID": "lectures/lecture15/lecture15.html#learning-as-finding-minimum-potential-energy",
    "href": "lectures/lecture15/lecture15.html#learning-as-finding-minimum-potential-energy",
    "title": "Repetiion",
    "section": "3. Learning as Finding Minimum Potential Energy",
    "text": "3. Learning as Finding Minimum Potential Energy\nTraining a neural network is like a ball rolling down a hill: 1. Start somewhere on the hill (initial weights) 2. Look which way is downhill (calculate error) 3. Take a small step in that direction (update weights) 4. Repeat until you reach the bottom (minimum error)\n\n# Visualize a simple \"energy landscape\"\nx = np.linspace(-5, 5, 100)\ny = x**2  # Simple parabola like potential energy well\n\nplt.figure(figsize=(8, 5))\nplt.plot(x, y)\nplt.title('Learning is Like Finding Minimum Potential Energy')\nplt.xlabel('Weight Value')\nplt.ylabel('Error (like Potential Energy)')\nplt.grid(True)\n\n# Mark the minimum\nplt.plot(0, 0, 'ro', label='Minimum Error')\nplt.legend()\nplt.show()"
  },
  {
    "objectID": "lectures/lecture15/lecture15.html#practical-example-particle-detection",
    "href": "lectures/lecture15/lecture15.html#practical-example-particle-detection",
    "title": "Repetiion",
    "section": "4. Practical Example: Particle Detection",
    "text": "4. Practical Example: Particle Detection\nLet‚Äôs build a simple ‚Äúneuron‚Äù that could help detect particles:\n\ndef simple_neuron(energy, momentum, weight1, weight2, bias):\n    # Combine inputs like forces combining\n    total_input = weight1 * energy + weight2 * momentum + bias\n    # Convert to probability using sigmoid\n    probability = sigmoid(total_input)\n    return probability\n\n# Example values\nenergy = 100  # MeV\nmomentum = 50 # MeV/c\nw1, w2 = 0.01, 0.02  # Some random weights\nb = -1\n\nprobability = simple_neuron(energy, momentum, w1, w2, b)\nprint(f\"Probability this is our particle: {probability:.2%}\")\n\nProbability this is our particle: 73.11%"
  },
  {
    "objectID": "lectures/lecture15/lecture15.html#visualizing-decision-boundaries",
    "href": "lectures/lecture15/lecture15.html#visualizing-decision-boundaries",
    "title": "Repetiion",
    "section": "5. Visualizing Decision Boundaries",
    "text": "5. Visualizing Decision Boundaries\nJust like phase transitions in physics separate different states of matter, neural networks create boundaries between different classifications:\n\n# Create a grid of points\nE, M = np.meshgrid(np.linspace(0, 200, 100), np.linspace(0, 100, 100))\nZ = simple_neuron(E, M, w1, w2, b)\n\nplt.figure(figsize=(10, 6))\nplt.contourf(E, M, Z, levels=20)\nplt.colorbar(label='Classification Probability')\nplt.title('Particle Classification Boundary')\nplt.xlabel('Energy (MeV)')\nplt.ylabel('Momentum (MeV/c)')\nplt.show()"
  },
  {
    "objectID": "lectures/lecture15/lecture15.html#key-takeaways",
    "href": "lectures/lecture15/lecture15.html#key-takeaways",
    "title": "Repetiion",
    "section": "Key Takeaways",
    "text": "Key Takeaways\nNeural Networks are like physical systems: 1. Process inputs like energy flow 2. Have natural limits (like terminal velocity) 3. Find minimum energy states during training 4. Create boundaries between different states 5. Follow principles of optimization we see in nature"
  },
  {
    "objectID": "lectures/lecture15/lecture15.html#try-it-yourself",
    "href": "lectures/lecture15/lecture15.html#try-it-yourself",
    "title": "Repetiion",
    "section": "Try It Yourself!",
    "text": "Try It Yourself!\nChange the weights and bias in the particle detection example above. How does this affect the decision boundary? This is similar to adjusting the parameters of a physical system!"
  },
  {
    "objectID": "lectures/lecture12/01-lecture12.html",
    "href": "lectures/lecture12/01-lecture12.html",
    "title": "Lecture 12",
    "section": "",
    "text": "Introduction to more advanced simulation techniques (e.g., finite difference methods).\nStructuring a Python project (modules, documentation, testing).\n\n\n\n\n\nSimulating wave propagation, reflection, and transmission in different media.\nVisualization: Animating wave motion and energy transfer.\n\n\n\n- Introduction to the final project, where students choose a physics problem to model and solve using Python.\n- Discussion of project expectations, timelines, and resources.\n- Homework: Start working on the final project by selecting a topic and outlining the approach.\n\n\n\n## Ideal Gas Simulation with Pressure, Gravity, and Collisions\n\nUse the sliders below to adjust the speed of the gas particles and the gravitational force acting on them. The pressure exerted by the particles on the container walls will be displayed.\n\n  Adjust Particle Speed:\n  \n\n\n  Adjust Gravity:\n  \n\nPressure: 0 Pa"
  },
  {
    "objectID": "lectures/lecture12/01-lecture12.html#advanced-waves-and-final-project-introduction",
    "href": "lectures/lecture12/01-lecture12.html#advanced-waves-and-final-project-introduction",
    "title": "Lecture 12",
    "section": "",
    "text": "Introduction to more advanced simulation techniques (e.g., finite difference methods).\nStructuring a Python project (modules, documentation, testing).\n\n\n\n\n\nSimulating wave propagation, reflection, and transmission in different media.\nVisualization: Animating wave motion and energy transfer.\n\n\n\n- Introduction to the final project, where students choose a physics problem to model and solve using Python.\n- Discussion of project expectations, timelines, and resources.\n- Homework: Start working on the final project by selecting a topic and outlining the approach.\n\n\n\n## Ideal Gas Simulation with Pressure, Gravity, and Collisions\n\nUse the sliders below to adjust the speed of the gas particles and the gravitational force acting on them. The pressure exerted by the particles on the container walls will be displayed.\n\n  Adjust Particle Speed:\n  \n\n\n  Adjust Gravity:\n  \n\nPressure: 0 Pa"
  },
  {
    "objectID": "lectures/lecture12/4_repetition.html",
    "href": "lectures/lecture12/4_repetition.html",
    "title": "Repetition solving ODEs",
    "section": "",
    "text": "Since we have already solved ODEs in one of the past lectures, we should repeat this here. The following exercises will help you to get a better understanding of the solution of ODEs. Try to solve the exercises by yourself and with the help of the contents of Lecture 8.\n\n\n\n\n\n\nSelf-Exercise 1: Simple Harmonic Oscillator\n\n\n\nWrite a program to solve the equation of motion for a simple harmonic oscillator. This example demonstrates how to solve a second-order differential equation using scipy‚Äôs odeint.\nThe equation of motion is: \\(\\frac{d^2x}{dt^2} + \\omega^2x = 0\\)\nThis represents an idealized spring-mass system or pendulum with small oscillations.\n\n\n\n\n\n\n\nUse odeint(oscillator, initial_state, t, args=(omega,)) to solve the system. The solution will have two columns: position ([:,0]) and velocity ([:,1]). Create a plot showing position vs time using matplotlib. Remember to label your axes and add a title.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSelf-Exercise 2: Radioactive Decay\n\n\n\nModel the process of radioactive decay, a fundamental concept in nuclear physics. This exercise shows how to solve a first-order differential equation that describes exponential decay.\nThe decay equation is: \\(\\frac{dN}{dt} = -\\lambda N\\)\nWhere \\(N\\) is the number of atoms and \\(\\lambda\\) is the decay constant.\n\n\n\n\n\n\n\nUse odeint(decay, N0, t, args=(lambda_,)) to solve the equation. The solution will be a 1D array of N values. Plot N vs t to visualize the exponential decay. Consider adding a horizontal line at N0/2 to show the half-life. Use plt.grid(True) to make the plot easier to read.\n\n\n\n\n\n\n\n\nSolution"
  },
  {
    "objectID": "lectures/lecture12/3_diffusion_equation.html",
    "href": "lectures/lecture12/3_diffusion_equation.html",
    "title": "Diffusion equation",
    "section": "",
    "text": "So far, we have always looked at ordinary differential equations, i.e.¬†differential equations where the physical quantity we considered was depending only on one variable. In a lot of physical problems, the observable quantities depend on multiple variables like time and space. The differential equations, which govern those problems are partial differential equations. The diffusion equation is one of them. It pops up in various forms in physics, describing also heat conduction and in a slighly modified way this is corresponding to the time dependent Schr√∂dinger equation."
  },
  {
    "objectID": "lectures/lecture12/3_diffusion_equation.html#physical-model",
    "href": "lectures/lecture12/3_diffusion_equation.html#physical-model",
    "title": "Diffusion equation",
    "section": "Physical Model",
    "text": "Physical Model\nYou‚Äôve probably seen how ink spreads in water - this spreading is called diffusion and is the result of the Brownian motion of ink particles in water. We have already simulated the random motion in Lecture 5 and the real-time animation below shows this process, when all particles are starting at the center of the box. The diffusion equation describes how the concentration of particles (the number of particles per unit volume) changes over time and space.\nWhile physicists describe this with complex equations, our goal in this course is to learn how to simulate this process using Python. So the main task will be to split the diffusion equation into small pieces that we can calculate with a computer.\nThe basic diffusion equation looks like this:\n\\[\\begin{equation}\n\\frac{\\partial c({\\bf r},t)}{\\partial t}=D\\Delta c ({\\bf r},t)\n\\end{equation}\\]\nHere, \\(c\\) represents the concentration (like how much ink is at each point), \\(t\\) is time, and \\({\\bf r}\\) is position. \\(D\\) is just a number that tells us how fast the diffusion happens. Its unit is length squared per time.\nTo make this easier to program, we‚Äôll look at diffusion in just one direction (like along a line). This gives us:\n\\[\\begin{equation}\n\\frac{\\partial c(x,t)}{\\partial t}=D\\frac{\\partial^2 c(x,t)}{\\partial x^{2}}\n\\end{equation}\\]\nTo turn this equation into code, we need to break up space and time into small pieces. We‚Äôll use \\(c^{n}_{i}\\) in our program, where \\({\\bf n}\\) is which time step we‚Äôre on, and \\({\\bf i}\\) tells us which point in space we‚Äôre looking at.\n\n\n\n\n\nwidth = 600\nheight = 600\nmargin = ({top: 20, right: 30, bottom: 20, left: 40})\nplotHeight = 100\n\nviewof simulation = {\n  // Create main container\n  const container = d3.create(\"div\")\n    .style(\"display\", \"flex\")\n    .style(\"flex-direction\", \"column\");\n\n  // Create SVG for particle simulation\n  const svg = container.append(\"svg\")\n    .attr(\"width\", width)\n    .attr(\"height\", height - plotHeight)\n    .attr(\"viewBox\", [0, 0, width, height - plotHeight]);\n\n  // Create SVG for histogram\n  const histogramSvg = container.append(\"svg\")\n    .attr(\"width\", width)\n    .attr(\"height\", plotHeight)\n    .attr(\"viewBox\", [0, 0, width, plotHeight]);\n\n  const numParticles = 1000;\n  const D = 0.5; // Diffusion coefficient\n  const numBins = 80;\n\n  // Create particles at the center\n  const particles = Array.from({length: numParticles}, () =&gt; ({\n    x: width / 2,\n    y: (height - plotHeight) / 2,\n    vx: 0,\n    vy: 0\n  }));\n\n  // Setup scales for histogram\n  const xScale = d3.scaleLinear()\n    .domain([0, width])\n    .range([margin.left, width - margin.right]);\n\n  const yScale = d3.scaleLinear()\n    .domain([0, numParticles/5])\n    .range([plotHeight - margin.bottom, margin.top]);\n\n  // Create histogram generator\n  const histogram = d3.bin()\n    .domain(xScale.domain())\n    .thresholds(xScale.ticks(numBins))\n    .value(d =&gt; d.x);\n\n  // Create histogram group\n  const histogramGroup = histogramSvg.append(\"g\");\n\n  // Add axes\n  histogramSvg.append(\"g\")\n    .attr(\"transform\", `translate(0,${plotHeight - margin.bottom})`)\n    .call(d3.axisBottom(xScale));\n/*\n  histogramSvg.append(\"g\")\n    .attr(\"transform\", `translate(${margin.left},0)`)\n    .call(d3.axisLeft(yScale));\n*/\n  // Animation function\n  function animate() {\n    particles.forEach(particle =&gt; {\n      // Random walk implementation based on diffusion equation\n      const randomAngle = Math.random() * 2 * Math.PI;\n      const displacement = Math.sqrt(2 * D);\n\n      particle.x += displacement * Math.cos(randomAngle);\n      particle.y += displacement * Math.sin(randomAngle);\n\n      // Bounce off walls\n      if (particle.x &lt; 0) particle.x = 0;\n      if (particle.x &gt; width) particle.x = width;\n      if (particle.y &lt; 0) particle.y = 0;\n      if (particle.y &gt; (height - plotHeight)) particle.y = height - plotHeight;\n    });\n\n    // Update particle positions\n    circles\n      .attr(\"cx\", d =&gt; d.x)\n      .attr(\"cy\", d =&gt; d.y);\n\n    // Update histogram\n    const bins = histogram(particles);\n\n    const bars = histogramGroup.selectAll(\"rect\")\n      .data(bins);\n\n    bars.enter()\n      .append(\"rect\")\n      .merge(bars)\n      .attr(\"x\", d =&gt; xScale(d.x0))\n      .attr(\"y\", d =&gt; yScale(d.length))\n      .attr(\"width\", d =&gt; Math.max(0, xScale(d.x1) - xScale(d.x0) - 1))\n      .attr(\"height\", d =&gt; yScale(0) - yScale(d.length))\n      .attr(\"fill\", \"steelblue\");\n\n    bars.exit().remove();\n  }\n\n  // Create circles for particles\n  const circles = svg.selectAll(\"circle\")\n    .data(particles)\n    .join(\"circle\")\n    .attr(\"r\", 2)\n    .attr(\"fill\", \"steelblue\")\n    .attr(\"opacity\", 0.6);\n\n  // Start animation\n  d3.timer(animate);\n\n  return container.node();\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†1: Simulation showing the diffusion of particles in a 2D box. Particles move randomly based on the diffusion equation. The histogram shows the distribution of particles along the x-axis.\n\n\n\n\n\nSpatial derivative\n\n\nSpatial derivative\nLet‚Äôs break down how we handle changes in space. Just like before, we can estimate how quickly the concentration changes in space using three points:\n\\[\\begin{equation}\n\\frac{\\partial^{2} c(x,t)}{\\partial x^2}\\approx\\frac{c_{i+1}^{n}-2c_{i}^{n}+c_{i-1}^{n}}{\\Delta x^2}\n\\end{equation}\\]\nThink of this as looking at how the concentration changes between neighboring points. We‚Äôll collect all these concentrations at a particular time \\(n\\) into a list: \\({\\bf C}=\\lbrace c_{0}^{n},c_{1}^{n},c_{2}^{n}, \\ldots, c_{5}^{n}\\rbrace\\).\nTo make calculations easier for the computer, we can write this as a matrix equation:\n\\(M=\\frac{\\partial^2}{\\partial x^2}=\\frac{1}{\\delta x^2}\n\\begin{bmatrix}\n-2 & 1  & 0 & 0 & 0 & 0\\\\\n1 & -2 & 1 & 0 & 0 & 0\\\\\n0 & 1  & -2 & 1 & 0 & 0\\\\\n0 & 0  & 1  & -2 & 1 & 0\\\\\n0 & 0  & 0  &  1 & -2 & 1\\\\\n0 & 0  & 0  &  0 &  1 & -2\\\\\n\\end{bmatrix}\\)\nEach row in this matrix represents how we calculate the change at one point using its neighbors. We haven‚Äôt yet considered what happens at the edges of our system (the boundary conditions).\nThis lets us write our diffusion equation in a simpler form:\n\\[\\begin{equation}\n\\frac{\\partial c(x,t)}{\\partial t}\\approx DM{\\bf C}^{n}\n\\end{equation}\\]\nHere, \\(M\\) is our matrix from above, and \\({\\bf C}\\) is our list of concentrations. The \\(n\\) tells us we‚Äôre looking at a specific moment in time.\n\n\nTemporal derivative\nJust like we split up space into points, we also need to split up time into small steps. The change in concentration over time can be estimated by looking at how much it changes between two time steps:\n\\[\\begin{equation}\n\\frac{\\partial c(x,t)}{\\partial t}=\\frac{c_{i}^{n+1}-c_{i}^{n}}{\\delta t}\n\\end{equation}\\]\nHere, \\(n\\) tells us which time step we‚Äôre on (just like \\(i\\) told us which space point we were looking at). This equation works for any point in space \\(i\\).\nTo make our calculation more accurate, we use something called the Crank Nicolson scheme. First, we write our time derivative as:\n\\[\\begin{equation}\n\\frac{\\partial c}{\\partial t} = f(x)\n\\end{equation}\\]\nwhere \\(f(x)\\) is the spatial part we found earlier:\n\\[\\begin{equation}\nf(x)=D\\frac{\\partial^2 c(x,t)}{\\partial x^{2}}\n\\end{equation}\\]\nThe Crank Nicolson scheme tells us to take the average of this function at the current time step and the next time step:\n\\[\\begin{equation}\n\\frac{\\partial c}{\\partial t} \\approx \\frac{1}{2}\\left ( f^{n+1}(x)+f^{n}(x)\\right)\n\\end{equation}\\]\nwhere \\(n\\) keeps track of which time step we‚Äôre on.\n\n\nBringing all together\nWe can now bring all sides together to develop our implicit scheme.\n\\[\\begin{equation}\n\\frac{{\\bf C^{n+1}}-{\\bf C}^{n}}{\\delta t}=\\frac{1}{2} \\left (D M {\\bf C}^{n+1}+D M {\\bf C}^{n} \\right)\n\\end{equation}\\]\nWe can transform the last equation to yield the value of of the concentration at the time index \\(n+1\\), i.e.\n\\[\\begin{equation}\n\\left({\\bf I}-\\frac{\\delta t}{2}D M \\right ){\\bf C}^{n+1}=\\left({\\bf I}+\\frac{\\delta t}{2}D M \\right ){\\bf C}^{n}\n\\end{equation}\\]\nwhere \\({\\bf I}\\) is the identity matrix. This will correspond in our code to\n\\[\\begin{equation}\n{\\bf A}{\\bf C}^{n+1}={\\bf B}{\\bf C}^{n}\n\\end{equation}\\]\nwhere \\({\\bf A}=\\left({\\bf I}-\\frac{\\delta t}{2}D M \\right )\\) and \\({\\bf B}=\\left({\\bf I}+\\frac{\\delta t}{2}D M \\right )\\)."
  },
  {
    "objectID": "lectures/lecture12/3_diffusion_equation.html#numerical-solution",
    "href": "lectures/lecture12/3_diffusion_equation.html#numerical-solution",
    "title": "Diffusion equation",
    "section": "Numerical Solution",
    "text": "Numerical Solution\nWe are now ready to write some code. To simulate diffusion, we need two key pieces of information: what happens at the edges of our system (boundary conditions) and how the concentration looks at the start (initial condition).\nLet‚Äôs imagine we‚Äôre looking at diffusion along a line of length L=1. At both ends of this line (x=0 and x=L), we‚Äôll keep the concentration at zero throughout the simulation. This might represent, for example, a situation where any particles that reach the edges are immediately removed:\n\\[\\begin{equation}\nc(0,t)=c(L,t)=0\n\\end{equation}\\]\nFor our starting condition, we‚Äôll create a bell-shaped curve (Gaussian distribution) centered in the middle of our line (at x=L/2). This is like placing a concentrated drop of ink at the center:\n\\[\\begin{equation}\nc(x,0)=\\frac{1}{\\sigma\\sqrt{2\\pi }}e^{-\\frac{(x-L/2)^2}{2\\sigma^2}}\n\\end{equation}\\]\nHere, œÉ=0.05 controls how narrow or wide our initial distribution is - a smaller œÉ means a more concentrated initial drop.\n\nSetup Domain\n\n\n\n\n\n\n\n\nInitial Conditions\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMatrix Setup\n\n\n\n\n\n\n\n\nSolution\nTo solve this system of equations, we‚Äôll use the spsolve function from the scipy.sparse.linalg module. This function is designed to solve sparse linear systems efficiently. Here is a detailed explanation of the code:\n1data = []\n2data.append(c)\n\n3for i in range(NT):\n4    A = (I -dt/2*D*M)\n5    B = (I + dt/2*D*M)*c\n6    c = sparse.linalg.spsolve(A, B)\n7    c = np.array(c)\n8    data.append(c)\n\n1\n\nInitialize empty list to store concentration profiles\n\n2\n\nStore initial condition as first element\n\n3\n\nLoop over all time steps\n\n4\n\nCreate matrix A for left side of equation: (I - dt/2D‚àÇ¬≤/‚àÇx¬≤)\n\n5\n\nCreate matrix B times current concentration: (I + dt/2D‚àÇ¬≤/‚àÇx¬≤)*c^n\n\n6\n\nSolve linear system Ac^(n+1) = Bc^n for next time step\n\n7\n\nConvert solution to numpy array for consistency\n\n8\n\nStore concentration profile of current time step"
  },
  {
    "objectID": "lectures/lecture12/3_diffusion_equation.html#where-to-go-from-here",
    "href": "lectures/lecture12/3_diffusion_equation.html#where-to-go-from-here",
    "title": "Diffusion equation",
    "section": "Where to go from here",
    "text": "Where to go from here\nThe diffusion equation we have solved here is a simple example of a partial differential equation. A similar type of equation is the heat equation, which describes how heat spreads in a material. Finally, also the Schr√∂dinger equation is a partial differential equation, which describes the time evolution of a quantum system. You could apply your knowledge of the diffusion equation to solve these more complex problems."
  },
  {
    "objectID": "lectures/lecture01/01-lecture01.html",
    "href": "lectures/lecture01/01-lecture01.html",
    "title": "Getting Started with Jupyter Notebooks",
    "section": "",
    "text": "As physicists, we need to:\n\nCalculate results from equations\nVisualize data and theoretical predictions\nDocument our work with equations and explanations\nShare reproducible results with colleagues\n\nJupyter Notebooks let us do all of this in one place!\n\n\n\n\n\n\nWhat You‚Äôll Create Today\n\n\n\nBy the end of this Lecture, you‚Äôll generate plots like this:\n\n\n\n\n\n\n\n\n\nAll from physics equations you already know!",
    "crumbs": [
      "üöÄ Week 1: Your First Physics Code",
      "Setup: Jupyter Notebooks"
    ]
  },
  {
    "objectID": "lectures/lecture01/01-lecture01.html#why-jupyter",
    "href": "lectures/lecture01/01-lecture01.html#why-jupyter",
    "title": "Getting Started with Jupyter Notebooks",
    "section": "",
    "text": "As physicists, we need to:\n\nCalculate results from equations\nVisualize data and theoretical predictions\nDocument our work with equations and explanations\nShare reproducible results with colleagues\n\nJupyter Notebooks let us do all of this in one place!\n\n\n\n\n\n\nWhat You‚Äôll Create Today\n\n\n\nBy the end of this Lecture, you‚Äôll generate plots like this:\n\n\n\n\n\n\n\n\n\nAll from physics equations you already know!",
    "crumbs": [
      "üöÄ Week 1: Your First Physics Code",
      "Setup: Jupyter Notebooks"
    ]
  },
  {
    "objectID": "lectures/lecture01/01-lecture01.html#what-is-a-jupyter-notebook",
    "href": "lectures/lecture01/01-lecture01.html#what-is-a-jupyter-notebook",
    "title": "Getting Started with Jupyter Notebooks",
    "section": "What is a Jupyter Notebook?",
    "text": "What is a Jupyter Notebook?\nA Jupyter Notebook is a web-based interactive document that combines:\n\nCode (Python) that you can run\nResults (numbers, plots, animations)\nDocumentation (text, equations in LaTeX)\n\nThink of it as a digital lab notebook for computational physics.\n\n\n\n\n\n\nKey Advantage\n\n\n\nUnlike traditional programming where you write everything first and then run it, Jupyter lets you experiment interactively - run small pieces of code, see results immediately, and build up your solution step by step.",
    "crumbs": [
      "üöÄ Week 1: Your First Physics Code",
      "Setup: Jupyter Notebooks"
    ]
  },
  {
    "objectID": "lectures/lecture01/01-lecture01.html#opening-jupyter-lab",
    "href": "lectures/lecture01/01-lecture01.html#opening-jupyter-lab",
    "title": "Getting Started with Jupyter Notebooks",
    "section": "Opening Jupyter Lab",
    "text": "Opening Jupyter Lab\n\nOption 1: Anaconda Navigator (Recommended for Beginners)\n\nOpen Anaconda Navigator\nClick Launch under JupyterLab\nYour browser opens automatically\n\n\n\nOption 2: Command Line\nOpen terminal and type:\njupyter lab\n\n\n\n\n\n\nTroubleshooting\n\n\n\nIf Jupyter doesn‚Äôt start, check: - Anaconda is installed - You‚Äôre connected to the internet (first time only) - Try restarting Anaconda Navigator",
    "crumbs": [
      "üöÄ Week 1: Your First Physics Code",
      "Setup: Jupyter Notebooks"
    ]
  },
  {
    "objectID": "lectures/lecture01/01-lecture01.html#jupyterlab-interface",
    "href": "lectures/lecture01/01-lecture01.html#jupyterlab-interface",
    "title": "Getting Started with Jupyter Notebooks",
    "section": "JupyterLab Interface",
    "text": "JupyterLab Interface\nWhen JupyterLab opens, you‚Äôll see:\n\nLeft sidebar: File browser (like Windows Explorer/Finder)\nMain area: Where notebooks open\nLauncher tab: Click ‚ÄúPython 3‚Äù under Notebook to create a new notebook\n\n\n\n\n\n\n\nTry It Yourself (Embedded Demo)\n\n\n\n\n\nHere‚Äôs a live JupyterLab environment you can experiment with:\nOpen Fullscreen",
    "crumbs": [
      "üöÄ Week 1: Your First Physics Code",
      "Setup: Jupyter Notebooks"
    ]
  },
  {
    "objectID": "lectures/lecture01/01-lecture01.html#creating-your-first-notebook",
    "href": "lectures/lecture01/01-lecture01.html#creating-your-first-notebook",
    "title": "Getting Started with Jupyter Notebooks",
    "section": "Creating Your First Notebook",
    "text": "Creating Your First Notebook\n\nClick Python 3 tile under ‚ÄúNotebook‚Äù in the Launcher\nA new tab opens with an empty notebook\nSave it: File ‚Üí Save Notebook As‚Ä¶ ‚Üí physics_week1.ipynb\n\n\n\n\n\n\n\nFile Extension\n\n\n\nJupyter notebooks end in .ipynb (IPython Notebook)",
    "crumbs": [
      "üöÄ Week 1: Your First Physics Code",
      "Setup: Jupyter Notebooks"
    ]
  },
  {
    "objectID": "lectures/lecture01/01-lecture01.html#two-types-of-cells",
    "href": "lectures/lecture01/01-lecture01.html#two-types-of-cells",
    "title": "Getting Started with Jupyter Notebooks",
    "section": "Two Types of Cells",
    "text": "Two Types of Cells\nJupyter notebooks consist of cells - individual blocks that contain either code or text.\n\nCode Cells (Default)\n\nWrite Python code here\nRun to see results\nIdentified by [ ]: on the left\n\n\n\nMarkdown Cells\n\nWrite notes, explanations, equations\nUse for documentation\nChange a cell to Markdown: Click cell, then press M key",
    "crumbs": [
      "üöÄ Week 1: Your First Physics Code",
      "Setup: Jupyter Notebooks"
    ]
  },
  {
    "objectID": "lectures/lecture01/01-lecture01.html#your-first-calculation",
    "href": "lectures/lecture01/01-lecture01.html#your-first-calculation",
    "title": "Getting Started with Jupyter Notebooks",
    "section": "Your First Calculation üéØ",
    "text": "Your First Calculation üéØ\nLet‚Äôs calculate gravitational potential energy!\n\nPhysics\n\\[E_{\\text{pot}} = mgh\\]\n\n\nCode\nType this in your first cell:\n# Gravitational potential energy\nm = 2.0    # mass in kg\ng = 9.81   # gravity in m/s¬≤\nh = 10.0   # height in m\n\nE_pot = m * g * h\n\nprint(f\"Potential energy: {E_pot} J\")\n\n\nRun It!\n\nClick the ‚ñ∂ button (top of cell), OR\nPress Shift + Enter (run and move to next cell), OR\nPress Ctrl/Cmd + Enter (run and stay)\n\nYou should see: Potential energy: 196.2 J\n\n\n\n\n\n\nPro Tip\n\n\n\nShift + Enter is the most common way to run cells - you‚Äôll use this constantly!",
    "crumbs": [
      "üöÄ Week 1: Your First Physics Code",
      "Setup: Jupyter Notebooks"
    ]
  },
  {
    "objectID": "lectures/lecture01/01-lecture01.html#essential-keyboard-shortcuts",
    "href": "lectures/lecture01/01-lecture01.html#essential-keyboard-shortcuts",
    "title": "Getting Started with Jupyter Notebooks",
    "section": "Essential Keyboard Shortcuts",
    "text": "Essential Keyboard Shortcuts\nYou‚Äôll save tons of time with these shortcuts:\n\nRunning Cells\n\n\n\nShortcut\nAction\n\n\n\n\nShift + Enter\nRun cell and move to next\n\n\nCtrl/Cmd + Enter\nRun cell and stay\n\n\n\n\n\nCell Operations (press Esc first to enter command mode)\n\n\n\nShortcut\nAction\n\n\n\n\nB\nInsert cell below\n\n\nA\nInsert cell above\n\n\nD D\nDelete cell (press D twice)\n\n\nM\nChange to Markdown cell\n\n\nY\nChange to Code cell\n\n\nZ\nUndo delete\n\n\n\n\n\nEditing\n\n\n\nShortcut\nAction\n\n\n\n\nEnter\nEnter edit mode\n\n\nEsc\nExit edit mode (command mode)\n\n\n\n\n\n\n\n\n\nTwo Modes\n\n\n\n\nEdit mode (green border): Type in cell\nCommand mode (blue border): Use keyboard shortcuts\n\nPress Esc to switch to command mode, Enter to switch to edit mode.",
    "crumbs": [
      "üöÄ Week 1: Your First Physics Code",
      "Setup: Jupyter Notebooks"
    ]
  },
  {
    "objectID": "lectures/lecture01/01-lecture01.html#try-it-multi-step-calculation",
    "href": "lectures/lecture01/01-lecture01.html#try-it-multi-step-calculation",
    "title": "Getting Started with Jupyter Notebooks",
    "section": "Try It: Multi-Step Calculation",
    "text": "Try It: Multi-Step Calculation\nLet‚Äôs calculate the time for a ball to fall from height h.\nPhysics: \\(h = \\frac{1}{2}gt^2\\) ‚Üí \\(t = \\sqrt{\\frac{2h}{g}}\\)\nYour Task:\n\nCreate a new cell below (press B)\nType this code:\n\nimport numpy as np  # We need square root\n\nh = 10.0   # height in m\ng = 9.81   # gravity in m/s¬≤\n\nt = np.sqrt(2 * h / g)\n\nprint(f\"Fall time: {t:.2f} seconds\")\n\nRun it! (Shift + Enter)",
    "crumbs": [
      "üöÄ Week 1: Your First Physics Code",
      "Setup: Jupyter Notebooks"
    ]
  },
  {
    "objectID": "lectures/lecture01/01-lecture01.html#adding-documentation-with-markdown",
    "href": "lectures/lecture01/01-lecture01.html#adding-documentation-with-markdown",
    "title": "Getting Started with Jupyter Notebooks",
    "section": "Adding Documentation with Markdown",
    "text": "Adding Documentation with Markdown\nGood physics notebooks explain what you‚Äôre doing!\n\nCreate a Markdown Cell\n\nInsert a new cell above your code (press Esc, then A)\nChange it to Markdown (press M)\nType:\n\n## Free Fall Calculation\n\nWe calculate the time for an object to fall from height $h = 10$ m.\n\nThe equation is:\n$$t = \\sqrt{\\frac{2h}{g}}$$\n\nwhere $g = 9.81 \\, \\text{m/s}^2$ is gravitational acceleration.\n\nRun the cell (Shift + Enter) to render it\n\n\n\n\n\n\n\nLaTeX Equations\n\n\n\n\nInline equation: $E = mc^2$ ‚Üí \\(E = mc^2\\)\nDisplay equation: $$E = mc^2$$ ‚Üí \\[E = mc^2\\]",
    "crumbs": [
      "üöÄ Week 1: Your First Physics Code",
      "Setup: Jupyter Notebooks"
    ]
  },
  {
    "objectID": "lectures/lecture01/01-lecture01.html#your-first-plot",
    "href": "lectures/lecture01/01-lecture01.html#your-first-plot",
    "title": "Getting Started with Jupyter Notebooks",
    "section": "Your First Plot! üìä",
    "text": "Your First Plot! üìä\nNow let‚Äôs visualize physics! This is where Jupyter really shines - you can see your calculations come to life.\n\nPlotting a Falling Ball\nLet‚Äôs plot the height of our falling ball over time. Don‚Äôt worry about understanding every detail - just see how easy it is to create beautiful graphs!\nCreate a new cell and type:\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Calculate fall time\nh = 10.0\ng = 9.81\nt_fall = np.sqrt(2 * h / g)\n\n# Create time points from 0 to landing\nt = np.linspace(0, t_fall, 50)\n\n# Calculate height at each time: h = h0 - (1/2)gt¬≤\nheight = h - 0.5 * g * t**2\n\n# Create the plot\nplt.plot(t, height, 'b-', linewidth=2)\nplt.xlabel('Time (s)')\nplt.ylabel('Height (m)')\nplt.title('Ball Falling from 10m')\nplt.grid(True, alpha=0.3)\nplt.show()\nRun it! You just created your first physics visualization! üéâ\n\n\n\n\n\n\nWhat Just Happened?\n\n\n\n\nmatplotlib.pyplot is Python‚Äôs plotting library\nnp.linspace(0, t_fall, 50) creates 50 evenly-spaced time points\nplt.plot() draws the curve\nThe labels and grid make it look professional\n\nDon‚Äôt memorize this yet - we‚Äôll cover all the details in Lecture 4. For now, just enjoy seeing your calculation as a graph!\n\n\n\n\nChallenge: Plot Velocity\nThe velocity increases as the ball falls: \\(v = gt\\)\nTry modifying the code to plot velocity vs time instead!\n\n\n\n\n\n\nSolution\n\n\n\n\n\n# Calculate velocity at each time point\nvelocity = g * t\n\nplt.plot(t, velocity, 'r-', linewidth=2)\nplt.xlabel('Time (s)')\nplt.ylabel('Velocity (m/s)')\nplt.title('Velocity of Falling Ball')\nplt.grid(True, alpha=0.3)\nplt.show()\nNotice how velocity increases linearly - exactly what the equation predicts!",
    "crumbs": [
      "üöÄ Week 1: Your First Physics Code",
      "Setup: Jupyter Notebooks"
    ]
  },
  {
    "objectID": "lectures/lecture01/01-lecture01.html#saving-your-work",
    "href": "lectures/lecture01/01-lecture01.html#saving-your-work",
    "title": "Getting Started with Jupyter Notebooks",
    "section": "Saving Your Work",
    "text": "Saving Your Work\n\n ## What‚Äôs Next? üìä\nNow that you know the basics:\n\nLater: Advanced Plotting Techniques\n\nMultiple plots, logarithmic scales, 3D plots, animations, and more\nBuild on what you just learned!\n\nNext: Variables & Numbers\n\nUnderstand Python fundamentals in detail\nLearn about data types, operations, and more\n\n\nJupyter auto-saves every few minutes, but you should also:\n\nManual save: Ctrl/Cmd + S or File ‚Üí Save Notebook\nDownload: File ‚Üí Save and Export Notebook As ‚Üí HTML/PDF\n\n\n\n\n\n\n\nImportant!\n\n\n\nSaving the notebook saves your code and markdown, but also the output. If you want a clean notebook, do: Kernel ‚Üí Restart Kernel and Clear All Outputs before saving.",
    "crumbs": [
      "üöÄ Week 1: Your First Physics Code",
      "Setup: Jupyter Notebooks"
    ]
  },
  {
    "objectID": "lectures/lecture01/01-lecture01.html#whats-next",
    "href": "lectures/lecture01/01-lecture01.html#whats-next",
    "title": "Getting Started with Jupyter Notebooks",
    "section": "What‚Äôs Next? üìä",
    "text": "What‚Äôs Next? üìä\nNow that you know the basics:\n\nNext lesson: Plotting Your First Graph\n\nYou‚Äôll create beautiful physics visualizations\n\nThen: Variables & Numbers\n\nUnderstand what you just used in detail",
    "crumbs": [
      "üöÄ Week 1: Your First Physics Code",
      "Setup: Jupyter Notebooks"
    ]
  },
  {
    "objectID": "lectures/lecture01/01-lecture01.html#quick-reference-card",
    "href": "lectures/lecture01/01-lecture01.html#quick-reference-card",
    "title": "Getting Started with Jupyter Notebooks",
    "section": "Quick Reference Card",
    "text": "Quick Reference Card\n\nMost Important Commands\nShift + Enter  ‚Üí Run cell\nEsc + B        ‚Üí New cell below\nEsc + M        ‚Üí Change to Markdown\nEsc + D D      ‚Üí Delete cell\nCtrl/Cmd + S   ‚Üí Save\n\n\nGetting Help\n\nFunction help: Type ?function_name in a cell and run\nDocumentation: Press Shift + Tab while cursor is on a function name",
    "crumbs": [
      "üöÄ Week 1: Your First Physics Code",
      "Setup: Jupyter Notebooks"
    ]
  },
  {
    "objectID": "lectures/lecture01/01-lecture01.html#advanced-topics-optional",
    "href": "lectures/lecture01/01-lecture01.html#advanced-topics-optional",
    "title": "Getting Started with Jupyter Notebooks",
    "section": "Advanced Topics (Optional)",
    "text": "Advanced Topics (Optional)\n\n\n\n\n\n\nWhat is a Kernel?\n\n\n\n\n\nThe kernel is the computational engine that runs your code. Think of it as Python running in the background.\nKernel indicator (top-right):\n\n‚ö™ Idle: Ready to run code\n‚ö´ Busy: Currently executing\n\nKernel menu operations:\n\nRestart Kernel: Clears all variables, starts fresh\nInterrupt Kernel: Stops long-running code\n\nYou‚Äôll need to restart if:\n\nVariables get messy\nCode is stuck in an infinite loop (interrupt first, then restart)\nYou want a clean slate\n\n\n\n\n\n\n\n\n\n\nMarkdown Cheatsheet\n\n\n\n\n\n# Heading 1\n## Heading 2\n### Heading 3\n\n**bold text**\n*italic text*\n\n- Bullet list\n- Another item\n\n1. Numbered list\n2. Another item\n\n[Link text](https://www.example.com)\n\nInline code: `x = 5`\n\nEquation: $E = mc^2$\n\nDisplay equation:\n$$\\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a}$$\n\n\n\n\n\n\n\n\n\nComplete Jupyter Documentation\n\n\n\n\n\nFor more advanced features (magic commands, debugging, widgets), see:\n\nOfficial Jupyter Documentation\nJupyterLab Documentation",
    "crumbs": [
      "üöÄ Week 1: Your First Physics Code",
      "Setup: Jupyter Notebooks"
    ]
  },
  {
    "objectID": "lectures/lecture01/01-lecture01.html#summary",
    "href": "lectures/lecture01/01-lecture01.html#summary",
    "title": "Getting Started with Jupyter Notebooks",
    "section": "Summary ‚úÖ",
    "text": "Summary ‚úÖ\nYou‚Äôve learned:\n\n‚úì What Jupyter notebooks are and why they‚Äôre useful for physics\n‚úì How to open JupyterLab and create a notebook\n‚úì The difference between code and Markdown cells\n‚úì How to run code and see results\n‚úì Essential keyboard shortcuts\n‚úì How to document your work with equations\n\nYou‚Äôre ready to start plotting! Move on to the next lesson.\n\n\n\n\n\n\n\nPractice Exercise\n\n\n\nBefore the next class, try this:\n\nCreate a new notebook called practice.ipynb\nCalculate the kinetic energy of a 1000 kg car traveling at 30 m/s\nUse a Markdown cell to write the equation: \\(E_k = \\frac{1}{2}mv^2\\)\nPrint the result in Joules\nBonus plotting challenge: Plot how kinetic energy changes with velocity\n\nUse velocities from 0 to 40 m/s\nHint: Copy and modify the falling ball plotting code!\n\nSave your notebook\n\nSolution: - Energy at 30 m/s: 450,000 J (or 450 kJ) - The plot should show a parabolic curve (energy ‚àù v¬≤)",
    "crumbs": [
      "üöÄ Week 1: Your First Physics Code",
      "Setup: Jupyter Notebooks"
    ]
  },
  {
    "objectID": "lectures/lecture01/3_datatypes.html",
    "href": "lectures/lecture01/3_datatypes.html",
    "title": "Data Types",
    "section": "",
    "text": "It‚Äôs time to look at different data types we may find useful in our course. Besides the number types mentioned previously, there are also other types like strings, lists, tuples, dictionaries and sets.\nEach of these data types has a number of connected methods (functions) which allow to manipulate the data contained in a variable. If you want to know which methods are available for a certain object use the command dir, e.g.\nThe following few cells will give you a short introduction into each type."
  },
  {
    "objectID": "lectures/lecture01/3_datatypes.html#strings",
    "href": "lectures/lecture01/3_datatypes.html#strings",
    "title": "Data Types",
    "section": "Strings",
    "text": "Strings\nStrings are lists of keyboard characters as well as other characters not on your keyboard. They are useful for printing results on the screen, during reading and writing of data.\n\n\n\n\n\n\n\n\n\n\n\n\nString can be concatenated using the + operator.\n\n\n\n\n\n\n\n\n\n\n\n\nAs strings are lists, each character in a string can be accessed by addressing the position in the string (see Lists section)\n\n\n\n\n\n\nStrings can also be made out of numbers.\n\n\n\n\n\n\nIf you want to obtain a number of a string, you can use what is known as type casting. Using type casting you may convert the string or any other data type into a different type if this is possible. To find out if a string is a pure number you may use the str.isnumeric method. For the above string, we may want to do a conversion to the type int by typing:\n\n\n\n\n\n\n\n\n\n\n\n\nThere are a number of methods connected to the string data type. Usually the relate to formatting or finding sub-strings. Formatting will be a topic in our next lecture. Here we just refer to one simple find example."
  },
  {
    "objectID": "lectures/lecture01/3_datatypes.html#quiz-data-types-in-python",
    "href": "lectures/lecture01/3_datatypes.html#quiz-data-types-in-python",
    "title": "Data Types",
    "section": "Quiz: Data Types in Python",
    "text": "Quiz: Data Types in Python\nLet‚Äôs test your understanding of Python data types!\n\n\nWhat is the output of the following code?\na = [1, 2, 3]\nb = (1, 2, 3)\nprint(type(a), type(b))\n\n&lt;class 'list'&gt; &lt;class 'list'&gt;\n&lt;class 'list'&gt; &lt;class 'tuple'&gt;\n&lt;class 'tuple'&gt; &lt;class 'list'&gt;\n&lt;class 'tuple'&gt; &lt;class 'tuple'&gt;\n\nWhich of the following is mutable?\n\nList\nTuple\nString\nInteger\n\nWhat will be the output of this code?\nmy_dict = {'a': 1, 'b': 2, 'c': 3}\nprint(my_dict['b'])\n\na\n2\nb\nKeyError\n\nHow do you create an empty set in Python?\n\n{}\n[]\nset()\n()\n\nWhat is the result of 3 + 4.0?\n\n7\n7.0\n‚Äò7.0‚Äô\nTypeError\n\n\n\n\n\n\n\n\n\nClick to reveal answers\n\n\n\n\n\n\n&lt;class 'list'&gt; &lt;class 'tuple'&gt;\nList\n2\nset()\n7.0"
  },
  {
    "objectID": "lectures/lecture06/01-lecture06.html",
    "href": "lectures/lecture06/01-lecture06.html",
    "title": "Lecture 6",
    "section": "",
    "text": "Advanced conditionals and loops for simulating complex scenarios.\nIntroduction to basic data structures (dictionaries) for handling multiple objects.\n\n\n\n\n\nSimulating elastic and inelastic collisions in one and two dimensions.\nApplying conservation laws (momentum and energy) to check the validity of the simulation.\nVisualization: Plotting the trajectories and velocities of colliding objects.\nHomework: Simulate a multi-object collision scenario."
  },
  {
    "objectID": "lectures/lecture06/01-lecture06.html#collisions-and-conservation-laws",
    "href": "lectures/lecture06/01-lecture06.html#collisions-and-conservation-laws",
    "title": "Lecture 6",
    "section": "",
    "text": "Advanced conditionals and loops for simulating complex scenarios.\nIntroduction to basic data structures (dictionaries) for handling multiple objects.\n\n\n\n\n\nSimulating elastic and inelastic collisions in one and two dimensions.\nApplying conservation laws (momentum and energy) to check the validity of the simulation.\nVisualization: Plotting the trajectories and velocities of colliding objects.\nHomework: Simulate a multi-object collision scenario."
  },
  {
    "objectID": "lectures/lecture06/test.html",
    "href": "lectures/lecture06/test.html",
    "title": "Title",
    "section": "",
    "text": "viewof aSlider = Inputs.range([-4, 0], { label: \"a\", step: 0.01, value: -1.7 });\nviewof bSlider = Inputs.range([-2, 2], { label: \"b\", step: 0.01, value: 1.3 });\nviewof cSlider = Inputs.range([-2, 2], { label: \"c\", step: 0.01, value: 1.0 });\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfiltered = transpose(data);\n// Create the plot\n\nxValues = Array.from({ length: 100 }, (_, i) =&gt; i / 100);\nparabolaData = xValues.map(x =&gt; ({ x, y: parabola(x, aSlider, bSlider, cSlider) }));\n\n\nparabola = (x, a, b, c) =&gt; a * x**2 + b * x + c\n\ncalculateChiSquared = (data, a, b, c) =&gt; {\n  let chisq = 0\n  let x= data.map(d =&gt; d.x)\n  let y= data.map(d =&gt; d.y)\n  let err= data.map(d =&gt; d.error)\n  for (let i = 0; i &lt; x.length; i++) {\n    let y_model = parabola(x[i], a, b, c)\n    chisq += ((y[i] - y_model) / err[i])**2\n  }\n  return chisq\n}\n\nchisq = calculateChiSquared(filtered, aSlider, bSlider, cSlider)\n\nPlot.plot({\n  marks: [\n    Plot.dot(filtered, { x: \"x\", y: \"y\" }),\n    Plot.ruleY(filtered, { x: \"x\", y1: d =&gt; d.y - d.error, y2: d =&gt; d.y + d.error }),\n    Plot.line(parabolaData, { x: \"x\", y: \"y\" }),\n    Plot.text([{ x: 0.8, y: 1.5, label: `œá¬≤: ${chisq.toFixed(2)}` }], {\n          x: \"x\",\n          y: \"y\",\n          text: \"label\",\n          dy: -10, // Adjust vertical position if needed\n          fill: \"black\", // Set text color\n          fontSize: 16\n        }),\n    Plot.frame()\n  ],\n  x: {\n    label: \"X Axis\",\n    labelAnchor: \"center\",\n    labelOffset: 35,\n    grid: true,\n    tickFormat: \".2f\", // Format ticks to 2 decimal places\n    domain: [0, 1]\n  },\n  y: {\n    label: \"Y Axis\",\n    grid: true,\n    tickFormat: \".2f\", // Format ticks to 2 decimal places\n    labelAnchor: \"center\",  // Center the label on its axis\n    labelAngle: -90,\n    labelOffset: 60,\n    domain: [0, 2],\n  },\n  width: 400,\n  height: 400,\n  marginLeft: 100,\n  marginBottom: 40,\n  style: {\n    fontSize: \"14px\",          // This sets the base font size\n    \"axis.label\": {\n      fontSize: \"18px\",        // This sets the font size for axis labels\n      fontWeight: \"bold\"       // Optionally make it bold\n    },\n    \"axis.tick\": {\n      fontSize: \"14px\"         // This sets the font size for tick labels\n    }\n  },\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHello Here‚Äôs how you can do it:\n\nStep 1: Create the DataFrame in Python\n\n\n\n\n\n\n\nimport numpy as np\nimport io\nimport matplotlib.pyplot as plt\nfrom scipy.optimize import curve_fit\nplt.rcParams.update({'font.size': 18})\nfrom ipywidgets import interact, interactive, fixed, interact_manual\nimport ipywidgets as widgets\n\n# default values for plotting\nplt.rcParams.update({'font.size': 12,\n                     'lines.linewidth': 1,\n                     'lines.markersize': 10,\n                     'axes.labelsize': 11,\n                     'xtick.labelsize' : 10,\n                     'ytick.labelsize' : 10,\n                     'xtick.top' : True,\n                     'xtick.direction' : 'in',\n                     'ytick.right' : True,\n                     'ytick.direction' : 'in',})\n\ndata_str= \"\"\"\n0.000000000000000000e+00 9.916839204057067425e-01 5.332818799198481979e-02\n1.111111111111111049e-01 1.183667840440161712e+00 5.339559646742838422e-02\n2.222222222222222099e-01 1.310862148961057017e+00 5.366783326382672248e-02\n3.333333333333333148e-01 1.193174867265999639e+00 5.435097493883071090e-02\n4.444444444444444198e-01 1.265354130824580148e+00 5.576995501488732354e-02\n5.555555555555555802e-01 1.234277634100806154e+00 5.832636573698059268e-02\n6.666666666666666297e-01 1.067204799568996387e+00 6.242706729257353759e-02\n7.777777777777776791e-01 7.113706894723520469e-01 6.840334070620925078e-02\n8.888888888888888395e-01 5.111625429539546905e-01 7.645872257082597656e-02\n1.000000000000000000e+00 1.360838209996238390e+00 4.666811165343753287e-01\n\"\"\"\nx_data, y_data, err = np.loadtxt(io.StringIO(data_str), unpack=True)\n\ndef parabola(x,a,b,c):\n    return(a*x**2+b*x+c)\n\ndef plot(a,b,c):\n    y=parabola(x,a,b,c)\n    plt.figure(figsize=(8,6))\n    chisq=(((y_data-parabola(x_data,a,b,c))/err)**2).sum()\n    plt.plot(x,y,label=r'$\\chi^2$={0:6.3f}'.format(chisq))\n    plt.errorbar(x_data,y_data,yerr=err,marker='o',fmt=\"none\",color='k')\n\n    plt.scatter(x_data,y_data,marker='o',color='k')\n    plt.legend()\n    plt.xlabel('x- position')\n    plt.ylabel('y- position')\n    plt.show()\n\nx=np.linspace(0,1,100)\ninteract(plot,a=-1.7,b=1.3,c=1.0);"
  },
  {
    "objectID": "lectures/lecture08/3_solving_ODEs.html",
    "href": "lectures/lecture08/3_solving_ODEs.html",
    "title": "Solving ODEs",
    "section": "",
    "text": "All the stuff we have defined in the previous sections is useful for solving ordinary differential equations. This will bring us closer to solving out physics problems now."
  },
  {
    "objectID": "lectures/lecture08/3_solving_ODEs.html#harmonic-oscillator",
    "href": "lectures/lecture08/3_solving_ODEs.html#harmonic-oscillator",
    "title": "Solving ODEs",
    "section": "Harmonic Oscillator",
    "text": "Harmonic Oscillator\n\n\n\n\n\n\nPhysics Interlude: The harmonic oscillator\n\n\n\nWe are going to tackle as a first very simple problem, the harmonic oscillator and we will demonstrate that with the matrix (Crank-Nicholson method or implicit scheme), the Euler type integration method and using some ‚Äòunknown‚Äô integrator in the module SciPy.\nThe equation of motion for a classical harmonic oscillator is given\n\\[\\begin{equation}\n\\frac{\\mathrm{d}^2x}{\\mathrm{d}t^2}+\\omega^2 x=0\n\\end{equation}\\]\nThis is a second order differential equation which requires for its solution two initial conditions. The first initial condition is the initial elongation \\(x(t=0)=x_{0}\\) and the second the initial velocity \\(\\dot{x}(t=0)=v_{0}\\)."
  },
  {
    "objectID": "lectures/lecture08/3_solving_ODEs.html#implicit-solution",
    "href": "lectures/lecture08/3_solving_ODEs.html#implicit-solution",
    "title": "Solving ODEs",
    "section": "Implicit Solution",
    "text": "Implicit Solution\nLets start with the matrix appraoch we have just learned about. Using the matrix version, we can transform the above equation into a system of coupled equations, which we can solve with some standard methods available from e.g.¬†the SciPy module.\n\nDefine Matrices\nOur matrix will consist of two parts. The first containing the second derivative and the second just the elongation. Suppose we want to calculate the position \\(x(t)\\) at 6 instances in time \\(t_{i}\\) then the matrix version of the second derivative reads as\n(\\(x_{1}=x(t_{1}), \\ldots\\)).\n\\(T=\\frac{d^2x}{dt^2}=\\frac{1}{\\delta t^2}\n\\begin{bmatrix}\n-2 & 1  & 0 & 0 & 0 & 0\\\\\n1 & -2 & 1 & 0 & 0 & 0\\\\\n0 & 1  & -2 & 1 & 0 & 0\\\\\n0 & 0  & 1  & -2 & 1 & 0\\\\\n0 & 0  & 0  &  1 & -2 & 1\\\\\n0 & 0  & 0  &  0 &  1 & -2\\\\\n\\end{bmatrix}\n\\begin{bmatrix}\nx_{1}\\\\\nx_{2}\\\\\nx_{3}\\\\\nx_{4}\\\\\nx_{5}\\\\\nx_{6}\n\\end{bmatrix}\\)\nThe second term in the equation of motion is a multiplication of the elongation \\(x(t_{i})\\) by \\(\\omega^{2}\\) and can be written as\n\\(V=\\omega^2 x=\\begin{bmatrix}\n\\omega^2  & 0  & 0 & 0 & 0 & 0\\\\\n0 & \\omega^2  & 0 & 0 & 0 & 0\\\\\n0 & 0  & \\omega^2  & 0 & 0 & 0\\\\\n0 & 0  & 0  & \\omega^2  & 0 & 0\\\\\n0 & 0  & 0  &  0 & \\omega^2  & 0\\\\\n0 & 0  & 0  &  0 &  0 & \\omega^2 \\\\\n\\end{bmatrix}\n\\begin{bmatrix}\nx_{1}\\\\\nx_{2}\\\\\nx_{3}\\\\\nx_{4}\\\\\nx_{5}\\\\\nx_{6}\n\\end{bmatrix}\\)\nThe left hand side of the would threfore contain a sum of the two matrices \\(M=T+V\\) multiplied by the vector \\(x\\). We have therfore almost all things together to solve this differential equation with the help of an implicit scheme. What we have ignored so far are the initial conditions.\n\n\nUse Initial Conditions\nThe matrix given for the second detivative actually implies already some initial (bounary) conditions. You probably noticed that the matrix contains incomplete coefficients for the second derivative in the first and last line. The first line contains \\((-2,1)\\), but the second derivative should contain \\((1,-2,1)\\). This \\((-2,1)\\) thus always includes the boundary condition that \\(x_{0}=0\\). To include our own initial/boundary conditions, we have to construct the matrix for the second derivative slightly differently and modify the differential equation to\n\\[\\begin{equation}\n\\frac{\\mathrm{d}^2x}{\\mathrm{d}t^2}+\\omega^2 x=b\n\\end{equation}\\]\nwhere the vector b takes care of the initial conditions.\nIf we have \\(N\\) positions in time at which we calculate the elongation \\(x\\), we have a \\(N\\times N\\) matrix of for the second derivatives. The lower \\(N-2\\) lines will contain the the coefficients for the second derivative \\((1,-2,1)\\). The first two lines supply the initial/boundary conditions.\nThe initial condition for the elongation \\(x(t=0)=x_{0}\\) is obtained when the first element of the first line is a 1. The matrix multiplication \\(M\\, x=b\\) for yields thus in the first line \\(x_{1}=b_{1}\\) and we set \\(b_{1}=x_{0}\\). The second line shall give the initial velocity. So the matrix entries of the second line contain a first derivative \\((-1,1)\\). The matrix multiplication thus yields \\(x_{2}-x_{1}=b_{2}\\). We can therefore need to set \\(b_{2}=v_{0}\\delta t\\). All of the other entries of \\(b\\) shall be set to zero according to the differential equation of the harmonic oscillator.\nOur final problem \\(M\\, x=b\\) will thus have the following shape\n\\[\\begin{equation}\n\\begin{bmatrix}\n1 & 0  & 0 & 0 & 0 & 0\\\\\n-1 & 1 & 0 & 0 & 0 & 0\\\\\n1 & -2+\\omega^2*\\delta t^2  & 1 & 0 & 0 & 0\\\\\n0 & 1  & -2+\\omega^2*\\delta t^2  & 1 & 0 & 0\\\\\n0 & 0  & 1  &  -2+\\omega^2*\\delta t^2 & 1 & 0\\\\\n0 & 0  & 0  &  1 &  -2+\\omega^2*\\delta t^2 & 1\\\\\n\\end{bmatrix}\n\\begin{bmatrix}\nx_{1}\\\\\nx_{2}\\\\\nx_{3}\\\\\nx_{4}\\\\\nx_{5}\\\\\nx_{6}\n\\end{bmatrix}=\n\\begin{bmatrix}\nx_{0}\\\\\nv_{0}\\delta t\\\\\n0\\\\\n0\\\\\n0\\\\\n0\n\\end{bmatrix}\n\\end{equation}\\]\n\n\nSolution\nThis is the final system of coupled equations which we can supply to any matrix solver. We will use a solver from the scipy.linalg module. Lets have a look at the details below.\nN=10\n\n(diags([-2., 1., 1.], [-1,-2, 0],\n    shape=(N, N))+diags([1], [-1], shape=(N, N))* omega**2*dt**2)"
  },
  {
    "objectID": "lectures/lecture08/3_solving_ODEs.html#explicit-solution---numerical-integration",
    "href": "lectures/lecture08/3_solving_ODEs.html#explicit-solution---numerical-integration",
    "title": "Solving ODEs",
    "section": "Explicit Solution - Numerical Integration",
    "text": "Explicit Solution - Numerical Integration\nBefore implementing explicit numerical schemes, let‚Äôs develop a standardized approach for solving ODEs. This framework will allow us to solve different problems using various methods with minimal code modification.\nLet‚Äôs examine the free fall problem as an example:\n\\[\\begin{equation}\n\\ddot{x}= -g\n\\end{equation}\\]\nThis second-order equation can be transformed into a system of two first-order equations:\n\\[\\begin{eqnarray}\n\\dot{x} &= v \\\\\n\\dot{v} &= -g\n\\end{eqnarray}\\]\nUsing the Euler method, these equations become:\n\\[\\begin{eqnarray}\nx_{i+1} &= x_i + v_i \\Delta t \\\\\nv_{i+1} &= v_i - g\\Delta t\n\\end{eqnarray}\\]\nNote: The original equations had \\(\\dot{x}\\) and \\(\\dot{v}\\) in the right-hand side, which should be replaced with their actual values (\\(v\\) and \\(-g\\) respectively).\nThese equations can be written more compactly in vector form:\n\\[\\begin{equation}\n\\vec{y}_{i+1} = \\vec{y}_i + \\dot{\\vec{y}}_i \\Delta t\n\\end{equation}\\]\nwhere\n\\[\\begin{equation}\n\\vec{y}=\n\\begin{bmatrix}\nx \\\\\nv\n\\end{bmatrix}\n\\end{equation}\\]\nand\n\\[\\begin{equation}\n\\dot{\\vec{y}}=\n\\begin{bmatrix}\nv \\\\\n-g\n\\end{bmatrix}\n\\end{equation}\\]\nThis vector formulation allows us to separate: 1. Problem definition (specifying \\(\\dot{\\vec{y}}\\) as a function of \\(\\vec{y}\\) and \\(t\\)) 2. Solution method (implementing the numerical integration scheme)\nWe‚Äôll explore three numerical methods:\n\nEuler Method: First-order accurate\nEuler-Cromer Method: Modified Euler method, better for oscillatory systems\nMidpoint Method: Second-order accurate\n\nMore sophisticated methods like the Runge-Kutta family offer higher accuracy but are not covered here.\n\nEuler Method\nThe Euler method is derived from the Taylor expansion of the solution \\(\\vec{y}(t)\\) around the current time \\(t\\):\n\\[\\begin{equation}\n\\vec{y}(t+\\Delta t)=\\vec{y}(t)+\\dot{\\vec{y}}(t)\\Delta t+\\frac{1}{2}\\ddot{\\vec{y}}(t)\\Delta t^{2}+ \\mathcal{O}(\\Delta t^3)\n\\end{equation}\\]\nThe Euler method approximates this by truncating after the first-order term:\n\\[\\begin{equation}\n\\vec{y}(t+\\Delta t) \\approx \\vec{y}(t) + \\dot{\\vec{y}}(t) \\Delta t\n\\end{equation}\\]\nFor our free fall example, this becomes:\n\\[\\begin{equation}\n\\begin{bmatrix} x_{i+1} \\\\ v_{i+1} \\end{bmatrix} =\n\\begin{bmatrix} x_i \\\\ v_i \\end{bmatrix} +\n\\begin{bmatrix} v_i \\\\ -g \\end{bmatrix} \\Delta t\n\\end{equation}\\]\nError Analysis: The method has two distinct types of errors. The local truncation error, which represents the error made in a single step, is of order \\(\\mathcal{O}(\\Delta t^2)\\). This corresponds to the first term omitted in the Taylor expansion. The global truncation error, which accumulates over the entire integration interval \\([0,\\tau]\\), is of order \\(\\mathcal{O}(\\Delta t)\\). This can be understood by considering that we take \\(N = \\tau/\\Delta t\\) steps, each contributing an error proportional to \\(\\Delta t^2\\). The total error thus scales as \\(N \\cdot \\Delta t^2 = \\tau \\Delta t\\).\nLimitations and Extensions: The method is directly applicable only to first-order systems of the form \\(\\dot{\\vec{y}} = \\vec{f}(\\vec{y},t)\\). However, this is not a fundamental limitation as higher-order equations can be converted to systems of first-order equations. For example, a second-order equation \\(\\ddot{x} = f(x,\\dot{x},t)\\) can be transformed into a system of two first-order equations by introducing the velocity as an additional variable. The resulting system becomes:\n\\[\\begin{equation}\n\\begin{bmatrix} \\dot{x} \\\\ \\dot{v} \\end{bmatrix} =\n\\begin{bmatrix} v \\\\ f(x,v,t) \\end{bmatrix}\n\\end{equation}\\]\nThis transformation allows us to apply the method to a wider class of problems while maintaining its fundamental characteristics.\n\n\nEuler-Cromer Method\nThe Euler-Cromer method (also known as the semi-implicit Euler method) modifies the basic Euler method by using the updated velocity when calculating the position. For a system described by position and velocity:\n\\[\\begin{equation}\n\\begin{aligned}\n\\dot{x} &= v \\\\\n\\dot{v} &= f(x,v,t)\n\\end{aligned}\n\\end{equation}\\]\nThe integration steps are:\n\\[\\begin{equation}\n\\begin{aligned}\nv_{i+1} &= v_i + f(x_i,v_i,t_i)\\Delta t \\\\\nx_{i+1} &= x_i + v_{i+1}\\Delta t\n\\end{aligned}\n\\end{equation}\\]\nFor our free fall example: \\[\\begin{equation}\n\\begin{aligned}\nv_{i+1} &= v_i - g\\Delta t \\\\\nx_{i+1} &= x_i + v_{i+1}\\Delta t\n\\end{aligned}\n\\end{equation}\\]\nEnergy Behavior: The method shows improved energy conservation for oscillatory systems compared to the standard Euler method. While the Euler method typically increases energy over time, the Euler-Cromer method exhibits small energy oscillations around the correct value.\nError Analysis: The method maintains a local truncation error of \\(\\mathcal{O}(\\Delta t^2)\\) and a global truncation error of \\(\\mathcal{O}(\\Delta t)\\). Despite having the same order of accuracy as the Euler method, it provides more stable solutions for oscillatory systems.\nAdvantages: The Euler-Cromer method represents a simple modification of the Euler method that achieves better stability for oscillatory systems without requiring additional function evaluations.\nLimitations: The method remains first-order accurate globally and is not symmetric in time. While it performs well for certain types of problems, particularly oscillatory systems, it may not be suitable for all differential equations.\nComparison with Euler Method:\n# Euler Method\nv[i+1] = v[i] + f(x[i],v[i],t[i])*dt\nx[i+1] = x[i] + v[i]*dt       # Uses old velocity\n\n# Euler-Cromer Method\nv[i+1] = v[i] + f(x[i],v[i],t[i])*dt\nx[i+1] = x[i] + v[i+1]*dt     # Uses new velocity\n\n\nMidpoint Method\nThe Midpoint Method (also known as the second-order Runge-Kutta method) improves upon both the Euler and Euler-Cromer methods by using the average of the derivatives at the current point and an estimated midpoint.\nFor a system of first-order differential equations:\n\\[\\begin{equation}\n\\dot{\\vec{y}} = \\vec{f}(\\vec{y},t)\n\\end{equation}\\]\nThe algorithm proceeds in two steps:\n\nCalculate an intermediate point using an Euler step to the midpoint: \\[\\begin{equation}\n\\vec{k}_1 = \\vec{f}(\\vec{y}_i,t_i)\n\\end{equation}\\] \\[\\begin{equation}\n\\vec{y}_{i+1/2} = \\vec{y}_i + \\frac{\\Delta t}{2}\\vec{k}_1\n\\end{equation}\\]\nUse the derivative at this midpoint for the full step: \\[\\begin{equation}\n\\vec{k}_2 = \\vec{f}(\\vec{y}_{i+1/2},t_i+\\Delta t/2)\n\\end{equation}\\] \\[\\begin{equation}\n\\vec{y}_{i+1} = \\vec{y}_i + \\Delta t\\vec{k}_2\n\\end{equation}\\]\n\nFor our free fall example, this becomes:\n\\[\\begin{equation}\n\\begin{aligned}\nv_{i+1/2} &= v_i - \\frac{g\\Delta t}{2} \\\\\nx_{i+1/2} &= x_i + v_i\\frac{\\Delta t}{2} \\\\\nv_{i+1} &= v_i - g\\Delta t \\\\\nx_{i+1} &= x_i + v_{i+1/2}\\Delta t\n\\end{aligned}\n\\end{equation}\\]\nError Analysis: The method achieves higher accuracy than both Euler and Euler-Cromer methods with:\n\nLocal truncation error: \\(\\mathcal{O}(\\Delta t^3)\\)\nGlobal truncation error: \\(\\mathcal{O}(\\Delta t^2)\\)\n\nImplementation:\ndef midpoint_step(y, t, dt, f):\n    # Calculate k1\n    k1 = f(y, t)\n\n    # Calculate midpoint\n    y_mid = y + 0.5 * dt * k1\n\n    # Calculate k2 at midpoint\n    k2 = f(y_mid, t + 0.5*dt)\n\n    # Full step using midpoint derivative\n    return y + dt * k2\n\n\n\n\n\n\n\n\n\n\n\nPutting it all together\nNow we can implement our numerical solution by combining our understanding of both the physical system and numerical methods. This implementation consists of two main parts: defining the differential equation and solving it numerically.\n\nThe Definition of the Problem\nFor the simple harmonic oscillator, we start with the second-order differential equation:\n\\[\\begin{equation}\n\\frac{d^2x}{dt^2} + \\omega^2x = 0\n\\end{equation}\\]\nTo solve this numerically, we convert it to a system of first-order equations using our state vector \\(\\vec{y} = [x, v]^T\\):\n\\[\\begin{equation}\n\\frac{d}{dt}\\begin{bmatrix} x \\\\ v \\end{bmatrix} =\n\\begin{bmatrix} v \\\\ -\\omega^2x \\end{bmatrix}\n\\end{equation}\\]\nThis is implemented as: ~~~ def SHO(state, time): ‚Äú‚Äú‚Äù Define the harmonic oscillator system. state[0] : position x state[1] : velocity v returns : [dx/dt, dv/dt] ‚Äú‚Äú‚Äù g0 = state[1] # dx/dt = v g1 = -k/m*state[0] # dv/dt = -œâ¬≤x return np.array([g0, g1]) ~~~\nThis function defines our physical system by returning the derivatives of our state variables at any given point.\n\n\nSolving the Problem\nWith our system defined, we can implement the numerical solution using Euler‚Äôs method. The basic algorithm takes the current state and advances it by one time step:\ndef euler(y, t, dt, derivs):\n    \"\"\"\n    Perform one step of the Euler method.\n    y      : current state [x, v]\n    t      : current time\n    dt     : time step\n    derivs : function returning derivatives\n    \"\"\"\n    y_next = y + derivs(y, t) * dt\n    return y_next\nThis simple structure allows us to solve different physical problems by just changing the derivative function. For example, we can solve the free fall problem with initial conditions \\(x_0=0\\) and \\(v_0=10\\), or the harmonic oscillator with specified spring constant \\(k\\) and mass \\(m\\).\nThe key advantage of this structure lies in its flexibility. We can change the physical system by providing a different derivative function, implement various numerical methods by modifying the integration step, and explore the system behavior by adjusting parameters and initial conditions. This modular approach allows us to study a wide range of physical systems using the same basic numerical framework."
  },
  {
    "objectID": "lectures/lecture08/3_solving_ODEs.html#sec-solving-ODE",
    "href": "lectures/lecture08/3_solving_ODEs.html#sec-solving-ODE",
    "title": "Solving ODEs",
    "section": "Solving the Harmonic Oscillator with SciPy",
    "text": "Solving the Harmonic Oscillator with SciPy\nHaving explored basic numerical integration methods, we can now utilize more sophisticated tools available in SciPy. The scipy.integrate.odeint() function provides a robust and accurate integration method with several advantages over our simple implementations.\nTo use SciPy‚Äôs integrator:\nfrom scipy.integrate import odeint\nThe basic syntax is:\nsolution = odeint(derivative_function, initial_conditions, time_points)\nwhere:\n\nderivative_function defines the system (like our SHO function)\ninitial_conditions is a vector containing \\([x_0, v_0]\\)\ntime_points is an array of times at which to compute the solution\n\nThe odeint function offers several significant advantages over our simple implementations. It features adaptive step size control, which automatically adjusts the integration step size based on the local error. The function performs continuous error estimation and correction to maintain accuracy throughout the integration. It also provides various integration methods that can be selected based on the problem‚Äôs requirements. The function is capable of handling stiff equations, which are particularly challenging for simpler methods, and generally provides better numerical stability across a wide range of problems.\nFor example, to solve the harmonic oscillator:\ndef SHO(state, t, k=1.0, m=1.0):\n    x, v = state\n    return [v, -k/m * x]\n\n# Initial conditions\ny0 = [1.0, 0.0]  # x‚ÇÄ = 1, v‚ÇÄ = 0\nt = np.linspace(0, 10, 1000)\n\n# Solve the system\nsolution = odeint(SHO, y0, t)\nThe solution array contains:\n\nsolution[:, 0]: position values\nsolution[:, 1]: velocity values\n\nHaving understood the fundamentals of numerical integration through our implementations of Euler and other methods, we can now confidently use this more sophisticated tool for solving differential equations more accurately and efficiently.\n\nSetup\n\n\n\n\n\n\n\n\nDefinition\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n\n\nPlotting"
  },
  {
    "objectID": "lectures/lecture08/3_solving_ODEs.html#damped-driven-pendulum-in-scipy",
    "href": "lectures/lecture08/3_solving_ODEs.html#damped-driven-pendulum-in-scipy",
    "title": "Solving ODEs",
    "section": "Damped Driven Pendulum in SciPy",
    "text": "Damped Driven Pendulum in SciPy\nWrite a derivs function for a damped driven pendulum:\n\\[\\begin{equation}\n\\ddot{\\theta}=-\\frac{g}{L}\\sin(\\theta)-b \\dot{\\theta}+\\beta\\cos(\\omega t)\n\\end{equation}\\]\nUse this derivs function with the SciPy solver and plot the result for different parameters. Vary the damping parameter \\(b\\). Observe the contributions of the homogeneous and the particular solution. Plot the amplitude of the stationary solution as a function of frequency!\n\nSetup\n\n\n\n\n\n\n\n\nDefinition\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n\n\nPlotting"
  },
  {
    "objectID": "lectures/lecture08/4_solving_ODEs.html",
    "href": "lectures/lecture08/4_solving_ODEs.html",
    "title": "Solving Ordinary Differential Equations (ODEs)",
    "section": "",
    "text": "This lecture covers methods for solving ordinary differential equations (ODEs), which are fundamental to many physics problems. We‚Äôll explore different numerical approaches, from basic to more sophisticated methods."
  },
  {
    "objectID": "lectures/lecture08/4_solving_ODEs.html#introduction",
    "href": "lectures/lecture08/4_solving_ODEs.html#introduction",
    "title": "Solving Ordinary Differential Equations (ODEs)",
    "section": "",
    "text": "This lecture covers methods for solving ordinary differential equations (ODEs), which are fundamental to many physics problems. We‚Äôll explore different numerical approaches, from basic to more sophisticated methods."
  },
  {
    "objectID": "lectures/lecture08/4_solving_ODEs.html#the-harmonic-oscillator",
    "href": "lectures/lecture08/4_solving_ODEs.html#the-harmonic-oscillator",
    "title": "Solving Ordinary Differential Equations (ODEs)",
    "section": "The Harmonic Oscillator",
    "text": "The Harmonic Oscillator\n\n\n\n\n\n\nThe Classical Harmonic Oscillator\n\n\n\nThe harmonic oscillator represents one of the most important physical systems, appearing in: - Mechanical oscillations (springs, pendulums) - Electrical circuits (LC circuits) - Quantum mechanics (quantum harmonic oscillator) - Molecular vibrations\nThe equation of motion is:\n\\[\\begin{equation}\n\\frac{d^2x}{dt^2} + \\omega^2 x = 0\n\\end{equation}\\]\nwhere: - \\(x\\) is the displacement - \\(t\\) is time - \\(\\omega = \\sqrt{k/m}\\) is the angular frequency - \\(k\\) is the spring constant - \\(m\\) is the mass\nInitial conditions required: - Initial position: \\(x(t=0) = x_0\\) - Initial velocity: \\(\\dot{x}(t=0) = v_0\\)"
  },
  {
    "objectID": "lectures/lecture08/4_solving_ODEs.html#numerical-solution-methods",
    "href": "lectures/lecture08/4_solving_ODEs.html#numerical-solution-methods",
    "title": "Solving Ordinary Differential Equations (ODEs)",
    "section": "Numerical Solution Methods",
    "text": "Numerical Solution Methods\n\n1. Implicit Solution (Crank-Nicolson Method)\nThe matrix approach transforms our second-order ODE into a system of coupled equations. This method is particularly stable for oscillatory systems.\n\nMatrix Construction\nFor \\(N\\) time points, we construct two matrices:\n\nThe second derivative matrix (\\(T\\)):\n\n\\[\\begin{equation}\nT=\\frac{1}{\\delta t^2}\n\\begin{bmatrix}\n-2 & 1  & 0 & \\cdots & 0\\\\\n1 & -2 & 1 & \\cdots & 0\\\\\n\\vdots & \\ddots & \\ddots & \\ddots & \\vdots\\\\\n0 & \\cdots & 1 & -2 & 1\\\\\n0 & \\cdots & 0 & 1 & -2\n\\end{bmatrix}\n\\end{equation}\\]\n\nThe potential term matrix (\\(V\\)):\n\n\\[\\begin{equation}\nV = \\omega^2\n\\begin{bmatrix}\n1 & 0 & \\cdots & 0\\\\\n0 & 1 & \\cdots & 0\\\\\n\\vdots & \\vdots & \\ddots & \\vdots\\\\\n0 & 0 & \\cdots & 1\n\\end{bmatrix}\n\\end{equation}\\]"
  },
  {
    "objectID": "lectures/lecture08/4_solving_ODEs.html#explicit-solution-methods",
    "href": "lectures/lecture08/4_solving_ODEs.html#explicit-solution-methods",
    "title": "Solving Ordinary Differential Equations (ODEs)",
    "section": "Explicit Solution Methods",
    "text": "Explicit Solution Methods\n\nState-Space Representation\nTo implement explicit numerical methods effectively, we first convert our second-order ODE into a system of first-order equations. This state-space representation is crucial for numerical integration.\nFor the harmonic oscillator:\n\\[\\begin{equation}\n\\ddot{x} + \\omega^2x = 0\n\\end{equation}\\]\nWe define: - Position: \\(x\\) - Velocity: \\(v = \\dot{x}\\)\nThis gives us the system:\n\\[\\begin{equation}\n\\begin{bmatrix} \\dot{x} \\\\ \\dot{v} \\end{bmatrix} =\n\\begin{bmatrix} v \\\\ -\\omega^2x \\end{bmatrix}\n\\end{equation}\\]\nOur state vector is:\n\\[\\begin{equation}\ny = \\begin{bmatrix} x \\\\ v \\end{bmatrix}\n\\end{equation}\\]\n\n\n1. Euler Method\nThe Euler method is the simplest numerical integration technique. It comes directly from the Taylor expansion:\n\\[\\begin{equation}\ny(t + \\Delta t) = y(t) + \\dot{y}(t)\\Delta t + O(\\Delta t^2)\n\\end{equation}\\]\n\n\n\n\n\n\n\n\n2. Euler-Cromer Method\nThe Euler-Cromer method (also known as the semi-implicit Euler method) is particularly good for oscillatory systems because it conserves energy better than the standard Euler method.\nKey difference: - Uses the updated velocity to compute position - Better energy conservation for oscillatory systems\n\\[\\begin{align}\nv_{i+1} &= v_i - \\omega^2 x_i \\Delta t \\\\\nx_{i+1} &= x_i + v_{i+1} \\Delta t\n\\end{align}\\]\n\n\n\n\n\n\n\n\n3. Velocity Verlet Method\nThe Velocity Verlet method is a symplectic integrator that provides excellent energy conservation for Hamiltonian systems. It‚Äôs particularly useful for molecular dynamics simulations.\nThe algorithm: 1. Update position using current velocity and acceleration 2. Calculate new acceleration at new position 3. Update velocity using average of old and new accelerations\n\\[\\begin{align}\nx_{i+1} &= x_i + v_i\\Delta t + \\frac{1}{2}a_i\\Delta t^2 \\\\\na_{i+1} &= -\\omega^2 x_{i+1} \\\\\nv_{i+1} &= v_i + \\frac{1}{2}(a_i + a_{i+1})\\Delta t\n\\end{align}\\]\n\n\n\n\n\n\n\n\nComparison of Methods\nLet‚Äôs compare these methods for the harmonic oscillator:\n\n\n\n\n\n\n\n\n\n\n\n\nMethod Characteristics\n\n\n\n\nEuler Method:\n\nSimplest method\nFirst-order accurate (\\(O(\\Delta t)\\))\nOften unstable for oscillatory systems\nEnergy tends to increase over time\n\nEuler-Cromer Method:\n\nBetter energy conservation\nStill first-order accurate\nMore stable for oscillatory systems\nEnergy tends to decrease slightly over time\n\nVelocity Verlet Method:\n\nSecond-order accurate (\\(O(\\Delta t^2)\\))\nExcellent energy conservation\nSymplectic (preserves phase space volume)\nRecommended for long-time integration"
  },
  {
    "objectID": "lectures/lecture08/4_solving_ODEs.html#solving-odes-with-scipy",
    "href": "lectures/lecture08/4_solving_ODEs.html#solving-odes-with-scipy",
    "title": "Solving Ordinary Differential Equations (ODEs)",
    "section": "Solving ODEs with SciPy",
    "text": "Solving ODEs with SciPy\nSciPy provides sophisticated ODE solvers through scipy.integrate.odeint and scipy.integrate.solve_ivp. These implementations use advanced algorithms with automatic step size adjustment and error control.\n\nUsing scipy.integrate.odeint\nThe odeint function uses the LSODA algorithm from the FORTRAN library ODEPACK, which automatically switches between methods for stiff and non-stiff problems.\n\n\n\n\n\n\nStiff vs Non-stiff Problems\n\n\n\n\nStiff problems: Have multiple timescales with widely different magnitudes\nNon-stiff problems: Have timescales of similar magnitude\n\nLSODA uses: - Adams method for non-stiff problems - BDF method (Backward Differentiation Formula) for stiff problems\n\n\n\n\n\n\n\n\n\n\nUsing scipy.integrate.solve_ivp\nThe newer solve_ivp function provides more control over the integration process and supports multiple modern solving methods.\n\n\n\n\n\n\n\n\n\n\n\n\nAvailable Methods in solve_ivp\n\n\n\n\nRK45 (default):\n\nExplicit Runge-Kutta method of order 5(4)\nGood general-purpose method\nAdaptive step size\n\nRK23:\n\nExplicit Runge-Kutta method of order 3(2)\nUsually faster but less accurate than RK45\nGood for rough solutions\n\nDOP853:\n\nExplicit Runge-Kutta method of order 8\nHigh accuracy\nMore expensive computationally\n\nBDF:\n\nImplicit method\nGood for stiff problems\nVariable order (1 to 5)\n\nLSODA:\n\nAutomatic method switching\nAdapts between Adams and BDF\nGood all-purpose solver\n\n\n\n\n\n\nAdvantages of SciPy Methods\n\nAdaptive Step Size:\n\nAutomatically adjusts step size for efficiency\nMaintains desired accuracy\nHandles rapid changes better\n\nError Control:\n\nSpecified through relative and absolute tolerances\nEnsures solution reliability\nProvides error estimates\n\nMethod Selection:\n\nChoose method based on problem characteristics\nAutomatic stiffness detection (LSODA)\nHigher-order methods available\n\nDense Output:\n\nContinuous solution representation\nInterpolation between steps\nEfficient for plotting or further analysis"
  },
  {
    "objectID": "lectures/lecture08/4_solving_ODEs.html#damped-driven-pendulum",
    "href": "lectures/lecture08/4_solving_ODEs.html#damped-driven-pendulum",
    "title": "Solving Ordinary Differential Equations (ODEs)",
    "section": "Damped Driven Pendulum",
    "text": "Damped Driven Pendulum\nThe damped driven pendulum is an excellent example of a nonlinear system that can exhibit both regular and chaotic behavior.\n\n\n\n\n\n\nThe Damped Driven Pendulum Equation\n\n\n\nThe equation of motion is:\n\\[\\begin{equation}\n\\ddot{\\theta} + \\frac{g}{L}\\sin(\\theta) + b\\dot{\\theta} = \\beta\\cos(\\omega t)\n\\end{equation}\\]\nwhere: - \\(\\theta\\) is the angle from vertical - \\(g\\) is gravitational acceleration - \\(L\\) is pendulum length - \\(b\\) is damping coefficient - \\(\\beta\\) is driving amplitude - \\(\\omega\\) is driving frequency\n\n\n\n\n\n\n\n\n\nParameter Study: Transition to Chaos\nLet‚Äôs examine how the system behavior changes with driving amplitude:\n\n\n\n\n\n\n\n\n\n\n\n\nKey Features of the Damped Driven Pendulum\n\n\n\n\nRegular Motion:\n\nSmall driving forces lead to periodic motion\nSystem settles into a stable orbit\nPredictable long-term behavior\n\nChaotic Motion:\n\nLarger driving forces can lead to chaos\nSensitive dependence on initial conditions\nUnpredictable long-term behavior\n\nBifurcations:\n\nSystem can transition between different types of motion\nCritical points where behavior changes qualitatively\nPeriod doubling route to chaos\n\nEnergy Balance:\n\nDriving force adds energy\nDamping removes energy\nCompetition leads to rich dynamics\n\n\n\n\n\n\nEnergy Analysis\nLet‚Äôs analyze the system‚Äôs energy over time:\n\n\n\n\n\n\nThis completes our analysis of the damped driven pendulum, demonstrating its rich dynamical behavior and various analysis techniques. The system serves as an excellent example of how nonlinearity can lead to complex behavior in even seemingly simple mechanical systems."
  },
  {
    "objectID": "lectures/lecture09/3_fourier_analysis.html",
    "href": "lectures/lecture09/3_fourier_analysis.html",
    "title": "Fourier Analysis",
    "section": "",
    "text": "Fourier analysis, or the description of functions as a series of sine and cosine functions, serves as a powerful tool in both numerical data analysis and the solution of differential equations. In experimental physics, Fourier transforms find widespread applications. For instance, optical tweezers utilize frequency spectra to characterize positional fluctuations, while Lock-In detection employs Fourier analysis for specific frequency signals. Additionally, many optical phenomena can be understood through the lens of Fourier transforms.\nFourier analysis extends far beyond these examples, finding applications across numerous fields of physics and engineering. In this lecture, we will examine Fourier Series and Fourier transforms from a mathematical perspective. We will apply these concepts to analyze the frequency spectrum of oscillations in coupled pendula, and later revisit them when simulating the motion of a Gaussian wavepacket in quantum mechanics."
  },
  {
    "objectID": "lectures/lecture09/3_fourier_analysis.html#fourier-series",
    "href": "lectures/lecture09/3_fourier_analysis.html#fourier-series",
    "title": "Fourier Analysis",
    "section": "Fourier series",
    "text": "Fourier series\nA Fourier series represents a periodic function \\(f(t)\\) with period \\(2\\pi\\) or, more generally, any arbitrary interval \\(T\\) as a sum of sine and cosine functions:\n\\[\nf(t)=\\frac{A_{0}}{2}+\\sum_{k=1}^{\\infty}\\left ( A_{k}\\cos\\left (\\omega_k t\\right) + B_{k}\\sin\\left (\\omega_k t\\right)\\right )\n\\tag{1}\\]\nwhere \\(\\omega_k=\\frac{2\\pi k}{T}\\). Here, \\(T\\) represents the period of the cosine and sine functions, with their amplitudes defined by the coefficients \\(A_k\\) and \\(B_k\\). The term \\(A_0\\) represents a constant offset added to the oscillating functions. Equation¬†1 expresses an arbitrary periodic function \\(f(t)\\) on an interval T as a sum of oscillating sine and cosine functions with discrete frequencies (\\(\\omega_k\\)):\n\\[\\begin{equation*}\n\\omega_k= 0, \\frac{2\\pi}{T}, \\frac{4\\pi}{T}, \\frac{6\\pi}{T}, ... , \\frac{n\\pi}{T}\n\\end{equation*}\\]\nand varying amplitudes. We can demonstrate that the cosine and sine functions in the sum (Equation¬†1) are orthogonal using the trigonometric identity:\n\\[\\begin{equation}\n\\sin(\\omega_{i} t)\\sin(\\omega_{k}t )=\\frac{1}{2}\\lbrace\\cos((\\omega_{i}-\\omega_{k})t)- \\cos((\\omega_{i}+\\omega_{k})t\\rbrace\n\\end{equation}\\]\nThis leads to the integral:\n\\[\\begin{equation}\n\\int\\limits_{-\\frac{T}{2}}^{+\\frac{T}{2}}  \\sin(\\omega_{i}t)\\sin (\\omega_k t) dt\n\\end{equation}\\]\nwhich splits into two integrals over cosine functions with sum \\((\\omega_{1}+\\omega_{2})\\) and difference frequency \\((\\omega_{1}-\\omega_{2})\\). With \\(\\omega_k=k 2\\pi/T\\), \\((k \\in \\mathbb{Z}^+ )\\), this evaluates to:\n\\[\\begin{equation}\n\\int\\limits_{-\\frac{T}{2}}^{+\\frac{T}{2}}  \\sin(\\omega_{i}t)\\sin (\\omega_k t) dt  =\\begin{cases}\n0 &\\text{for }  i\\neq k, \\\\\nT/2 &\\text{for }  i=k\n\\end{cases}\n\\end{equation}\\]\nA similar result holds for cosine functions:\n\\[\\begin{equation}\n\\int\\limits_{-\\frac{T}{2}}^{+\\frac{T}{2}}  \\cos(\\omega_{i}t)\\cos (\\omega_k t) dt  =\\begin{cases}\n0 &\\text{for }  i\\neq k, \\\\\nT/2 &\\text{for }  i=k\n\\end{cases}\n\\end{equation}\\]\nThe coefficients \\(A_k\\) and \\(B_k\\) are determined by projecting the function \\(f(t)\\) onto these basis functions:\n\\[\\begin{align}\n\\int\\limits_{-\\frac{T}{2}}^{+\\frac{T}{2}} & \\cos (\\omega_k t) dt  =\\begin{cases}\n0 &\\text{for }  k\\neq0, \\\\\nT &\\text{for }  k=0\n\\end{cases} \\\\\n\\int\\limits_{-\\frac{T}{2}}^{+\\frac{T}{2}} & \\sin(\\omega_k t) dt=0  \\text{ for all }k\n\\end{align}\\]\nFor the cosine coefficients:\n\\[\\begin{equation}\\label{A_k}\nA_k=\\frac{2}{T}\\int\\limits_{-\\frac{T}{2}}^{+\\frac{T}{2}} f(t)\\cos(\\omega_k t) dt  \\text{ for } k \\neq 0\n\\end{equation}\\]\nand the constant term:\n\\[\\begin{equation}\nA_0= \\frac{1}{T}\\int\\limits_{-\\frac{T}{2}}^{+\\frac{T}{2}} f(t) dt\n\\end{equation}\\]\nFinally, for the sine coefficients:\n\\[\\begin{equation}\\label{B_k}\nB_k=\\frac{2}{T}\\int\\limits_{-\\frac{T}{2}}^{+\\frac{T}{2}} f(t) \\sin(\\omega_k t) dt,\\,  \\forall k\n\\end{equation}\\]"
  },
  {
    "objectID": "lectures/lecture09/3_fourier_analysis.html#fourier-transform",
    "href": "lectures/lecture09/3_fourier_analysis.html#fourier-transform",
    "title": "Fourier Analysis",
    "section": "Fourier transform",
    "text": "Fourier transform\nThe Fourier transform extends the concept of Fourier series by representing arbitrary non-periodic functions \\(f(t)\\) through a continuous spectrum of complex functions \\(\\exp(i\\omega t)\\). Known as the continuous Fourier transform, this approach replaces the discrete frequency sum of sine and cosine functions found in Fourier series with an integral over complex exponential functions \\(\\exp(i\\omega t)\\) spanning continuous frequency values \\(\\omega\\).\nThe Fourier transform of a function \\(f(t)\\) is defined as:\n\\[\nF(\\omega)=\\int\\limits_{-\\infty}^{+\\infty}f(t)e^{-i\\omega t}dt\n\\tag{2}\\]\nwhere \\(F(\\omega)\\) represents the spectrum of frequencies present in \\(f(t)\\). The inverse Fourier transform recovers the original function \\(f(t)\\) from its frequency spectrum (Equation¬†2):\n\\[\\begin{equation}\\label{eq:inverse_FT}\nf(t)=\\frac{1}{2\\pi}\\int\\limits_{-\\infty}^{+\\infty}F(\\omega)e^{+i\\omega t}dt\n\\end{equation}\\]\nThe Fourier transform \\(F(\\omega)\\) yields a complex number, encoding both phase and amplitude information of the oscillations. The phase of oscillation at frequency \\(\\omega\\) is given by:\n\\[\\begin{equation}\n\\phi=\\tan^{-1}\\left(\\frac{Im(F(\\omega))}{Re(F(\\omega))}\\right)\n\\end{equation}\\]\nwhile the amplitude at frequency \\(\\omega\\) is:\n\\[\\begin{equation}\nx_{0}^{\\rm theo}=|F(\\omega)|\n\\end{equation}\\]\nModern computing offers efficient algorithms for Fourier transformation, particularly the Fast Fourier Transform (FFT) implemented in libraries like NumPy. We‚Äôll use these algorithms to identify oscillation patterns in our signals. Here‚Äôs an example of using NumPy‚Äôs FFT functions to compute the transform and generate the corresponding frequency axis:\nf=np.fft.fft(alpha)\nfreq = np.fft.fftfreq(t.shape[-1],time/t.shape[-1])"
  },
  {
    "objectID": "lectures/lecture09/3_fourier_analysis.html#frequency-analysis-of-our-coupled-pendula",
    "href": "lectures/lecture09/3_fourier_analysis.html#frequency-analysis-of-our-coupled-pendula",
    "title": "Fourier Analysis",
    "section": "Frequency analysis of our coupled pendula",
    "text": "Frequency analysis of our coupled pendula\nLet us now apply Fourier analysis to examine the data from our previous simulation of coupled pendula, which includes both normal modes and beat mode oscillations of the harmonic oscillator.\n\n\n\n\n\n\nFirst, we extract the time series data and angular displacements into separate arrays for clearer analysis:\n\n\n\n\n\n\nNext, we perform the Fourier transform of our signals and visualize their frequency spectra:\n\n\n\n\n\n\nOur analysis reveals that the beat mode represents a superposition of the system‚Äôs two normal modes. This demonstrates a fundamental principle: any possible state of a coupled oscillator system can be constructed from a superposition of its normal modes with specific amplitudes."
  },
  {
    "objectID": "lectures/lecture07/1_curve_fitting.html",
    "href": "lectures/lecture07/1_curve_fitting.html",
    "title": "Curve fitting",
    "section": "",
    "text": "Let‚Äôs take a break from physics-related topics and explore another crucial area: curve fitting. We‚Äôll focus on demonstrating how to apply the least-squares method to fit a quadratic function with three parameters to experimental data. It‚Äôs worth noting that this approach can be applied to more complex functions or even simpler linear models.\nBefore diving into the fitting process, it‚Äôs essential to consider how to best estimate your model parameters. In some cases, you may be able to derive explicit estimators for the parameters, which can simplify the fitting procedure. Therefore, it‚Äôs advisable to carefully consider your approach before beginning the actual fitting process.\nFor those who want to delve deeper into this subject, you might find it interesting to explore concepts like maximum likelihood estimation. This method offers an alternative approach to parameter estimation and can provide valuable insights in certain scenarios."
  },
  {
    "objectID": "lectures/lecture07/1_curve_fitting.html#idea",
    "href": "lectures/lecture07/1_curve_fitting.html#idea",
    "title": "Curve fitting",
    "section": "Idea",
    "text": "Idea\nIn experimental physics, we often collect data points to understand the underlying physical phenomena. This process involves fitting a mathematical model to the experimental data.\nThe data typically comes as a series of paired points:\n\n\n\nx-data\ny-data\n\n\n\n\n\\(x_{1}\\)\n\\(y_{1}\\)\n\n\n\\(x_{2}\\)\n\\(y_{2}\\)\n\n\n‚Ä¶\n‚Ä¶\n\n\n\\(x_{N}\\)\n\\(y_{N}\\)\n\n\n\nEach point \\(\\{x_i, y_i\\}\\) may represent the result of multiple independent measurements. For instance, \\(y_1\\) could be the mean of several measurements \\(y_{1,j}\\):\n\\[y_1 = \\frac{1}{N}\\sum_{j=1}^N y_{1,j}\\]\nWhen these measurements have an uncertainty \\(\\sigma\\) for individual readings, the sum of all measurements has a variance of \\(N\\sigma^2\\) and a standard deviation of \\(\\sqrt{N}\\sigma\\). Consequently, the mean value has an associated error (standard deviation) known as the Standard Error of the Mean (SEOM):\n\\[\\sigma_{SEOM} = \\frac{\\sigma}{\\sqrt{N}}\\]\nThis SEOM is crucial in physics measurements.\nIt‚Äôs also important to note the definition of variance:\n\\[\\sigma_1^2 = \\frac{1}{N} \\sum_{j=1}^N (y_{1,j} - y_1)^2\\]\nThis statistical framework forms the basis for analyzing experimental data and fitting mathematical models to understand the underlying physics."
  },
  {
    "objectID": "lectures/lecture07/1_curve_fitting.html#least-squares",
    "href": "lectures/lecture07/1_curve_fitting.html#least-squares",
    "title": "Curve fitting",
    "section": "Least squares",
    "text": "Least squares\nIn experimental physics, we often collect data points to understand the underlying physical phenomena. To make sense of this data, we fit a mathematical model to it. One common method for fitting data is the least squares method.\n\nWhy use least squares fitting?\nThe goal of least squares fitting is to find the set of parameters for our model that best describes the data. This is done by minimizing the differences (or residuals) between the observed data points and the model‚Äôs predictions.\n\n\nGaussian uncertainty and probability\nWhen we take measurements, there is always some uncertainty. Often, this uncertainty can be modeled using a Gaussian (normal) distribution. This distribution is characterized by its mean (average value) and standard deviation (a measure of the spread of the data).\nIf we describe our data with a model function, which delivers a function value \\(f(x_{i},a)\\) for a set of parameters \\(a\\) at the position \\(x_{i}\\), the Gaussian uncertainty dictates a probability of finding a data value \\(y_{i}\\):\n\\[\\begin{equation}\np_{y_{i}}=\\frac{1}{\\sqrt{2\\pi}\\sigma_{i}}\\exp\\left(-\\frac{(y_{i}-f(x_{i},a))^2}{2\\sigma_{i}^2}\\right)\n\\end{equation}\\]\nHere, \\(\\sigma_{i}\\) represents the uncertainty in the measurement \\(y_{i}\\).\n\n\nCombining probabilities for multiple data points\nTo understand how well our model fits all the data points, we need to consider the combined probability of observing all the data points. This is done by multiplying the individual probabilities:\n\\[\\begin{equation}\np(y_{1},\\ldots,y_{N})=\\prod_{i=1}^{N}\\frac{1}{\\sqrt{2\\pi}\\sigma_{i}}\\exp\\left(-\\frac{(y_{i}-f(x_{i},a))^2}{2\\sigma_{i}^2}\\right)\n\\end{equation}\\]\n\n\nMaximizing the joint probability\nThe best fit of the model to the data is achieved when this joint probability is maximized. To simplify the calculations, we take the logarithm of the joint probability:\n\\[\\begin{equation}\n\\ln(p(y_{1},\\ldots,y_{N}))=-\\frac{1}{2}\\sum_{i=1}^{N}\\left( \\frac{y_{i}-f(x_{i},a)}{\\sigma_{i}}\\right)^2 - \\sum_{i=1}^{N}\\ln\\left( \\sigma_{i}\\sqrt{2\\pi}\\right)\n\\end{equation}\\]\nThe first term on the right side (except the factor 1/2) is the least squared deviation, also known as \\(\\chi^{2}\\):\n\\[\\begin{equation}\n\\chi^{2} =\\sum_{i=1}^{N}\\left( \\frac{y_{i}-f(x_{i},a)}{\\sigma_{i}}\\right)^2\n\\end{equation}\\]\nThe second term is just a constant value given by the uncertainties of our experimental data."
  },
  {
    "objectID": "lectures/lecture07/1_curve_fitting.html#data",
    "href": "lectures/lecture07/1_curve_fitting.html#data",
    "title": "Curve fitting",
    "section": "Data",
    "text": "Data\nLet‚Äôs have a look at the meaning of this equation. Let‚Äôs assume we measure the trajectory of a ball that has been thrown at an angle \\(\\alpha\\) with an initial velocity \\(v_{0}\\). We have collected data points by measuring the height of the ball above the ground at equally spaced distances from the throwing person.\n\n\n\n\n    \n    \n    \n        \n        \n        \n        \n        \n        \n        \n        \n    \n    \n   \n    \n      \n  \n        \n    \n    \n  \n        \n    \n    \n  \n        \n    \n      \n  \n        \n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n        \n    \n\n\n    Loading ITables v2.5.2 from the internet...\n    (need help?)\n    \n\n\n\n\nThe table above shows the measured data points \\(y_{i}\\) at the position \\(x_{i}\\) with the associated uncertainties \\(\\sigma_{i}\\).\nWe can plot the data and expect, of course, a parabola. Therefore, we model our experimental data with a parabola like\n\\[\\begin{equation}\ny = ax^2 + bx + c\n\\end{equation}\\]\nwhere the parameter \\(a\\) must be negative since the parabola is inverted.\nI have created an interactive plot with an interact widget, as this allows you to play around with the parameters. The value of \\(\\chi^2\\) is also included in the legend, so you can get an impression of how good your fit of the data is.\n\nviewof aSlider = Inputs.range([-4, 0], { label: \"a\", step: 0.01, value: -1.7 });\nviewof bSlider = Inputs.range([-2, 2], { label: \"b\", step: 0.01, value: 1.3 });\nviewof cSlider = Inputs.range([-2, 2], { label: \"c\", step: 0.01, value: 1.0 });\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfiltered = transpose(data);\n// Create the plot\n\nxValues = Array.from({ length: 100 }, (_, i) =&gt; i / 100);\nparabolaData = xValues.map(x =&gt; ({ x, y: parabola(x, aSlider, bSlider, cSlider) }));\n\n\nparabola = (x, a, b, c) =&gt; a * x**2 + b * x + c\n\ncalculateChiSquared = (data, a, b, c) =&gt; {\n  let chisq = 0\n  let x= data.map(d =&gt; d.x)\n  let y= data.map(d =&gt; d.y)\n  let err= data.map(d =&gt; d.error)\n  for (let i = 0; i &lt; x.length; i++) {\n    let y_model = parabola(x[i], a, b, c)\n    chisq += ((y[i] - y_model) / err[i])**2\n  }\n  return chisq\n}\n\nchisq = calculateChiSquared(filtered, aSlider, bSlider, cSlider)\n\nPlot.plot({\n  marks: [\n    Plot.dot(filtered, { x: \"x\", y: \"y\" }),\n    Plot.ruleY(filtered, { x: \"x\", y1: d =&gt; d.y - d.error, y2: d =&gt; d.y + d.error }),\n    Plot.line(parabolaData, { x: \"x\", y: \"y\" }),\n    Plot.text([{ x: 0.8, y: 1.5, label: `œá¬≤: ${chisq.toFixed(2)}` }], {\n          x: \"x\",\n          y: \"y\",\n          text: \"label\",\n          dy: -10, // Adjust vertical position if needed\n          fill: \"black\", // Set text color\n          fontSize: 16\n        }),\n    Plot.frame()\n  ],\n  x: {\n    label: \"X Axis\",\n    labelAnchor: \"center\",\n    labelOffset: 35,\n    grid: true,\n    tickFormat: \".2f\", // Format ticks to 2 decimal places\n    domain: [0, 1]\n  },\n  y: {\n    label: \"Y Axis\",\n    grid: true,\n    tickFormat: \".2f\", // Format ticks to 2 decimal places\n    labelAnchor: \"center\",  // Center the label on its axis\n    labelAngle: -90,\n    labelOffset: 60,\n    domain: [0, 2],\n  },\n  width: 400,\n  height: 400,\n  marginLeft: 100,\n  marginBottom: 40,\n  style: {\n    fontSize: \"14px\",          // This sets the base font size\n    \"axis.label\": {\n      fontSize: \"18px\",        // This sets the font size for axis labels\n      fontWeight: \"bold\"       // Optionally make it bold\n    },\n    \"axis.tick\": {\n      fontSize: \"14px\"         // This sets the font size for tick labels\n    }\n  },\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe have that troubling point at the right edge with a large uncertainty. However, since the value of \\(\\chi^2\\) divides the deviation by the uncertainty \\(\\sigma_{i}\\), the weight for this point overall in the \\(\\chi^2\\) is smaller than for the other points.\n\\[\\begin{equation}\n\\chi^{2}=\\sum_{i=1}^{N}\\left( \\frac{y_{i}-f(x_{i},a)}{\\sigma_{i}}\\right)^2\n\\end{equation}\\]\nYou may simply check the effect by changing the uncertainty of the last data points in the error array."
  },
  {
    "objectID": "lectures/lecture07/1_curve_fitting.html#least-square-fitting",
    "href": "lectures/lecture07/1_curve_fitting.html#least-square-fitting",
    "title": "Curve fitting",
    "section": "Least square fitting",
    "text": "Least square fitting\nTo find the best fit of the model to the experimental data, we use the least squares method. This method minimizes the sum of the squared differences between the observed data points and the model‚Äôs predictions.\nMathematically, we achieve this by minimizing the least squares, i.e., finding the parameters \\(a\\) that minimize the following expression:\n\\[\\begin{equation}\n\\frac{d\\chi^{2}}{da}=\\sum_{i=1}^{N}\\frac{1}{\\sigma_{i}^2}\\frac{df(x_{i},a)}{da}[y_{i}-f(x_{i},a)]=0\n\\end{equation}\\]\nThis kind of least squares minimization is done by fitting software using different types of algorithms.\n\nFitting with SciPy\nLet‚Äôs do some fitting using the SciPy library, which is a powerful tool for scientific computing in Python. We will use the curve_fit method from the optimize sub-module of SciPy.\nFirst, we need to define the model function we would like to fit to the data. In this case, we will use our parabola function:\n\n\n\n\n\n\nNext, we need to provide initial guesses for the parameters. These initial guesses help the fitting algorithm start the search for the optimal parameters:\n\n\n\n\n\n\nWe then call the curve_fit function to perform the fitting:\n\n\n\n\n\n\n\n\n\n\n\n\ncurve_fit Function\n\n\n\n\n\nThe curve_fit function is used to fit a model function to data. It finds the optimal parameters for the model function that minimize the sum of the squared residuals between the observed data and the model‚Äôs predictions.\n\nParameters\n\nparabola:\n\nThis is the model function that you want to fit to the data. In this case, parabola is a function that represents a quadratic equation of the form ( y = ax^2 + bx + c ).\n\nx_data:\n\nThis is the array of independent variable data points (the x-values).\n\ny_data:\n\nThis is the array of dependent variable data points (the y-values).\n\nsigma=err:\n\nThis parameter specifies the uncertainties (standard deviations) of the y-data points. The err array contains the uncertainties for each y-data point. These uncertainties are used to weight the residuals in the least squares optimization.\n\np0=init_guess:\n\nThis parameter provides the initial guesses for the parameters of the model function. The init_guess array contains the initial guesses for the parameters ( a ), ( b ), and ( c ). Providing good initial guesses can help the optimization algorithm converge more quickly and accurately.\n\nabsolute_sigma=True:\n\nThis parameter indicates whether the provided sigma values are absolute uncertainties. If absolute_sigma is set to True, the sigma values are treated as absolute uncertainties. If absolute_sigma is set to False, the sigma values are treated as relative uncertainties, and the covariance matrix of the parameters will be scaled accordingly.\n\n\n\n\nReturn Value\nThe curve_fit function returns two values:\n\npopt:\n\nAn array containing the optimal values for the parameters of the model function that minimize the sum of the squared residuals.\n\npcov:\n\nThe covariance matrix of the optimal parameters. The diagonal elements of this matrix provide the variances of the parameter estimates, and the off-diagonal elements provide the covariances between the parameter estimates.\n\n\n\n\n\n\nThe fit variable contains the results of the fitting process. It is composed of various results, which we can split into the fitted parameters and the covariance matrix:\n\n\n\n\n\n\nThe ans variable contains the fitted parameters fit_a, fit_b, and fit_c, while the cov variable contains the covariance matrix. Let‚Äôs have a look at the fit and the \\(\\chi^{2}\\) value first:\n\n\n\n\n\n\nWe can then plot the fitted curve along with the original data points and the \\(\\chi^{2}\\) value:\n\n\n\n\n\n\n\n\n\\(\\chi\\)-squared value\nThe value of \\(\\chi^2\\) gives you a measure of the quality of the fit. We can judge the quality by calculating the expectation value of \\(\\chi^2\\):\n\\[\\begin{equation}\n\\langle \\chi^{2}\\rangle =\\sum_{i=1}^{N} \\frac{\\langle (y_{i}-f(x_{i},a) )^2\\rangle }{\\sigma_{i}^2}=\\sum_{i=1}^{N} \\frac{\\sigma_{i}^2}{\\sigma_{i}^2}=N\n\\end{equation}\\]\nSo, the mean of the least squared deviation increases with the number of data points. Therefore:\n\n\\(\\chi^{2} \\gg N\\) means that the fit is bad.\n\\(\\chi^{2} &lt; N\\) means that the uncertainties are wrong.\n\nThe first case may occur if you don‚Äôt have a good fit to your data, for example, if you are using the wrong model. The second case typically occurs if you don‚Äôt have accurate estimates of the uncertainties and you assume all uncertainties to be constant.\nIt is really important to have a good estimate of the uncertainties and to include them in your fit. If you include the uncertainties in your fit, it is called a weighted fit. If you don‚Äôt include the uncertainties (meaning you keep them constant), it is called an unweighted fit.\nFor our fit above, we obtain a \\(\\chi^{2}\\) which is on the order of \\(N=10\\), which tells you that I have created the data with reasonable accuracy.\n\n\nResiduals\nAnother way to assess the quality of the fit is by looking at the residuals. Residuals are defined as the deviation of the data from the model for the best fit:\n\\[\\begin{equation}\nr_i = y_i - f(x_{i},a)\n\\end{equation}\\]\nThe residuals can also be expressed as the percentage of the deviation of the data from the fit:\n\\[\\begin{equation}\nr_i = 100 \\left( \\frac{y_i - f(x_{i},a)}{y_i} \\right)\n\\end{equation}\\]\n\n\nImportance of Residuals\nResiduals are important because they provide insight into how well the model fits the data. If the residuals show only statistical fluctuations around zero, then the fit and likely also the model are good. However, if there are systematic patterns in the residuals, it may indicate that the model is not adequately capturing the underlying relationship in the data.\n\n\nVisualizing Residuals\nLet‚Äôs visualize the residuals to better understand their distribution. We will plot the residuals as a function of the independent variable \\(x\\).\n\n\n\n\n\n\n\n\n\n\n\n\nCommon Patterns in Residuals\n\n\n\n\n\nRandom Fluctuations Around Zero:\n\nIf the residuals are randomly scattered around zero, it suggests that the model is a good fit for the data.\n\nSystematic Patterns:\n\nIf the residuals show a systematic pattern (e.g., a trend or periodicity), it may indicate that the model is not capturing some aspect of the data. This could suggest the need for a more complex model.\n\nIncreasing or Decreasing Trends:\n\nIf the residuals increase or decrease with \\(x\\), it may indicate heteroscedasticity (non-constant variance) or that a different functional form is needed."
  },
  {
    "objectID": "lectures/lecture07/1_curve_fitting.html#covariance-matrix",
    "href": "lectures/lecture07/1_curve_fitting.html#covariance-matrix",
    "title": "Curve fitting",
    "section": "Covariance Matrix",
    "text": "Covariance Matrix\nIn the previous sections, we discussed how to fit a model to experimental data and assess the quality of the fit using residuals. Now, let‚Äôs take a closer look at the uncertainties in the fit parameters and how they are related to each other. This is where the covariance matrix comes into play.\n\nPurpose of the Covariance Matrix\nThe covariance matrix provides important information about the uncertainties in the fit parameters and how these uncertainties are related to each other. It helps us understand the precision of the parameter estimates and whether the parameters are independent or correlated.\n\n\nUnderstanding Covariance\nCovariance is a measure of how much two random variables change together. If the covariance between two variables is positive, it means that they tend to increase or decrease together. If the covariance is negative, it means that one variable tends to increase when the other decreases. If the covariance is zero, it means that the variables are independent.\n\n\nCovariance Matrix in Curve Fitting\nWhen we fit a model to data, we obtain estimates for the parameters of the model. These estimates have uncertainties due to the measurement errors in the data. The covariance matrix quantifies these uncertainties and the relationships between them.\nFor a model with three parameters \\((a, b, c)\\), the covariance matrix is a \\(3 \\times 3\\) matrix that looks like this:\n\\[\\begin{equation}\n{\\rm cov}(p_{i}, p_{j}) =\n\\begin{bmatrix}\n\\sigma_{aa}^{2} & \\sigma_{ab}^{2} & \\sigma_{ac}^{2} \\\\\n\\sigma_{ba}^{2} & \\sigma_{bb}^{2} & \\sigma_{bc}^{2} \\\\\n\\sigma_{ca}^{2} & \\sigma_{cb}^{2} & \\sigma_{cc}^{2}\n\\end{bmatrix}\n\\end{equation}\\]\nThe diagonal elements provide the variances (squared uncertainties) of the fit parameters, while the off-diagonal elements describe the covariances between the parameters.\n\n\nExample\nLet‚Äôs calculate the covariance matrix for our fitted model and interpret the results.\n\n\n\n\n\n\n\n\nInterpreting the Covariance Matrix\nThe covariance matrix provides valuable information about the uncertainties in the fit parameters:\n\nDiagonal Elements: The diagonal elements represent the variances of the parameters. The square root of these values gives the standard deviations (uncertainties) of the parameters.\nOff-Diagonal Elements: The off-diagonal elements represent the covariances between the parameters. If these values are large, it indicates that the parameters are correlated.\n\n\n\nGenerating Synthetic Data\nTo better understand the covariance matrix, let‚Äôs generate synthetic data and fit the model to each dataset. This will help us visualize the uncertainties in the parameters.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCorrelation Matrix\nTo better understand the relationships between the parameters, we can normalize the covariance matrix to obtain the correlation matrix. The correlation matrix has values between -1 and 1, where 1 indicates perfect positive correlation, -1 indicates perfect negative correlation, and 0 indicates no correlation.\n\n\n\n\n\n\n\n\nVisualizing the Covariance and Correlation\nLet‚Äôs visualize the covariance and correlation between the parameters using scatter plots.\n\n\n\n\n\n\nBy examining the covariance and correlation matrices, we can gain a deeper understanding of the uncertainties in the fit parameters and how they are related to each other.\n\n\nImproving the Model\nIf we find that the parameters are highly correlated, we might want to find a better model containing more independent parameters. For example, we can write down a different model:\n\\[\\begin{equation}\ny = a(x - b)^2 + c\n\\end{equation}\\]\nThis model also contains three parameters, but the parameter \\(b\\) directly refers to the maximum of our parabola, while the parameter \\(a\\) denotes its curvature.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe see from the covariance matrix that the new model has a smaller correlation of the parameters with each other.\n\n\n\n\n\n\nThis is also expressed by our correlation matrix.\n\n\n\n\n\n\nBy examining the covariance and correlation matrices, we can gain valuable insights into the uncertainties in the fit parameters and how to improve our model."
  },
  {
    "objectID": "lectures/lecture10/1_spring_pendulum.html",
    "href": "lectures/lecture10/1_spring_pendulum.html",
    "title": "Spring Pendulum",
    "section": "",
    "text": "In the last lectures, we have explored the use the scipy module odeint to do the work of solving differential equations for us. We have studied coupled pendula and explored the details of the solutions. This time we have two more projects ahead of us. We first want to consider the motion of a spring pendulum and then come from that to the motion of planets. Both are examples where we have not only a tangential accelaration but also a radial component. Otherwise, these problems do look similar than the ones we considered before."
  },
  {
    "objectID": "lectures/lecture10/1_spring_pendulum.html#physical-model",
    "href": "lectures/lecture10/1_spring_pendulum.html#physical-model",
    "title": "Spring Pendulum",
    "section": "Physical Model",
    "text": "Physical Model\nThe image below shows the situation we would like to cover in our second project. This is also a kind of coupled pendula, however, the situation is more subtle.\nWe have a single spring which is mounted to a support and a mass. The spring can be elongated in length but also in angle so that you finally have a pendulum and a spring. Both motions are coupled now in a similar way as for the coupled pendula we treated. This time, however, the length change of the spring modulates the frequency of the pendulum.\n\n\n\nSpringPendulum.png\n\n\n\nEquations of motion\nA mass \\(m\\) is attached to a spring with spring constant \\(k\\), which is attached to a support point as shown in the figure. The length of the resulting pendulum at any given time is the spring rest length \\(L_0\\) plus the stretch (or compression) \\(L\\), and the angle of the pendulum with respect to the vertical is \\(\\theta\\).\nThe differential equations for this system are given by\n\\[\\begin{eqnarray}\n\\ddot{L}&=&(L_0+L)\\dot{\\theta}^2-\\frac{k}{m}L+g\\cos(\\theta)\\\\\n\\ddot{\\theta}&=&-\\frac{1}{L_0+L}[g\\sin(\\theta)+2\\dot{L}\\dot{\\theta}]\n\\end{eqnarray}\\]\nLet‚Äôs break down the terms in these equations:\nFor the radial motion (L):\n\n\\((L_0+L)\\dot{\\theta}^2\\) represents the centrifugal force term\n\\(-\\frac{k}{m}L\\) is the restoring force of the spring (Hooke‚Äôs law)\n\\(g\\cos(\\theta)\\) is the component of gravity along the radial direction\n\nFor the angular motion (Œ∏):\n\n\\(g\\sin(\\theta)\\) represents the gravitational torque\n\\(2\\dot{L}\\dot{\\theta}\\) is the Coriolis force term\nThe factor \\(\\frac{1}{L_0+L}\\) comes from the moment of inertia\n\nThe equations are coupled - the radial and angular motions affect each other. The system shows interesting behavior like:\n\nEnergy exchange between radial and angular modes\nNon-linear oscillations\nPotential for chaotic motion under certain conditions\n\nThe key players in this equation are the centrifugal and Coriolis forces. These forces are fictitious forces that arise when we consider the motion of an object in a rotating frame of reference. The centrifugal force is the force that pushes an object away from the center of rotation, while the Coriolis force is the force that acts perpendicular to the direction of motion of an object in a rotating frame.\nCentrifugal Force:\n\\[\\begin{equation}\n\\vec{F}_{\\text{centrifugal}} = m(\\vec{\\omega} \\times (\\vec{\\omega} \\times \\vec{r}))\n\\end{equation}\\]\nCoriolis Force: \\[\\begin{equation}\n\\vec{F}_{\\text{Coriolis}} = 2m(\\vec{\\omega} \\times \\vec{v}_{\\text{rel}})\n\\end{equation}\\]\nwhere:\n\n\\(m\\) is the mass\n\\(\\vec{\\omega}\\) is the angular velocity vector\n\\(\\vec{r}\\) is the position vector\n\\(\\vec{v}_{\\text{rel}}\\) is the velocity relative to the rotating frame\n\\(\\times\\) denotes the cross product\n\nIn component form, if we consider rotation about the z-axis with \\(\\vec{\\omega} = \\omega\\hat{k}\\), these become:\nCentrifugal Force: \\[\\begin{equation}\n\\vec{F}_{\\text{centrifugal}} = m\\omega^2(x\\hat{i} + y\\hat{j})\n\\end{equation}\\]\nCoriolis Force: \\[\\begin{equation}\n\\vec{F}_{\\text{Coriolis}} = 2m\\omega(-v_y\\hat{i} + v_x\\hat{j})\n\\end{equation}\\]\nwhere \\(\\hat{i}\\), \\(\\hat{j}\\), and \\(\\hat{k}\\) are unit vectors in the x, y, and z directions respectively.\nBelow we write a program that plots the motion of the mass for some initial \\(\\theta\\neq0\\). Explore different solutions. We should get that when the spring is very stiff (large k), it reduces approximately to a simple pendulum. When \\(\\theta\\) is small, it can show beats between the spring and pendulum modes."
  },
  {
    "objectID": "lectures/lecture10/1_spring_pendulum.html#numerical-solution",
    "href": "lectures/lecture10/1_spring_pendulum.html#numerical-solution",
    "title": "Spring Pendulum",
    "section": "Numerical Solution",
    "text": "Numerical Solution\nFor the numerical solution of the differential equations, we will use the odeint function from the scipy module. So this is another training for us to use this function.\n\nInitial parameters\nWe will have to think about the initial conditions. We will later modify them to see how the system behaves in different regimes.\n\n\n\n\n\n\n\n\nSolution\nThe solution of the differential equations is done by the odeint function.\n\n\n\n\n\n\nThe provided answer is a 2D array with the first column being the length of the spring, the second column the velocity of the spring, the third column the angle of the pendulum, and the fourth column the angular velocity of the pendulum.\n\n\n\n\n\n\nWe can convert the answer to the x and y positions of the mass. This is done by the following code. As the length \\(L\\) is only the elongation of the spring, we have to add the equilibrium length \\(L_0\\) to get the total length of the spring. The x and y positions are then given by \\(L\\sin(\\theta)\\) and \\(L\\cos(\\theta)\\).\n\n\n\n\n\n\n\n\nPlotting\nThe plots below show the motion of the mass in the x-y plane.\n\n\n\n\n\n\nThe next plot is providing the so called phase space plot. This is a plot of the velocity of the mass versus the position of the mass. This plot is very useful to understand the dynamics of the system.\n\n\n\n\n\n\nFinally we plot the phase space of the pendulum. This is the angle of the pendulum versus the angular velocity of the pendulum.\n\n\n\n\n\n\n\nAngle and Length over Time"
  },
  {
    "objectID": "lectures/lecture11/1_repetition.html",
    "href": "lectures/lecture11/1_repetition.html",
    "title": "Repetition",
    "section": "",
    "text": "After we have completed the first part of the course, we will have a repetition session to review the main concepts and topics covered so far. This will help reinforce your understanding and prepare you for the final exam. This part contains a number of exercises you can work on to test your knowledge and skills."
  },
  {
    "objectID": "lectures/lecture11/1_repetition.html#what-is-a-program",
    "href": "lectures/lecture11/1_repetition.html#what-is-a-program",
    "title": "Repetition",
    "section": "What is a Program?",
    "text": "What is a Program?\nA program is a sequence of instructions that tells a computer how to perform a specific task. These instructions must be:\n\nPrecise and unambiguous\nWritten in a language the computer understands\nLogically structured\nDesigned to achieve a specific goal"
  },
  {
    "objectID": "lectures/lecture11/1_repetition.html#basic-elements-of-python",
    "href": "lectures/lecture11/1_repetition.html#basic-elements-of-python",
    "title": "Repetition",
    "section": "Basic Elements of Python",
    "text": "Basic Elements of Python\n\nVariables and Data Types\nIn Python, variables are containers for storing data values. Python is dynamically typed, meaning you don‚Äôt need to declare variable types explicitly.\n\n\n\n\n\n\n\n\n\n\n\n\nSelf-Exercise 1: Unit Conversion\n\n\n\n\n\nWrite a program that converts a temperature from Celsius to Fahrenheit and Kelvin. Use the formulas:\n\n¬∞F = (¬∞C √ó 9/5) + 32\nK = ¬∞C + 273.15\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNumerical Operations\nPython supports all basic mathematical operations:\n\n\n\n\n\n\n\n\n\n\n\n\nSelf-Exercise 2: Basic Kinematics\n\n\n\n\n\nCalculate the final velocity of an object given its initial velocity, acceleration, and time. Use the formula: v = v‚ÇÄ + at\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLists and Arrays\nFor physics calculations, we often need to work with collections of numbers:\n\n\n\n\n\n\n\n\n\n\n\n\nSelf-Exercise 3: Force Calculations\n\n\n\n\n\nCreate an array of masses (in kg) and calculate the force of gravity on each mass. Use F = mg where g = 9.81 m/s¬≤. Numpy is already imported and can be used with np\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution"
  },
  {
    "objectID": "lectures/lecture11/1_repetition.html#control-structures",
    "href": "lectures/lecture11/1_repetition.html#control-structures",
    "title": "Repetition",
    "section": "Control Structures",
    "text": "Control Structures\n\nConditional Statements\nConditional statements allow programs to make decisions:\n\n\n\n\n\n\n\n\n\n\n\n\nSelf-Exercise 4: Phase of Matter\n\n\n\n\n\nWrite a program that determines the phase of water based on its temperature (assume standard pressure):\n\nBelow 0¬∞C: Solid (Ice)\n0-100¬∞C: Liquid\nAbove 100¬∞C: Gas (Steam)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSelf-Exercise 5: Projectile Range Calculator\n\n\n\n\n\nWrite a program that calculates if a projectile will hit a target given:\n\nInitial velocity\nLaunch angle\nTarget distance\n\nUse the range formula: \\(R = \\frac{v_0^2 \\sin(2\\theta)}{g}\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLoops\nLoops allow repetition of code:\n\n\n\n\n\n\n\n\n\n\n\n\nSelf-Exercise 6: Radioactive Decay Calculator\n\n\n\n\n\nWrite a program that simulates radioactive decay over multiple half-lives:\n\nStart with an initial number of atoms (\\(N_0\\))\nCalculate remaining atoms after each half-life period\nContinue for 5 half-lives\n\nUse the formula \\(N(t) = N_0 \\cdot \\left(\\frac{1}{2}\\right)^{t/t_{1/2}}\\) where \\(t_{1/2}\\) is the half-life.\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSelf-Exercise 7: Time to Ground Calculator\n\n\n\n\n\nWrite a program that calculates how long it takes for an object to reach the ground when dropped from different heights:\n\nStart with an initial height \\(h_0\\)\nCalculate position using \\(y = h_0 - \\frac{1}{2}gt^2\\)\nFind the time when \\(y = 0\\)\nUse small time steps (\\(dt = 0.01s\\))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution"
  },
  {
    "objectID": "lectures/lecture11/1_repetition.html#basic-numerical-calculations",
    "href": "lectures/lecture11/1_repetition.html#basic-numerical-calculations",
    "title": "Repetition",
    "section": "Basic Numerical Calculations",
    "text": "Basic Numerical Calculations\nFor physics, we often use NumPy for numerical calculations:"
  },
  {
    "objectID": "lectures/lecture11/1_repetition.html#simple-physics-example",
    "href": "lectures/lecture11/1_repetition.html#simple-physics-example",
    "title": "Repetition",
    "section": "Simple Physics Example",
    "text": "Simple Physics Example\nLet‚Äôs calculate the position of a projectile under gravity:"
  },
  {
    "objectID": "lectures/lecture11/1_repetition.html#code-organization",
    "href": "lectures/lecture11/1_repetition.html#code-organization",
    "title": "Repetition",
    "section": "Code Organization",
    "text": "Code Organization\n\nUse meaningful variable names\nAdd comments to explain complex logic\nBreak down complex problems into smaller functions\nUse consistent indentation"
  },
  {
    "objectID": "lectures/lecture11/1_repetition.html#example-of-well-organized-code",
    "href": "lectures/lecture11/1_repetition.html#example-of-well-organized-code",
    "title": "Repetition",
    "section": "Example of Well-Organized Code",
    "text": "Example of Well-Organized Code\nHere‚Äôs an example calculating the period of a simple pendulum:"
  },
  {
    "objectID": "lectures/lecture11/1_repetition.html#classes-and-objects",
    "href": "lectures/lecture11/1_repetition.html#classes-and-objects",
    "title": "Repetition",
    "section": "Classes and Objects",
    "text": "Classes and Objects\nClasses are blueprints for creating objects that combine data (attributes) and functions (methods). This is particularly useful for modeling physical systems.\n\nBasic Class Structure\n\n\n\n\n\n\n\n\n\n\n\n\nAdvanced Self-Exercise 8: Electric Charge Class\n\n\n\n\n\nCreate a class representing an electric charge that can:\n\nStore position \\((x, y)\\), charge magnitude \\((q)\\), and mass \\((m)\\)\nCalculate electric potential at a point using \\(V = \\frac{kq}{r}\\)\nCalculate electric force on another charge using \\(F = \\frac{kq_1q_2}{r^2}\\)\nCalculate the direction of force (attraction/repulsion)\n\nUse \\(k = 8.99 \\times 10^9\\) N\\(\\cdot\\)m¬≤/C¬≤ (Coulomb‚Äôs constant)\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution"
  },
  {
    "objectID": "lectures/lecture11/1_repetition.html#a-physics-example-harmonic-oscillator",
    "href": "lectures/lecture11/1_repetition.html#a-physics-example-harmonic-oscillator",
    "title": "Repetition",
    "section": "A Physics Example: Harmonic Oscillator",
    "text": "A Physics Example: Harmonic Oscillator\nHere‚Äôs a more complete example modeling a harmonic oscillator:"
  },
  {
    "objectID": "lectures/lecture11/1_repetition.html#inheritance",
    "href": "lectures/lecture11/1_repetition.html#inheritance",
    "title": "Repetition",
    "section": "Inheritance",
    "text": "Inheritance\nClasses can inherit properties and methods from other classes:"
  },
  {
    "objectID": "lectures/lecture11/1_repetition.html#key-points-about-classes",
    "href": "lectures/lecture11/1_repetition.html#key-points-about-classes",
    "title": "Repetition",
    "section": "Key Points About Classes",
    "text": "Key Points About Classes\n\nClasses combine data (attributes) and functions (methods)\nThe __init__ method initializes new objects\nself refers to the instance of the class\nMethods can modify the object‚Äôs state\nInheritance allows creating specialized versions of classes\nClasses help organize code and model real-world systems\n\nClasses are particularly useful in physics for: - Modeling physical systems - Organizing simulation code - Creating reusable components - Building hierarchies of related objects"
  },
  {
    "objectID": "lectures/lecture02/02-lecture02.html",
    "href": "lectures/lecture02/02-lecture02.html",
    "title": "Modules",
    "section": "",
    "text": "Most of the functionality in Python is provided by modules. The Python Standard Library is a large collection of modules that provides cross-platform implementations of common facilities such as access to the operating system, file I/O, string management, network communication, math, web-scraping, text manipulation, machine learning and much more.\nTo use a module in a Python module it first has to be imported. A module can be imported using the import statement. For example, to import the module math, which contains many standard mathematical functions, we can do:\n\n\n\n\n\n\nThis includes the whole module and makes it available for use later in the program. Alternatively, we can chose to import all symbols (functions and variables) in a module so that we don‚Äôt need to use the prefix ‚Äúmath.‚Äù every time we use something from the math module:\n\n\n\n\n\n\nThis pattern can be very convenient, but in large programs that include many modules it is often a good idea to keep the symbols from each module in their own namespaces, by using the import math pattern. This would eliminate potentially confusing problems.\n\nNamespaces\n\n\n\n\n\n\nNamespaces\n\n\n\nA namespace is an identifier used to organize objects, e.g.¬†the methods and variables of a module. The prefix math. we have used in the previous section is such a namespace. You may also create your own namespace for a module. This is done by using the import math as mymath pattern.\n\n\n\n\n\n\n\n\nYou may also only import specific functions of a module.\n\n\n\n\n\n\n\n\nDirectory of a module\nOnce a module is imported, we can list the symbols it provides using the dir function:\n\n\n\n\n\n\nAnd using the function help we can get a description of each function (almost .. not all functions have docstrings, as they are technically called, but the vast majority of functions are documented this way).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe can also use the help function directly on modules: Try\nhelp(math)\nSome very useful modules form the Python standard library are os, sys, math, shutil, re, subprocess, multiprocessing, threading.\nA complete lists of standard modules for Python 3 is available at http://docs.python.org/3/library/ .\n\n\nAdvanced topics\n\n\n\n\n\n\nCreate Your Own Modules\n\n\n\n\n\nCreating your own modules in Python is a great way to organize your code and make it reusable. A module is simply a file containing Python definitions and statements. Here‚Äôs how you can create and use your own module:\n\nCreating a Module\nTo create a module, you just need to save your Python code in a file with a .py extension. For example, let‚Äôs create a module named mymodule.py with the following content:\n# mymodule.py\n\ndef greet(name: str) -&gt; str:\n    return f\"Hello, {name}!\"\n\ndef add(a: int, b: int) -&gt; int:\n    return a + b\n\n\nUsing Your Module\nOnce you have created your module, you can import it into other Python scripts using the import statement. Here‚Äôs an example of how to use the mymodule we just created:\n# main.py\n\nimport mymodule\n\n# Use the functions from mymodule\nprint(mymodule.greet(\"Alice\"))\nprint(mymodule.add(5, 3))\n\n\nImporting Specific Functions\nYou can also import specific functions from a module using the from ... import ... syntax:\n# main.py\n\nfrom mymodule import greet, add\n\n# Use the imported functions directly\nprint(greet(\"Bob\"))\nprint(add(10, 7))\n\n\nModule Search Path\nWhen you import a module, Python searches for the module in the following locations: 1. The directory containing the input script (or the current directory if no script is specified). 2. The directories listed in the PYTHONPATH environment variable. 3. The default directory where Python is installed.\nYou can view the module search path by printing the sys.path variable:\nimport sys\nprint(sys.path)\n\n\nCreating Packages\nA package is a way of organizing related modules into a directory hierarchy. A package is simply a directory that contains a special file named __init__.py, which can be empty. Here‚Äôs an example of how to create a package:\nmypackage/\n    __init__.py\n    module1.py\n    module2.py\nYou can then import modules from the package using the dot notation:\n# main.py\n\nfrom mypackage import module1, module2\n\n# Use the functions from the modules\nprint(module1.some_function())\nprint(module2.another_function())\nCreating and using modules and packages in Python helps you organize your code better and makes it easier to maintain and reuse.\n\n\nNamespaces in Packages\nYou can also create sub-packages by adding more directories with __init__.py files. This allows you to create a hierarchical structure for your modules:\nmypackage/\n    __init__.py\n    subpackage/\n        __init__.py\n        submodule.py\nYou can then import submodules using the full package name:\n# main.py\n\nfrom mypackage.subpackage import submodule\n\n# Use the functions from the submodule\nprint(submodule.some_sub_function())"
  },
  {
    "objectID": "lectures/lecture02/01-lecture02.html",
    "href": "lectures/lecture02/01-lecture02.html",
    "title": "Python Overview",
    "section": "",
    "text": "Functions are reusable blocks of code that can be executed multiple times from different parts of your program. They help in organizing code, making it more readable, and reducing redundancy. Functions can take input arguments and return output values.\n\nDefining a FunctionCalling a Function\n\n\nA function in Python is defined using the def keyword followed by the name of the function, which is usually descriptive and indicates what the function does. The parameters inside the parentheses indicate what data the function expects to receive. The -&gt; symbol is used to specify the return type of the function.\nHere‚Äôs an example:\n\n\n\n\n\n\n\n\nFunctions can be called by specifying the name of the function followed by parentheses containing the arguments. The arguments passed to the function should match the number and type of parameters defined in the function. Here‚Äôs an example:"
  },
  {
    "objectID": "lectures/lecture02/01-lecture02.html#functions",
    "href": "lectures/lecture02/01-lecture02.html#functions",
    "title": "Python Overview",
    "section": "",
    "text": "Functions are reusable blocks of code that can be executed multiple times from different parts of your program. They help in organizing code, making it more readable, and reducing redundancy. Functions can take input arguments and return output values.\n\nDefining a FunctionCalling a Function\n\n\nA function in Python is defined using the def keyword followed by the name of the function, which is usually descriptive and indicates what the function does. The parameters inside the parentheses indicate what data the function expects to receive. The -&gt; symbol is used to specify the return type of the function.\nHere‚Äôs an example:\n\n\n\n\n\n\n\n\nFunctions can be called by specifying the name of the function followed by parentheses containing the arguments. The arguments passed to the function should match the number and type of parameters defined in the function. Here‚Äôs an example:"
  },
  {
    "objectID": "lectures/lecture02/01-lecture02.html#loops",
    "href": "lectures/lecture02/01-lecture02.html#loops",
    "title": "Python Overview",
    "section": "Loops",
    "text": "Loops\nLoops are used to execute a block of code repeatedly. There are two main types of loops in Python: for loops and while loops.\n\nFor LoopWhile Loop\n\n\nA for loop in Python is used to iterate over a sequence (such as a list or string) and execute a block of code for each item in the sequence. Here‚Äôs an example:\n\n\n\n\n\n\n\n\nA while loop in Python is used to execute a block of code while a certain condition is met. The loop continues as long as the condition is true. Here‚Äôs an example:"
  },
  {
    "objectID": "lectures/lecture02/01-lecture02.html#conditional-statements",
    "href": "lectures/lecture02/01-lecture02.html#conditional-statements",
    "title": "Python Overview",
    "section": "Conditional Statements",
    "text": "Conditional Statements\nConditional statements are used to control the flow of your program based on conditions. The main conditional statements in Python are if, else, and elif.\n\nIf StatementElse StatementElif Statement\n\n\nAn if statement in Python is used to execute a block of code if a certain condition is met. Here‚Äôs an example:\n\n\n\n\n\n\n\n\nAn else statement in Python is used to execute a block of code if the condition in an if statement is not met. Here‚Äôs an example:\n\n\n\n\n\n\n\n\nAn elif statement in Python is used to execute a block of code if the condition in an if statement is not met but under an extra condition. Here‚Äôs an example:"
  },
  {
    "objectID": "lectures/lecture02/3_datatypes.html",
    "href": "lectures/lecture02/3_datatypes.html",
    "title": "Data Types in Python",
    "section": "",
    "text": "It‚Äôs time to look at different data types we may find useful in our course. Besides the number types mentioned previously, there are also other types like strings, lists, tuples, dictionaries and sets.\nEach of these data types has a number of connected methods (functions) which allow to manipulate the data contained in a variable. If you want to know which methods are available for a certain object use the command dir, e.g.\nThe following few cells will give you a short introduction into each type."
  },
  {
    "objectID": "lectures/lecture02/3_datatypes.html#strings",
    "href": "lectures/lecture02/3_datatypes.html#strings",
    "title": "Data Types in Python",
    "section": "Strings",
    "text": "Strings\nStrings are lists of keyboard characters as well as other characters not on your keyboard. They are useful for printing results on the screen, during reading and writing of data.\n\n\n\n\n\n\n\n\n\n\n\n\nString can be concatenated using the + operator.\n\n\n\n\n\n\n\n\n\n\n\n\nAs strings are lists, each character in a string can be accessed by addressing the position in the string (see Lists section)\n\n\n\n\n\n\nStrings can also be made out of numbers.\n\n\n\n\n\n\nIf you want to obtain a number of a string, you can use what is known as type casting. Using type casting you may convert the string or any other data type into a different type if this is possible. To find out if a string is a pure number you may use the str.isnumeric method. For the above string, we may want to do a conversion to the type int by typing:\n\n\n\n\n\n\n\n\n\n\n\n\nThere are a number of methods connected to the string data type. Usually the relate to formatting or finding sub-strings. Formatting will be a topic in our next lecture. Here we just refer to one simple find example."
  },
  {
    "objectID": "lectures/lecture02/3_datatypes.html#lists",
    "href": "lectures/lecture02/3_datatypes.html#lists",
    "title": "Data Types in Python",
    "section": "Lists",
    "text": "Lists\nLists have a variety of uses. They are useful, for example, in various bookkeeping tasks that arise in computer programming. Like arrays, they are sometimes used to store data. However, lists do not have the specialized properties and tools that make arrays so powerful for scientific computing. So in general, we prefer arrays to lists for working with scientific data. For other tasks, lists work just fine and can even be preferable to arrays.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIndividual elements in a list can be accessed by the variable name and the number (index) of the list element put in square brackets. Note that the index for the elements start at 0 for the first element (left).\n\n\n\n\n\n\nIndices in Python\n\n\n\nThe first element of a list or array is accessed by the index 0. If the array has N elements, the last entries index is N-1.\n\n\n\n\n\n\n\n\nElements may be also accessed from the back by nagative indices. b[-1] denotes the last element in the list and b[-2], the element before the last.\n\n\n\n\n\n\n\n\n\n\n\n\nThe length of a list can be obtained by the len command if you need the number of elements in the list for your calculations.\n\n\n\n\n\n\nThere are powerful ways to iterate through a list and also through arrays in form of iterator. This is called list comprehension. We will talk about them later in more detail. Here is an example, which shows the powerful options you have in Python.\n\n\n\n\n\n\nIndividual elements in a list can be replaced by assigning a new value to them\n\n\n\n\n\n\n\n\n\n\n\n\nLists can be concatanated by the + operator\n\n\n\n\n\n\nA very useful feature for lists in python is the slicing of lists. Slicing means, that we access only a range of elements in the list, i.e.¬†element 3 to 7. This is done by inserting the starting and the ending element number separated by a colon (:) in the square brackets. The index numbers can be positive or negative again.\n\n\n\n\n\n\nInserting a second colon behind the ending element index together with a thrid number allows even to select only ever second or third element from a list.\n\n\n\n\n\n\nIt is sometimes also useful to reverse a list. This can be easily done with the reverse command.\n\n\n\n\n\n\nLists may be created in different ways. An empty list can be created by assigning emtpy square brackets to a variable name. You can append elements to the list with the help of the append command which has to be added to the variable name as shown below. This way of adding a particular function, which is part of a certain variable class is part of object oriented programming.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA list of numbers can be easily created by the range() command.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLists (and also tuples below) can be multidimensional as well, i.e.¬†for an image. The individual elements may then be addressed by supplying two indices in two square brackets."
  },
  {
    "objectID": "lectures/lecture02/3_datatypes.html#tuples",
    "href": "lectures/lecture02/3_datatypes.html#tuples",
    "title": "Data Types in Python",
    "section": "Tuples",
    "text": "Tuples\nTuples are also list, but immutable. That means, if a tuple has been once defined, it cannot be changed. Try to change an element to see the result.\n\n\n\n\n\n\nTuples may be unpacked, e.g.¬†its values may be assigned to normal variables in the following way"
  },
  {
    "objectID": "lectures/lecture02/3_datatypes.html#dictionaries",
    "href": "lectures/lecture02/3_datatypes.html#dictionaries",
    "title": "Data Types in Python",
    "section": "Dictionaries",
    "text": "Dictionaries\nDictionaries are like lists, but the elements of dictionaries are accessed in a different way than for lists. The elements of lists and arrays are numbered consecutively, and to access an element of a list or an array, you simply refer to the number corresponding to its position in the sequence. The elements of dictionaries are accessed by ‚Äúkeys‚Äù, which can be either strings or (arbitrary) integers (in no particular order). Dictionaries are an important part of core Python. However, we do not make much use of them in this introduction to scientific Python, so our discussion of them is limited."
  },
  {
    "objectID": "lectures/lecture02/3_datatypes.html#sets",
    "href": "lectures/lecture02/3_datatypes.html#sets",
    "title": "Data Types in Python",
    "section": "Sets",
    "text": "Sets\nSets are like lists but have immutable unique entries, which means the elements can not be changed once defined. An emtpy set is created by the set() method.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYou may add elements to a set with the add method:\nYou may also remove objects with the discard method:\n\n\n\n\n\n\nYou may also apply a variety of operation to sets checking their intersection, union or difference."
  },
  {
    "objectID": "lectures/lecture02/3_datatypes.html#quiz-data-types-in-python",
    "href": "lectures/lecture02/3_datatypes.html#quiz-data-types-in-python",
    "title": "Data Types in Python",
    "section": "Quiz: Data Types in Python",
    "text": "Quiz: Data Types in Python\nLet‚Äôs test your understanding of Python data types!\n\n\nWhat is the output of the following code?\na = [1, 2, 3]\nb = (1, 2, 3)\nprint(type(a), type(b))\n\n&lt;class 'list'&gt; &lt;class 'list'&gt;\n&lt;class 'list'&gt; &lt;class 'tuple'&gt;\n&lt;class 'tuple'&gt; &lt;class 'list'&gt;\n&lt;class 'tuple'&gt; &lt;class 'tuple'&gt;\n\nWhich of the following is mutable?\n\nList\nTuple\nString\nInteger\n\nWhat will be the output of this code?\nmy_dict = {'a': 1, 'b': 2, 'c': 3}\nprint(my_dict['b'])\n\na\n2\nb\nKeyError\n\nHow do you create an empty set in Python?\n\n{}\n[]\nset()\n()\n\nWhat is the result of 3 + 4.0?\n\n7\n7.0\n‚Äò7.0‚Äô\nTypeError\n\n\n\n\n\n\n\n\n\nClick to reveal answers\n\n\n\n\n\n\n&lt;class 'list'&gt; &lt;class 'tuple'&gt;\nList\n2\nset()\n7.0"
  },
  {
    "objectID": "lectures/lecture02/04-summary02.html",
    "href": "lectures/lecture02/04-summary02.html",
    "title": "Einf√ºhrung in die Modellierung Physikalischer Prozesse",
    "section": "",
    "text": "Click to expand Matplotlib Plotting Cheat Sheet\n\n\n\n\n\n\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nplt.figure(figsize=(width, height))\n\n\n\nplt.plot(x, y, 'bo-')  # Blue line with circle markers\nplt.xlabel('X-axis label')\nplt.ylabel('Y-axis label')\nplt.title('Plot Title')\nplt.legend(['Label'], loc='best')\n\n\n\nplt.scatter(x, y, marker='o')\n\n\n\nplt.hist(data, bins=10, density=True)\n\n\n\nplt.plot(x, y1, 'b-', label='Line 1')\nplt.scatter(x, y2, color='r', label='Scatter')\nplt.legend()\n\n\n\nplt.savefig('filename.pdf')\n\n\n\nplt.errorbar(x, y, yerr=yerror, fmt='ro', ecolor='black')\n\n\n\nplt.xlim(xmin, xmax)\nplt.ylim(ymin, ymax)\n\n\n\nmasked_data = np.ma.masked_where(condition, data)\n\n\n\nplt.semilogx(x, y)  # Log scale on x-axis\nplt.semilogy(x, y)  # Log scale on y-axis\nplt.loglog(x, y)    # Log scale on both axes\n\n\n\nplt.subplot(rows, cols, plot_number)\n\n\n\nplt.contour(X, Y, Z, levels)\nplt.contourf(X, Y, Z, levels)  # Filled contour plot\n\n\n\nplt.imshow(data, extent=[xmin, xmax, ymin, ymax], cmap='colormap')\n\n\n\nfrom mpl_toolkits import mplot3d\nax = plt.axes(projection='3d')\nax.plot3D(x, y, z)\nax.scatter3D(x, y, z)\nax.plot_surface(X, Y, Z)\n\n\n\nplt.rcParams.update({'font.size': 12, 'lines.linewidth': 2})\nplt.tight_layout()\nRemember to always call plt.show() to display your plots!"
  },
  {
    "objectID": "lectures/lecture02/04-summary02.html#matplotlib-plotting-cheat-sheet",
    "href": "lectures/lecture02/04-summary02.html#matplotlib-plotting-cheat-sheet",
    "title": "Einf√ºhrung in die Modellierung Physikalischer Prozesse",
    "section": "",
    "text": "Click to expand Matplotlib Plotting Cheat Sheet\n\n\n\n\n\n\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nplt.figure(figsize=(width, height))\n\n\n\nplt.plot(x, y, 'bo-')  # Blue line with circle markers\nplt.xlabel('X-axis label')\nplt.ylabel('Y-axis label')\nplt.title('Plot Title')\nplt.legend(['Label'], loc='best')\n\n\n\nplt.scatter(x, y, marker='o')\n\n\n\nplt.hist(data, bins=10, density=True)\n\n\n\nplt.plot(x, y1, 'b-', label='Line 1')\nplt.scatter(x, y2, color='r', label='Scatter')\nplt.legend()\n\n\n\nplt.savefig('filename.pdf')\n\n\n\nplt.errorbar(x, y, yerr=yerror, fmt='ro', ecolor='black')\n\n\n\nplt.xlim(xmin, xmax)\nplt.ylim(ymin, ymax)\n\n\n\nmasked_data = np.ma.masked_where(condition, data)\n\n\n\nplt.semilogx(x, y)  # Log scale on x-axis\nplt.semilogy(x, y)  # Log scale on y-axis\nplt.loglog(x, y)    # Log scale on both axes\n\n\n\nplt.subplot(rows, cols, plot_number)\n\n\n\nplt.contour(X, Y, Z, levels)\nplt.contourf(X, Y, Z, levels)  # Filled contour plot\n\n\n\nplt.imshow(data, extent=[xmin, xmax, ymin, ymax], cmap='colormap')\n\n\n\nfrom mpl_toolkits import mplot3d\nax = plt.axes(projection='3d')\nax.plot3D(x, y, z)\nax.scatter3D(x, y, z)\nax.plot_surface(X, Y, Z)\n\n\n\nplt.rcParams.update({'font.size': 12, 'lines.linewidth': 2})\nplt.tight_layout()\nRemember to always call plt.show() to display your plots!"
  },
  {
    "objectID": "lectures/lecture02/04-summary02.html#basic-setup",
    "href": "lectures/lecture02/04-summary02.html#basic-setup",
    "title": "Einf√ºhrung in die Modellierung Physikalischer Prozesse",
    "section": "",
    "text": "import matplotlib.pyplot as plt\nimport numpy as np\n\nplt.figure(figsize=(width, height))"
  },
  {
    "objectID": "lectures/lecture02/04-summary02.html#line-plots",
    "href": "lectures/lecture02/04-summary02.html#line-plots",
    "title": "Einf√ºhrung in die Modellierung Physikalischer Prozesse",
    "section": "",
    "text": "plt.plot(x, y, 'bo-')  # Blue line with circle markers\nplt.xlabel('X-axis label')\nplt.ylabel('Y-axis label')\nplt.title('Plot Title')\nplt.legend(['Label'], loc='best')"
  },
  {
    "objectID": "lectures/lecture02/04-summary02.html#scatter-plots",
    "href": "lectures/lecture02/04-summary02.html#scatter-plots",
    "title": "Einf√ºhrung in die Modellierung Physikalischer Prozesse",
    "section": "",
    "text": "plt.scatter(x, y, marker='o')"
  },
  {
    "objectID": "lectures/lecture02/04-summary02.html#histograms",
    "href": "lectures/lecture02/04-summary02.html#histograms",
    "title": "Einf√ºhrung in die Modellierung Physikalischer Prozesse",
    "section": "",
    "text": "plt.hist(data, bins=10, density=True)"
  },
  {
    "objectID": "lectures/lecture02/04-summary02.html#combined-plots",
    "href": "lectures/lecture02/04-summary02.html#combined-plots",
    "title": "Einf√ºhrung in die Modellierung Physikalischer Prozesse",
    "section": "",
    "text": "plt.plot(x, y1, 'b-', label='Line 1')\nplt.scatter(x, y2, color='r', label='Scatter')\nplt.legend()"
  },
  {
    "objectID": "lectures/lecture02/04-summary02.html#saving-figures",
    "href": "lectures/lecture02/04-summary02.html#saving-figures",
    "title": "Einf√ºhrung in die Modellierung Physikalischer Prozesse",
    "section": "",
    "text": "plt.savefig('filename.pdf')"
  },
  {
    "objectID": "lectures/lecture02/04-summary02.html#error-bars",
    "href": "lectures/lecture02/04-summary02.html#error-bars",
    "title": "Einf√ºhrung in die Modellierung Physikalischer Prozesse",
    "section": "",
    "text": "plt.errorbar(x, y, yerr=yerror, fmt='ro', ecolor='black')"
  },
  {
    "objectID": "lectures/lecture02/04-summary02.html#setting-plot-limits",
    "href": "lectures/lecture02/04-summary02.html#setting-plot-limits",
    "title": "Einf√ºhrung in die Modellierung Physikalischer Prozesse",
    "section": "",
    "text": "plt.xlim(xmin, xmax)\nplt.ylim(ymin, ymax)"
  },
  {
    "objectID": "lectures/lecture02/04-summary02.html#masked-arrays",
    "href": "lectures/lecture02/04-summary02.html#masked-arrays",
    "title": "Einf√ºhrung in die Modellierung Physikalischer Prozesse",
    "section": "",
    "text": "masked_data = np.ma.masked_where(condition, data)"
  },
  {
    "objectID": "lectures/lecture02/04-summary02.html#logarithmic-plots",
    "href": "lectures/lecture02/04-summary02.html#logarithmic-plots",
    "title": "Einf√ºhrung in die Modellierung Physikalischer Prozesse",
    "section": "",
    "text": "plt.semilogx(x, y)  # Log scale on x-axis\nplt.semilogy(x, y)  # Log scale on y-axis\nplt.loglog(x, y)    # Log scale on both axes"
  },
  {
    "objectID": "lectures/lecture02/04-summary02.html#multiple-subplots",
    "href": "lectures/lecture02/04-summary02.html#multiple-subplots",
    "title": "Einf√ºhrung in die Modellierung Physikalischer Prozesse",
    "section": "",
    "text": "plt.subplot(rows, cols, plot_number)"
  },
  {
    "objectID": "lectures/lecture02/04-summary02.html#contour-plots",
    "href": "lectures/lecture02/04-summary02.html#contour-plots",
    "title": "Einf√ºhrung in die Modellierung Physikalischer Prozesse",
    "section": "",
    "text": "plt.contour(X, Y, Z, levels)\nplt.contourf(X, Y, Z, levels)  # Filled contour plot"
  },
  {
    "objectID": "lectures/lecture02/04-summary02.html#image-plots",
    "href": "lectures/lecture02/04-summary02.html#image-plots",
    "title": "Einf√ºhrung in die Modellierung Physikalischer Prozesse",
    "section": "",
    "text": "plt.imshow(data, extent=[xmin, xmax, ymin, ymax], cmap='colormap')"
  },
  {
    "objectID": "lectures/lecture02/04-summary02.html#d-plots",
    "href": "lectures/lecture02/04-summary02.html#d-plots",
    "title": "Einf√ºhrung in die Modellierung Physikalischer Prozesse",
    "section": "",
    "text": "from mpl_toolkits import mplot3d\nax = plt.axes(projection='3d')\nax.plot3D(x, y, z)\nax.scatter3D(x, y, z)\nax.plot_surface(X, Y, Z)"
  },
  {
    "objectID": "lectures/lecture02/04-summary02.html#customization",
    "href": "lectures/lecture02/04-summary02.html#customization",
    "title": "Einf√ºhrung in die Modellierung Physikalischer Prozesse",
    "section": "",
    "text": "plt.rcParams.update({'font.size': 12, 'lines.linewidth': 2})\nplt.tight_layout()\nRemember to always call plt.show() to display your plots!"
  },
  {
    "objectID": "lectures/lecture03/1_numpy.html",
    "href": "lectures/lecture03/1_numpy.html",
    "title": "NumPy Module",
    "section": "",
    "text": "Numpy is the core library for scientific computing in Python. It provides a high-performance multidimensional array object and tools for working with these arrays. The NumPy array, formally called ndarray in NumPy documentation, is the real workhorse of data structures for scientific and engineering applications. The NumPy array is similar to a list but where all the elements of the list are of the same type. The elements of a NumPy array are usually numbers, but can also be booleans, strings, or other objects. When the elements are numbers, they must all be of the same type."
  },
  {
    "objectID": "lectures/lecture03/1_numpy.html#creating-numpy-arrays",
    "href": "lectures/lecture03/1_numpy.html#creating-numpy-arrays",
    "title": "NumPy Module",
    "section": "Creating Numpy Arrays",
    "text": "Creating Numpy Arrays\nThere are a number of ways to initialize new numpy arrays, for example from\n\na Python list or tuples\nusing functions that are dedicated to generating numpy arrays, such as arange, linspace, etc.\nreading data from files which will be covered in the files section\n\n\nFrom lists\nFor example, to create new vector and matrix arrays from Python lists we can use the numpy.array function.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUsing array-generating functions\nFor larger arrays it is inpractical to initialize the data manually, using explicit python lists. Instead we can use one of the many functions in numpy that generate arrays of different forms. Some of the more common are:\n\n\n\n\n\n\n\n\n\n\n\n\n\nlinspace and logspace\nThe linspace function creates an array of N evenly spaced points between a starting point and an ending point. The form of the function is linspace(start, stop, N).If the third argument N is omitted,then N=50.\n\n\n\n\n\n\nlogspace is doing equivelent things with logaritmic spacing. Other types of array creation techniques are listed below. Try around with these commands to get a feeling what they do.\n\n\n\n\n\n\n\n\nmgrid\nmgrid generates a multi-dimensional matrix with increasing value entries, for example in columns and rows:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndiag\ndiag generates a diagonal matrix with the list supplied to it. The values can be also offset from the main diagonal.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nzeros and ones\nzeros and ones creates a matrix with the dimensions given in the argument and filled with 0 or 1."
  },
  {
    "objectID": "lectures/lecture03/1_numpy.html#manipulating-numpy-arrays",
    "href": "lectures/lecture03/1_numpy.html#manipulating-numpy-arrays",
    "title": "NumPy Module",
    "section": "Manipulating NumPy arrays",
    "text": "Manipulating NumPy arrays\n\nSlicing\nSlicing is the name for extracting part of an array by the syntax M[lower:upper:step]\n\n\n\n\n\n\n\n\n\n\n\n\nAny of the three parameters in M[lower:upper:step] can be ommited.\n\n\n\n\n\n\n\n\n\n\n\n\nNegative indices counts from the end of the array (positive index from the begining):\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIndex slicing works exactly the same way for multidimensional arrays:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDifferences\n\n\n\nSlicing can be effectively used to calculate differences for example for the calculation of derivatives. Here the position \\(y_i\\) of an object has been measured at times \\(t_i\\) and stored in an array each. We wish to calculate the average velocity at the times \\(t_{i}\\) from the arrays by\n\\[\\begin{equation}\nv_{i}=\\frac{y_i-y_{i-1}}{t_{i}-t_{i-1}}\n\\end{equation}\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReshaping\nArrays can be reshaped into any form, which contains the same number of elements.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdding a new dimension: newaxis\nWith newaxis, we can insert new dimensions in an array, for example converting a vector to a column or row matrix.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStacking and repeating arrays\n\n\n\n\n\nUsing function repeat, tile, vstack, hstack, and concatenate we can create larger vectors and matrices from smaller ones. Please try the individual functions yourself in your notebook. We wont discuss them in detail.\n\nTile and repeat\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConcatenate\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHstack and vstack"
  },
  {
    "objectID": "lectures/lecture03/1_numpy.html#applying-mathematical-functions",
    "href": "lectures/lecture03/1_numpy.html#applying-mathematical-functions",
    "title": "NumPy Module",
    "section": "Applying mathematical functions",
    "text": "Applying mathematical functions\nAll kinds of mathematica operations can be carried out on arrays. Typically these operation act element wise as seen from the examples below.\n\nOperation involving one array\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOperations involving multiple arrays\nVector operations enable efficient element-wise calculations where corresponding elements at matching positions are processed simultaneously. Instead of handling elements one by one, these operations work on entire arrays at once, making them particularly fast. When multiplying two vectors using these operations, the result is not a single number (as in a dot product) but rather a new array where each element is the product of the corresponding elements from the input vectors. This element-wise multiplication is just one example of vector operations, which can include addition, subtraction, and other mathematical functions."
  },
  {
    "objectID": "lectures/lecture04/2_brownian_motion copy.html",
    "href": "lectures/lecture04/2_brownian_motion copy.html",
    "title": "Brownian Motion",
    "section": "",
    "text": "File as PDF\nWe will use our newly gained knowledge about classes for the simulation of Brownian motion. This actually perfectly fits to the object oriented programming topic, as each Brownian particle (or colloid) can be seen as an object instanciated from the same class, but perhaps with different properties. Some particles might be larger and some smaller for example. We know already some part of that, as we have covered it in earlier lectures."
  },
  {
    "objectID": "lectures/lecture04/2_brownian_motion copy.html#physics",
    "href": "lectures/lecture04/2_brownian_motion copy.html#physics",
    "title": "Brownian Motion",
    "section": "Physics",
    "text": "Physics\nThe Brownian motion of a colloidal particle (called solute) results from the collisions with the surrounding solvent molecules. Due to these collisions, the particle has in equilibrium a mean kinetic energy defined by the temperature. With this kinetic energy it would travel a mean distance \\(l\\) before it takes another random direction and go another step length \\(l\\). This mean distance the particle travels is very short in liquids. It is on the other of picometers. It has been shown by Lindenberg and L√©vy that a sequence of many such infinitesimal small random steps leads to a total effect, which can be approximated by a normal distribution. This important theorem is called the central limit theorem.\nFor our Brownian motion the sequence of tiny steps leads after a time \\(t\\) to the following probability distribution to find the particle at a position \\(x\\) if it initially started at \\(x=0\\):\n\\[\\begin{equation}\np(x,\\Delta t)=\\frac{1}{\\sqrt{4\\pi D \\Delta t}}e^{-\\frac{x^2}{4D \\Delta t}}\n\\end{equation}\\]\nwhere \\(D\\) is the diffusion coefficient. Thus each step of our Brownian motion simulation for a timestep of \\(\\Delta t\\) is taken from a Gaussian distribution with a varaince of \\(\\sigma^2=2D \\Delta t\\).\nFor our simulation that means that we can draw numbers from a normal distribution with np.random.normal with the standard deviation \\(\\sigma=\\sqrt{2D \\Delta t}\\) as a parameter. This has to be done for the x-coordinate and the y-coordinate.\nThe code for our Brownian motion therefore is\nsigma=np.sqrt(2*D*dt)\ndx,dy=[(np.random.normal(0.0, sigma),np.random.normal(0.0, sigma)]\nx=x+dx\ny=y+dy\nwhich gives a whole 2d trajectory. With the help of this, we would like to write a colloidal particle class. So lets make a plan how this could work out."
  },
  {
    "objectID": "lectures/lecture04/2_brownian_motion copy.html#class-planning",
    "href": "lectures/lecture04/2_brownian_motion copy.html#class-planning",
    "title": "Brownian Motion",
    "section": "Class Planning",
    "text": "Class Planning\n\nPhysics project Colloidal particle class\nWe will define a class for a colloidal particle, which we may use later for our projects as well. This makes sense, as we can have different colloidal particles of different radius for example, which do start to carry out Brownian motion from different positions. A colloidal particle is and object, which has properties very much in the same way as classes intend that. The whole definition requires some planning, especially on what the class should keep track of and what the object.\nThe particle class shall keep track of\n* the total number of colloidal particles\n* the value of k_B T/(6 pi eta) = 2.2e-19\nThe class shall provide the class specific methods\n* how_many() which returns the total number of colloids\n* __str__ which returns a string with radius and position of the particle\n\n\nPhysics interlude: Colloidal particle class\nEach object shall then contain the following properties\n* the particle radius, R\n* a list of all x position, x\n* a list of all y position, y\n* the index of the colloid, index\n* the diffusion coefficient given by k_B T/(6 pi eta R), D\nThe object shall provide the following methods\n* sim_trajectory() simulate a whole trajectory at once\n* update(dt) do one step of Brownian motion with a time step dt as argument, return the current position\n* get_trajectory() return the trajectory as a pandas DataFrame with the columns x and y\n* get_D() return the diffusion coefficient\n\n\n\n\n\n\n\n\nNote:\nNote that the function sim_trajectory is actually calling the function update of the same object to generate the whole trajectory at once."
  },
  {
    "objectID": "lectures/lecture04/2_brownian_motion copy.html#simulating",
    "href": "lectures/lecture04/2_brownian_motion copy.html#simulating",
    "title": "Brownian Motion",
    "section": "Simulating",
    "text": "Simulating\nWith the help of this Colloid class, we would like to carry out simulations of Brownian motion of multiple particles. The simulations shall\n\ntake n=200 particles\nhave N=200 trajectory points each\nstart all at 0,0\nparticle objects should be stored in a list p_list"
  },
  {
    "objectID": "lectures/lecture04/2_brownian_motion copy.html#plotting-the-trajectories",
    "href": "lectures/lecture04/2_brownian_motion copy.html#plotting-the-trajectories",
    "title": "Brownian Motion",
    "section": "Plotting the trajectories",
    "text": "Plotting the trajectories\nThe next step is to plot all the trajectories."
  },
  {
    "objectID": "lectures/lecture04/2_brownian_motion copy.html#characterizing-the-brownian-motion",
    "href": "lectures/lecture04/2_brownian_motion copy.html#characterizing-the-brownian-motion",
    "title": "Brownian Motion",
    "section": "Characterizing the Brownian motion",
    "text": "Characterizing the Brownian motion\nNow that we have a number of trajectories, we can analyze the motion of our Brownian particles.\n\nCalculate the particle speed\nOne way is to calculate its speed by measuring how far it traveled within a certain time \\(n\\, dt\\), where \\(dt\\) is the timestep of out simulation. We can do that as\n\\[\\begin{equation}\nv(n dt) = \\frac{&lt;\\sqrt{(x_{i+n}-x_{i})^2+(y_{i+n}-y_{i})^2}&gt;}{n\\,dt}\n\\end{equation}\\]\nThe angular brackets on the top take care of the fact that we can measure the distance traveled within a certain time \\(n\\, dt\\) several times along a trajectory.\n\n\n\nmsd\n\n\nThese values can be used to calculate a mean speed. Note that there is not an equal amount of data pairs for all separations available. For \\(n=1\\) there are 5 distances available. For \\(n=5\\), however, only 1. This changes the statistical accuracy of the mean.\n\n\n\n\n\n\nThe result of this analysis shows, that each particle has an apparent speed which seems to increase with decreasing time of observation or which decreases with increasing time. This would mean that there is some friction at work, which slows down the particle in time, but this is apparently not true. Also an infinite speed at zero time appears to be unphysical. The correct answer is just that the speed is no good measure to characterize the motion of a Brownian particle.\n\n\nCalculate the particle mean squared displacement\nA better way to characterize the motion of a Brownian particle is the mean squared displacement, as we have already mentioned it in previous lectures. We may compare our simulation now to the theoretical prediction, which is\n\\[\\begin{equation}\n\\langle \\Delta r^{2}(t)\\rangle=2 d D t\n\\end{equation}\\]\nwhere \\(d\\) is the dimension of the random walk, which is \\(d=2\\) in our case.\n\n\n\n\n\n\nThe results show that the mean squared displacement of the individual particles follows on average the theoretical predictions of a linear growth in time. That means, we are able to read the diffusion coefficient from the slope of the MSD of the individual particles if recorded in a simulation or an experiment.\nYet, each individual MSD is deviating strongly from the theoretical prediction especially at large times. This is due to the fact mentioned earlier that our simulation (or experimental) data only has a limited number of data points, while the theoretical prediction is made for the limit of infinite data points.\n\nWarning: Analysis of MSD data\nSingle particle tracking, either in the experiment or in numerical simulations can therefore only deliver an estimate of the diffusion coefficient and care should be taken when using the whole MSD to obtain the diffusion coefficient. One typically uses only a short fraction of the whole MSD data at short times."
  },
  {
    "objectID": "lectures/lecture04/1_quantum_mechanics.html",
    "href": "lectures/lecture04/1_quantum_mechanics.html",
    "title": "Quantum Mechanics",
    "section": "",
    "text": "In the last lecture, we have modeled electromagnetic waves not by solving the wave equation, but by taking the solutions of wave equations like a plane wave or a spherical wave. Today we will solve a wave equation, but not for electromagnetic waves, but for matter waves. We will solve the stationary Schr√∂dinger equation with the implicit solution scheme, which we have already applied for the diffusion equation. With the help of that we will tackle the particle in a box, the harmonic oscillator and the periodic potential. All of these problems have also analytical solutions, thus we do not need the numerical solution in principle. But it will give us some practice on how to tackle such problems. As not all of you might be familiar with the physical description of quantum mechanics, we will give a short introduction into this field first.\nimport numpy as np\nfrom scipy.sparse import diags\nfrom scipy.sparse.linalg import eigsh\nimport matplotlib.pyplot as plt\n\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\n\n# default values for plotting\nplt.rcParams.update({'font.size': 12,\n                     'axes.titlesize': 18,\n                     'axes.labelsize': 16,\n                     'axes.labelpad': 14,\n                     'lines.linewidth': 1,\n                     'lines.markersize': 10,\n                     'xtick.labelsize' : 16,\n                     'ytick.labelsize' : 16,\n                     'xtick.top' : True,\n                     'xtick.direction' : 'in',\n                     'ytick.right' : True,\n                     'ytick.direction' : 'in',})"
  },
  {
    "objectID": "lectures/lecture04/1_quantum_mechanics.html#quantum-mechanics-in-a-nutshell",
    "href": "lectures/lecture04/1_quantum_mechanics.html#quantum-mechanics-in-a-nutshell",
    "title": "Quantum Mechanics",
    "section": "Quantum Mechanics in a Nutshell",
    "text": "Quantum Mechanics in a Nutshell\nQuantum Mechanics assumes that all particles propagate as waves. They are described by a wavefunction \\(\\Psi(x,t)\\). A quantum mechanical object thus posseses an amplitude and a phase which propagate in space and time. One could see the wavefunction in analogy to the electric field \\(\\vec{E}(x)\\) of an electromagnetic wave. As the square of the electric field describes the propagation of energy of a wave, the square magnitude of the wavefunction, i.e.¬†\\(|\\Psi(x,t)|^2\\), describes the propagation of probability density of the quantum mechanical wave. The wavefunction itself is thus just the probability amplitude.\n\nTime dependent Schr√∂dinger equation\nThe dynamics of a quantum mechanical wave is described,for example, by the time dependent Schr√∂dinger equation\n\\[\\begin{equation}\n-i\\hbar\\frac{\\partial \\Psi(x,t)}{\\partial t} = \\left ( \\frac{-\\hbar^2 }{2m}\\frac{\\partial^2}{\\partial x^2}+V(x,t) \\right ) \\Psi(x,t)\n\\end{equation}\\]\nwhis is written here for one dimension only.\nThe bracket on the right side of the above equation contains the so-called Hamilton operator \\(\\hat{H}\\). The Hamilton operator \\(\\hat{H}\\) contains the energy operators for the kinetic and potential energies and represents the total energy of the system.\n\\[\\begin{equation}\n\\hat{H}=\\left ( \\frac{-\\hbar^2 }{2m}\\frac{\\partial^2}{\\partial x^2}+V(x,t) \\right )\n\\end{equation}\\]\n\n\nStationary Schr√∂dinger equation\nOur first problems will be stationary problems. We will not ask for the temporal development of the quantum object. We will rather ask, what solutions without time dependence are possible. In general this is much like the question asking what kind of standing waves are possible on a string or in an optical resonator. In quantum mechanics the boundaries, which define the standing waves are formed by the potential energy \\(V(x)\\).\nWe therefore also need the stationary Schr√∂dinger equation, where the left side of the time dependent Schr√∂dinger equation does not depend on time, hence is constant in time. This stationary (time-independent) Schr√∂dinger equation is\n\\[\\begin{equation}\n\\hat{H}\\Psi(x)=E\\Psi(x)\n\\end{equation}\\]\nThe Hamilton operator \\(\\hat{H}\\) gives a recipe how to calculate the energies for a given wavefunction \\(\\Psi(x)\\) in terms of derivates or multiplications by functions. If this recipe reduces to a multiplication of the wave function with a number \\(E\\), then these wavefunctions are eigenfunction of the Hamilton operator and the values of \\(E\\) are the eigenvalues of the problem, i.e.¬†the time-independent solutions of this differential equation."
  },
  {
    "objectID": "lectures/lecture04/1_quantum_mechanics.html#recap-implicit-solution",
    "href": "lectures/lecture04/1_quantum_mechanics.html#recap-implicit-solution",
    "title": "Quantum Mechanics",
    "section": "Recap: Implicit Solution",
    "text": "Recap: Implicit Solution\nAccording to our above description, the Hamilton operator \\(\\hat{H}\\) contains two parts, a second derivative in the position, which represents the kinetic energy and the potential energy operator \\(V(x)\\), which is in the simplest case just a function of \\(x\\).\n\\[\\begin{equation}\n\\left ( \\frac{-\\hbar^2 }{2m}\\frac{\\partial^2}{\\partial x^2}+V(x) \\right ) \\Psi(x)=E\\Psi(x)\n\\end{equation}\\]\nSince we want to apply our implicit solution scheme (Cranck Nicolson), we want to represent both parts as matrices.\n\nKinetic energy\nWe remember that we can write the second derivative of our wavefunction \\(\\Psi(x)\\) in the finite difference approximation as\n\\[\\begin{equation}\n\\Psi^{''}(x)=\\frac{\\Psi(x+\\delta x)-2\\Psi(x)+\\Psi(x-\\delta x)}{\\delta x^{2}}\n\\end{equation}\\]\nIf we want to evaluate the wavefunction at certain positions \\(x_{i}\\), then this second derivative translates into\n\\(T\\Psi=\\frac{d^2}{dx^2}\\Psi=\\frac{1}{\\delta x^2}\n\\begin{bmatrix}\n-2 & 1  & 0 & 0 & 0 & 0\\\\\n1 & -2 & 1 & 0 & 0 & 0\\\\\n0 & 1  & -2 & 1 & 0 & 0\\\\\n0 & 0  & 1  & -2 & 1 & 0\\\\\n0 & 0  & 0  &  1 & -2 & 1\\\\\n0 & 0  & 0  &  0 &  1 & -2\\\\\n\\end{bmatrix}\n\\begin{bmatrix}\n\\Psi(x_{1})\\\\\n\\Psi(x_{2})\\\\\n\\Psi(x_{3})\\\\\n\\Psi(x_{4})\\\\\n\\Psi(x_{5})\\\\\n\\Psi(x_{6})\n\\end{bmatrix}\\)\nif we just use 6 positions. Please remember, that in the version above, we have imposed already boundary conditions in the first and the last row, which are \\(\\Psi(x_{0})=0\\) and \\(\\Psi(x_{7})=0\\). If we multiply this matrix by \\(-\\hbar^{2}/2m\\), we obtain the kinetic energy for an object of mass \\(m\\).\n\n\nPotential energy\nThe potential energy values are just values at the diagonal of the matrix\n\\(V\\Psi=\n\\begin{bmatrix}\nV(x_{1}) & 0  & 0 & 0 & 0 & 0\\\\\n0 & V(x_{2}) & 0 & 0 & 0 & 0\\\\\n0 & 0  & V(x_{3}) & 0 & 0 & 0\\\\\n0 & 0  & 0  & V(x_{4}) & 0 & 0\\\\\n0 & 0  & 0  &  0 & V(x_{5}) & 0\\\\\n0 & 0  & 0  &  0 &  0 & V(x_{6})\\\\\n\\end{bmatrix}\n\\begin{bmatrix}\n\\Psi(x_{1})\\\\\n\\Psi(x_{2})\\\\\n\\Psi(x_{3})\\\\\n\\Psi(x_{4})\\\\\n\\Psi(x_{5})\\\\\n\\Psi(x_{6})\n\\end{bmatrix}\\)\nan you may insert the specific potential energy values for your particular problem here.\nOur final problem \\(\\hat{H}\\Psi=E\\Psi\\) will thus have the following shape\n\\[\\begin{equation}\n\\begin{bmatrix}\n-2+V(x_{1}) & 1  & 0 & 0 & 0 & 0\\\\\n1 & -2+V(x_{2}) & 1 & 0 & 0 & 0\\\\\n0 & 1 & -2+V(x_{3})  & 1 & 0 & 0 \\\\\n0 &0 & 1  & -2+V(x_{4})  & 1 & 0 \\\\\n0 & 0 & 0  & 1  &  -2+V(x_{5}) & 1 \\\\\n0 & 0 & 0  & 0  &  1 &  -2+V(x_{6}) \\\\\n\\end{bmatrix}\n\\begin{bmatrix}\n\\Psi(x_{1})\\\\\n\\Psi(x_{2})\\\\\n\\Psi(x_{3})\\\\\n\\Psi(x_{4})\\\\\n\\Psi(x_{5})\\\\\n\\Psi(x_{6})\n\\end{bmatrix}=E\n\\begin{bmatrix}\n\\Psi(x_{1})\\\\\n\\Psi(x_{2})\\\\\n\\Psi(x_{3})\\\\\n\\Psi(x_{4})\\\\\n\\Psi(x_{5})\\\\\n\\Psi(x_{6})\n\\end{bmatrix}\n\\end{equation}\\]\nwhere I skipped the prefactor \\(-\\hbar^2/2m\\), to fit the matrices on one line. Yet I did not succeed. This is the final system of coupled equations which we can supply to any matrix solver. We will use a solver from the scipy.linalg module. In case we have special boundary conditions, we need to take them into account and replace the first and the last line for example with the particular boundary conditions."
  },
  {
    "objectID": "lectures/lecture04/04-plotting.html",
    "href": "lectures/lecture04/04-plotting.html",
    "title": "Plotting",
    "section": "",
    "text": "Data visualization through plotting is a crucial tool for analyzing and interpreting scientific data and theoretical predictions. While plotting capabilities are not built into Python‚Äôs core, they are available through various external library modules. Matplotlib is widely recognized as the de facto standard for plotting in Python. However, several other powerful plotting libraries exist, including PlotLy, Seaborn, and Bokeh, each offering unique features and capabilities for data visualization.\nAs Matplotlib is an external library (actually a collection of libraries), it must be imported into any script that uses it. While Matplotlib relies heavily on NumPy, importing NumPy separately is not always necessary for basic plotting. However, for most scientific applications, you‚Äôll likely use both. To create 2D plots, you typically start by importing Matplotlib‚Äôs pyplot module:\nThis import introduces the implicit interface of pyplot for creating figures and plots. Matplotlib offers two main interfaces:\nWe will use most of the the the pyplot interface as in the examples below. The section Additional Plotting will refer to the explicit programming of figures.\nWe can set some of the parameters for the appearance of graphs globally. In case you still want to modify a part of it, you can set individual parameters later during plotting. The command used here is the\nfunction, which takes a dictionary with the specific parameters as key."
  },
  {
    "objectID": "lectures/lecture04/04-plotting.html#simple-plotting",
    "href": "lectures/lecture04/04-plotting.html#simple-plotting",
    "title": "Plotting",
    "section": "Simple Plotting",
    "text": "Simple Plotting\nMatplotlib offers multiple levels of functionality for creating plots. Throughout this section, we‚Äôll primarily focus on using commands that leverage default settings. This approach simplifies the process, as Matplotlib automatically handles much of the graph layout. These high-level commands are ideal for quickly creating effective visualizations without delving into intricate details. At the end of this section, we‚Äôll briefly touch upon more advanced techniques that provide greater control over plot elements and layout.\n\nAnatomy of a Line Plot\nTo create a basic line plot, use the following command:\nplt.plot(x, y)\nBy default, this generates a line plot. However, you can customize the appearance by adjusting various parameters within the plot() function. For instance, you can modify it to resemble a scatter plot by changing certain arguments. The versatility of this command allows for a range of visual representations beyond simple line plots.\nLet‚Äôs create a simple line plot of the sine function over the interval [0, 4œÄ]. We‚Äôll use NumPy to generate the x-values and calculate the corresponding y-values. The following code snippet demonstrates this process:\n1x = np.linspace(0, 4.*np.pi, 100)\n2y = np.sin(x)\n\n3plt.figure(figsize=(4,3))\n4plt.plot(x, y)\n5plt.tight_layout()\n6plt.show()\n\n1\n\nCreate an array of 100 values between 0 and 4œÄ.\n\n2\n\nCalculate the sine of each value in the array.\n\n3\n\ncreate a new figure\n\n4\n\nplot the data\n\n5\n\nautomatically adjust the layout\n\n6\n\nshow the figure\n\n\nHere is the code in a Python cell:\n\n\n\n\n\n\nTry to change the values of the x and y arrays and see how the plot changes.\n\n\n\n\n\n\nWhy use plt.tight_layout()\n\n\n\n\n\nplt.tight_layout() is a very useful function in Matplotlib that automatically adjusts the spacing between plot elements to prevent overlapping and ensure that all elements fit within the figure area. Here‚Äôs what it does:\n\nPadding Adjustment: It adjusts the padding between and around subplots to prevent overlapping of axis labels, titles, and other elements.\nSubplot Spacing: It optimizes the space between multiple subplots in a figure.\nText Accommodation: It ensures that all text elements (like titles, labels, and legends) fit within the figure without being cut off.\nMargin Adjustment: It adjusts the margins around the entire figure to make sure everything fits neatly.\nAutomatic Resizing: If necessary, it can slightly resize subplot areas to accommodate all elements.\nLegend Positioning: It takes into account the presence and position of legends when adjusting layouts.\n\nKey benefits of using plt.tight_layout():\n\nIt saves time in manual adjustment of plot elements.\nIt helps create more professional-looking and readable plots.\nIt‚Äôs particularly useful when creating figures with multiple subplots or when saving figures to files.\n\nYou typically call plt.tight_layout() just before plt.show() or plt.savefig(). For example:\nplt.figure()\n# ... (your plotting code here)\nplt.tight_layout()\nplt.show()\n\n\n\n\nAxis Labels\nTo enhance the clarity and interpretability of our plots, it‚Äôs crucial to provide context through proper labeling. Let‚Äôs add descriptive axis labels to our diagram, a practice that significantly improves the readability and comprehension of the data being presented.\nplt.xlabel('x-label')\nplt.ylabel('y-label')\n\n\n\n\n\n\n\n\nLegends\nplt.plot(..., label=r'$\\sin(x)$')\nplt.legend(loc='lower left')\n\n\n\n\n\n\n\n\nPlots with error bars\nWhen plotting experimental data it is customary to include error bars that indicate graphically the degree of uncertainty that exists in the measurement of each data point. The MatPlotLib function errorbar plots data with error bars attached. It can be used in a way that either replaces or augments the plot function. Both vertical and horizontal error bars can be displayed. The figure below illustrates the use of error bars.\n\n\n\n\n\n\n\n\nSaving figures\nTo save a figure to a file we can use the savefig method in the Figure class. Matplotlib can generate high-quality output in a number formats, including PNG, JPG, EPS, SVG, PGF and PDF. For scientific papers, I recommend using PDF whenever possible. (LaTeX documents compiled with pdflatex can include PDFs using the includegraphics command). In some cases, PGF can also be good alternative."
  },
  {
    "objectID": "lectures/lecture04/04-plotting.html#other-plot-types",
    "href": "lectures/lecture04/04-plotting.html#other-plot-types",
    "title": "Plotting",
    "section": "Other Plot Types",
    "text": "Other Plot Types\n\nScatter plot\nIf you prefer to use symbols for plotting just use the\nplt.scatter(x,y)\ncommand of pylab. Note that the scatter command requires a x and y values and you can set the marker symbol (see an overview of the marker symbols).\n\n\n\n\n\n\n\n\nHistograms\nA very useful plotting command is also the hist command. It generates a histogram of the data provided. A histogram is a graphical representation of the distribution of numerical data. It is an estimate of the probability distribution of a continuous variable. To construct a histogram, the first step is to ‚Äúbin‚Äù the range of values‚Äîthat is, divide the entire range of values into a series of intervals‚Äîand then count how many values fall into each interval. The bins are usually specified as consecutive, non-overlapping intervals of a variable. The bins must be adjacent, and are often (but not required to be) of equal size.\nWhen using the histogram function, you have flexibility in how the data is grouped. If you only provide the dataset, the function will automatically determine appropriate bins. However, you can also specify custom bins by passing an array of intervals using the syntax hist(data, bins=b), where b is your custom array of bin edges. To normalize the histogram so that the total area under it equals 1, you can set the density parameter to True. It‚Äôs worth noting that the histogram function doesn‚Äôt just create a visual representation; it also returns useful information such as the count of data points in each bin and the bin edges themselves.\n\n\n\n\n\n\nPhysics Interlude- Probability density for finding an oscillating particle\n\n\n\nLet‚Äôs integrate histogram plotting with a fundamental physics concept: the simple harmonic oscillator in one dimension. This system is described by a specific equation of motion:\n\\[\\begin{equation}\n\\ddot{x}(t) = -\\omega^2 x(t)\n\\end{equation}\\]\nFor an initial elongation \\(\\Delta x\\) at \\(t=0\\), the solution is:\n\\[\\begin{equation}\nx(t) = \\Delta x \\cos(\\omega t)\n\\end{equation}\\]\nTo calculate the probability of finding the spring at a certain elongation, we need to consider the time spent at different positions. The time \\(dt\\) spent in the interval [\\(x(t)\\), \\(x(t)+dx\\)] depends on the speed:\n\\[\\begin{equation}\nv(t) = \\frac{dx}{dt} = -\\omega \\Delta x \\sin(\\omega t)\n\\end{equation}\\]\nThe probability of finding the oscillator in a certain interval is the fraction of time spent in this interval, normalized by half the oscillation period \\(T/2\\):\n\\[\\begin{equation}\n\\frac{dt}{T/2} = \\frac{1}{T/2}\\frac{dx}{v(t)} = \\frac{1}{T/2}\\frac{-dx}{\\omega \\Delta x \\sin(\\omega t)}\n\\end{equation}\\]\nGiven that \\(\\omega = 2\\pi/T\\), we can derive the probability density:\n\\[\\begin{equation}\np(x)dx = \\frac{1}{\\pi \\Delta x}\\frac{dx}{\\sqrt{1-\\left(\\frac{x(t)}{\\Delta x}\\right)^2}}\n\\end{equation}\\]\nThis probability density reveals that the spring is more likely to be found at elongations where its speed is low. This principle extends to non-equilibrium physics, where entities moving with variable speed are more likely to be found in locations where they move slowly.\nWe can visualize this using the histogram function. By evaluating the position at equidistant times using the equation of motion and creating a histogram of these positions, we can represent the probability of finding the oscillator at certain positions. When properly normalized, this histogram will reflect the theoretical probability density we derived.\n\n\n\n\n\n\n\n\n\n\nSetting plotting limits and excluding data\nIf you want to zoom in to s specific region of a plot you can set the limits of the individual axes.\n\n\n\n\n\n\n\n\nMasked arrays\nSometimes you encounter situations, when you wish to mask some of the data of your plot, because they are not showing real data as the vertical lines in the plot above. For this purpose, you can mask the data arrays in various ways to not show up. The example below uses the\nnp.ma.masked_where()\nfunction of NumPy, which takes a condition as the first argument and what should be returned if that condition is fulfilled.\n\n\n\n\n\n\nIf you look at the resulting array, you will find, that the entries have not been removed but replaced by --, so the values are not existent and thefore not plotted.\n\n\n\n\n\n\n\nLogarithmic plots\n\n\n\n\n\nData sets can span many orders of magnitude from fractional quantities much smaller than unity to values much larger than unity. In such cases it is often useful to plot the data on logarithmic axes.\n\nSemi-log plots\nFor data sets that vary exponentially in the independent variable, it is often useful to use one or more logarithmic axes. Radioactive decay of unstable nuclei, for example, exhibits an exponential decrease in the number of particles emitted from the nuclei as a function of time.\nMatPlotLib provides two functions for making semi-logarithmic plots, semilogx and semilogy, for creating plots with logarithmic x and y axes, with linear y and x axes, respectively. We illustrate their use in the program below, which made the above plots.\n\n\n\n\n\n\n\n\nLog-log plots\nMatPlotLib can also make log-log or double-logarithmic plots using the function loglog. It is useful when both the \\(x\\) and \\(y\\) data span many orders of magnitude. Data that are described by a power law \\(y=Ax^b\\), where \\(A\\) and \\(b\\) are constants, appear as straight lines when plotted on a log-log plot. Again, the loglog function works just like the plot function but with logarithmic axes.\n\n\n\n\n\n\n\n\n\n\n\n\nCombined plots\nYou can combine multiple data with the same axes by stacking multiple plots.\n\n\n\n\n\n\n\n\nArranging multiple plots\nOften you want to create two or more graphs and place them next to one another, generally because they are related to each other in some way.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnimations\n\n\n\n\n\nMatplotlib can also be used to create animations. The FuncAnimation class makes it easy to create animations by repeatedly calling a function to update the plot. The following example shows a simple pendulum animation.\n\n\n\n\n\n\n\n\n\n\n\nSimple contour plot\n\n\n\n\n\n\nPhysics Interlude\n\n\n\n\n\n\nContour and Density Plots\nA contour plots are useful tools to study two dimensional data, meaning \\(Z(X,Y)\\). A contour plots the lines of constant value of the function \\(Z\\).\n\n\nUnderstanding Wave Interference\nImagine throwing two stones into a pond. Each stone creates circular waves that spread out. When these waves meet, they create interesting patterns - this is called interference. Let‚Äôs explore this using physics and Python!\n\nWhat is a Wave?\nA wave can be described mathematically. For our example, we‚Äôll look at spherical waves (like those in the pond). Each wave has: - An amplitude (how tall the wave is) - A wavelength (distance between wave peaks) - A frequency (how fast it oscillates)\n\n\nMathematical Description\nFor a single wave source, we can write: \\[\\begin{equation}\nU(r)=e^{-i\\,k r}\n\\end{equation}\\]\nWhere: - \\(k\\) is related to the wavelength (\\(k = 2\\pi/\\lambda\\)) - \\(r\\) is the distance from the source - We‚Äôve simplified by ignoring how the wave gets smaller as it travels (\\(1/r\\) term)\n\n\nTwo Wave Sources\nWhen we have two wave sources (like two stones dropped in the pond): 1. Each source creates its own wave 2. The waves combine where they meet 3. The total wave is the sum of both waves\n\n\n\ninterference\n\n\nMathematically: \\[\\begin{equation}\nU_{total} = e^{-i\\,k r_1} + e^{-i\\,k r_2}\n\\end{equation}\\]\nWhere \\(r_1\\) and \\(r_2\\) are the distances from each source.\n\n\nWhat We See (Intensity)\nWhat we actually see is the intensity of the combined waves:\n\\[\\begin{equation}\n\\text{Intensity} \\propto |U_{total}|^2\n\\end{equation}\\]\nThis will show us where the waves:\n\nAdd up (bright regions - constructive interference)\nCancel out (dark regions - destructive interference)\n\nLet‚Äôs create a Python program to visualize this!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nColor contour plot\n\n\n\n\n\n\n\n\nImage plot\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdvanced Plotting - Explicit Version\n\n\n\n\n\nAdvanced Plotting - Explicit Version\nWhile we have so far largely relied on the default setting and the automatic arrangement of plots, there is also a way to precisely design your plot. Python provides the tools of object oriented programming and thus modules provide classes which can be instanced into objects. This explicit interfaces allows you to control all details without the automatisms of pyplot.\nThe figure below, which is taken from the matplotlib documentation website shows the sets of commands and the objects in the figure, the commands refer to. It is a nice reference, when creating a figure.\n\n\n\nanatomy of a figure\n\n\n\nPlots with Multiple Spines\nSometimes it is very useful to plot different quantities in the same plot with the same x-axis but with different y-axes. Here is some example, where each line plot has its own y-axis.\n\n\n\n\n\n\n\n\nInsets\nInsets are plots within plots using their own axes. We therefore need to create two axes systems, if we want to have a main plot and and inset.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSpine axis\n\n\n\n\n\n\n\n\nPolar plot\n\n\n\n\n\n\n\n\nText annotation\nAnnotating text in matplotlib figures can be done using the text function. It supports LaTeX formatting just like axis label texts and titles:\n\n\n\n\n\n\n\n\n3D Plotting\nMatplotlib was initially designed with only two-dimensional plotting in mind. Around the time of the 1.0 release, some three-dimensional plotting utilities were built on top of Matplotlib‚Äôs two-dimensional display, and the result is a convenient (if somewhat limited) set of tools for three-dimensional data visualization. Three-dimensional plots are enabled by importing the mplot3d toolkit, included with the main Matplotlib installation:\n\n\n\n\n\n\nOnce this submodule is imported, a three-dimensional axes can be created by passing the keyword projection=‚Äò3d‚Äô to any of the normal axes creation routines:\n\nProjection Scence\n\n\n\n\n\n\nWith this three-dimensional axes enabled, we can now plot a variety of three-dimensional plot types. Three-dimensional plotting is one of the functionalities that benefits immensely from viewing figures interactively rather than statically in the notebook; recall that to use interactive figures, you can use %matplotlib notebook rather than %matplotlib inline when running this code.\n\n\nLine Plotting in 3D\nfrom sets of (x, y, z) triples. In analogy with the more common two-dimensional plots discussed earlier, these can be created using the ax.plot3D and ax.scatter3D functions. The call signature for these is nearly identical to that of their two-dimensional counterparts, so you can refer to Simple Line Plots and Simple Scatter Plots for more information on controlling the output. Here we‚Äôll plot a trigonometric spiral, along with some points drawn randomly near the line:\n\n\n\n\n\n\nNotice that by default, the scatter points have their transparency adjusted to give a sense of depth on the page. While the three-dimensional effect is sometimes difficult to see within a static image, an interactive view can lead to some nice intuition about the layout of the points. Use the scatter3D or the plot3D method to plot a random walk in 3-dimensions in your exercise.\n\n\nSurface Plotting\nA surface plot is like a wireframe plot, but each face of the wireframe is a filled polygon. Adding a colormap to the filled polygons can aid perception of the topology of the surface being visualized:"
  },
  {
    "objectID": "lectures/lecture04/04-plotting.html#contour-and-density-plots",
    "href": "lectures/lecture04/04-plotting.html#contour-and-density-plots",
    "title": "Plotting",
    "section": "Contour and Density Plots",
    "text": "Contour and Density Plots\nA contour plots are useful tools to study two dimensional data, meaning \\(Z(X,Y)\\). A contour plots the lines of constant value of the function \\(Z\\)."
  },
  {
    "objectID": "lectures/lecture04/04-plotting.html#understanding-wave-interference",
    "href": "lectures/lecture04/04-plotting.html#understanding-wave-interference",
    "title": "Plotting",
    "section": "Understanding Wave Interference",
    "text": "Understanding Wave Interference\nImagine throwing two stones into a pond. Each stone creates circular waves that spread out. When these waves meet, they create interesting patterns - this is called interference. Let‚Äôs explore this using physics and Python!\n\nWhat is a Wave?\nA wave can be described mathematically. For our example, we‚Äôll look at spherical waves (like those in the pond). Each wave has: - An amplitude (how tall the wave is) - A wavelength (distance between wave peaks) - A frequency (how fast it oscillates)\n\n\nMathematical Description\nFor a single wave source, we can write: \\[\\begin{equation}\nU(r)=e^{-i\\,k r}\n\\end{equation}\\]\nWhere: - \\(k\\) is related to the wavelength (\\(k = 2\\pi/\\lambda\\)) - \\(r\\) is the distance from the source - We‚Äôve simplified by ignoring how the wave gets smaller as it travels (\\(1/r\\) term)\n\n\nTwo Wave Sources\nWhen we have two wave sources (like two stones dropped in the pond): 1. Each source creates its own wave 2. The waves combine where they meet 3. The total wave is the sum of both waves\n\n\n\ninterference\n\n\nMathematically: \\[\\begin{equation}\nU_{total} = e^{-i\\,k r_1} + e^{-i\\,k r_2}\n\\end{equation}\\]\nWhere \\(r_1\\) and \\(r_2\\) are the distances from each source.\n\n\nWhat We See (Intensity)\nWhat we actually see is the intensity of the combined waves:\n\\[\\begin{equation}\n\\text{Intensity} \\propto |U_{total}|^2\n\\end{equation}\\]\nThis will show us where the waves:\n\nAdd up (bright regions - constructive interference)\nCancel out (dark regions - destructive interference)\n\nLet‚Äôs create a Python program to visualize this!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nColor contour plot\n\n\n\n\n\n\n\n\nImage plot"
  },
  {
    "objectID": "lectures/lecture04/04-plotting.html#advanced-plotting---explicit-version",
    "href": "lectures/lecture04/04-plotting.html#advanced-plotting---explicit-version",
    "title": "Plotting",
    "section": "Advanced Plotting - Explicit Version",
    "text": "Advanced Plotting - Explicit Version\nWhile we have so far largely relied on the default setting and the automatic arrangement of plots, there is also a way to precisely design your plot. Python provides the tools of object oriented programming and thus modules provide classes which can be instanced into objects. This explicit interfaces allows you to control all details without the automatisms of pyplot.\nThe figure below, which is taken from the matplotlib documentation website shows the sets of commands and the objects in the figure, the commands refer to. It is a nice reference, when creating a figure.\n\n\n\nanatomy of a figure\n\n\n\nPlots with Multiple Spines\nSometimes it is very useful to plot different quantities in the same plot with the same x-axis but with different y-axes. Here is some example, where each line plot has its own y-axis.\n\n\n\n\n\n\n\n\nInsets\nInsets are plots within plots using their own axes. We therefore need to create two axes systems, if we want to have a main plot and and inset.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSpine axis\n\n\n\n\n\n\n\n\nPolar plot\n\n\n\n\n\n\n\n\nText annotation\nAnnotating text in matplotlib figures can be done using the text function. It supports LaTeX formatting just like axis label texts and titles:\n\n\n\n\n\n\n\n\n3D Plotting\nMatplotlib was initially designed with only two-dimensional plotting in mind. Around the time of the 1.0 release, some three-dimensional plotting utilities were built on top of Matplotlib‚Äôs two-dimensional display, and the result is a convenient (if somewhat limited) set of tools for three-dimensional data visualization. Three-dimensional plots are enabled by importing the mplot3d toolkit, included with the main Matplotlib installation:\n\n\n\n\n\n\nOnce this submodule is imported, a three-dimensional axes can be created by passing the keyword projection=‚Äò3d‚Äô to any of the normal axes creation routines:\n\nProjection Scence\n\n\n\n\n\n\nWith this three-dimensional axes enabled, we can now plot a variety of three-dimensional plot types. Three-dimensional plotting is one of the functionalities that benefits immensely from viewing figures interactively rather than statically in the notebook; recall that to use interactive figures, you can use %matplotlib notebook rather than %matplotlib inline when running this code.\n\n\nLine Plotting in 3D\nfrom sets of (x, y, z) triples. In analogy with the more common two-dimensional plots discussed earlier, these can be created using the ax.plot3D and ax.scatter3D functions. The call signature for these is nearly identical to that of their two-dimensional counterparts, so you can refer to Simple Line Plots and Simple Scatter Plots for more information on controlling the output. Here we‚Äôll plot a trigonometric spiral, along with some points drawn randomly near the line:\n\n\n\n\n\n\nNotice that by default, the scatter points have their transparency adjusted to give a sense of depth on the page. While the three-dimensional effect is sometimes difficult to see within a static image, an interactive view can lead to some nice intuition about the layout of the points. Use the scatter3D or the plot3D method to plot a random walk in 3-dimensions in your exercise.\n\n\nSurface Plotting\nA surface plot is like a wireframe plot, but each face of the wireframe is a filled polygon. Adding a colormap to the filled polygons can aid perception of the topology of the surface being visualized:"
  },
  {
    "objectID": "seminars/seminar07/seminar7.html",
    "href": "seminars/seminar07/seminar7.html",
    "title": "Seminar Coding Session 1",
    "section": "",
    "text": "To practice the concepts covered in the lectures, we have prepared a few coding exercises. These exercises are designed to help you to get further used into programming. Each question is related to a physics problem and all of them have a solution that you can check after you have tried to solve them.\nEach exercise is also equipped with a time estimate to help you plan your work. The time estimates are approximate and rather valid for students without prior knowledge of programming and python before this course.\nYou are going to solve at least two of the four exercises below in the seminar. You can choose the exercises you want to solve. One of the students will present the solution to the exercise and we will discuss the solution together.\n\n\n\n\n\n\nExample 1: Distance Calculation\n\n\n\nCalculate the total distance traveled by a car moving at constant velocity for different time intervals. This problem demonstrates the linear relationship between distance and time when velocity remains constant.\nUsing the formula for uniform motion \\(d = v \\cdot t\\), where \\(d\\) is displacement, \\(v\\) is velocity, and \\(t\\) is time, we‚Äôll calculate distances for several time points and visualize the results in a plot. This will help illustrate how distance increases linearly with time when velocity is constant.\nTime estimate: 20-25 minutes\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nCreate an array of time points from 0 to 10 seconds and calculate the distance traveled at each time point using the formula \\(d = v \\cdot t\\). Use a for loop to print the time and distance values. Finally, create a simple plot of distance vs time using plt.plot().\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExample 2: Weight on Different Planets\n\n\n\nCalculate weight (\\(F = mg\\)) of an object on different planets using a list of gravitational accelerations. The weight force depends on both the mass of the object and the local gravitational acceleration. By comparing the weight of the same object across different planets, we can understand how gravitational forces vary throughout our solar system. We‚Äôll use Newton‚Äôs second law in the form \\(F = mg\\) where \\(m\\) is the object‚Äôs mass and \\(g\\) is the local gravitational acceleration.\nTime estimate: 10-15 minutes\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nCalculate and print the weights in a for loop. Try to use thezip() function to iterate over two lists simultaneously. Think about formatted printing using f-strings. f\"{variable:.2f}\" inside the print function will print the variable with two decimal places.\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExample 3: Simple Kinetic Energy Calculator\n\n\n\nWrite a function to calculate kinetic energy (\\(KE = \\frac{1}{2}mv^2\\)) and test it with different values. This example demonstrates how to create and use a function to calculate the kinetic energy of objects with different masses moving at a given velocity. Kinetic energy is a scalar quantity that depends on both mass and velocity, with velocity having a squared relationship. By testing the function with multiple masses, we can observe how kinetic energy scales with mass while keeping velocity constant.\nTime estimate: 15-20 minutes\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nDefine a function calculate_ke(mass, velocity) that returns the kinetic energy. Use a for loop to calculate and print the kinetic energy for different masses. Use formatted printing to print the results.\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExample 4: Average Speed Calculator\n\n\n\nCalculate average speed from a list of distances and times (segments of a journey). First, sum up the total distances traveled and times taken for the complete journey. Then, use the formula \\(v_{avg} = \\frac{\\text{total distance}}{\\text{total time}}\\) to find the overall average speed. We‚Äôll also calculate individual segment speeds for comparison.\nTime estimate: 20-25 minutes\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nCalculate the total distance and total time using the sum() function. Calculate the average speed using the formula \\(v_{avg} = \\frac{\\text{total distance}}{\\text{total time}}\\). Use a for loop to calculate and print the speed for each segment.\n\n\n\n\n\n\n\n\n\n\n\nTip"
  },
  {
    "objectID": "seminars/seminar09/add ons.html",
    "href": "seminars/seminar09/add ons.html",
    "title": "Einf√ºhrung in die Modellierung Physikalischer Prozesse",
    "section": "",
    "text": "Example 6: Simple Particle Class\n\n\n\nCreate a Particle class to represent a point mass with basic properties (mass, position, velocity) and methods to calculate its kinetic and potential energy. This introduces basic class concepts without getting too complex.\nTime estimate: 20 minutes\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nYou‚Äôll need to:\n\nStore mass, position, and velocity as class attributes (self.mass etc.)\nUse numpy arrays for position and velocity vectors\nDefine gravitational constant g = 9.81\nUse np.linalg.norm() to calculate speed from velocity vector\nRemember formulas: K = 1/2mv¬≤, U = mgh, E = K + U\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExample 8: Two-Body System\n\n\n\nCreate a simple class to calculate the gravitational force and potential energy between two masses. This introduces basic physics calculations in an object-oriented way.\nTime estimate: 20 minutes\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nYou‚Äôll need to:\n\nUse the gravitational force equation F = Gm1m2/r¬≤\nUse the gravitational potential energy equation U = -Gm1m2/r\nCreate a method to calculate and print both values\nUse scientific notation (:.2e) for readable output\nInclude units (N for force, J for energy) in the output\n\n\n\n\n\n\n\n\n\n\n\n\nNote"
  },
  {
    "objectID": "seminars/seminar08/seminar8.html",
    "href": "seminars/seminar08/seminar8.html",
    "title": "Seminar Coding Exercises 2",
    "section": "",
    "text": "Building on our previous coding exercise, we have prepared another set of problems to further develop your programming skills. Like before, these exercises apply physics concepts and include solutions you can check after attempting them yourself.\nEach exercise includes a time estimate to help you plan your work. These estimates are approximate and particularly relevant for students who are still new to programming and Python.\nAs in the previous seminar, you will choose and solve two of the five exercises below. One student will present their solution to each chosen exercise, followed by a group discussion of the approach and implementation.\n\n\n\n\n\n\nExample 1: Free Fall Motion\n\n\n\nWrite a program that calculates and visualizes the position and velocity of a freely falling object at different times. This exercise will help you understand how to implement basic physics equations in Python and create meaningful visualizations of the results.\nUse the equations of motion for an object under constant acceleration (gravity):\n\n\\(y(t) = y_0 + v_0t - \\frac{1}{2}gt^2\\)\n\\(v(t) = v_0 - gt\\)\n\nWhere \\(g = 9.81\\) m/s¬≤ (acceleration due to gravity), initial height \\(y_0 = 100\\)m, and initial velocity \\(v_0 = 0\\) m/s. Calculate values for the first 5 seconds in 0.5s intervals and create plots showing how both position and velocity change over time.\nTime estimate: 15-20 minutes\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nYou‚Äôll need to:\n\nCreate a time array using np.arange() from 0 to 5s with 0.5s steps\nUse the equations to calculate position and velocity arrays\nCreate a figure with two subplots:\n\nLeft subplot: Position vs Time\nRight subplot: Velocity vs Time\n\nLabel your axes and add titles\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExample 2: Projectile Range Calculator\n\n\n\nWrite a function that calculates the range of a projectile given its initial velocity and launch angle. This exercise will help you understand how to implement trigonometric functions and explore how launch angle affects projectile motion.\nUse:\n\nRange = \\((v_0^2 \\sin(2\\theta)) / g\\)\n\nwhere \\(v_0\\) is the initial velocity and \\(\\theta\\) is the launch angle.\nTest the function for angles between 0¬∞ and 90¬∞ in steps of 15¬∞ and determine which angle gives the maximum range. Consider how this relates to the theoretical maximum at 45¬∞.\nTime estimate: 15-20 minutes\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nYou‚Äôll need to:\n\nDefine a function that takes initial velocity (\\(v_0\\)) and angle (\\(\\theta\\)) as inputs\nConvert the angle from degrees to radians using \\(\\text{np.deg2rad}()\\)\nUse the range equation: \\(\\frac{v_0^2 \\sin(2\\theta)}{g}\\)\nTest the function with angles from \\(0^\\circ\\) to \\(90^\\circ\\) in steps of \\(15^\\circ\\)\nPrint the range for each angle\nCalculate and print the maximum range at \\(45^\\circ\\)\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExample 3: Simple Harmonic Motion\n\n\n\nCalculate and plot the position of a mass on a spring over time using:\n\n\\(x(t) = A\\cos(\\omega t)\\)\n\nwhere \\(A\\) is amplitude and \\(\\omega\\) is angular frequency (\\(\\omega = \\sqrt{k/m}\\)). Plot the position over several oscillation periods to visualize the periodic motion. Use appropriate axis labels and title to clearly show what is being plotted.\nTime estimate: 15-20 minutes\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nYou‚Äôll need to:\n\nCalculate omega using \\(\\omega = \\sqrt{k/m}\\)\nCreate a time array using np.linspace() from 0 to 10s with 1000 points\nCalculate position using \\(x(t) = A\\cos(\\omega t)\\)\nCreate a plot with:\n\nPosition vs Time\nAppropriate axis labels\nTitle\nGrid\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExample 4: Work and Energy\n\n\n\nCalculate the work done by a variable force \\(F(x) = kx^2\\) over a distance. Use numerical integration (simple Riemann sum) to find the work:\n\n\\(W = \\int_{x_1}^{x_2} F(x)dx\\)\n\nCreate a function that takes the force constant k, start position x1, end position x2, and number of integration steps as inputs. Calculate the work done by breaking the interval into small steps and summing the force times the distance for each step.\nTime estimate: 15-20 minutes\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nYou‚Äôll need to:\n\nCreate a function that takes x and k as inputs to calculate force\nCreate a function that:\n\nCreates an array of x values using np.linspace()\nCalculates step size dx\nCalculates force at each x value\nMultiplies force by dx and sums to get total work\n\nTest the function with sample values and display result\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExample 5: Elastic Collision Analysis\n\n\n\nWrite a program that analyzes an elastic collision between two objects. Given initial velocities and masses, calculate final velocities using conservation of momentum and kinetic energy:\n\nConservation of Momentum: \\(m_1v_1 + m_2v_2 = m_1v_1' + m_2v_2'\\)\nConservation of Energy: \\(\\frac{1}{2}m_1v_1^2 + \\frac{1}{2}m_2v_2^2 = \\frac{1}{2}m_1v_1'^2 + \\frac{1}{2}m_2v_2'^2\\)\n\nWrite a function that takes masses and initial velocities as inputs and returns the final velocities. Then test the function with different combinations of masses and velocities to verify that both momentum and energy are conserved in each case.\nTime estimate: 20-25 minutes\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nYou‚Äôll need to:\n\nUse the elastic collision equations:\n\n\\(v_1' = \\frac{m_1 - m_2}{m_1 + m_2}v_1 + \\frac{2m_2}{m_1 + m_2}v_2\\)\n\\(v_2' = \\frac{2m_1}{m_1 + m_2}v_1 + \\frac{m_2 - m_1}{m_1 + m_2}v_2\\)\n\nCreate a function that:\n\nTakes masses and initial velocities as input\nReturns final velocities using the equations\n\nFor each test case:\n\nCalculate final velocities\nVerify momentum conservation\nVerify energy conservation\n\nPrint results showing:\n\nInitial conditions\nFinal velocities\nConservation of momentum and energy\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote"
  },
  {
    "objectID": "seminars/seminar06/Report/Figures/Figure1/Figure1.html",
    "href": "seminars/seminar06/Report/Figures/Figure1/Figure1.html",
    "title": "Einf√ºhrung in die Modellierung Physikalischer Prozesse",
    "section": "",
    "text": "import matplotlib as mpl\nimport matplotlib.font_manager as font_manager\nfrom IPython.core.display import HTML\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom directory_tree import display_tree\n\n\nplt.rcParams.update({'font.size': 12,\n                     'lines.linewidth': 1,\n                     'lines.markersize': 10,\n                     'axes.labelsize': 11,\n                     'xtick.labelsize' : 10,\n                     'ytick.labelsize' : 10,\n                     'xtick.top' : True,\n                     'xtick.direction' : 'in',\n                     'ytick.right' : True,\n                     'ytick.direction' : 'in',}) \n\n%config InlineBackend.figure_format = 'retina'\n\n\ndef get_size(w,h):\n    return((w/2.54,h/2.54))\n\n\nplt.figure(figsize=get_size(7,5),dpi=150)\nx=np.linspace(0,np.pi*4,200)\nplt.plot(x,np.sin(x)*np.cos(2*x),color='r')\nplt.xlabel(r\"angle $\\theta$ in [rad]\")\nplt.ylabel(r\"$\\sin(\\theta)$\")\nplt.savefig(\"../figure1.pdf\",bbox_inches = 'tight')\nplt.show()"
  },
  {
    "objectID": "seminars/seminar06/25_publication_ready_figures.html",
    "href": "seminars/seminar06/25_publication_ready_figures.html",
    "title": "Erstellung ver√∂ffentlichungsreifer Diagramme",
    "section": "",
    "text": "Optimale Plotgr√∂√üen f√ºr wissenschaftliche Arbeiten\nIn diesem Leitfaden zeige ich Ihnen, wie Sie Plots in einer standardisierten, publikationstauglichen Gr√∂√üe erstellen k√∂nnen. Die Hinweise sind sowohl f√ºr Jupyter-Notebooks als auch f√ºr wissenschaftliche Arbeiten wie Semesterarbeiten geeignet.\nBeim Export von Plots als PDF-Dateien werden Vektorgrafiken erzeugt, die sich nachtr√§glich verlustfrei skalieren lassen. Dies erm√∂glicht zwar eine flexible Anpassung an ein- oder zweispaltige Layoutformate, kann aber zu Inkonsistenzen f√ºhren: Unterschiedliche Skalierungsfaktoren resultieren oft in verschiedenen Gr√∂√üen von Achsenbeschriftungen und Markierungen, was das Gesamtbild der Arbeit beeintr√§chtigt.\nDie bessere Strategie ist es, von Anfang an einheitliche Plotgr√∂√üen zu verwenden: - Definieren Sie Standards f√ºr ein- und zweispaltige Abbildungen - Legen Sie einheitliche Gr√∂√üen f√ºr Achsenbeschriftungen und Markierungen fest - Erstellen Sie alle Plots direkt in der finalen Gr√∂√üe\nIm Folgenden stelle ich praktische Techniken vor, mit denen Sie direkt aus Jupyter-Notebooks publikationsreife Plots erstellen und speichern k√∂nnen."
  },
  {
    "objectID": "seminars/seminar06/25_publication_ready_figures.html#erstellen-eines-diagramms-mit-einer-bestimmten-gr√∂√üe-des-begrenzungsrahmens",
    "href": "seminars/seminar06/25_publication_ready_figures.html#erstellen-eines-diagramms-mit-einer-bestimmten-gr√∂√üe-des-begrenzungsrahmens",
    "title": "Erstellung ver√∂ffentlichungsreifer Diagramme",
    "section": "Erstellen eines Diagramms mit einer bestimmten Gr√∂√üe des Begrenzungsrahmens",
    "text": "Erstellen eines Diagramms mit einer bestimmten Gr√∂√üe des Begrenzungsrahmens\nWenn Sie einen Plot in matplotlib erstellen, k√∂nnen Sie eine Gr√∂√üe mit dem Parameter figsize festlegen, z.B.\nplt.figure(figsize=(3,2))\nf√ºr eine Abbildung mit einer Breite von 3 inches bzw. 7,62 cm und einer H√∂he von 2 inches (5,08 cm). Wenn Sie diesen Parameter nicht verwenden oder sogar den Befehl plt.figure() nicht nutzen, verwendet matplotlib die Standardgr√∂√üe, die h√§ufig 8 inches mal 6 inches betr√§gt. Diese Standardgr√∂√üe ist viel zu gro√ü, da die Abbildung dann fast eine ganze A4-Seite breit w√§re. Eine angemessene Gr√∂√üe f√ºr einen Plot in einer einzelnen Spalte eines zweispaltigen Dokuments w√§ren die oben genannten 3 inches mal 2 inches, da die gesamte Seitenbreite 21 cm minus einem Rand von etwa 3 cm auf jeder Seite eine Spaltenbreite von ungef√§hr (21-6)/2=7,5 cm ergibt.\nDer in Figure¬†1 gezeigte Plot wurde mit den folgenden Befehlen erstellt\nplt.figure(figsize=(3,2), dpi=150)\nx=np.linspace(0,np.pi*4,200)\nplt.plot(x,np.sin(x),color='k')\nplt.xlabel(r\"angle $\\theta$ in [rad]\")\nplt.ylabel(r\"$\\sin(\\theta)$\")\nplt.savefig(\"figure_example.pdf\",\n    bbox_inches = 'tight')\nplt.show()\nDie daraus resultierende PDF-Datei enth√§lt eine Grafik mit einem Begrenzungsrahmen, der genau 3 Zoll mal 2 Zoll gro√ü ist. Wenn Sie das Diagramm in ein beliebiges Zeichenprogramm wie Adobe Illustrator, Affinity Designer oder sogar in eine Textverarbeitungssoftware wie Word oder Pages einf√ºgen, hat der Begrenzungsrahmen dieses Diagramms genau diese Gr√∂√üe, und Sie k√∂nnen weitere Diagramme anordnen, um eine ganze Abbildung zu erstellen, ohne die Skalierung √§ndern zu m√ºssen. Wenn Sie das Diagramm in einem zweispaltigen LaTeX-Manuskript verwenden, kann es ohne Skalierung verwendet werden, d.h. durch includegraphics{Figure 1.pdf} wird es in der entsprechenden Gr√∂√üe √ºber eine Spalte angezeigt.\nEs gibt noch ein paar weitere Dinge zu beachten.\n\nW√§hrend der Begrenzungsrahmen dieser Abbildung diese Gr√∂√üe hat, ist der Achsenrahmen kleiner, und oft bleibt auf der linken/unteren Seite ein gewisser Leerraum zwischen den Achsenbeschriftungen und dem Rand des Begrenzungsrahmens. Das h√§ngt sehr stark von Ihrem spezifischen Diagramm ab. Wie Sie eine Abbildung mit einer festen Achsenrahmengr√∂√üe erstellen, wird im zweiten Abschnitt behandelt.\nDie Schriftgr√∂√üe auf der Achse betr√§gt jetzt 10 oder 11 Punkte, was der Schriftgr√∂√üe der meisten Dokumente entspricht, die Sie mit dieser Abbildung erstellen. Ich habe die folgenden plt.rcParams verwendet: ‚Äòaxes.labelsize‚Äô: 11, ‚Äòxtick.labelsize‚Äô : 10, ‚Äòytick.labelsize‚Äô : 10 f√ºr die gezeigte Darstellung.\nSie werden auch feststellen, dass die Arbeit mit dieser Abbildungsgr√∂√üe in einem Jupyter-Notebook nicht gut ist. Das hat damit zu tun, wie Jupyter die Ausgabe in eine PNG-Datei √ºbersetzt, die inline angezeigt wird. Eine M√∂glichkeit, den Plot im Jupyter-Notebook zu vergr√∂√üern, aber die PDF-Gr√∂√üe beizubehalten, besteht darin, den Parameter dpi im Befehl plt.figure(figsize=(3,2), dpi=150) zu erh√∂hen. Normalerweise ist er auf dpi=75 eingestellt, was jetzt viel zu klein ist. Eine Einstellung von dpi=150 scheint ein vern√ºnftiger Kompromiss zwischen Bildschirm- und Druckgr√∂√üe zu sein. Wenn Sie v√∂llig unabh√§ngig sein wollen\nDer Befehl plt.savefig verwendet einen zus√§tzlichen bbox_inches = 'tight' Parameter, der sicherstellt, dass die Boundingbox auch wirklich alle Komponenten des Plots genau umschlie√üt.\n\n\nimport matplotlib as mpl\nimport matplotlib.font_manager as font_manager\nfrom IPython.core.display import HTML\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom directory_tree import display_tree\n\n\nplt.rcParams.update({'font.size': 12,\n                     'lines.linewidth': 1,\n                     'lines.markersize': 10,\n                     'axes.labelsize': 11,\n                     'xtick.labelsize' : 10,\n                     'ytick.labelsize' : 10,\n                     'xtick.top' : True,\n                     'xtick.direction' : 'in',\n                     'ytick.right' : True,\n                     'ytick.direction' : 'in',\n                     'figure.dpi': 150})\n\n\ndef get_size(w,h):\n    return((w/2.54,h/2.54))\n\n\nplt.figure(figsize=get_size(7,6))\nx=np.linspace(0,np.pi*4,200)\nplt.plot(x,np.sin(x),color='k')\nplt.xlabel(r\"angle $\\theta$ in [rad]\")\nplt.ylabel(r\"$\\sin(\\theta)$\")\nplt.tight_layout()\nplt.savefig(\"figure_example3.pdf\", transparent=True)\nplt.show()\n\n\n\n\n\n\n\n\nWenn Sie dieses Bild in eine beliebige Software laden, erhalten Sie ein Bild mit einer Gr√∂√üe, die der eingestellten Breite entspricht.\n\n\n\n\n\n\nFigure¬†1"
  },
  {
    "objectID": "seminars/seminar06/25_publication_ready_figures.html#erstellen-eines-diagramms-mit-einer-bestimmten-achsenrahmengr√∂√üe",
    "href": "seminars/seminar06/25_publication_ready_figures.html#erstellen-eines-diagramms-mit-einer-bestimmten-achsenrahmengr√∂√üe",
    "title": "Erstellung ver√∂ffentlichungsreifer Diagramme",
    "section": "Erstellen eines Diagramms mit einer bestimmten Achsenrahmengr√∂√üe",
    "text": "Erstellen eines Diagramms mit einer bestimmten Achsenrahmengr√∂√üe\nDer Achsenrahmen ist die Box des Rahmens, der die Achsen bereitstellt. Beim Erstellen einer Figur mit dem Befehl plt.figure() wird der Achsenrahmen von matplotlib so berechnet, dass er innerhalb der durch figsize angegebenen Boundingbox liegt, so dass alle Achsenbeschriftungen ebenfalls hineinpassen. Der Achsenrahmen ist daher kleiner als die angegebene Bounding Box und h√§ngt oft von den Achsenbeschriftungen und weiteren Dingen ab. Wenn Sie einen Plot mit einer festen Gr√∂√üe des Achsenrahmens erstellen wollen, ist es sinnvoll, eine Funktion in Ihrem Code unterzubringen, die die Gr√∂√üe des Achsenrahmens festlegt. Diese Funktion k√∂nnte lauten\ndef set_size(w,h, ax=None):\n    \"\"\" w, h: width, height in inches \"\"\"\n    if not ax: ax=plt.gca()\n      l = ax.figure.subplotpars.left\n      r = ax.figure.subplotpars.right\n    t = ax.figure.subplotpars.top\n    b = ax.figure.subplotpars.bottom\n    figw = float(w)/(r-l)\n    figh = float(h)/(t-b)\n    ax.figure.set_size_inches(figw, figh)\nwobei Sie die gew√ºnschte Breite und H√∂he (in Zoll) der aktuellen Achse ax angeben m√ºssen. Die Funktion gibt nichts zur√ºck, sondern legt direkt die Gr√∂√üe fest.\n\ndef set_size(w,h, ax=None):\n    \"\"\" w, h: width, height in inches \"\"\"\n    if not ax: ax=plt.gca()\n    l = ax.figure.subplotpars.left\n    r = ax.figure.subplotpars.right\n    t = ax.figure.subplotpars.top\n    b = ax.figure.subplotpars.bottom\n    figw = float(w)/(r-l)\n    figh = float(h)/(t-b)\n    ax.figure.set_size_inches(figw, figh)\n\nfig=plt.figure(dpi=150)\nax=plt.axes()\nax.plot(x,np.sin(x),color='k')\nax.set_xlabel(r\"angle $\\theta$ in [rad]\")\nax.set_ylabel(r\"$\\sin(\\theta)$\")\nset_size(3,2)\nplt.savefig(\"figure_example2.pdf\", bbox_inches='tight', transparent=True)\nplt.show()\n\n\n\n\n\n\n\n\nWenn Sie diese Abbildung in ein Grafikprogramm oder eine Textverarbeitungssoftware laden, sollte das Abbildungsfeld eine Gr√∂√üe von 7,62 cm mal 5,08 cm haben, ohne dass eine Neuskalierung erfolgt:"
  },
  {
    "objectID": "seminars/seminar06/25_publication_ready_figures.html#auswahl-der-schriftarten",
    "href": "seminars/seminar06/25_publication_ready_figures.html#auswahl-der-schriftarten",
    "title": "Erstellung ver√∂ffentlichungsreifer Diagramme",
    "section": "Auswahl der Schriftarten",
    "text": "Auswahl der Schriftarten\nMatplotlib kann auf eine Reihe von verschiedenen Schriftarten zugreifen. Es kann schwierig sein, die passende Schriftart f√ºr den Formelstil Ihres Dokuments oder Ihrer Publikation zu finden. Eine Liste der Schriftarten, die Matplotlib zur Verf√ºgung stehen, kann mit dem folgenden Codeschnipsel abgerufen werden, den ich hier gefunden habe.\n\nfrom IPython.display import HTML, display\n\ndef make_html(fontname):\n    return \"&lt;p&gt;{font}: &lt;span style='font-family:{font}; font-size: 24px;'&gt;{font}&lt;/p&gt;\".format(font=fontname)\n\ncode = \"\\n\".join([make_html(font) for font in sorted(set([f.name for f in font_manager.fontManager.ttflist]))])\n\ndisplay(HTML(\"&lt;div style='column-count: 2;'&gt;{}&lt;/div&gt;\".format(code)))\n\n.Aqua Kana: .Aqua Kana\n.CJK Symbols Fallback HK: .CJK Symbols Fallback HK\n.Keyboard: .Keyboard\n.New York: .New York\n.SF Arabic: .SF Arabic\n.SF Arabic Rounded: .SF Arabic Rounded\n.SF Armenian: .SF Armenian\n.SF Armenian Rounded: .SF Armenian Rounded\n.SF Camera: .SF Camera\n.SF Compact Rounded: .SF Compact Rounded\n.SF Georgian: .SF Georgian\n.SF Georgian Rounded: .SF Georgian Rounded\n.SF Hebrew: .SF Hebrew\n.SF Hebrew Rounded: .SF Hebrew Rounded\n.SF NS Mono: .SF NS Mono\n.SF NS Rounded: .SF NS Rounded\n.SF Soft Numeric: .SF Soft Numeric\n.ThonburiUI: .ThonburiUI\nAcademy Engraved LET: Academy Engraved LET\nAdelle Sans Devanagari: Adelle Sans Devanagari\nAkayaKanadaka: AkayaKanadaka\nAkayaTelivigala: AkayaTelivigala\nAl Bayan: Al Bayan\nAl Nile: Al Nile\nAl Tarikh: Al Tarikh\nAmerican Typewriter: American Typewriter\nAndale Mono: Andale Mono\nAnnai MN: Annai MN\nApple Braille: Apple Braille\nApple Chancery: Apple Chancery\nApple LiGothic: Apple LiGothic\nApple LiSung: Apple LiSung\nApple SD Gothic Neo: Apple SD Gothic Neo\nApple Symbols: Apple Symbols\nAppleGothic: AppleGothic\nAppleMyungjo: AppleMyungjo\nArial: Arial\nArial Black: Arial Black\nArial Hebrew: Arial Hebrew\nArial Narrow: Arial Narrow\nArial Rounded MT Bold: Arial Rounded MT Bold\nArial Unicode MS: Arial Unicode MS\nArima Koshi: Arima Koshi\nArima Madurai: Arima Madurai\nAthelas: Athelas\nAvenir: Avenir\nAvenir Next: Avenir Next\nAvenir Next Condensed: Avenir Next Condensed\nAyuthaya: Ayuthaya\nBM Dohyeon: BM Dohyeon\nBM Hanna 11yrs Old: BM Hanna 11yrs Old\nBM Hanna Air: BM Hanna Air\nBM Hanna Pro: BM Hanna Pro\nBM Jua: BM Jua\nBM Kirang Haerang: BM Kirang Haerang\nBM Yeonsung: BM Yeonsung\nBaghdad: Baghdad\nBai Jamjuree: Bai Jamjuree\nBaloo 2: Baloo 2\nBaloo Bhai 2: Baloo Bhai 2\nBaloo Bhaijaan: Baloo Bhaijaan\nBaloo Bhaina 2: Baloo Bhaina 2\nBaloo Chettan 2: Baloo Chettan 2\nBaloo Da 2: Baloo Da 2\nBaloo Paaji 2: Baloo Paaji 2\nBaloo Tamma 2: Baloo Tamma 2\nBaloo Tammudu 2: Baloo Tammudu 2\nBaloo Thambi 2: Baloo Thambi 2\nBangla MN: Bangla MN\nBangla Sangam MN: Bangla Sangam MN\nBaoli SC: Baoli SC\nBaskerville: Baskerville\nBeirut: Beirut\nBiauKaiHK: BiauKaiHK\nBig Caslon: Big Caslon\nBodoni 72: Bodoni 72\nBodoni 72 Oldstyle: Bodoni 72 Oldstyle\nBodoni 72 Smallcaps: Bodoni 72 Smallcaps\nBodoni Ornaments: Bodoni Ornaments\nBradley Hand: Bradley Hand\nBrush Script MT: Brush Script MT\nCambay Devanagari: Cambay Devanagari\nChakra Petch: Chakra Petch\nChalkboard: Chalkboard\nChalkboard SE: Chalkboard SE\nChalkduster: Chalkduster\nCharm: Charm\nCharmonman: Charmonman\nCharter: Charter\nCochin: Cochin\nComic Sans MS: Comic Sans MS\nCopperplate: Copperplate\nCorsiva Hebrew: Corsiva Hebrew\nCourier: Courier\nCourier New: Courier New\nDIN Alternate: DIN Alternate\nDIN Condensed: DIN Condensed\nDamascus: Damascus\nDecoType Naskh: DecoType Naskh\nDejaVu Sans: DejaVu Sans\nDejaVu Sans Display: DejaVu Sans Display\nDejaVu Sans Mono: DejaVu Sans Mono\nDejaVu Serif: DejaVu Serif\nDejaVu Serif Display: DejaVu Serif Display\nDevanagari MT: Devanagari MT\nDevanagari Sangam MN: Devanagari Sangam MN\nDidot: Didot\nDiwan Kufi: Diwan Kufi\nDiwan Thuluth: Diwan Thuluth\nEuphemia UCAS: Euphemia UCAS\nFahkwang: Fahkwang\nFarah: Farah\nFarisi: Farisi\nFutura: Futura\nGalvji: Galvji\nGeeza Pro: Geeza Pro\nGeneva: Geneva\nGeorgia: Georgia\nGill Sans: Gill Sans\nGotu: Gotu\nGujarati MT: Gujarati MT\nGujarati Sangam MN: Gujarati Sangam MN\nGungSeo: GungSeo\nGurmukhi MN: Gurmukhi MN\nGurmukhi MT: Gurmukhi MT\nGurmukhi Sangam MN: Gurmukhi Sangam MN\nHannotate SC: Hannotate SC\nHanziPen SC: HanziPen SC\nHeadLineA: HeadLineA\nHei: Hei\nHeiti TC: Heiti TC\nHelvetica: Helvetica\nHelvetica Neue: Helvetica Neue\nHerculanum: Herculanum\nHiragino Maru Gothic Pro: Hiragino Maru Gothic Pro\nHiragino Mincho ProN: Hiragino Mincho ProN\nHiragino Sans: Hiragino Sans\nHiragino Sans GB: Hiragino Sans GB\nHiragino Sans TC: Hiragino Sans TC\nHoefler Text: Hoefler Text\nHubballi: Hubballi\nITF Devanagari: ITF Devanagari\nImpact: Impact\nInaiMathi: InaiMathi\nIowan Old Style: Iowan Old Style\nJaini: Jaini\nJaini Purva: Jaini Purva\nK2D: K2D\nKai: Kai\nKailasa: Kailasa\nKaiti SC: Kaiti SC\nKannada MN: Kannada MN\nKannada Sangam MN: Kannada Sangam MN\nKatari: Katari\nKavivanar: Kavivanar\nKefa: Kefa\nKhmer MN: Khmer MN\nKhmer Sangam MN: Khmer Sangam MN\nKlee: Klee\nKoHo: KoHo\nKodchasan: Kodchasan\nKohinoor Bangla: Kohinoor Bangla\nKohinoor Devanagari: Kohinoor Devanagari\nKohinoor Gujarati: Kohinoor Gujarati\nKohinoor Telugu: Kohinoor Telugu\nKokonor: Kokonor\nKrub: Krub\nKrungthep: Krungthep\nKufiStandardGK: KufiStandardGK\nLahore Gurmukhi: Lahore Gurmukhi\nLantinghei SC: Lantinghei SC\nLao MN: Lao MN\nLao Sangam MN: Lao Sangam MN\nLava Devanagari: Lava Devanagari\nLava Kannada: Lava Kannada\nLava Telugu: Lava Telugu\nLiHei Pro: LiHei Pro\nLiSong Pro: LiSong Pro\nLibian SC: Libian SC\nLingWai SC: LingWai SC\nLingWai TC: LingWai TC\nLucida Grande: Lucida Grande\nLuminari: Luminari\nMaku: Maku\nMalayalam MN: Malayalam MN\nMalayalam Sangam MN: Malayalam Sangam MN\nMali: Mali\nMarion: Marion\nMarker Felt: Marker Felt\nMenlo: Menlo\nMicrosoft Sans Serif: Microsoft Sans Serif\nMishafi: Mishafi\nMishafi Gold: Mishafi Gold\nModak: Modak\nMonaco: Monaco\nMshtakan: Mshtakan\nMukta: Mukta\nMukta Mahee: Mukta Mahee\nMukta Malar: Mukta Malar\nMukta Vaani: Mukta Vaani\nMuna: Muna\nMyanmar MN: Myanmar MN\nMyanmar Sangam MN: Myanmar Sangam MN\nNadeem: Nadeem\nNanum Brush Script: Nanum Brush Script\nNanum Gothic: Nanum Gothic\nNanum Myeongjo: Nanum Myeongjo\nNew Peninim MT: New Peninim MT\nNiramit: Niramit\nNoteworthy: Noteworthy\nNoto Nastaliq Urdu: Noto Nastaliq Urdu\nNoto Sans Adlam: Noto Sans Adlam\nNoto Sans Armenian: Noto Sans Armenian\nNoto Sans Avestan: Noto Sans Avestan\nNoto Sans Bamum: Noto Sans Bamum\nNoto Sans Bassa Vah: Noto Sans Bassa Vah\nNoto Sans Batak: Noto Sans Batak\nNoto Sans Bhaiksuki: Noto Sans Bhaiksuki\nNoto Sans Brahmi: Noto Sans Brahmi\nNoto Sans Buginese: Noto Sans Buginese\nNoto Sans Buhid: Noto Sans Buhid\nNoto Sans Canadian Aboriginal: Noto Sans Canadian Aboriginal\nNoto Sans Carian: Noto Sans Carian\nNoto Sans Caucasian Albanian: Noto Sans Caucasian Albanian\nNoto Sans Chakma: Noto Sans Chakma\nNoto Sans Cham: Noto Sans Cham\nNoto Sans Coptic: Noto Sans Coptic\nNoto Sans Cuneiform: Noto Sans Cuneiform\nNoto Sans Cypriot: Noto Sans Cypriot\nNoto Sans Duployan: Noto Sans Duployan\nNoto Sans Egyptian Hieroglyphs: Noto Sans Egyptian Hieroglyphs\nNoto Sans Elbasan: Noto Sans Elbasan\nNoto Sans Glagolitic: Noto Sans Glagolitic\nNoto Sans Gothic: Noto Sans Gothic\nNoto Sans Gunjala Gondi: Noto Sans Gunjala Gondi\nNoto Sans Hanifi Rohingya: Noto Sans Hanifi Rohingya\nNoto Sans Hanunoo: Noto Sans Hanunoo\nNoto Sans Hatran: Noto Sans Hatran\nNoto Sans Imperial Aramaic: Noto Sans Imperial Aramaic\nNoto Sans Inscriptional Pahlavi: Noto Sans Inscriptional Pahlavi\nNoto Sans Inscriptional Parthian: Noto Sans Inscriptional Parthian\nNoto Sans Javanese: Noto Sans Javanese\nNoto Sans Kaithi: Noto Sans Kaithi\nNoto Sans Kannada: Noto Sans Kannada\nNoto Sans Kayah Li: Noto Sans Kayah Li\nNoto Sans Kharoshthi: Noto Sans Kharoshthi\nNoto Sans Khojki: Noto Sans Khojki\nNoto Sans Khudawadi: Noto Sans Khudawadi\nNoto Sans Lepcha: Noto Sans Lepcha\nNoto Sans Limbu: Noto Sans Limbu\nNoto Sans Linear A: Noto Sans Linear A\nNoto Sans Linear B: Noto Sans Linear B\nNoto Sans Lisu: Noto Sans Lisu\nNoto Sans Lycian: Noto Sans Lycian\nNoto Sans Lydian: Noto Sans Lydian\nNoto Sans Mahajani: Noto Sans Mahajani\nNoto Sans Mandaic: Noto Sans Mandaic\nNoto Sans Manichaean: Noto Sans Manichaean\nNoto Sans Marchen: Noto Sans Marchen\nNoto Sans Masaram Gondi: Noto Sans Masaram Gondi\nNoto Sans Meetei Mayek: Noto Sans Meetei Mayek\nNoto Sans Mende Kikakui: Noto Sans Mende Kikakui\nNoto Sans Meroitic: Noto Sans Meroitic\nNoto Sans Miao: Noto Sans Miao\nNoto Sans Modi: Noto Sans Modi\nNoto Sans Mongolian: Noto Sans Mongolian\nNoto Sans Mro: Noto Sans Mro\nNoto Sans Multani: Noto Sans Multani\nNoto Sans Myanmar: Noto Sans Myanmar\nNoto Sans NKo: Noto Sans NKo\nNoto Sans Nabataean: Noto Sans Nabataean\nNoto Sans New Tai Lue: Noto Sans New Tai Lue\nNoto Sans Newa: Noto Sans Newa\nNoto Sans Ol Chiki: Noto Sans Ol Chiki\nNoto Sans Old Hungarian: Noto Sans Old Hungarian\nNoto Sans Old Italic: Noto Sans Old Italic\nNoto Sans Old North Arabian: Noto Sans Old North Arabian\nNoto Sans Old Permic: Noto Sans Old Permic\nNoto Sans Old Persian: Noto Sans Old Persian\nNoto Sans Old South Arabian: Noto Sans Old South Arabian\nNoto Sans Old Turkic: Noto Sans Old Turkic\nNoto Sans Oriya: Noto Sans Oriya\nNoto Sans Osage: Noto Sans Osage\nNoto Sans Osmanya: Noto Sans Osmanya\nNoto Sans Pahawh Hmong: Noto Sans Pahawh Hmong\nNoto Sans Palmyrene: Noto Sans Palmyrene\nNoto Sans Pau Cin Hau: Noto Sans Pau Cin Hau\nNoto Sans PhagsPa: Noto Sans PhagsPa\nNoto Sans Phoenician: Noto Sans Phoenician\nNoto Sans Psalter Pahlavi: Noto Sans Psalter Pahlavi\nNoto Sans Rejang: Noto Sans Rejang\nNoto Sans Samaritan: Noto Sans Samaritan\nNoto Sans Saurashtra: Noto Sans Saurashtra\nNoto Sans Sharada: Noto Sans Sharada\nNoto Sans Siddham: Noto Sans Siddham\nNoto Sans Sora Sompeng: Noto Sans Sora Sompeng\nNoto Sans Sundanese: Noto Sans Sundanese\nNoto Sans Syloti Nagri: Noto Sans Syloti Nagri\nNoto Sans Syriac: Noto Sans Syriac\nNoto Sans Tagalog: Noto Sans Tagalog\nNoto Sans Tagbanwa: Noto Sans Tagbanwa\nNoto Sans Tai Le: Noto Sans Tai Le\nNoto Sans Tai Tham: Noto Sans Tai Tham\nNoto Sans Tai Viet: Noto Sans Tai Viet\nNoto Sans Takri: Noto Sans Takri\nNoto Sans Thaana: Noto Sans Thaana\nNoto Sans Tifinagh: Noto Sans Tifinagh\nNoto Sans Tirhuta: Noto Sans Tirhuta\nNoto Sans Ugaritic: Noto Sans Ugaritic\nNoto Sans Vai: Noto Sans Vai\nNoto Sans Wancho: Noto Sans Wancho\nNoto Sans Warang Citi: Noto Sans Warang Citi\nNoto Sans Yi: Noto Sans Yi\nNoto Serif Ahom: Noto Serif Ahom\nNoto Serif Balinese: Noto Serif Balinese\nNoto Serif Hmong Nyiakeng: Noto Serif Hmong Nyiakeng\nNoto Serif Kannada: Noto Serif Kannada\nNoto Serif Myanmar: Noto Serif Myanmar\nNoto Serif Yezidi: Noto Serif Yezidi\nOctober Compressed Devanagari: October Compressed Devanagari\nOctober Compressed Tamil: October Compressed Tamil\nOctober Condensed Devanagari: October Condensed Devanagari\nOctober Condensed Tamil: October Condensed Tamil\nOctober Devanagari: October Devanagari\nOctober Tamil: October Tamil\nOptima: Optima\nOriya MN: Oriya MN\nOriya Sangam MN: Oriya Sangam MN\nOsaka: Osaka\nPCMyungjo: PCMyungjo\nPSL Ornanong Pro: PSL Ornanong Pro\nPT Mono: PT Mono\nPT Sans: PT Sans\nPT Serif: PT Serif\nPT Serif Caption: PT Serif Caption\nPadyakke Expanded One: Padyakke Expanded One\nPalatino: Palatino\nPapyrus: Papyrus\nParty LET: Party LET\nPhosphate: Phosphate\nPilGi: PilGi\nPlantagenet Cherokee: Plantagenet Cherokee\nRaanana: Raanana\nRockwell: Rockwell\nSTFangsong: STFangsong\nSTHeiti: STHeiti\nSTIX Two Math: STIX Two Math\nSTIX Two Text: STIX Two Text\nSTIXGeneral: STIXGeneral\nSTIXIntegralsD: STIXIntegralsD\nSTIXIntegralsSm: STIXIntegralsSm\nSTIXIntegralsUp: STIXIntegralsUp\nSTIXIntegralsUpD: STIXIntegralsUpD\nSTIXIntegralsUpSm: STIXIntegralsUpSm\nSTIXNonUnicode: STIXNonUnicode\nSTIXSizeFiveSym: STIXSizeFiveSym\nSTIXSizeFourSym: STIXSizeFourSym\nSTIXSizeOneSym: STIXSizeOneSym\nSTIXSizeThreeSym: STIXSizeThreeSym\nSTIXSizeTwoSym: STIXSizeTwoSym\nSTIXVariants: STIXVariants\nSama Devanagari: Sama Devanagari\nSama Gujarati: Sama Gujarati\nSama Gurmukhi: Sama Gurmukhi\nSama Kannada: Sama Kannada\nSama Malayalam: Sama Malayalam\nSama Tamil: Sama Tamil\nSana: Sana\nSarabun: Sarabun\nSathu: Sathu\nSavoye LET: Savoye LET\nSeravek: Seravek\nShobhika: Shobhika\nShree Devanagari 714: Shree Devanagari 714\nSignPainter: SignPainter\nSilom: Silom\nSimSong: SimSong\nSinhala MN: Sinhala MN\nSinhala Sangam MN: Sinhala Sangam MN\nSkia: Skia\nSnell Roundhand: Snell Roundhand\nSongti SC: Songti SC\nSrisakdi: Srisakdi\nSukhumvit Set: Sukhumvit Set\nSuperclarendon: Superclarendon\nSymbol: Symbol\nSystem Font: System Font\nTahoma: Tahoma\nTamil MN: Tamil MN\nTamil Sangam MN: Tamil Sangam MN\nTelugu MN: Telugu MN\nTelugu Sangam MN: Telugu Sangam MN\nThonburi: Thonburi\nTimes: Times\nTimes New Roman: Times New Roman\nTiro Bangla: Tiro Bangla\nTiro Devanagari Hindi: Tiro Devanagari Hindi\nTiro Devanagari Marathi: Tiro Devanagari Marathi\nTiro Devanagari Sanskrit: Tiro Devanagari Sanskrit\nTiro Gurmukhi: Tiro Gurmukhi\nTiro Kannada: Tiro Kannada\nTiro Tamil: Tiro Tamil\nTiro Telugu: Tiro Telugu\nToppan Bunkyu Gothic: Toppan Bunkyu Gothic\nToppan Bunkyu Midashi Gothic: Toppan Bunkyu Midashi Gothic\nToppan Bunkyu Midashi Mincho: Toppan Bunkyu Midashi Mincho\nToppan Bunkyu Mincho: Toppan Bunkyu Mincho\nTrattatello: Trattatello\nTrebuchet MS: Trebuchet MS\nTsukushi A Round Gothic: Tsukushi A Round Gothic\nTsukushi B Round Gothic: Tsukushi B Round Gothic\nVerdana: Verdana\nWaseem: Waseem\nWawati SC: Wawati SC\nWawati TC: Wawati TC\nWebdings: Webdings\nWingdings: Wingdings\nWingdings 2: Wingdings 2\nWingdings 3: Wingdings 3\nXingkai SC: Xingkai SC\nYuGothic: YuGothic\nYuKyokasho Yoko: YuKyokasho Yoko\nYuMincho: YuMincho\nYuanti SC: Yuanti SC\nYuppy SC: Yuppy SC\nYuppy TC: Yuppy TC\nZapf Dingbats: Zapf Dingbats\nZapfino: Zapfino\ncmb10: cmb10\ncmex10: cmex10\ncmmi10: cmmi10\ncmr10: cmr10\ncmss10: cmss10\ncmsy10: cmsy10\ncmtt10: cmtt10\n\n\nFalls Sie Ihr Dokument in LaTeX schreiben, k√∂nnten die cmXXXX-Schriften f√ºr Sie von Interesse sein, da sie den in LaTeX-Dokumenten verwendeten Schriften entsprechen. Hier ist ein Beispiel:\n\ncmfont = font_manager.FontProperties(fname=mpl.get_data_path() + '/fonts/ttf/cmr10.ttf')\nplt.rcParams.update({'font.size': 12,\n                     'axes.titlesize': 12,\n                     'axes.labelsize': 12,\n                     'axes.labelpad': 12,\n                     'lines.linewidth': 1,\n                     'lines.markersize': 10,\n                     'xtick.labelsize' : 10,\n                     'ytick.labelsize' : 10,\n                     'xtick.top' : True,\n                     'xtick.direction' : 'in',\n                     'ytick.right' : True,\n                     'ytick.direction' : 'in',\n                     'font.family' : 'serif',\n                     'font.serif' : cmfont.get_name(),\n                     \"axes.formatter.use_mathtext\": True,\n                     'text.usetex': True,\n                     'mathtext.fontset' : 'cm'\n                    })\n\n\nx=np.linspace(0,np.pi,100)\n\n\nplt.figure(figsize=get_size(6,5),dpi=150)\nplt.plot(x,np.sin(x))\nplt.xlabel(r\"velocity $v$\")\nplt.ylabel(r\"position $r$\")\nplt.show()"
  },
  {
    "objectID": "seminars/seminar06/25_publication_ready_figures.html#ein-dokument-vorbereiten",
    "href": "seminars/seminar06/25_publication_ready_figures.html#ein-dokument-vorbereiten",
    "title": "Erstellung ver√∂ffentlichungsreifer Diagramme",
    "section": "Ein Dokument vorbereiten",
    "text": "Ein Dokument vorbereiten\nWenn man ein Dokument (Bachelorarbeit z.B.) erstellt, ist es n√ºtzlich, seine Daten und Texte geschickt zur organisieren, um sich Arbeit zu ersparen. Hier ist ein Beipiel,\n\ndisplay_tree(\"Report\")\n\nReport/\n‚îú‚îÄ‚îÄ Figures/\n‚îÇ   ‚îú‚îÄ‚îÄ Figure1/\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Figure1.ipynb\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Figure1_files/\n‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ libs/\n‚îÇ   ‚îÇ           ‚îú‚îÄ‚îÄ bootstrap/\n‚îÇ   ‚îÇ           ‚îÇ   ‚îú‚îÄ‚îÄ bootstrap-icons.css\n‚îÇ   ‚îÇ           ‚îÇ   ‚îú‚îÄ‚îÄ bootstrap-icons.woff\n‚îÇ   ‚îÇ           ‚îÇ   ‚îú‚îÄ‚îÄ bootstrap.min.css\n‚îÇ   ‚îÇ           ‚îÇ   ‚îî‚îÄ‚îÄ bootstrap.min.js\n‚îÇ   ‚îÇ           ‚îú‚îÄ‚îÄ clipboard/\n‚îÇ   ‚îÇ           ‚îÇ   ‚îî‚îÄ‚îÄ clipboard.min.js\n‚îÇ   ‚îÇ           ‚îú‚îÄ‚îÄ quarto-contrib/\n‚îÇ   ‚îÇ           ‚îÇ   ‚îî‚îÄ‚îÄ live-runtime/\n‚îÇ   ‚îÇ           ‚îÇ       ‚îú‚îÄ‚îÄ live-runtime.css\n‚îÇ   ‚îÇ           ‚îÇ       ‚îú‚îÄ‚îÄ live-runtime.js\n‚îÇ   ‚îÇ           ‚îÇ       ‚îî‚îÄ‚îÄ pyodide-worker.js\n‚îÇ   ‚îÇ           ‚îú‚îÄ‚îÄ quarto-html/\n‚îÇ   ‚îÇ           ‚îÇ   ‚îú‚îÄ‚îÄ anchor.min.js\n‚îÇ   ‚îÇ           ‚îÇ   ‚îú‚îÄ‚îÄ popper.min.js\n‚îÇ   ‚îÇ           ‚îÇ   ‚îú‚îÄ‚îÄ quarto-syntax-highlighting.css\n‚îÇ   ‚îÇ           ‚îÇ   ‚îú‚îÄ‚îÄ quarto.js\n‚îÇ   ‚îÇ           ‚îÇ   ‚îú‚îÄ‚îÄ tippy.css\n‚îÇ   ‚îÇ           ‚îÇ   ‚îî‚îÄ‚îÄ tippy.umd.min.js\n‚îÇ   ‚îÇ           ‚îî‚îÄ‚îÄ quarto-ojs/\n‚îÇ   ‚îÇ               ‚îú‚îÄ‚îÄ quarto-ojs-runtime.js\n‚îÇ   ‚îÇ               ‚îî‚îÄ‚îÄ quarto-ojs.css\n‚îÇ   ‚îú‚îÄ‚îÄ figure1.pdf\n‚îÇ   ‚îú‚îÄ‚îÄ Figure2/\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Figure2.ipynb\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Figure2_files/\n‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ libs/\n‚îÇ   ‚îÇ           ‚îú‚îÄ‚îÄ bootstrap/\n‚îÇ   ‚îÇ           ‚îÇ   ‚îú‚îÄ‚îÄ bootstrap-icons.css\n‚îÇ   ‚îÇ           ‚îÇ   ‚îú‚îÄ‚îÄ bootstrap-icons.woff\n‚îÇ   ‚îÇ           ‚îÇ   ‚îú‚îÄ‚îÄ bootstrap.min.css\n‚îÇ   ‚îÇ           ‚îÇ   ‚îî‚îÄ‚îÄ bootstrap.min.js\n‚îÇ   ‚îÇ           ‚îú‚îÄ‚îÄ clipboard/\n‚îÇ   ‚îÇ           ‚îÇ   ‚îî‚îÄ‚îÄ clipboard.min.js\n‚îÇ   ‚îÇ           ‚îú‚îÄ‚îÄ quarto-contrib/\n‚îÇ   ‚îÇ           ‚îÇ   ‚îî‚îÄ‚îÄ live-runtime/\n‚îÇ   ‚îÇ           ‚îÇ       ‚îú‚îÄ‚îÄ live-runtime.css\n‚îÇ   ‚îÇ           ‚îÇ       ‚îú‚îÄ‚îÄ live-runtime.js\n‚îÇ   ‚îÇ           ‚îÇ       ‚îî‚îÄ‚îÄ pyodide-worker.js\n‚îÇ   ‚îÇ           ‚îú‚îÄ‚îÄ quarto-html/\n‚îÇ   ‚îÇ           ‚îÇ   ‚îú‚îÄ‚îÄ anchor.min.js\n‚îÇ   ‚îÇ           ‚îÇ   ‚îú‚îÄ‚îÄ popper.min.js\n‚îÇ   ‚îÇ           ‚îÇ   ‚îú‚îÄ‚îÄ quarto-syntax-highlighting.css\n‚îÇ   ‚îÇ           ‚îÇ   ‚îú‚îÄ‚îÄ quarto.js\n‚îÇ   ‚îÇ           ‚îÇ   ‚îú‚îÄ‚îÄ tippy.css\n‚îÇ   ‚îÇ           ‚îÇ   ‚îî‚îÄ‚îÄ tippy.umd.min.js\n‚îÇ   ‚îÇ           ‚îî‚îÄ‚îÄ quarto-ojs/\n‚îÇ   ‚îÇ               ‚îú‚îÄ‚îÄ quarto-ojs-runtime.js\n‚îÇ   ‚îÇ               ‚îî‚îÄ‚îÄ quarto-ojs.css\n‚îÇ   ‚îî‚îÄ‚îÄ figure2.pdf\n‚îî‚îÄ‚îÄ Text/\n    ‚îú‚îÄ‚îÄ article.aux\n    ‚îú‚îÄ‚îÄ article.fdb_latexmk\n    ‚îú‚îÄ‚îÄ article.fls\n    ‚îú‚îÄ‚îÄ article.log\n    ‚îú‚îÄ‚îÄ article.pdf\n    ‚îú‚îÄ‚îÄ article.synctex.gz\n    ‚îú‚îÄ‚îÄ article.tex\n    ‚îú‚îÄ‚îÄ content/\n    ‚îÇ   ‚îú‚îÄ‚îÄ 01_introduction.tex\n    ‚îÇ   ‚îú‚îÄ‚îÄ 02_theory.tex\n    ‚îÇ   ‚îú‚îÄ‚îÄ 03_results.tex\n    ‚îÇ   ‚îî‚îÄ‚îÄ 04_conclusions.tex\n    ‚îú‚îÄ‚îÄ paper.aux\n    ‚îú‚îÄ‚îÄ paper.bbl\n    ‚îú‚îÄ‚îÄ paper.blg\n    ‚îú‚îÄ‚îÄ paper.fdb_latexmk\n    ‚îú‚îÄ‚îÄ paper.fls\n    ‚îú‚îÄ‚îÄ paper.log\n    ‚îú‚îÄ‚îÄ paper.pdf\n    ‚îú‚îÄ‚îÄ paper.qmd\n    ‚îú‚îÄ‚îÄ paper.synctex.gz\n    ‚îú‚îÄ‚îÄ paper.tex\n    ‚îú‚îÄ‚îÄ paper_files/\n    ‚îÇ   ‚îî‚îÄ‚îÄ libs/\n    ‚îÇ       ‚îú‚îÄ‚îÄ bootstrap/\n    ‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ bootstrap-icons.css\n    ‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ bootstrap-icons.woff\n    ‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ bootstrap.min.css\n    ‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ bootstrap.min.js\n    ‚îÇ       ‚îú‚îÄ‚îÄ clipboard/\n    ‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ clipboard.min.js\n    ‚îÇ       ‚îú‚îÄ‚îÄ quarto-contrib/\n    ‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ live-runtime/\n    ‚îÇ       ‚îÇ       ‚îú‚îÄ‚îÄ live-runtime.css\n    ‚îÇ       ‚îÇ       ‚îú‚îÄ‚îÄ live-runtime.js\n    ‚îÇ       ‚îÇ       ‚îî‚îÄ‚îÄ pyodide-worker.js\n    ‚îÇ       ‚îú‚îÄ‚îÄ quarto-html/\n    ‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ anchor.min.js\n    ‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ popper.min.js\n    ‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ quarto-syntax-highlighting.css\n    ‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ quarto.js\n    ‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ tippy.css\n    ‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ tippy.umd.min.js\n    ‚îÇ       ‚îî‚îÄ‚îÄ quarto-ojs/\n    ‚îÇ           ‚îú‚îÄ‚îÄ quarto-ojs-runtime.js\n    ‚îÇ           ‚îî‚îÄ‚îÄ quarto-ojs.css\n    ‚îî‚îÄ‚îÄ paperNotes.bib\n\n\n/var/folders/t4/_9qps8wj56jc60nwkr3nrcr00000gn/T/ipykernel_22030/929351223.py:1: DeprecationWarning: The `display_tree` Function is Deprecated and will be Removed in a Future Release. Please use `DirectoryTree` Instead. End of Life Date is \"31st December 2024\".\n  display_tree(\"Report\")"
  },
  {
    "objectID": "seminars/seminar01/MDSimulation.html",
    "href": "seminars/seminar01/MDSimulation.html",
    "title": "Molecular Dynamics Simulations in EMPP 2024",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\nplt.rcParams.update({'font.size': 8,\n                     'lines.linewidth': 1,\n                     'lines.markersize': 10,\n                     'axes.labelsize': 10,\n                     'axes.titlesize': 10,\n                     'xtick.labelsize' : 10,\n                     'ytick.labelsize' : 10,\n                     'xtick.top' : True,\n                     'xtick.direction' : 'in',\n                     'ytick.right' : True,\n                     'ytick.direction' : 'in',})\n\ndef get_size(w,h):\n    return((w/2.54,h/2.54))"
  },
  {
    "objectID": "seminars/seminar01/MDSimulation.html#lenard-jones-potential",
    "href": "seminars/seminar01/MDSimulation.html#lenard-jones-potential",
    "title": "Molecular Dynamics Simulations in EMPP 2024",
    "section": "Lenard-Jones Potential",
    "text": "Lenard-Jones Potential\n\ndef lennard_jones(r, epsilon=1, sigma=1):\n    return 4 * epsilon * ((sigma/r)**12 - (sigma/r)**6)\n\nr = np.linspace(0.8, 3, 1000)\nV = lennard_jones(r)\n\nplt.figure(figsize=get_size(8, 6),dpi=150)\nplt.plot(r, V, 'b-', linewidth=2)\nplt.grid(True)\nplt.xlabel('r/œÉ')\nplt.ylabel('V/Œµ')\nplt.title('Lennard-Jones Potential')\nplt.axhline(y=0, color='k', linestyle='-', alpha=0.3)\nplt.ylim(-1.5, 3)\nplt.show()"
  },
  {
    "objectID": "seminars/seminar01/MDSimulation.html#taylor-expansion",
    "href": "seminars/seminar01/MDSimulation.html#taylor-expansion",
    "title": "Molecular Dynamics Simulations in EMPP 2024",
    "section": "Taylor Expansion",
    "text": "Taylor Expansion\n\nx = np.linspace(-2*np.pi, 2*np.pi, 1000)\ny = np.sin(x)\ny_taylor = x - 1/6*x**3\ny_taylor1 = x - 1/6*x**3+x**5/120\n\n\nplt.figure(figsize=get_size(8, 6),dpi=150)\nplt.plot(x, y, 'b-', label='sin(x)', linewidth=2)\nplt.plot(x, y_taylor, 'r--', label='O(5)', linewidth=2)\nplt.plot(x, y_taylor1, 'g--', label='O(7)', linewidth=2)\nplt.grid(True)\nplt.xlabel('x')\nplt.ylabel('f(x)')\nplt.xlim(-2,2)\nplt.ylim(-1.3,1.3)\nplt.title('Taylor Expansion of sin(x)')\nplt.legend()\nplt.show()"
  },
  {
    "objectID": "seminars/seminar01/MDSimulation.html#velocity-verlet",
    "href": "seminars/seminar01/MDSimulation.html#velocity-verlet",
    "title": "Molecular Dynamics Simulations in EMPP 2024",
    "section": "Velocity Verlet",
    "text": "Velocity Verlet\n\ng = 9.81  # m/s^2\ndt = 0.01  # time step\nt_max = 2.0  # total simulation time\nsteps = int(t_max/dt)\n\n# Initial conditions\ny0 = 20.0  # initial height\nv0 = 0.0   # initial velocity\n\n\n# Arrays to store results\nt = np.zeros(steps)\ny = np.zeros(steps)\nv = np.zeros(steps)\na = np.zeros(steps)\n\n# Initial values\ny[0] = y0\nv[0] = v0\na[0] = -g\n\n# Velocity Verlet integration\nfor i in range(1, steps):\n    t[i] = i * dt\n    y[i] = y[i-1] + v[i-1] * dt + 0.5 * a[i-1] * dt**2  # update position\n    a_new = -g                                          # new acceleration (assuming constant gravity)\n    v[i] = v[i-1] + 0.5 * (a[i-1] + a_new) * dt  # update velocity\n    a[i] = a_new  # store new acceleration\n\nplt.figure(figsize=get_size(8, 6), dpi=150)\nplt.plot(t, y)\nplt.xlabel('Time (s)')\nplt.ylabel('Height (m)')\nplt.title('Free Fall Motion')\nplt.grid(True)\nplt.show()"
  },
  {
    "objectID": "seminars/seminar01/MDSimulation.html#class-for-an-atom",
    "href": "seminars/seminar01/MDSimulation.html#class-for-an-atom",
    "title": "Molecular Dynamics Simulations in EMPP 2024",
    "section": "Class for an Atom",
    "text": "Class for an Atom"
  },
  {
    "objectID": "seminars/Assignment5.html",
    "href": "seminars/Assignment5.html",
    "title": "Assignment 5",
    "section": "",
    "text": "Write a function \\(G(f, x, ...)\\) that takes a function \\(f(x,...)\\) as an argument with a variable number of additional parameters. The function¬†G shall take the arguments f, x and the parameters of f.¬†It shall calculate the sum of all function values of f.¬†You should import the numpy module as np. A definition of f¬†is not required.¬†\n\nimport numpy as np\n\ndef G(f,x,*params):\n    return np.sum(f(x,*params))\n\n\nx=np.linspace(0,10,100)-5\ny=np.linspace(0,10,100)-5\n\nX,Y=np.meshgrid(x,y)\n\n\nR=np.zeros([len(x),len(y)])\n\nfor i in range(0,len(x)): # gehe durch jede Zeile\n    for j in range(0,len(y)): # gehe durch jede Spalte\n        R[i,j]=np.sqrt(x[j]**2+y[i]**2)\n\n\nimport matplotlib.pyplot as plt\n\n\nplt.contour(x,y,R)\nplt.axhline(y=0)\nplt.axvline(x=0)\nplt.axis(\"square\")\n\n\n\n\n\n\n\n\n\ndef line(x,a,b):\n   return a*x+b\n\nx = np.arange(5,11,1)\nprint(G(line,x,5,5))\n\n255"
  },
  {
    "objectID": "seminars/Assignment5.html#problem-1",
    "href": "seminars/Assignment5.html#problem-1",
    "title": "Assignment 5",
    "section": "",
    "text": "Write a function \\(G(f, x, ...)\\) that takes a function \\(f(x,...)\\) as an argument with a variable number of additional parameters. The function¬†G shall take the arguments f, x and the parameters of f.¬†It shall calculate the sum of all function values of f.¬†You should import the numpy module as np. A definition of f¬†is not required.¬†\n\nimport numpy as np\n\ndef G(f,x,*params):\n    return np.sum(f(x,*params))\n\n\nx=np.linspace(0,10,100)-5\ny=np.linspace(0,10,100)-5\n\nX,Y=np.meshgrid(x,y)\n\n\nR=np.zeros([len(x),len(y)])\n\nfor i in range(0,len(x)): # gehe durch jede Zeile\n    for j in range(0,len(y)): # gehe durch jede Spalte\n        R[i,j]=np.sqrt(x[j]**2+y[i]**2)\n\n\nimport matplotlib.pyplot as plt\n\n\nplt.contour(x,y,R)\nplt.axhline(y=0)\nplt.axvline(x=0)\nplt.axis(\"square\")\n\n\n\n\n\n\n\n\n\ndef line(x,a,b):\n   return a*x+b\n\nx = np.arange(5,11,1)\nprint(G(line,x,5,5))\n\n255"
  },
  {
    "objectID": "seminars/Assignment5.html#problem-2",
    "href": "seminars/Assignment5.html#problem-2",
    "title": "Assignment 5",
    "section": "Problem 2",
    "text": "Problem 2\nWrite a Python program that:\nConstructs a 10x10 matrix D that approximates the first derivative operator using finite differences. Uses for loops to build the matrix. Do not import any library(math, NumPy, etc.). Apply the following finite difference schemes:\n\nForward difference¬†at the first point.\nBackward difference¬†at the last point.\nCentral difference at all interior points.\n\nAssumes a constant grid spacing h (you can set¬†h = 1 for simplicity).\nFinite Difference Schemes:\nForward Difference (at the first point, i=0): \\(f'(x_0) \\approx \\frac{f(x_1) - f(x_0)}{h}\\)\nBackward Difference (at the last point, i=N-1):¬†¬† \\(f'(x_{N-1}) \\approx \\frac{f(x_{N-1}) - f(x_{N-2})}{h}\\)\nCentral Difference (at interior points, 1 ‚â§ i ‚â§ N-2):¬†¬† \\(f'(x_i) \\approx \\frac{f(x_{i+1}) - f(x_{i-1})}{2h}\\)\nInstructions:\n\nInitialize a 10x10 matrix D filled with zeros.\nUse for loops to populate the matrix according to the finite difference schemes.\nDo not print anything.\n\n\nliste=[[(i,j) for i in range(N)] for j in range(N)]\n\n\nN = 10\nh = 1.0\n\nD = [[0.0 for _ in range(N)] for _ in range(N)]\n\n# Forward difference for the first point\nD[0][0] = -1.0 / h\nD[0][1] = 1.0 / h\n\n# Central difference for interior points\nfor i in range(1,N-1):\n    D[i][i-1] = -0.5 / h\n    D[i][i+1] = 0.5 / h\n    \n# Backward difference for the last point\nD[N-1][N-2] = -1.0 / h\nD[N-1][N-1] = 1.0 / h\n\n\\[\nU(\\vec{r},t)=U_0\\exp(i(\\omega t- \\vec{k} \\cdot \\vec{r}))\n\\]\n\nx=np.linspace(0,10,100)\ny=np.linspace(0,10,100)\nZ=np.zeros([10,10])\n\nX,Y=np.meshgrid(x,y)\n\nR=np.array([X,Y,0],dtype=object)\n\n\nplt.imshow(np.real(np.exp(-1j*np.dot(k,R))))\n\n\n\n\n\n\n\n\n\nnp.dot(k,R)plt.imshow()\n\narray([[ 0.        ,  1.11111111,  2.22222222,  3.33333333,  4.44444444,\n         5.55555556,  6.66666667,  7.77777778,  8.88888889, 10.        ],\n       [ 0.        ,  1.11111111,  2.22222222,  3.33333333,  4.44444444,\n         5.55555556,  6.66666667,  7.77777778,  8.88888889, 10.        ],\n       [ 0.        ,  1.11111111,  2.22222222,  3.33333333,  4.44444444,\n         5.55555556,  6.66666667,  7.77777778,  8.88888889, 10.        ],\n       [ 0.        ,  1.11111111,  2.22222222,  3.33333333,  4.44444444,\n         5.55555556,  6.66666667,  7.77777778,  8.88888889, 10.        ],\n       [ 0.        ,  1.11111111,  2.22222222,  3.33333333,  4.44444444,\n         5.55555556,  6.66666667,  7.77777778,  8.88888889, 10.        ],\n       [ 0.        ,  1.11111111,  2.22222222,  3.33333333,  4.44444444,\n         5.55555556,  6.66666667,  7.77777778,  8.88888889, 10.        ],\n       [ 0.        ,  1.11111111,  2.22222222,  3.33333333,  4.44444444,\n         5.55555556,  6.66666667,  7.77777778,  8.88888889, 10.        ],\n       [ 0.        ,  1.11111111,  2.22222222,  3.33333333,  4.44444444,\n         5.55555556,  6.66666667,  7.77777778,  8.88888889, 10.        ],\n       [ 0.        ,  1.11111111,  2.22222222,  3.33333333,  4.44444444,\n         5.55555556,  6.66666667,  7.77777778,  8.88888889, 10.        ],\n       [ 0.        ,  1.11111111,  2.22222222,  3.33333333,  4.44444444,\n         5.55555556,  6.66666667,  7.77777778,  8.88888889, 10.        ]])\n\n\n\nnp.dot(k,R)\n\narray([[ 0.        ,  1.11111111,  2.22222222,  3.33333333,  4.44444444,\n         5.55555556,  6.66666667,  7.77777778,  8.88888889, 10.        ],\n       [ 0.        ,  1.11111111,  2.22222222,  3.33333333,  4.44444444,\n         5.55555556,  6.66666667,  7.77777778,  8.88888889, 10.        ],\n       [ 0.        ,  1.11111111,  2.22222222,  3.33333333,  4.44444444,\n         5.55555556,  6.66666667,  7.77777778,  8.88888889, 10.        ],\n       [ 0.        ,  1.11111111,  2.22222222,  3.33333333,  4.44444444,\n         5.55555556,  6.66666667,  7.77777778,  8.88888889, 10.        ],\n       [ 0.        ,  1.11111111,  2.22222222,  3.33333333,  4.44444444,\n         5.55555556,  6.66666667,  7.77777778,  8.88888889, 10.        ],\n       [ 0.        ,  1.11111111,  2.22222222,  3.33333333,  4.44444444,\n         5.55555556,  6.66666667,  7.77777778,  8.88888889, 10.        ],\n       [ 0.        ,  1.11111111,  2.22222222,  3.33333333,  4.44444444,\n         5.55555556,  6.66666667,  7.77777778,  8.88888889, 10.        ],\n       [ 0.        ,  1.11111111,  2.22222222,  3.33333333,  4.44444444,\n         5.55555556,  6.66666667,  7.77777778,  8.88888889, 10.        ],\n       [ 0.        ,  1.11111111,  2.22222222,  3.33333333,  4.44444444,\n         5.55555556,  6.66666667,  7.77777778,  8.88888889, 10.        ],\n       [ 0.        ,  1.11111111,  2.22222222,  3.33333333,  4.44444444,\n         5.55555556,  6.66666667,  7.77777778,  8.88888889, 10.        ]])\n\n\n\nk=np.array([1,1,0])\n\n\ndef plane(r,omega=1,t=0,k):\n    \n\nnp.complex128(1j)\n\n\n\n\n\narray([[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9.],\n       [10., 11., 12., 13., 14., 15., 16., 17., 18., 19.],\n       [20., 21., 22., 23., 24., 25., 26., 27., 28., 29.],\n       [30., 31., 32., 33., 34., 35., 36., 37., 38., 39.],\n       [40., 41., 42., 43., 44., 45., 46., 47., 48., 49.],\n       [50., 51., 52., 53., 54., 55., 56., 57., 58., 59.],\n       [60., 61., 62., 63., 64., 65., 66., 67., 68., 69.],\n       [70., 71., 72., 73., 74., 75., 76., 77., 78., 79.],\n       [80., 81., 82., 83., 84., 85., 86., 87., 88., 89.],\n       [90., 91., 92., 93., 94., 95., 96., 97., 98., 99.]])\n\n\n\nimport numpy as np\n\nA = np.array([\n    [1, -1, 3, -2],\n    [-2, 4, -3, 1],\n    [3, -1, 10, -4],\n    [4, -3, 8, -2],\n])\n\nB = np.array([1, 0.5, 2.9, 0.6])\n\nx = np.linalg.solve(A, B)\n\n\ntype(np.round(sum(x),1))\n\nnumpy.float64"
  },
  {
    "objectID": "seminars/Assignment 3.html",
    "href": "seminars/Assignment 3.html",
    "title": "Assignment 3",
    "section": "",
    "text": "Problem 1\nDefine a class with the name particle with a constructor that initializes the property D with twice the value supplied as an argument to the constructor.¬†\n\nclass particle:\n    def __init__(self,R):\n        self.D=2*R\n\nProblem 2\nWrite a class particle that has a class variable id. Implement a constructor that assigns a unique id property to each instance from the class id, increasing by 1 each time an instance (object) is created. The first created object id should be 1.\n\nclass particle:\n    id = 0\n    def __init__(self):\n        particle.id+=1\n        self.id = particle.id\n    \n    def __del__(self):\n        particle.id-=1\n\nProblem 3\nWrite a class particle that is constructed with two parameters that are stored in the properties R¬†and type_t of the object (R goes first). The type_t property should be of type string and be either ‚Äúcircle‚Äù or ‚Äúsquare‚Äù.\nWrite a class method¬†area that calculates the area of the object from the parameter R depending on the property type_t. The result of the area calculation should be stored in the property A, which should be 0 initially.\nCreate an object c which is a circle and compute its area. Create an object s which is a square without computing its area. The R parameter of these objects can be an arbitrary positive number.\nYou have two answer attempts without penalty.\n\nfrom math import pi\n\nclass particle:\n    def __init__(self, R, type_t):\n        self.R = R\n        self.type_t = type_t\n        self.A = 0\n        \n    def area(self):\n        if self.type_t == \"square\":\n            self.A = self.R**2\n        elif self.type_t == \"circle\":\n            self.A = pi*self.R**2\n        else:\n            self.A = 0\n            \nc=particle(3,\"circle\")\nc.area()\ns=particle(3,\"square\")\n\n\nc.A\n\n28.274333882308138"
  },
  {
    "objectID": "seminars/seminar03/md3.html",
    "href": "seminars/seminar03/md3.html",
    "title": "Step-by-Step Development of a Molecular Dynamics Simulation",
    "section": "",
    "text": "We define a class Atom that contains the properties of an atom. The class Atom has the following attributes:\nclass Atom:\n    dimension = 2\n\n    def __init__(self, atom_id, atom_type, position, velocity=None, mass=None):\n        self.id = atom_id\n        self.type = atom_type\n        self.position = position\n        self.velocity = velocity if velocity is not None else np.zeros(dimension)\n        self.mass = mass\n        self.force = np.zeros(dimension)\nThe class Atom has the following attributes:\n\nid: The unique identifier of the atom\ntype: The type of the atom (hydrogen or oxygen or ‚Ä¶)\nposition: The position of the atom in 3D space (x, y, z)\nvelocity: The velocity of the atom in 3D space (vx, vy, vz)\nmass: The mass of the atom\nforce: The force acting on the atom in 3D space (fx, fy, fz)\n\nIn addition, we will need some information on the other atoms that are bound to the atom. We will store this information later in a list of atoms called boundto. Since we start with a monoatomic gas, we will not need this information for now. Note that position, velocity, and force are 3D vectors and we store them in numpy arrays. This is a very convenient way to handle vectors and matrices in Python.\nThe class Atom should further implement a number of functions, called methods in object-oriented programming, that allow us to interact with the atom. The following methods are implemented in the Atom class:\n\n\ndef add_force(self, force):\n    \"\"\"Add force contribution to total force on atom\"\"\"\n    self.force += force\n\n\n\ndef reset_force(self):\n    \"\"\"Reset force to zero at start of each step\"\"\"\n    self.force = np.zeros(dimension)\n\n\n\ndef update_position(self, dt):\n    \"\"\"First step of velocity Verlet: update position\"\"\"\n    self.position += self.velocity * dt + 0.5 * (self.force/self.mass) * dt**2\n\n\n\ndef update_velocity(self, dt, new_force):\n    \"\"\"Second step of velocity Verlet: update velocity using average force\"\"\"\n    self.velocity += 0.5 * (new_force + self.force)/self.mass * dt\n    self.force = new_force\n\n\n\ndef apply_periodic_boundaries(self, box_size):\n        \"\"\"Apply periodic boundary conditions\"\"\"\n        self.position = self.position % box_size\n\n\n\n\n\n\nComplete Atom class\n\n\n\n\n\nclass Atom:\n    def __init__(self, atom_id, atom_type, position, velocity=None, mass=None):\n        self.id = atom_id\n        self.type = atom_type\n        self.position = position\n        self.velocity = velocity if velocity is not None else np.random.randn(2)*20\n        self.mass = mass\n        self.force = np.zeros(2)\n\n\n    def add_force(self, force):\n        \"\"\"Add force contribution to total force on atom\"\"\"\n        self.force += force\n\n    def reset_force(self):\n        \"\"\"Reset force to zero at start of each step\"\"\"\n        self.force = np.zeros(2)\n\n    def update_position(self, dt):\n        \"\"\"First step of velocity Verlet: update position\"\"\"\n        self.position += self.velocity * dt + 0.5 * (self.force/self.mass) * dt**2\n\n    def update_velocity(self, dt, new_force):\n        \"\"\"Second step of velocity Verlet: update velocity using average force\"\"\"\n        self.velocity += 0.5 * (new_force + self.force)/self.mass * dt\n        self.force = new_force\n\n    def apply_periodic_boundaries(self, box_size):\n            \"\"\"Apply periodic boundary conditions\"\"\"\n            self.position = self.position % box_size\n\n\n\nThis would be a good time to do something simple with the atom class. Let‚Äôs create a bunch of atoms and plot them in a 2D space."
  },
  {
    "objectID": "seminars/seminar03/md3.html#implementations",
    "href": "seminars/seminar03/md3.html#implementations",
    "title": "Step-by-Step Development of a Molecular Dynamics Simulation",
    "section": "",
    "text": "We define a class Atom that contains the properties of an atom. The class Atom has the following attributes:\nclass Atom:\n    dimension = 2\n\n    def __init__(self, atom_id, atom_type, position, velocity=None, mass=None):\n        self.id = atom_id\n        self.type = atom_type\n        self.position = position\n        self.velocity = velocity if velocity is not None else np.zeros(dimension)\n        self.mass = mass\n        self.force = np.zeros(dimension)\nThe class Atom has the following attributes:\n\nid: The unique identifier of the atom\ntype: The type of the atom (hydrogen or oxygen or ‚Ä¶)\nposition: The position of the atom in 3D space (x, y, z)\nvelocity: The velocity of the atom in 3D space (vx, vy, vz)\nmass: The mass of the atom\nforce: The force acting on the atom in 3D space (fx, fy, fz)\n\nIn addition, we will need some information on the other atoms that are bound to the atom. We will store this information later in a list of atoms called boundto. Since we start with a monoatomic gas, we will not need this information for now. Note that position, velocity, and force are 3D vectors and we store them in numpy arrays. This is a very convenient way to handle vectors and matrices in Python.\nThe class Atom should further implement a number of functions, called methods in object-oriented programming, that allow us to interact with the atom. The following methods are implemented in the Atom class:\n\n\ndef add_force(self, force):\n    \"\"\"Add force contribution to total force on atom\"\"\"\n    self.force += force\n\n\n\ndef reset_force(self):\n    \"\"\"Reset force to zero at start of each step\"\"\"\n    self.force = np.zeros(dimension)\n\n\n\ndef update_position(self, dt):\n    \"\"\"First step of velocity Verlet: update position\"\"\"\n    self.position += self.velocity * dt + 0.5 * (self.force/self.mass) * dt**2\n\n\n\ndef update_velocity(self, dt, new_force):\n    \"\"\"Second step of velocity Verlet: update velocity using average force\"\"\"\n    self.velocity += 0.5 * (new_force + self.force)/self.mass * dt\n    self.force = new_force\n\n\n\ndef apply_periodic_boundaries(self, box_size):\n        \"\"\"Apply periodic boundary conditions\"\"\"\n        self.position = self.position % box_size\n\n\n\n\n\n\nComplete Atom class\n\n\n\n\n\nclass Atom:\n    def __init__(self, atom_id, atom_type, position, velocity=None, mass=None):\n        self.id = atom_id\n        self.type = atom_type\n        self.position = position\n        self.velocity = velocity if velocity is not None else np.random.randn(2)*20\n        self.mass = mass\n        self.force = np.zeros(2)\n\n\n    def add_force(self, force):\n        \"\"\"Add force contribution to total force on atom\"\"\"\n        self.force += force\n\n    def reset_force(self):\n        \"\"\"Reset force to zero at start of each step\"\"\"\n        self.force = np.zeros(2)\n\n    def update_position(self, dt):\n        \"\"\"First step of velocity Verlet: update position\"\"\"\n        self.position += self.velocity * dt + 0.5 * (self.force/self.mass) * dt**2\n\n    def update_velocity(self, dt, new_force):\n        \"\"\"Second step of velocity Verlet: update velocity using average force\"\"\"\n        self.velocity += 0.5 * (new_force + self.force)/self.mass * dt\n        self.force = new_force\n\n    def apply_periodic_boundaries(self, box_size):\n            \"\"\"Apply periodic boundary conditions\"\"\"\n            self.position = self.position % box_size\n\n\n\nThis would be a good time to do something simple with the atom class. Let‚Äôs create a bunch of atoms and plot them in a 2D space."
  },
  {
    "objectID": "seminars/Assignment 1/Assignment 1.html",
    "href": "seminars/Assignment 1/Assignment 1.html",
    "title": "Assignment 1",
    "section": "",
    "text": "n=range(1,11)\nmean=sum(n)/len(n)\n\n\nx = 5\ny = 10\n\nx, y = y, x\n\n\nlength = 10\nwidth = 5\n\narea = length * width\nperimeter = 2 * (length + width)\n\n\ntemp1_in_C = 25\ntemp1_in_F = (temp1_in_C * 9/5) + 32\n\ntemp2_in_F = 86\ntemp2_in_C = (temp2_in_F - 32) * 5/9\n\n\nmy_string = \"Hello, World!\"\n\nconcatenated_string = my_string + \" How are you?\"\nsliced_string = my_string[7:12]\nupper_case_string = my_string.upper()\nlower_case_string = my_string.lower()"
  },
  {
    "objectID": "seminars/seminar02/MD Simulation.html",
    "href": "seminars/seminar02/MD Simulation.html",
    "title": "Molecular Dynamics Simulations in EMPP 2024",
    "section": "",
    "text": "Before we implement all classes, we will first visualize the particles moving in a 2D box. We will use the matplotlib library to create an animation of the particles moving in the box. We will also implement periodic boundary conditions, so that particles that leave the box on one side re-enter on the opposite side.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom IPython.display import clear_output\nfrom scipy.spatial.distance import cdist\n\nplt.rcParams.update({'font.size': 8,\n                     'lines.linewidth': 1,\n                     'lines.markersize': 10,\n                     'axes.labelsize': 10,\n                     'axes.titlesize': 10,\n                     'xtick.labelsize' : 10,\n                     'ytick.labelsize' : 10,\n                     'xtick.top' : True,\n                     'xtick.direction' : 'in',\n                     'ytick.right' : True,\n                     'ytick.direction' : 'in',})\n\ndef get_size(w,h):\n    return((w/2.54,h/2.54))"
  },
  {
    "objectID": "seminars/seminar02/MD Simulation.html#part-2",
    "href": "seminars/seminar02/MD Simulation.html#part-2",
    "title": "Molecular Dynamics Simulations in EMPP 2024",
    "section": "",
    "text": "Before we implement all classes, we will first visualize the particles moving in a 2D box. We will use the matplotlib library to create an animation of the particles moving in the box. We will also implement periodic boundary conditions, so that particles that leave the box on one side re-enter on the opposite side.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom IPython.display import clear_output\nfrom scipy.spatial.distance import cdist\n\nplt.rcParams.update({'font.size': 8,\n                     'lines.linewidth': 1,\n                     'lines.markersize': 10,\n                     'axes.labelsize': 10,\n                     'axes.titlesize': 10,\n                     'xtick.labelsize' : 10,\n                     'ytick.labelsize' : 10,\n                     'xtick.top' : True,\n                     'xtick.direction' : 'in',\n                     'ytick.right' : True,\n                     'ytick.direction' : 'in',})\n\ndef get_size(w,h):\n    return((w/2.54,h/2.54))"
  },
  {
    "objectID": "seminars/seminar02/MD Simulation.html#create-a-particle-array",
    "href": "seminars/seminar02/MD Simulation.html#create-a-particle-array",
    "title": "Molecular Dynamics Simulations in EMPP 2024",
    "section": "Create a particle array",
    "text": "Create a particle array\nWe will start creating an array of particles in 2D using numpy. Out box will be of size (1,1).\n\n# number of particle per edge\nn_side =20\n\n# particle x and y coordinates\nx = np.linspace(0.05, 0.95, n_side)\ny = np.linspace(0.05, 0.95, n_side)\n\n# meshgrid of them to have points per particle\nxx, yy = np.meshgrid(x, y)\n\n# flatten the 2D array\nparticles = np.vstack([xx.ravel(), yy.ravel()]).T\n\nJust have a look at the array xx."
  },
  {
    "objectID": "seminars/seminar02/MD Simulation.html#create-particle-velocities",
    "href": "seminars/seminar02/MD Simulation.html#create-particle-velocities",
    "title": "Molecular Dynamics Simulations in EMPP 2024",
    "section": "Create particle velocities",
    "text": "Create particle velocities\n\nvelocities = np.random.normal(scale=0.005, size=(n_side**2, 2))\n\n\nvelocities.shape\n\n(400, 2)\n\n\n\nplt.figure(figsize=(5,5))\nplt.hist(velocities[:,1],density=True,bins=50)\nplt.xlabel(r\"$v_x$\")\nplt.xlabel(r\"$p(v_x)$\")\nplt.show()"
  },
  {
    "objectID": "seminars/seminar02/MD Simulation.html#do-one-step-by-hand-and-apply-the-boundary-conditions",
    "href": "seminars/seminar02/MD Simulation.html#do-one-step-by-hand-and-apply-the-boundary-conditions",
    "title": "Molecular Dynamics Simulations in EMPP 2024",
    "section": "Do one step by hand and apply the boundary conditions",
    "text": "Do one step by hand and apply the boundary conditions\nWe choose perdiodic boundary conditions. To apply them, the modulo operator % is a good choice.\n\n\n# Update particle positions based on their velocities\nparticles += velocities\n\n# Apply periodic boundary conditions in x direction (wrap around at 0 and 1)\nparticles[:, 0] = particles[:, 0] % 1\nparticles[:, 1] = particles[:, 1] % 1\n\n\n6 % 2\n\n0\n\n\nWe also need to handle collisions. This requires to calculate all pairwaise distances between all atoms. This could be quite time-consuming.\n\n\n# Calculate distances between all pairs of particles\ndistances = cdist(particles, particles)\n\n# Calculate collisions using the upper triangle of the distance matrix\n# distances &lt; 2*radius gives a boolean matrix where True means collision\n# np.triu takes only the upper triangle to avoid counting collisions twice\ncollisions = np.triu(distances &lt; 2*radius , 1)\n\n\ncollisions\n\narray([[False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False],\n       ...,\n       [False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False],\n       [False, False, False, ..., False, False, False]])\n\n\nThen we need to carry out the collision. We simplify everything assuming a central collision of masses of the same size. This allows us to swap the velocities and to remove the overlap.\n\n# Handle collisions between particles\nfor i, j in zip(*np.nonzero(collisions)):\n    # Exchange velocities between colliding particles (elastic collision)\n    velocities[i], velocities[j] = velocities[j], velocities[i].copy()\n\n    # Calculate how much particles overlap\n    overlap = 2*radius - distances[i, j]\n\n    # Calculate unit vector pointing from j to i\n    direction = particles[i] - particles[j]\n    direction /= np.linalg.norm(direction)\n\n    # Move particles apart to prevent overlap\n    particles[i] += 0.5 * overlap * direction\n    particles[j] -= 0.5 * overlap * direction\n\nThis is now carrying out the simulation loop all together handles the drawing. This is the key in this loop.\nClear the canvas for drawing\nclear_output(wait=True)\nDraw the particles\nax.scatter(particles[:, 0], particles[:, 1], s=100, edgecolors='r', facecolors='none')\nDisplay the figure\ndisplay(fig)\nplt.pause(0.01)\nax.clear()\n\nradius = 0.0177\nfig, ax = plt.subplots(figsize=(6,6))\n\nn_steps = 200\n\nfor _ in range(n_steps):\n    clear_output(wait=True)\n\n    # Update particle positions based on their velocities\n    particles += velocities\n    # Apply periodic boundary conditions in x direction (wrap around at 0 and 1)\n    particles[:, 0] = particles[:, 0] % 1\n    # Apply periodic boundary conditions in y direction (wrap around at 0 and 1)\n    particles[:, 1] = particles[:, 1] % 1\n    # Calculate distances between all pairs of particles\n    distances = cdist(particles, particles)\n\n    # Calculate collisions using the upper triangle of the distance matrix\n    # distances &lt; 2*radius gives a boolean matrix where True means collision\n    # np.triu takes only the upper triangle to avoid counting collisions twice\n    collisions = np.triu(distances &lt; 2*radius, 1)\n\n    # Handle collisions between particles\n    for i, j in zip(*np.nonzero(collisions)):\n        # Exchange velocities between colliding particles (elastic collision)\n        velocities[i], velocities[j] = velocities[j], velocities[i].copy()\n\n        # Calculate how much particles overlap\n        overlap = 2*radius - distances[i, j]\n\n        # Calculate unit vector pointing from j to i\n        direction = particles[i] - particles[j]\n        direction /= np.linalg.norm(direction)\n\n        # Move particles apart to prevent overlap\n        particles[i] += 0.5 * overlap * direction\n        particles[j] -= 0.5 * overlap * direction\n\n    ax.scatter(particles[:, 0], particles[:, 1], s=100, edgecolors='r', facecolors='none')\n\n\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.axis(\"off\")\n\n    display(fig)\n    plt.pause(0.01)\n    ax.clear()"
  },
  {
    "objectID": "seminars/seminar05/mdsim copy.html",
    "href": "seminars/seminar05/mdsim copy.html",
    "title": "Step-by-Step Development of a Molecular Dynamics Simulation",
    "section": "",
    "text": "# %% Load  modules and initialize\nfrom typing_extensions import ParamSpec\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom IPython.display import clear_output\nimport matplotlib.patches as patches\nplt.rcParams.update({'font.size': 8,\n                     'lines.linewidth': 1,\n                     'lines.markersize': 10,\n                     'axes.labelsize': 10,\n                     'axes.titlesize': 10,\n                     'xtick.labelsize' : 10,\n                     'ytick.labelsize' : 10,\n                     'xtick.top' : True,\n                     'xtick.direction' : 'in',\n                     'ytick.right' : True,\n                     'ytick.direction' : 'in',\n                     'figure.facecolor' : 'white',})\n\ndef get_size(w,h):\n    return((w/2.54,h/2.54))\n\n\n# %% Load the atom class we did already in the previous seminar\nclass Atom:\n    def __init__(self, atom_id, atom_type, position, velocity=None, mass=None):\n        self.id = atom_id\n        self.type = atom_type\n        self.position = position\n        self.velocity = velocity if velocity is not None else np.random.randn(2)*20\n        self.mass = mass\n        self.force = np.zeros(2)\n\n\n    def add_force(self, force):\n        \"\"\"Add force contribution to total force on atom\"\"\"\n        self.force += force\n\n    def reset_force(self):\n        \"\"\"Reset force to zero at start of each step\"\"\"\n        self.force = np.zeros(2)\n\n    def update_position(self, dt):\n        \"\"\"First step of velocity Verlet: update position\"\"\"\n        self.position += self.velocity * dt + 0.5 * (self.force/self.mass) * dt**2\n\n    def update_velocity(self, dt, new_force):\n        \"\"\"Second step of velocity Verlet: update velocity using average force\"\"\"\n        self.velocity += 0.5 * (new_force + self.force)/self.mass * dt\n        self.force = new_force\n\n    def apply_periodic_boundaries(self, box_size):\n            \"\"\"Apply periodic boundary conditions\"\"\"\n            self.position = self.position % box_size\n\nclass ForceField:\n    def __init__(self):\n        self.parameters = {\n            'C': {'epsilon': 1.615, 'sigma': 1.36},\n            'H': {'epsilon': 1.0, 'sigma': 1.0 },\n            'O': {'epsilon': 1.846, 'sigma': 3.0},\n        }\n        self.box_size = None  # Will be set when initializing the simulation\n\n    def get_pair_parameters(self, type1, type2):\n        # Apply mixing rules when needed\n        eps1 = self.parameters[type1]['epsilon']\n        eps2 = self.parameters[type2]['epsilon']\n        sig1 = self.parameters[type1]['sigma']\n        sig2 = self.parameters[type2]['sigma']\n\n        # Lorentz-Berthelot mixing rules\n        epsilon = np.sqrt(eps1 * eps2)\n        sigma = (sig1 + sig2) / 2\n\n        return epsilon, sigma\n\n    def minimum_image_distance(self, pos1, pos2):\n        \"\"\"Calculate minimum image distance between two positions\"\"\"\n        delta = pos1 - pos2\n        # Apply minimum image convention\n        delta = delta - self.box_size * np.round(delta / self.box_size)\n        return delta\n\n    def calculate_lj_force(self, atom1, atom2):\n        epsilon, sigma = self.get_pair_parameters(atom1.type, atom2.type)\n        r = self.minimum_image_distance(atom1.position, atom2.position)\n        r_mag = np.linalg.norm(r)\n\n        # Add cutoff distance for stability\n        if r_mag &gt; 3.5*sigma:\n            return np.zeros(2)\n\n        force_mag = 24 * epsilon * (\n            2 * (sigma/r_mag)**13\n            - (sigma/r_mag)**7\n        )\n        force = force_mag * r/r_mag\n        return force\n\n\n\n\n# %% Define the MD Simulation master controller class\n\nclass MDSimulation:\n    def __init__(self, atoms, forcefield, timestep, box_size):\n        self.atoms = atoms\n        self.forcefield = forcefield\n        self.forcefield.box_size = box_size  # Set box size in forcefield\n        self.timestep = timestep\n        self.box_size = np.array(box_size)\n        self.initial_energy = None\n        self.energy_history = []\n\n\n    def calculate_forces(self):\n        # Reset all forces\n        for atom in self.atoms:\n            atom.reset_force()\n\n        # Calculate forces between all pairs\n        for i, atom1 in enumerate(self.atoms):\n            for atom2 in self.atoms[i+1:]:\n                force = self.forcefield.calculate_lj_force(atom1, atom2)\n                atom1.add_force(force)\n                atom2.add_force(-force)  # Newton's third law\n\n    def update_positions_and_velocities(self):\n        # First step: Update positions using current forces\n        for atom in self.atoms:\n            atom.update_position(self.timestep)\n            # Apply periodic boundary conditions\n            atom.apply_periodic_boundaries(self.box_size)\n\n        # Recalculate forces with new positions\n        self.calculate_forces()\n\n        # Second step: Update velocities using average of old and new forces\n        for atom in self.atoms:\n            atom.update_velocity(self.timestep, atom.force)\n\n\n# %% Cell 6\ndef create_grid_atoms(num_atoms, box_size, type=\"H\",mass=1.0, random_offset=0.1):\n    box_size = np.array(box_size)\n\n    # Calculate grid dimensions\n    n = int(np.ceil(np.sqrt(num_atoms)))\n    spacing = np.min(box_size) / n\n\n    atoms = []\n    for i in range(num_atoms):\n        # Calculate grid position\n        row = i // n\n        col = i % n\n\n        # Base position\n        pos = np.array([col * spacing + spacing/2,\n                       row * spacing + spacing/2])\n\n        # Add random offset\n        pos += (np.random.rand(2) - 0.5) * spacing * random_offset\n\n        # Create atom\n        atoms.append(Atom(i, type, pos, mass=mass))\n\n    return atoms\n\n\n# %% Cell 7\ndef set_temperature(atoms, target_temperature):\n    N = len(atoms)      # number of atoms\n    Nf = 2 * N         # degrees of freedom in 2D\n\n    # Calculate current kinetic energy\n    current_ke = sum(0.5 * atom.mass * np.sum(atom.velocity**2) for atom in atoms)\n    current_temperature = 2 * current_ke / Nf  # kb = 1 in reduced units\n    print(current_temperature)\n    # Calculate scaling factor\n    scale_factor = np.sqrt(target_temperature / current_temperature)\n\n    # Scale velocities\n    for atom in atoms:\n        atom.velocity *= scale_factor\n\n\ndef initialize_velocities(atoms, temperature, seed=None):\n    if seed is not None:\n        np.random.seed(seed)\n\n    N = len(atoms)  # number of atoms\n    dim = 2         # 2D simulation\n\n    # Generate random velocities from normal distribution\n    velocities = np.random.normal(0, np.sqrt(temperature), size=(N, dim))\n\n    # Remove center of mass motion\n    total_momentum = np.sum([atom.mass * velocities[i] for i, atom in enumerate(atoms)], axis=0)\n    total_mass = np.sum([atom.mass for atom in atoms])\n    cm_velocity = total_momentum / total_mass\n\n    # Assign velocities to atoms\n    for i, atom in enumerate(atoms):\n        atom.velocity = velocities[i] - cm_velocity\n\n    # Scale velocities to exact temperature\n    set_temperature(atoms, temperature)\n\n    return atoms\n\n# %% run the simulation w\n\nbox_size = np.array([50.0, 50.0])  # Box dimensions\nnum_atoms = 200\n\nT=5\ndt = 0.01\n\n# Create atoms and set initial velocities\natoms = create_grid_atoms(num_atoms, box_size, type=\"H\",mass=1.0, random_offset=0.1)\natoms = initialize_velocities(atoms, temperature=T)\n\n\n# Create force field\nff = ForceField()\n\n\n# Create simulation with periodic boundaries\nsim = MDSimulation(atoms, ff, dt, box_size)\n\nfig, ax = plt.subplots(1,1,figsize=(6,6))\n\nfor step in range(1000):\n    clear_output(wait=True)\n    set_temperature(atoms, target_temperature=T)\n    sim.update_positions_and_velocities()\n\n\n    positions = [atom.position for atom in sim.atoms]\n    x_coords = [pos[0] for pos in positions]\n    y_coords = [pos[1] for pos in positions]\n\n    circle=patches.Circle((x_coords[0],y_coords[0]),ff.parameters[atoms[0].type][\"sigma\"],edgecolor=\"white\",fill=False)\n    ax.add_patch(circle)\n    ax.scatter(x_coords, y_coords,color=\"red\")\n    ax.set_xlim(0, box_size[0])\n    ax.set_ylim(0, box_size[1])\n    ax.axis(\"off\")\n\n    display(fig)\n\n    ax.clear()\n# %% Cell 8\n#\n\nvx=np.array([atom.velocity for atom in atoms])\n\nvx.reshape(200,2)\nplt.hist(vx[:,0],bins=20)"
  },
  {
    "objectID": "seminars/seminar05/mdsim copy.html#here-is-the-complete-code-for-the-molecular-dynamics-simulation",
    "href": "seminars/seminar05/mdsim copy.html#here-is-the-complete-code-for-the-molecular-dynamics-simulation",
    "title": "Step-by-Step Development of a Molecular Dynamics Simulation",
    "section": "",
    "text": "# %% Load  modules and initialize\nfrom typing_extensions import ParamSpec\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom IPython.display import clear_output\nimport matplotlib.patches as patches\nplt.rcParams.update({'font.size': 8,\n                     'lines.linewidth': 1,\n                     'lines.markersize': 10,\n                     'axes.labelsize': 10,\n                     'axes.titlesize': 10,\n                     'xtick.labelsize' : 10,\n                     'ytick.labelsize' : 10,\n                     'xtick.top' : True,\n                     'xtick.direction' : 'in',\n                     'ytick.right' : True,\n                     'ytick.direction' : 'in',\n                     'figure.facecolor' : 'white',})\n\ndef get_size(w,h):\n    return((w/2.54,h/2.54))\n\n\n# %% Load the atom class we did already in the previous seminar\nclass Atom:\n    def __init__(self, atom_id, atom_type, position, velocity=None, mass=None):\n        self.id = atom_id\n        self.type = atom_type\n        self.position = position\n        self.velocity = velocity if velocity is not None else np.random.randn(2)*20\n        self.mass = mass\n        self.force = np.zeros(2)\n\n\n    def add_force(self, force):\n        \"\"\"Add force contribution to total force on atom\"\"\"\n        self.force += force\n\n    def reset_force(self):\n        \"\"\"Reset force to zero at start of each step\"\"\"\n        self.force = np.zeros(2)\n\n    def update_position(self, dt):\n        \"\"\"First step of velocity Verlet: update position\"\"\"\n        self.position += self.velocity * dt + 0.5 * (self.force/self.mass) * dt**2\n\n    def update_velocity(self, dt, new_force):\n        \"\"\"Second step of velocity Verlet: update velocity using average force\"\"\"\n        self.velocity += 0.5 * (new_force + self.force)/self.mass * dt\n        self.force = new_force\n\n    def apply_periodic_boundaries(self, box_size):\n            \"\"\"Apply periodic boundary conditions\"\"\"\n            self.position = self.position % box_size\n\nclass ForceField:\n    def __init__(self):\n        self.parameters = {\n            'C': {'epsilon': 1.615, 'sigma': 1.36},\n            'H': {'epsilon': 1.0, 'sigma': 1.0 },\n            'O': {'epsilon': 1.846, 'sigma': 3.0},\n        }\n        self.box_size = None  # Will be set when initializing the simulation\n\n    def get_pair_parameters(self, type1, type2):\n        # Apply mixing rules when needed\n        eps1 = self.parameters[type1]['epsilon']\n        eps2 = self.parameters[type2]['epsilon']\n        sig1 = self.parameters[type1]['sigma']\n        sig2 = self.parameters[type2]['sigma']\n\n        # Lorentz-Berthelot mixing rules\n        epsilon = np.sqrt(eps1 * eps2)\n        sigma = (sig1 + sig2) / 2\n\n        return epsilon, sigma\n\n    def minimum_image_distance(self, pos1, pos2):\n        \"\"\"Calculate minimum image distance between two positions\"\"\"\n        delta = pos1 - pos2\n        # Apply minimum image convention\n        delta = delta - self.box_size * np.round(delta / self.box_size)\n        return delta\n\n    def calculate_lj_force(self, atom1, atom2):\n        epsilon, sigma = self.get_pair_parameters(atom1.type, atom2.type)\n        r = self.minimum_image_distance(atom1.position, atom2.position)\n        r_mag = np.linalg.norm(r)\n\n        # Add cutoff distance for stability\n        if r_mag &gt; 3.5*sigma:\n            return np.zeros(2)\n\n        force_mag = 24 * epsilon * (\n            2 * (sigma/r_mag)**13\n            - (sigma/r_mag)**7\n        )\n        force = force_mag * r/r_mag\n        return force\n\n\n\n\n# %% Define the MD Simulation master controller class\n\nclass MDSimulation:\n    def __init__(self, atoms, forcefield, timestep, box_size):\n        self.atoms = atoms\n        self.forcefield = forcefield\n        self.forcefield.box_size = box_size  # Set box size in forcefield\n        self.timestep = timestep\n        self.box_size = np.array(box_size)\n        self.initial_energy = None\n        self.energy_history = []\n\n\n    def calculate_forces(self):\n        # Reset all forces\n        for atom in self.atoms:\n            atom.reset_force()\n\n        # Calculate forces between all pairs\n        for i, atom1 in enumerate(self.atoms):\n            for atom2 in self.atoms[i+1:]:\n                force = self.forcefield.calculate_lj_force(atom1, atom2)\n                atom1.add_force(force)\n                atom2.add_force(-force)  # Newton's third law\n\n    def update_positions_and_velocities(self):\n        # First step: Update positions using current forces\n        for atom in self.atoms:\n            atom.update_position(self.timestep)\n            # Apply periodic boundary conditions\n            atom.apply_periodic_boundaries(self.box_size)\n\n        # Recalculate forces with new positions\n        self.calculate_forces()\n\n        # Second step: Update velocities using average of old and new forces\n        for atom in self.atoms:\n            atom.update_velocity(self.timestep, atom.force)\n\n\n# %% Cell 6\ndef create_grid_atoms(num_atoms, box_size, type=\"H\",mass=1.0, random_offset=0.1):\n    box_size = np.array(box_size)\n\n    # Calculate grid dimensions\n    n = int(np.ceil(np.sqrt(num_atoms)))\n    spacing = np.min(box_size) / n\n\n    atoms = []\n    for i in range(num_atoms):\n        # Calculate grid position\n        row = i // n\n        col = i % n\n\n        # Base position\n        pos = np.array([col * spacing + spacing/2,\n                       row * spacing + spacing/2])\n\n        # Add random offset\n        pos += (np.random.rand(2) - 0.5) * spacing * random_offset\n\n        # Create atom\n        atoms.append(Atom(i, type, pos, mass=mass))\n\n    return atoms\n\n\n# %% Cell 7\ndef set_temperature(atoms, target_temperature):\n    N = len(atoms)      # number of atoms\n    Nf = 2 * N         # degrees of freedom in 2D\n\n    # Calculate current kinetic energy\n    current_ke = sum(0.5 * atom.mass * np.sum(atom.velocity**2) for atom in atoms)\n    current_temperature = 2 * current_ke / Nf  # kb = 1 in reduced units\n    print(current_temperature)\n    # Calculate scaling factor\n    scale_factor = np.sqrt(target_temperature / current_temperature)\n\n    # Scale velocities\n    for atom in atoms:\n        atom.velocity *= scale_factor\n\n\ndef initialize_velocities(atoms, temperature, seed=None):\n    if seed is not None:\n        np.random.seed(seed)\n\n    N = len(atoms)  # number of atoms\n    dim = 2         # 2D simulation\n\n    # Generate random velocities from normal distribution\n    velocities = np.random.normal(0, np.sqrt(temperature), size=(N, dim))\n\n    # Remove center of mass motion\n    total_momentum = np.sum([atom.mass * velocities[i] for i, atom in enumerate(atoms)], axis=0)\n    total_mass = np.sum([atom.mass for atom in atoms])\n    cm_velocity = total_momentum / total_mass\n\n    # Assign velocities to atoms\n    for i, atom in enumerate(atoms):\n        atom.velocity = velocities[i] - cm_velocity\n\n    # Scale velocities to exact temperature\n    set_temperature(atoms, temperature)\n\n    return atoms\n\n# %% run the simulation w\n\nbox_size = np.array([50.0, 50.0])  # Box dimensions\nnum_atoms = 200\n\nT=5\ndt = 0.01\n\n# Create atoms and set initial velocities\natoms = create_grid_atoms(num_atoms, box_size, type=\"H\",mass=1.0, random_offset=0.1)\natoms = initialize_velocities(atoms, temperature=T)\n\n\n# Create force field\nff = ForceField()\n\n\n# Create simulation with periodic boundaries\nsim = MDSimulation(atoms, ff, dt, box_size)\n\nfig, ax = plt.subplots(1,1,figsize=(6,6))\n\nfor step in range(1000):\n    clear_output(wait=True)\n    set_temperature(atoms, target_temperature=T)\n    sim.update_positions_and_velocities()\n\n\n    positions = [atom.position for atom in sim.atoms]\n    x_coords = [pos[0] for pos in positions]\n    y_coords = [pos[1] for pos in positions]\n\n    circle=patches.Circle((x_coords[0],y_coords[0]),ff.parameters[atoms[0].type][\"sigma\"],edgecolor=\"white\",fill=False)\n    ax.add_patch(circle)\n    ax.scatter(x_coords, y_coords,color=\"red\")\n    ax.set_xlim(0, box_size[0])\n    ax.set_ylim(0, box_size[1])\n    ax.axis(\"off\")\n\n    display(fig)\n\n    ax.clear()\n# %% Cell 8\n#\n\nvx=np.array([atom.velocity for atom in atoms])\n\nvx.reshape(200,2)\nplt.hist(vx[:,0],bins=20)"
  },
  {
    "objectID": "seminars/seminar10/1_deep_learning.html",
    "href": "seminars/seminar10/1_deep_learning.html",
    "title": "Neural Networks",
    "section": "",
    "text": "Neural networks are one of the most commonly used machine learning objects nowadays. Mostly these systems are known as deep neural networks, which just says something about how many layers in which neurons are arranged exist. We will in this lecture have a look at the basic unit, the neuron, and how to connect and train a network. We will do all ourselves, that means, we will not use one of the many existing python modules, that simplifies the task. This notebook has been largely developed by Martin Fr√§nzl.\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\n\n\nplt.rcParams.update({'font.size': 18,\n                     'axes.titlesize': 20,\n                     'axes.labelsize': 20,\n                     'axes.labelpad': 1,\n                     'lines.linewidth': 2,\n                     'lines.markersize': 10,\n                     'xtick.labelsize' : 18,\n                     'ytick.labelsize' : 18,\n                     'xtick.top' : True,\n                     'xtick.direction' : 'in',\n                     'ytick.right' : True,\n                     'ytick.direction' : 'in'\n                    })\nIn this lecture we are going to build a neural network from scratch using Python and NumPy (The high-level libaries like Keras and TensorFlow will be covered in Part 2). We will build a network to recognize hand-written digits, using the famous MNIST data set.\nWe will start with the simplest possible ‚Äúnetwork‚Äù: A single node that recognizes just the digit 0. This is actually just an implementation of logistic regression, but it will help us understand some of the key components before things get more complicated. Then we‚Äôll extend that into a network with one hidden layer, still recognizing just 0. Finally, we will extend the network to recognize all the digits 0 through 9. That will give us a 92% accurate digit-recognizer."
  },
  {
    "objectID": "seminars/seminar10/1_deep_learning.html#the-mnist-data-set",
    "href": "seminars/seminar10/1_deep_learning.html#the-mnist-data-set",
    "title": "Neural Networks",
    "section": "The MNIST Data Set",
    "text": "The MNIST Data Set\nThe MNIST data set contains 70,000 images of hand-written digits, each 28 x 28 pixels, in greyscale with pixel-values from 0 to 255. We could download and preprocess the data ourselves, but the makers of the module sklearn already did that for us:\n\nLoad the data\n\nfrom sklearn.datasets import fetch_openml\nX, y = fetch_openml('mnist_784', version=1, return_X_y=True,as_frame=False)\n\nThe images are now contained in the array X, while the labels (so which number it is) are contained in y. Let‚Äôs have a look at a random image and label.\n\ni = 33419\nplt.imshow(np.array(X)[i].reshape(28, 28), cmap='gray')\nplt.colorbar()\nplt.show()\nprint('label: ',y[i])\n\n\n\n\n\n\n\n\nlabel:  8\n\n\n\n\nNormalize the data\nTo use data in neural networks as training data, it is always useful to normalize the data to the interval [0, 1].\n\nX = X/255\n\n\n\nPreparing training and testing data\nThe default MNIST labels say ‚Äò1‚Äô for an image of a one, ‚Äò2‚Äô for an image of a two, etc., but we are just building a zero classifier for now. So we want our labels to say 1 when we have a zero, and 0 otherwise. So we overwrite the labels accordingly:\n\ny_new = np.zeros(y.shape)\ny_new[np.where(y == '0')[0]] = 1\ny = y_new\n\nWe now split the data in a train and test set. The MNIST images are pre-arranged so that the first 60,000 can be used for training, and the last 10,000 for testing. We‚Äôll also transform the data into the shape we want, with each example in a column (instead of a row):\n\nm = 60000\nm_test = X.shape[0] - m\n\nX_train, X_test = X[:m].T, X[m:].T\ny_train, y_test = y[:m].reshape(1,m), y[m:].reshape(1, m_test)\n\nFinally, we shuffle the training set:\n\nnp.random.seed(1)\nshuffle_index = np.random.permutation(m)\nX_train, y_train = X_train[:,shuffle_index], y_train[:,shuffle_index]\n\nLet‚Äôs again have a look at random image and label just to check\n\ni = 39\nplt.imshow(X_train[:,i].reshape(28, 28), cmap='gray')\nplt.colorbar()\nplt.show()\nprint(y_train[:,i])\n\n\n\n\n\n\n\n\n[0.]\n\n\nTry to find a zero to check whether the corresponding label is a 1."
  },
  {
    "objectID": "seminars/seminar10/1_deep_learning.html#a-single-neuron",
    "href": "seminars/seminar10/1_deep_learning.html#a-single-neuron",
    "title": "Neural Networks",
    "section": "A Single Neuron",
    "text": "A Single Neuron\nThe basic unit of a neural network is a neuron. A neuron takes inputs, does some math with them, and produces one output. The neuron below does that with two inputs.\n\n\n\nimage\n\n\n\nForward Propogation\nThe neuron does now three things.\n\nTake input values and multipy by weights\n\n\\[\\begin{eqnarray}\nx_{1}\\rightarrow x_{1} w_{1}\\\\\nx_{2}\\rightarrow x_{2} w_{2}\n\\end{eqnarray}\\]\n\nAll the weighted inputs are the added to a bias value \\(b\\)\n\n\\[\\begin{equation}\nx_{1} w_{1}+ x_{2} w_{2}+b\n\\end{equation}\\]\n\nThe output is generated by applying a function \\(\\sigma()\\) \\[\\begin{equation}\ny=\\sigma( x_{1} w_{1}+ x_{2} w_{2}+b)\n\\end{equation}\\]\n\nThis function is called activation function. The activation function is used to turn an unbounded input value into a bounded output value with a predictable range. A commonly used activation function is the sigmoid function.\nFor a single input dataset \\(x\\) a more compact writing of the math above is\n\\[\\begin{equation*}\n\\hat{y} = \\sigma(w^{\\rm T} x + b)\\ .\n\\end{equation*}\\]\nHere \\(\\sigma\\) is the sigmoid function: \\[\\begin{equation*}\n\\sigma(z) = \\frac{1}{1+{\\rm e}^{-z}}\\ .\n\\end{equation*}\\]\nThe sigmoid function is something we can already define and plot.\n\ndef sigmoid(z):\n    return 1/(1 + np.exp(-z))\n\n\nx=np.linspace(-5,5,100)\nplt.figure(figsize=(5,3))\nplt.plot(x,sigmoid(x))\nplt.xlabel('input')\nplt.ylabel('output')\nplt.grid()\nplt.show()\n\n\n\n\n\n\n\n\nIf we now have this kind of two input neuron with the weights \\(w\\) and the bias value \\(b\\)\n\\[\\begin{eqnarray}\nw=[0,1]\\\\\nb=4\n\\end{eqnarray}\\]\nwe may supply and input\n\\[\\begin{eqnarray}\nx=[2,3]\n\\end{eqnarray}\\]\nwhich gives writing it a s a dot product\n\\[\\begin{equation}\ny=f(w\\cdot x+b)=f(7)=0.999\n\\end{equation}\\]\nThis procedure of propagating the input values to obtain and output value is called feedforward or forward propagation. Our first goal is now to create a network with a single neuron with 784 inputs (28 x 28), and a single sigmoid unit generating the output.\nThe above examples can be written and executed more efficiently in a vectorized form. Generating the output We‚Äôll vectorize by stacking examples side-by-side, so that our input matrix \\(X\\) has an example in each column. The vectorized form of the forward pass is then\n\\[\\begin{equation*}\n\\hat{y} = \\sigma(w^{\\rm T} X + b)\\ .\n\\end{equation*}\\]\nNote that \\(\\hat{y}\\) is now a vector, not a scalar as it was in the previous equation.\nIn our code we will compute this in two stages: Z = np.matmul(W.T, X) + b and then A = sigmoid(Z) (A for Activation). Breaking things up into stages like this is just for clarity - It will make our forward pass computations mirror the steps in our backward propagation computation.\n\n\nLoss Function\nSince we have now data and we also know how to propagate (at least in principle) the input through the single neuron here, we also need to define a measure for how far the output deviates from the input. This measure is called loss. The many different ways of defining a suitable loss. The mean squared error, as it appeared already during our fitting lecture, could be a suitable loss function\n\\[\\begin{equation}\nMSE(y,\\hat{y})=\\frac{1}{n}\\sum_{i=1}^{n}(y-\\hat{y})^2\n\\end{equation}\\]\nfor a number of \\(n\\) datasets. Here \\(\\hat{y}\\) is the data that is predicted by the network and \\(y\\) is the value which represents the so called ground truth, i.e.¬†the data provided by the training set.\nWe will not use the mean squared error bu the cross-entropy for our loss function. The formula for a single training example (one input image) is:\n\\[\\begin{equation*}\nL(y,\\hat{y}) = -y\\log(\\hat{y})-(1-y)\\log(1-\\hat{y})\\ .\n\\end{equation*}\\]\nThis error definition comes from the Shannon entropy definition, which you may look up in the web if you are interested. Averaging over a training set of \\(m\\) examples we then have:\n\\[\\begin{equation*}\nL(Y,\\hat{Y}) = -\\frac{1}{m}\\sum_{i = 0}^{m}y^{(i)}\\log(\\hat{y}^{(i)})-(1-y^{(i)})\\log(1-\\hat{y}^{(i)})\\ .\n\\end{equation*}\\]\nIn Python code, this looks like\n\ndef compute_loss(Y, Y_hat):\n    m = Y.shape[1]\n    L = -(1./m)*(np.sum(np.multiply(np.log(Y_hat), Y)) + np.sum(np.multiply(np.log(1 - Y_hat), (1 - Y))))\n    return L"
  },
  {
    "objectID": "seminars/seminar10/1_deep_learning.html#trainging-the-network",
    "href": "seminars/seminar10/1_deep_learning.html#trainging-the-network",
    "title": "Neural Networks",
    "section": "Trainging the Network",
    "text": "Trainging the Network\nThe goal of all neural network training procedures is to minimize the loss and we have to find a way to minimize that loss. This is not so much different from our fitting of function values before.\n\nBackward Propagation\nThe output of the network is determined by the input values and how we have distributed the weights \\(w\\) and the biases \\(b\\). We can write the loss function therefore as a function of the weights and losses\n\\[\nL(w_{1},w_{2},w_{3},\\ldots ,b_{1},b_{2},b_{3},\\ldots)\n\\]\nTo train the network, we would now try to find out, by how much the output values change if we do change a specific weight \\(w_j\\). This can be expressed by the partial derivative\n\\[\n\\frac{\\partial L}{\\partial w_j}\n\\]\nWe may then take a tiny step and correct the current value of \\(w_j\\) such that the network yields a new output. This way back from the current output of the network and its current loss to a correction of the weights to yield a smaller loss is called back propagation.\nCalculating derivatives\nFocusing on a single input image will make it easier to derive the formulas we need. Holding all values except \\(w_j\\) fixed, we can think of \\(L\\) as being computed in three steps: \\(w_j\\rightarrow z \\rightarrow \\hat{y} \\rightarrow L\\). The formulas for these steps are: \\[\\begin{align*}\nz &= w^{\\rm T} x + b\\ , \\\\\n\\hat{y} &= \\sigma(z)\\ , \\\\\nL(y,\\hat{y}) &= -y\\log(\\hat{y})-(1-y)\\log(1-\\hat{y})\\ .\n\\end{align*}\\]\nThe change of the loss function with the weights can then be split up by the chain rule into\n\\[\\begin{align*}\n\\frac{\\partial L}{\\partial w_j} = \\frac{\\partial L}{\\partial \\hat{y}}\\frac{\\partial \\hat{y}}{\\partial z}\\frac{\\partial z}{\\partial w_j}\n\\end{align*}\\] \nThere we have a product of three individual partial derivatives, which are a bit tedius to write down, but not to complicated. The read like\n\\(\\partial L/\\partial\\hat{y}\\): \\[\\begin{align*}\n\\frac{\\partial L}{\\partial\\hat{y}} &= \\frac{\\partial}{\\partial\\hat{y}}\\left(-y\\log(\\hat{y})-(1-y)\\log(1-\\hat{y})\\right) \\\\\n&= -y\\frac{\\partial}{\\partial\\hat{y}}\\log(\\hat{y})-(1-y)\\frac{\\partial}{\\partial\\hat{y}}\\log(1-\\hat{y}) \\\\\n&= -\\frac{y}{\\hat{y}} +\\frac{(1 - y)}{1-\\hat{y}} \\\\\n&= \\frac{\\hat{y} - y}{\\hat{y}(1-\\hat{y})}\n\\end{align*}\\]\n\\(\\partial \\hat{y}/\\partial z\\): \\[\\begin{align*}\n\\frac{\\partial }{\\partial z}\\sigma(z)\n&= \\frac{\\partial }{\\partial z}\\left(\\frac{1}{1 + {\\rm e}^{-z}}\\right) \\\\\n&= \\frac{1}{(1 + {\\rm e}^{-z})^2}\\frac{\\partial }{\\partial z}(1 + {\\rm e}^{-z}) \\\\\n&= \\frac{{\\rm e}^{-z}}{(1 + {\\rm e}^{-z})^2} \\\\\n&= \\frac{1}{1 + {\\rm e}^{-z}}\\frac{{\\rm e}^{-z}}{1 + {\\rm e}^{-z}} \\\\\n&= \\frac{1}{1 + {\\rm e}^{-z}}\\left(1 - \\frac{1}{1 + {\\rm e}^{-z}}\\right) \\\\\n&= \\sigma(z)(1-\\sigma(z)) \\\\\n&= \\hat{y}(1-\\hat{y})\n\\end{align*}\\]\n\\(\\partial z/\\partial w_j\\): \\[\\begin{align*}\n\\frac{\\partial }{\\partial w_j}(w^{\\rm T} x + b) &= \\frac{\\partial }{\\partial w_j}(w_0x_0 + \\dots + w_nx_n + b) \\\\\n&= x_j\n\\end{align*}\\]\nSubstituting back into the chain rule yields: \\[\\begin{align*}\n\\frac{\\partial L}{\\partial w_j}\n&= \\frac{\\partial L}{\\partial \\hat{y}}\\frac{\\partial \\hat{y}}{\\partial z}\\frac{\\partial z}{\\partial w_j} \\\\\n&= \\frac{\\hat{y} - y}{\\hat{y}(1-\\hat{y})}\\hat{y}(1-\\hat{y}) x_j \\\\\n&= (\\hat{y} - y)x_j\\ .\n\\end{align*}\\]\nwhich does not look that unfriendly anymore.\nIn vectorized form with \\(m\\) training examples this gives us \\[\\begin{align*}\n\\frac{\\partial L}{\\partial w} = \\frac{1}{m} X(\\hat{y} - y)^{\\rm T}\\ .\n\\end{align*}\\]\nA very similar derivation of \\(\\partial L/\\partial b\\) yields, for a single example: \\[\\begin{align*}\n\\frac{\\partial L}{\\partial b} = (\\hat{y} - y)\\ .\n\\end{align*}\\]\nIn vectorized form we get \\[\\begin{align*}\n\\frac{\\partial L}{\\partial b} = \\frac{1}{m}\\sum_{i=1}^{m}{(\\hat{y}^{(i)} - y^{(i)})}\\ .\n\\end{align*}\\]\nIn our code we label these gradients according to their denominators, as dW and db. So for backpropagation we compute dW = (1/m) * np.matmul(X, (A-Y).T) and db = (1/m)*np.sum(A-Y, axis=1, keepdims=True).\n\n\nStochastic Gradient Descent\nWe have all the tools we need to train a neural network now! We‚Äôll use an optimization algorithm called stochastic gradient descent (SGD) that tells us how to change our weights and biases to minimize loss. It is a simple umpdate of the weights and biases, which would read for the weights like\n\\[\nw\\leftarrow w-\\eta\\frac{\\partial L}{\\partial w}\n\\]\nwhere \\(\\eta\\) is a constant called the learning rate that controls how fast we train. All we‚Äôre doing is subtracting \\(\\eta \\partial L/\\partial w\\) from \\(w\\)\n\nIf \\(\\partial L/\\partial w\\) is positive, \\(w\\) will decrease, which makes L decrease.\nIf \\(\\partial L/\\partial w\\) is negative, \\(w\\) will increase, which makes L decrease.\n\nThe equations look equivalent for the bias \\(b\\). Our back propagation procedure will do that for as many steps we want, i.e.¬†until we feel that the output is close enough to the ground truth. Each back propagation step is called and epoch.\n\n\nBuild an Train\nNow we have all things together to create a single neuron network doing the analysis of the MNIST numbers. This type of data processing is called logistic regression based on the sigmoid function, which is a logistic function. So let‚Äôs create all in python code and train the network for 100 epochs.\n\nlearning_rate = 1\n\nX = np.array(X_train)\nY = np.array(y_train)\n\nn_x = X.shape[0]\nm = X.shape[1]\n\nW = np.random.randn(n_x, 1) * 0.01\nb = np.zeros((1, 1))\n\nfor i in range(200):\n    Z = np.matmul(W.T, X) + b\n    A = sigmoid(Z)\n\n    loss = compute_loss(Y, A)\n\n    dW = (1/m)*np.matmul(X, (A-Y).T)\n    db = (1/m)*np.sum(A-Y, axis=1, keepdims=True)\n\n    W = W - learning_rate * dW\n    b = b - learning_rate * db\n\n    if i % 10 == 0:\n        print(\"Epoch\", i, \" loss: \", loss)\n\nprint(\"Final loss:\", loss)\n\nEpoch 0  loss:  0.7471125121616977\nEpoch 10  loss:  0.07308269582929021\nEpoch 20  loss:  0.06131832354627721\nEpoch 30  loss:  0.05523011981200572\nEpoch 40  loss:  0.0513243202361425\nEpoch 50  loss:  0.04854004196371184\nEpoch 60  loss:  0.04642485272904433\nEpoch 70  loss:  0.04474722082574825\nEpoch 80  loss:  0.043374333931969114\nEpoch 90  loss:  0.04222371551840797\nEpoch 100  loss:  0.04124104599832092\nEpoch 110  loss:  0.04038888651110667\nEpoch 120  loss:  0.03964048057966332\nEpoch 130  loss:  0.0389761317586134\nEpoch 140  loss:  0.038380979206568466\nEpoch 150  loss:  0.03784357458020544\nEpoch 160  loss:  0.03735493964481513\nEpoch 170  loss:  0.03690792357698068\nEpoch 180  loss:  0.03649675336766015\nEpoch 190  loss:  0.036116712255247\nFinal loss: 0.03579805734492837\n\n\nWe do not really now how to judge the quality of our trained network. At least we saw that the loss is decreasing, which is good. We may judge the quality of our trained network by calculating the so-called confusion matrix. The confusion matrix is creating a matrix giving reports the actual values in the rows and the predicted values in the columns.\n\n\n\nconfusion_matrix\n\n\nThe entries in the matrix are called true positives (TP), false positives (FP), false negatives (FN), and true negatives (TN). Fortunately we can use a method of the sklearn module to calculate the confusion matrix. We just have to supply the predictions and the actual labels to it. To do so, we use the testing data set X_test which we have splitted earlier.\n\nfrom sklearn.metrics import confusion_matrix, classification_report\n\nZ = np.matmul(W.T,X_test) + b\nA = sigmoid(Z)\n\npredictions = (A&gt;.5)[0,:]\nlabels = (y_test == 1)[0,:]\n\nprint(confusion_matrix(predictions, labels))\n\n[[8973   33]\n [  47  947]]\n\n\n\nprint(classification_report(predictions, labels))\n\n              precision    recall  f1-score   support\n\n       False       0.99      1.00      1.00      9006\n        True       0.97      0.95      0.96       994\n\n    accuracy                           0.99     10000\n   macro avg       0.98      0.97      0.98     10000\nweighted avg       0.99      0.99      0.99     10000\n\n\n\n\n\nTesting our model\nWe can check a single image of our testing data with the following line. If the output number is bigger than 0.5, our number is likely a 0.\n\ni=200\nbool(sigmoid(np.matmul(W.T, np.array(X_test)[:,i])+b)&gt;0.5)\n\nFalse\n\n\n\nplt.imshow(np.array(X_test)[:,i].reshape(28,28),cmap='gray')"
  },
  {
    "objectID": "seminars/seminar10/1_deep_learning.html#network-with-hidden-layers",
    "href": "seminars/seminar10/1_deep_learning.html#network-with-hidden-layers",
    "title": "Neural Networks",
    "section": "Network with Hidden Layers",
    "text": "Network with Hidden Layers\nIn our example above, we just had an input layer and a single output neuron. More complex neural networks are containing many layers between the input layer and the output layer. These inbetween layers are called hidden layers. Here is a simple example of a neural network with a single hidden layer.\n\n\n\nhidden\n\n\nSo we have now and input layer with 784 inputs that are connected to 64 units in the hidden layer and 1 neuron in the output layer. We will not go through the derivations of all the formulas for the forward and backward passes this time. The code is a simple extension of what we did before and I hope easy to read.\n\nX = X_train\nY = y_train\n\nn_x = X.shape[0]\nn_h = 64\nlearning_rate = 1\n\nW1 = np.random.randn(n_h, n_x)\nb1 = np.zeros((n_h, 1))\nW2 = np.random.randn(1, n_h)\nb2 = np.zeros((1, 1))\n\nfor i in range(100):\n\n    Z1 = np.matmul(W1, X) + b1\n    A1 = sigmoid(Z1)\n    Z2 = np.matmul(W2, A1) + b2\n    A2 = sigmoid(Z2)\n\n    loss = compute_loss(Y, A2)\n\n    dZ2 = A2-Y\n    dW2 = (1./m) * np.matmul(dZ2, A1.T)\n    db2 = (1./m) * np.sum(dZ2, axis=1, keepdims=True)\n\n    dA1 = np.matmul(W2.T, dZ2)\n    dZ1 = dA1 * sigmoid(Z1) * (1 - sigmoid(Z1))\n    dW1 = (1./m) * np.matmul(dZ1, X.T)\n    db1 = (1./m) * np.sum(dZ1, axis=1, keepdims=True)\n\n    W2 = W2 - learning_rate * dW2\n    b2 = b2 - learning_rate * db2\n    W1 = W1 - learning_rate * dW1\n    b1 = b1 - learning_rate * db1\n\n    if i % 10 == 0:\n        print(\"Epoch\", i, \"loss: \", loss)\n\nprint(\"Final loss:\", loss)\n\nEpoch 0 loss:  2.395166635058746\nEpoch 10 loss:  0.22074168759268953\nEpoch 20 loss:  0.1660154822272753\nEpoch 30 loss:  0.13990677867922952\nEpoch 40 loss:  0.12390102523919129\nEpoch 50 loss:  0.11269161497108851\nEpoch 60 loss:  0.10421329497723456\nEpoch 70 loss:  0.09747959072905935\nEpoch 80 loss:  0.09194898313097832\nEpoch 90 loss:  0.0872943606401609\nFinal loss: 0.08367740628296327\n\n\nTo judge the newtork quality we do use again the confusion matrix.\n\nZ1 = np.matmul(W1, X_test) + b1\nA1 = sigmoid(Z1)\nZ2 = np.matmul(W2, A1) + b2\nA2 = sigmoid(Z2)\n\npredictions = (A2&gt;.5)[0,:]\nlabels = (y_test == 1)[0,:]\n\nprint(confusion_matrix(predictions, labels))\nprint(classification_report(predictions, labels))\n\n[[8905  178]\n [ 115  802]]\n              precision    recall  f1-score   support\n\n       False       0.99      0.98      0.98      9083\n        True       0.82      0.87      0.85       917\n\n    accuracy                           0.97     10000\n   macro avg       0.90      0.93      0.91     10000\nweighted avg       0.97      0.97      0.97     10000"
  },
  {
    "objectID": "seminars/seminar10/1_deep_learning.html#multiclass-network",
    "href": "seminars/seminar10/1_deep_learning.html#multiclass-network",
    "title": "Neural Networks",
    "section": "Multiclass Network",
    "text": "Multiclass Network\nSo far we did only classify if the number we feed to the network is just a 0 or not. We would like to recognize the different number now and therefore need a multiclass network. Each number is then a class and per class, we have multiple realizations of handwritten numbers. We therefore have to create an output layer, which is not only containing a single neuron, but 10 neurons. Each of these neuron can output a value between 0 and 1. Whenever the output is 1, the index of the neuron represents the number predicted.\nThe output array\n[0,1,0,0,0,0,0,0,0,0]\nwould therefore correspond to the value 1.\nFor this purpose, we need to reload the right labels.\n\nfrom sklearn.datasets import fetch_openml\nX, y = fetch_openml('mnist_784', version=1, return_X_y=True,as_frame=False)\n\nX = X / 255\n\nThen we‚Äôll one-hot encode MNIST‚Äôs labels, to get a 10 x 70,000 array.\n\ndigits = 10\nexamples = y.shape[0]\n\ny = y.reshape(1, examples)\n\nY_new = np.eye(digits)[y.astype('int32')]\nY_new = Y_new.T.reshape(digits, examples)\n\n\nY_new.shape\n\n(10, 70000)\n\n\nWe also seperate into trainging and testing data\n\nm = 60000\nm_test = X.shape[0] - m\n\nX_train, X_test = X[:m].T, X[m:].T\nY_train, Y_test = Y_new[:,:m], Y_new[:,m:]\n\nshuffle_index = np.random.permutation(m)\nX_train, Y_train = X_train[:, shuffle_index], Y_train[:, shuffle_index]\n\n\ni = 58\nplt.imshow(X_train[:,i].reshape(28,28), cmap='gray')\nplt.colorbar()\nplt.show()\nY_train[:,i]\n\n\n\n\n\n\n\n\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])\n\n\n\nChanges to the model\nOK, so let‚Äôs consider what changes we need to make to the model itself.\n\nForward Pass\nOnly the last layer of our network is changing. To add the softmax, we have to replace our lone, final node with a 10 unit layer. Its final activations are the exponentials of its z-values, normalized across all ten such exponentials. So instead of just computing \\(\\sigma(z)\\), we compute the activation for each unit \\(i\\) using the softmax function: \\[\\begin{align*}\n\\sigma(z)_i = \\frac{{\\rm e}^{z_i}}{\\sum_{j=0}^9{\\rm e}^{z_i}}\\ .\n\\end{align*}\\]\nSo, in our vectorized code, the last line of forward propagation will be A2 = np.exp(Z2) / np.sum(np.exp(Z2), axis=0).\n\n\nLoss Function\nOur loss function now has to generalize to more than two classes. The general formula for \\(n\\) classes is: \\[\\begin{align*}\nL(y,\\hat{y}) = -\\sum_{i=0}^n y_i\\log(\\hat{y}_i)\\ .\n\\end{align*}\\] Averaging over \\(m\\) training examples this becomes: \\[\\begin{align*}\nL(y,\\hat{y}) = -\\frac{1}{m}\\sum_{j=0}^m\\sum_{i=0}^n y_i^{(i)}\\log(\\hat{y}_i^{(i)})\\ .\n\\end{align*}\\]\nSo let‚Äôs define:\n\ndef compute_multiclass_loss(Y, Y_hat):\n    L_sum = np.sum(np.multiply(Y, np.log(Y_hat)))\n    m = Y.shape[1]\n    L = -(1/m) * L_sum\n    return L\n\n\n\nBack Propagation\nLuckily it turns out that back propagation isn‚Äôt really affected by the switch to a softmax. A softmax generalizes the sigmoid activiation we‚Äôve been using, and in such a way that the code we wrote earlier still works. We could verify this by deriving: \\[\\begin{align*}\n\\frac{\\partial L}{\\partial z_i} = \\hat{y}_i - y_i\\ .\n\\end{align*}\\]\nBut we won‚Äôt walk through the steps here. Let‚Äôs just go ahead and build our final network.\n\n\n\nBuild and Train\nAs we have now more weights and classes, the training takes longer and we actually need also more episodes to achieve a good accuracy.\n\nn_x = X_train.shape[0]\nn_h = 64\nlearning_rate = 1\n\nW1 = np.random.randn(n_h, n_x)\nb1 = np.zeros((n_h, 1))\nW2 = np.random.randn(digits, n_h)\nb2 = np.zeros((digits, 1))\n\nX = X_train\nY = Y_train\n\nfor i in range(200):\n\n    Z1 = np.matmul(W1,X) + b1\n    A1 = sigmoid(Z1)\n    Z2 = np.matmul(W2,A1) + b2\n    A2 = np.exp(Z2) / np.sum(np.exp(Z2), axis=0)\n\n    loss = compute_multiclass_loss(Y, A2)\n\n    dZ2 = A2-Y\n    dW2 = (1./m) * np.matmul(dZ2, A1.T)\n    db2 = (1./m) * np.sum(dZ2, axis=1, keepdims=True)\n\n    dA1 = np.matmul(W2.T, dZ2)\n    dZ1 = dA1 * sigmoid(Z1) * (1 - sigmoid(Z1))\n    dW1 = (1./m) * np.matmul(dZ1, X.T)\n    db1 = (1./m) * np.sum(dZ1, axis=1, keepdims=True)\n\n    W2 = W2 - learning_rate * dW2\n    b2 = b2 - learning_rate * db2\n    W1 = W1 - learning_rate * dW1\n    b1 = b1 - learning_rate * db1\n\n    if (i % 10 == 0):\n        print(\"Epoch\", i, \"loss: \", loss)\n\nprint(\"Final loss:\", loss)\n\nEpoch 0 loss:  9.359409945262723\nEpoch 10 loss:  2.480915410750769\nEpoch 20 loss:  1.674432764227767\nEpoch 30 loss:  1.3330104308788548\nEpoch 40 loss:  1.1447842302497118\nEpoch 50 loss:  1.0230964725181804\nEpoch 60 loss:  0.9368747323694273\nEpoch 70 loss:  0.871957389404843\nEpoch 80 loss:  0.8208795576102073\nEpoch 90 loss:  0.7793325725168161\nEpoch 100 loss:  0.7446649543545801\nEpoch 110 loss:  0.7151537041535516\nEpoch 120 loss:  0.6896258244540621\nEpoch 130 loss:  0.6672519100025255\nEpoch 140 loss:  0.6474268213495038\nEpoch 150 loss:  0.6296970416913454\nEpoch 160 loss:  0.6137147676333653\nEpoch 170 loss:  0.5992079750548168\nEpoch 180 loss:  0.5859603076597457\nEpoch 190 loss:  0.5737971945414019\nFinal loss: 0.5636592880338959\n\n\nLet‚Äôs see how we did:\n\nZ1 = np.matmul(W1, X_test) + b1\nA1 = sigmoid(Z1)\nZ2 = np.matmul(W2, A1) + b2\nA2 = np.exp(Z2) / np.sum(np.exp(Z2), axis=0)\n\npredictions = np.argmax(A2, axis=0)\nlabels = np.argmax(Y_test, axis=0)\n\n\nModel performance\n\nprint(confusion_matrix(predictions, labels))\nprint(classification_report(predictions, labels))\n\n[[ 896    0   26    8    8   22   30    4   14   10]\n [   0 1076   15    6    2    7    3    6   14    2]\n [  14   13  815   30   10   13   23   33   24   13]\n [  10   12   47  820    4   60    5   18   40   17]\n [   0    1   17    0  790   22   30   17   14  106]\n [  27    4    7   56    5  669   23    6   58   16]\n [  13    5   30    7   23   28  822    0   21    1]\n [   6    2   18   25   12   10    3  866   18   37]\n [  12   22   47   42   19   44   16   15  739   28]\n [   2    0   10   16  109   17    3   63   32  779]]\n              precision    recall  f1-score   support\n\n           0       0.91      0.88      0.90      1018\n           1       0.95      0.95      0.95      1131\n           2       0.79      0.82      0.81       988\n           3       0.81      0.79      0.80      1033\n           4       0.80      0.79      0.80       997\n           5       0.75      0.77      0.76       871\n           6       0.86      0.87      0.86       950\n           7       0.84      0.87      0.86       997\n           8       0.76      0.75      0.75       984\n           9       0.77      0.76      0.76      1031\n\n    accuracy                           0.83     10000\n   macro avg       0.82      0.83      0.82     10000\nweighted avg       0.83      0.83      0.83     10000\n\n\n\nWe are at 84% accuray across all digits, which could be of course better. We may now plot image and the corresponding prediction."
  },
  {
    "objectID": "seminars/seminar10/1_deep_learning.html#test-the-model",
    "href": "seminars/seminar10/1_deep_learning.html#test-the-model",
    "title": "Neural Networks",
    "section": "Test the model",
    "text": "Test the model\n\ni=2003\nplt.imshow(X_test[:,i].reshape(28,28), cmap='gray')\npredictions[i]\n\nnp.int64(5)"
  },
  {
    "objectID": "seminars/seminar10/seminar10.html#what-are-neural-networks",
    "href": "seminars/seminar10/seminar10.html#what-are-neural-networks",
    "title": "Neural Networks",
    "section": "What are Neural Networks?",
    "text": "What are Neural Networks?\nNeural networks are computational models inspired by how our brains process information. Just like our brain consists of interconnected neurons that process and transmit signals, artificial neural networks consist of mathematical ‚Äúneurons‚Äù that process numerical information. They‚Äôre particularly powerful for:\n\nRecognizing patterns in data\nMaking predictions\nClassifying information\nSolving complex problems"
  },
  {
    "objectID": "seminars/seminar10/seminar10.html#why-neural-networks-in-physics",
    "href": "seminars/seminar10/seminar10.html#why-neural-networks-in-physics",
    "title": "Neural Networks",
    "section": "Why Neural Networks in Physics?",
    "text": "Why Neural Networks in Physics?\nIn physics, we often encounter situations that push the boundaries of traditional approaches. Sometimes the mathematical models grow too complex to solve directly, while in other cases we face the challenge of analyzing vast amounts of experimental data. We frequently need to make predictions even when we have incomplete information about a system. These scenarios represent key areas where neural networks can provide valuable solutions.\nNeural networks help us with these challenges! Some real-world applications include:\n\nParticle physics: Identifying particles in detector data\nAstronomy: Classifying galaxies\nMaterials science: Predicting material properties\nQuantum mechanics: Solving many-body problems\nBiological physics: Modeling neural activity\nActive matter: Predicting collective behavior"
  },
  {
    "objectID": "seminars/seminar10/seminar10.html#data-for-neural-networks-teaching-computers-to-read-numbers",
    "href": "seminars/seminar10/seminar10.html#data-for-neural-networks-teaching-computers-to-read-numbers",
    "title": "Neural Networks",
    "section": "Data for Neural Networks: Teaching Computers to Read Numbers",
    "text": "Data for Neural Networks: Teaching Computers to Read Numbers\nLet‚Äôs start our journey into neural networks with an exciting challenge: teaching a computer to read handwritten numbers! We‚Äôll build this step by step using Python, starting with the basics and working our way up to something quite impressive.\nThink of this like teaching a child to recognize numbers - we‚Äôll start by teaching our computer to recognize just one number (zero), and then build up to recognizing all digits from 0 to 9.\n\n\n\nMNIS\n\n\nWe‚Äôll use a famous collection of handwritten numbers called the MNIST dataset. Imagine asking 70,000 different people to write down numbers - that‚Äôs what this dataset is! Each number is written on a small 28 x 28 grid (like graph paper), where each square (or pixel) is shaded in grayscale from white (0) to black (255)."
  },
  {
    "objectID": "seminars/seminar10/seminar10.html#getting-started-with-mnist",
    "href": "seminars/seminar10/seminar10.html#getting-started-with-mnist",
    "title": "Neural Networks",
    "section": "Getting Started with MNIST",
    "text": "Getting Started with MNIST\nJust like we need data from experiments in physics, we need data to train our neural network. Fortunately, other scientists have already collected this data for us:\n\nLoading Our Training Data\n\n\n\n\n\n\nHere, X contains all our images, and y contains the correct answer for each image (which number it is). Let‚Äôs look at one:\n\n\n\n\n\n\n\n\nMaking the Data Easier to Work With\nJust like we often normalize measurements in physics experiments (like dividing by the maximum value), we‚Äôll normalize our image data to be between 0 and 1:\n\n\n\n\n\n\n\n\nPreparing Our Training and Testing Sets\nFor now, we‚Äôll start simple: we‚Äôll just teach our network to recognize zeros. We‚Äôll mark zeros with a 1 and all other numbers with a 0:\n\n\n\n\n\n\nLike any good scientific experiment, we need both training data (to teach the network) and testing data (to check how well it learned). We‚Äôll use: - 60,000 images for training - 10,000 images for testing\n\n\n\n\n\n\nFinally, we shuffle our training data (like shuffling flashcards when studying):\n\n\n\n\n\n\nLet‚Äôs check our work by looking at one of our training images:\n\n\n\n\n\n\nTry looking at different images (change the number 39 above) until you find a zero - its label should be 1!"
  },
  {
    "objectID": "seminars/seminar10/seminar10.html#a-single-neuron",
    "href": "seminars/seminar10/seminar10.html#a-single-neuron",
    "title": "Neural Networks",
    "section": "A Single Neuron",
    "text": "A Single Neuron\nThe basic building block of any neural network is an artificial neuron. Similar to neurons in the human brain that process incoming signals and decide whether to fire or not, an artificial neuron processes numerical inputs through mathematical operations to produce a single output value. The following diagram shows a simple artificial neuron with two input values:\n\n\nUnderstanding Forward Propagation\nAn artificial neuron processes information in three distinct steps that together form what is called forward propagation:\n\nInput Weighting Each input value gets multiplied by a weight parameter. These weights determine how much influence each input has on the final output, similar to how synapses in biological neurons can be stronger or weaker. For two inputs, this operation looks like:\n\n\\[\\begin{eqnarray}\nx_{1}\\rightarrow x_{1} w_{1}\\\\\nx_{2}\\rightarrow x_{2} w_{2}\n\\end{eqnarray}\\]\n\nBias Addition After weighting the inputs, a bias value \\(b\\) is added to the sum. The bias helps the neuron learn by shifting the weighted sum up or down, making it easier or harder for the neuron to produce a strong output signal:\n\n\\[\\begin{equation}\nx_{1} w_{1}+ x_{2} w_{2}+b\n\\end{equation}\\]\n\nActivation Function The final step applies an activation function \\(\\sigma()\\) to the weighted sum plus bias. This function introduces non-linearity into the network, allowing it to learn complex patterns:\n\n\\[\\begin{equation}\ny=\\sigma( x_{1} w_{1}+ x_{2} w_{2}+b)\n\\end{equation}\\]\nThe activation function used in this example is called the sigmoid function. This function is particularly useful because it takes any input number (positive or negative, large or small) and transforms it into an output between 0 and 1. This property makes the sigmoid function ideal for tasks where the output should represent a probability or a binary decision.\nFor mathematical convenience, the above steps can be written more compactly using vector notation:\n\\[\\begin{equation*}\n\\hat{y} = \\sigma(w^{\\rm T} x + b)\\ .\n\\end{equation*}\\]\nThe sigmoid function has the following mathematical form: \\[\\begin{equation*}\n\\sigma(z) = \\frac{1}{1+{\\rm e}^{-z}}\\ .\n\\end{equation*}\\]\nHere is a Python implementation of the sigmoid function:\n\n\n\n\n\n\nThe following code visualizes how the sigmoid function transforms input values:\n\n\n\n\n\n\nTo understand how these components work together, consider a simple example with two inputs. Given:\n\\[\\begin{eqnarray}\nw=[0,1]\\\\\nb=4\n\\end{eqnarray}\\]\nAnd input values:\n\\[\\begin{eqnarray}\nx=[2,3]\n\\end{eqnarray}\\]\nThe computation becomes:\n\\[\\begin{equation}\ny=f(w\\cdot x+b)=f(7)=0.999\n\\end{equation}\\]\nThis process of moving from inputs to output through these mathematical operations is called forward propagation. The goal is to extend this concept to create a network capable of processing images, which requires 784 inputs (one for each pixel in a 28 x 28 image) and producing meaningful outputs.\nFor computational efficiency, these calculations can be performed on multiple inputs simultaneously using matrix operations. The forward pass equation becomes:\n\\[\\begin{equation*}\n\\hat{y} = \\sigma(w^{\\rm T} X + b)\\ .\n\\end{equation*}\\]\nIn this matrix form, \\(\\hat{y}\\) represents a vector of outputs rather than a single value. The implementation splits this computation into two parts:\n\nCalculate the weighted sum: Z = np.matmul(W.T, X) + b\nApply the activation function: A = sigmoid(Z)\n\nThis separation into distinct steps makes the code clearer and prepares for the more complex calculations needed in the backward propagation phase.\n\n\nLoss Function: Measuring How Wrong We Are\nNow that our network can make predictions, we need a way to measure how accurate those predictions are. Just like we measure error in physics experiments, we need to measure the error (or ‚Äúloss‚Äù) in our neural network‚Äôs predictions.\nThe simplest way would be to use mean squared error, which you‚Äôve seen before in data fitting:\n\\[\\begin{equation}\nMSE(y,\\hat{y})=\\frac{1}{n}\\sum_{i=1}^{n}(y-\\hat{y})^2\n\\end{equation}\\]\nHere, \\(y\\) is the true value (what we know is correct) and \\(\\hat{y}\\) is our network‚Äôs prediction.\nHowever, for this type of classification problem, we‚Äôll use a different measure called cross-entropy. For a single training example, it looks like this:\n\\[\\begin{equation*}\nL(y,\\hat{y}) = -y\\log(\\hat{y})-(1-y)\\log(1-\\hat{y})\\ .\n\\end{equation*}\\]\nWhen we have many training examples (\\(m\\) of them), we take the average:\n\\[\\begin{equation*}\nL(Y,\\hat{Y}) = -\\frac{1}{m}\\sum_{i = 0}^{m}y^{(i)}\\log(\\hat{y}^{(i)})-(1-y^{(i)})\\log(1-\\hat{y}^{(i)})\\ .\n\\end{equation*}\\]\nHere‚Äôs how we implement this in code:"
  },
  {
    "objectID": "seminars/seminar10/seminar10.html#training-the-network-making-our-network-learn",
    "href": "seminars/seminar10/seminar10.html#training-the-network-making-our-network-learn",
    "title": "Neural Networks",
    "section": "Training the Network: Making Our Network Learn",
    "text": "Training the Network: Making Our Network Learn\nThink of training a neural network like teaching a student - we need to: 1. See how well they‚Äôre doing (measure the loss) 2. Give feedback on what to improve 3. Let them practice and improve\n\nBackward Propagation: Learning from Mistakes\nJust like we adjust our aim when throwing a ball based on how far we missed, our network needs to adjust its weights and biases based on its errors. The loss function depends on all our weights and biases:\n\\[\nL(w_{1},w_{2},w_{3},\\ldots ,b_{1},b_{2},b_{3},\\ldots)\n\\]\nTo improve, we need to know how changing each weight affects our error. We can find this using partial derivatives:\n\\[\n\\frac{\\partial L}{\\partial w_j}\n\\]\nThis tells us ‚Äúif we change weight \\(w_j\\) a little bit, how much will our error change?‚Äù This process of calculating how to adjust weights based on errors is called back propagation.\nCalculating How to Improve\nLet‚Äôs break this down into steps. For a single image, we can follow how changes flow through the network: \\[\\begin{align*}\nz &= w^{\\rm T} x + b\\ , \\\\\n\\hat{y} &= \\sigma(z)\\ , \\\\\nL(y,\\hat{y}) &= -y\\log(\\hat{y})-(1-y)\\log(1-\\hat{y})\\ .\n\\end{align*}\\]\nUsing the chain rule from calculus:\n\\[\\begin{align*}\n\\frac{\\partial L}{\\partial w_j} = \\frac{\\partial L}{\\partial \\hat{y}}\\frac{\\partial \\hat{y}}{\\partial z}\\frac{\\partial z}{\\partial w_j}\n\\end{align*}\\] \nAfter working through the calculus (which we won‚Äôt detail here), we get three parts, each representing how different components of our network affect the final loss:\nFirst, we calculate how the loss changes with respect to our prediction (\\(\\hat{y}\\)):\n\\(\\partial L/\\partial\\hat{y}\\): \\[\\begin{align*}\n\\frac{\\partial L}{\\partial\\hat{y}} &= \\frac{\\hat{y} - y}{\\hat{y}(1-\\hat{y})}\n\\end{align*}\\]\nNext, we find how our prediction changes with respect to the weighted input (\\(z\\)). This is just the derivative of the sigmoid function:\n\\(\\partial \\hat{y}/\\partial z\\): \\[\\begin{align*}\n\\frac{\\partial }{\\partial z}\\sigma(z) &= \\hat{y}(1-\\hat{y})\n\\end{align*}\\]\nFinally, we calculate how the weighted input changes with respect to each weight. This is simply the corresponding input value:\n\\(\\partial z/\\partial w_j\\): \\[\\begin{align*}\n\\frac{\\partial }{\\partial w_j}(w^{\\rm T} x + b) &= x_j\n\\end{align*}\\]\nWhen we multiply these three components together using the chain rule, something remarkable happens - most terms cancel out, leaving us with this elegantly simple result: \\[\\begin{align*}\n\\frac{\\partial L}{\\partial w_j} = (\\hat{y} - y)x_j\\ .\n\\end{align*}\\]\nThis tells us that the adjustment to each weight should be proportional to both the prediction error (\\(\\hat{y} - y\\)) and the input value (\\(x_j\\)).\nWhen dealing with multiple training examples, we need to average these gradients:\n\\[\\begin{align*}\n\\frac{\\partial L}{\\partial w} = \\frac{1}{m} X(\\hat{y} - y)^{\\rm T}\\ .\n\\end{align*}\\]\nThe bias term follows a similar pattern. For a single example: \\[\\begin{align*}\n\\frac{\\partial L}{\\partial b} = (\\hat{y} - y)\\ .\n\\end{align*}\\]\nAnd for multiple training examples, we average the gradients: \\[\\begin{align*}\n\\frac{\\partial L}{\\partial b} = \\frac{1}{m}\\sum_{i=1}^{m}{(\\hat{y}^{(i)} - y^{(i)})}\\ .\n\\end{align*}\\]\nIn our code, these mathematical formulas translate directly into matrix operations: dW = (1/m) * np.matmul(X, (A-Y).T) and db = (1/m)*np.sum(A-Y, axis=1, keepdims=True).\n\n\nStochastic Gradient Descent: Teaching Our Network to Learn\nNow comes the exciting part - making our network learn! Just like how you adjust your throw when playing catch based on whether you threw too far or too short, our network needs to adjust its weights and biases based on its mistakes.\nWe‚Äôll use a learning method called stochastic gradient descent (SGD). Don‚Äôt let the fancy name scare you - it‚Äôs actually quite simple! Think of it like walking down a hill:\n\nLook around to see which way is steepest downhill (that‚Äôs the gradient)\nTake a small step in that direction\nRepeat until you reach the bottom\n\nMathematically, we update each weight using this formula:\n\\[\nw\\leftarrow w-\\eta\\frac{\\partial L}{\\partial w}\n\\]\nHere, \\(\\eta\\) (eta) is called the learning rate - it controls how big our steps are:\n\nToo large: We might overshoot the bottom\nToo small: Learning will take forever\n\nThe term \\(\\frac{\\partial L}{\\partial w}\\) tells us which direction to step:\n\nIf positive: The weight is too large, so decrease it\nIf negative: The weight is too small, so increase it\n\nWe do the same thing for the bias \\(b\\). Each complete pass through all our training data is called an ‚Äúepoch‚Äù.\nPhysics Connection: This is similar to finding the minimum of a potential well - we follow the direction where the potential decreases most rapidly!\n\n\nBuilding and Training Our First Network\nLet‚Äôs put everything together to create a network that can recognize handwritten numbers. We‚Äôll train it for 200 epochs (learning cycles) and watch how the loss decreases:\n\n\n\n\n\n\n\n\nEvaluating Our Network: How Well Did We Do?\nJust like in physics experiments, we need ways to measure how well our model performs. One powerful tool is the confusion matrix. Think of it as a report card for our network:\n\n\n\nconfusion_matrix\n\n\nThe confusion matrix shows: - True Positives (TP): We predicted ‚Äúyes‚Äù and were right - False Positives (FP): We predicted ‚Äúyes‚Äù but were wrong - True Negatives (TN): We predicted ‚Äúno‚Äù and were right - False Negatives (FN): We predicted ‚Äúno‚Äù but were wrong\nLet‚Äôs calculate this for our network:\n\n\n\n\n\n\n\n\nTesting Individual Images\nLet‚Äôs see our network in action! We can test it on individual images:"
  },
  {
    "objectID": "seminars/seminar10/seminar10.html#network-with-hidden-layers",
    "href": "seminars/seminar10/seminar10.html#network-with-hidden-layers",
    "title": "Neural Networks",
    "section": "Network with Hidden Layers",
    "text": "Network with Hidden Layers\nIn our example above, we just had an input layer and a single output neuron. More complex neural networks are containing many layers between the input layer and the output layer. These inbetween layers are called hidden layers. Here is a simple example of a neural network with a single hidden layer.\n\n\n\nhidden\n\n\nSo we have now and input layer with 784 inputs that are connected to 64 units in the hidden layer and 1 neuron in the output layer. We will not go through the derivations of all the formulas for the forward and backward passes this time. The code is a simple extension of what we did before and I hope easy to read.\n\n\n\n\n\n\nTo judge the newtork quality we do use again the confusion matrix."
  },
  {
    "objectID": "seminars/seminar10/seminar10.html#multiclass-network",
    "href": "seminars/seminar10/seminar10.html#multiclass-network",
    "title": "Neural Networks",
    "section": "Multiclass Network",
    "text": "Multiclass Network\nSo far we did only classify if the number we feed to the network is just a 0 or not. We would like to recognize the different number now and therefore need a multiclass network. Each number is then a class and per class, we have multiple realizations of handwritten numbers. We therefore have to create an output layer, which is not only containing a single neuron, but 10 neurons. Each of these neuron can output a value between 0 and 1. Whenever the output is 1, the index of the neuron represents the number predicted.\nThe output array\n[0,1,0,0,0,0,0,0,0,0]\nwould therefore correspond to the value 1.\nFor this purpose, we need to reload the right labels.\n\n\n\n\n\n\nThen we‚Äôll one-hot encode MNIST‚Äôs labels, to get a 10 x 70,000 array.\n\n\n\n\n\n\n\n\n\n\n\n\nWe also seperate into trainging and testing data\n\n\n\n\n\n\n\n\n\n\n\n\n\nChanges to the model\nOK, so let‚Äôs consider what changes we need to make to the model itself.\n\nForward Pass\nOnly the last layer of our network is changing. To add the softmax, we have to replace our lone, final node with a 10 unit layer. Its final activations are the exponentials of its z-values, normalized across all ten such exponentials. So instead of just computing \\(\\sigma(z)\\), we compute the activation for each unit \\(i\\) using the softmax function: \\[\\begin{align*}\n\\sigma(z)_i = \\frac{{\\rm e}^{z_i}}{\\sum_{j=0}^9{\\rm e}^{z_i}}\\ .\n\\end{align*}\\]\nSo, in our vectorized code, the last line of forward propagation will be A2 = np.exp(Z2) / np.sum(np.exp(Z2), axis=0).\n\n\nLoss Function\nOur loss function now has to generalize to more than two classes. The general formula for \\(n\\) classes is: \\[\\begin{align*}\nL(y,\\hat{y}) = -\\sum_{i=0}^n y_i\\log(\\hat{y}_i)\\ .\n\\end{align*}\\] Averaging over \\(m\\) training examples this becomes: \\[\\begin{align*}\nL(y,\\hat{y}) = -\\frac{1}{m}\\sum_{j=0}^m\\sum_{i=0}^n y_i^{(i)}\\log(\\hat{y}_i^{(i)})\\ .\n\\end{align*}\\]\nSo let‚Äôs define:\n\n\n\n\n\n\n\n\nBack Propagation\nLuckily it turns out that back propagation isn‚Äôt really affected by the switch to a softmax. A softmax generalizes the sigmoid activiation we‚Äôve been using, and in such a way that the code we wrote earlier still works. We could verify this by deriving: \\[\\begin{align*}\n\\frac{\\partial L}{\\partial z_i} = \\hat{y}_i - y_i\\ .\n\\end{align*}\\]\nBut we won‚Äôt walk through the steps here. Let‚Äôs just go ahead and build our final network.\n\n\n\nBuild and Train\nAs we have now more weights and classes, the training takes longer and we actually need also more episodes to achieve a good accuracy.\n\n\n\n\n\n\nLet‚Äôs see how we did:\n\n\n\n\n\n\n\nModel performance\n\n\n\n\n\n\nWe are at 84% accuray across all digits, which could be of course better. We may now plot image and the corresponding prediction."
  },
  {
    "objectID": "seminars/seminar10/seminar10.html#test-the-model",
    "href": "seminars/seminar10/seminar10.html#test-the-model",
    "title": "Neural Networks",
    "section": "Test the model",
    "text": "Test the model"
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "Summary",
    "section": "",
    "text": "Summary\nIn summary, this book has no content whatsoever."
  },
  {
    "objectID": "course-info/schedule.html",
    "href": "course-info/schedule.html",
    "title": "Zeitplan f√ºr den Kurs",
    "section": "",
    "text": "Der Kurs wird w√∂chentlich mit dem Zeitplan der Vorlesungen aktualisiert. Erwarten Sie also jeden\nDienstag ab 15. Oktober 2024, jeweils um 11:15\neine neue Vorlesung und eine neue Aufgabe ab 13:00.\nErfahrungsgem√§√ü werden die besten Ergebnisse erzielt, wenn Sie bei den Vorlesungen im H√∂rsaal anwesend sind. Das gesamte Material wird jedoch auch online zur Verf√ºgung stehen, sodass Sie jederzeit darauf zugreifen k√∂nnen, um zu lernen, wann immer es Ihnen passt."
  },
  {
    "objectID": "course-info/resources.html",
    "href": "course-info/resources.html",
    "title": "Quellen",
    "section": "",
    "text": "Vor allen anderen Sachen ist es f√ºr diesen Kurs wichtig, dass Sie w√§hrend der Vorlesung einen Internetzugang haben. Wir werden viele Beispiele und √úbungen durchf√ºhren, die auf Online-Ressourcen verweisen.\nInnerhalb der Universit√§t k√∂nnen die Eduroam-Netzwerke verwendet werden. Die notwendigen Profildaten k√∂nnen Sie hier finden.\nWeiterhin gibt es eine Menge weiterer gut strukturierter Ressourcen zu Python im Netz. Nachfolgend finden Sie nur eine sehr kleine Auswahl.",
    "crumbs": [
      "üìã Course Info",
      "Ressourcen"
    ]
  },
  {
    "objectID": "course-info/resources.html#hypothesis-annotation-tool",
    "href": "course-info/resources.html#hypothesis-annotation-tool",
    "title": "Quellen",
    "section": "Hypothesis Annotation Tool",
    "text": "Hypothesis Annotation Tool\n\nInvite to the Hypothesis annotation tool",
    "crumbs": [
      "üìã Course Info",
      "Ressourcen"
    ]
  },
  {
    "objectID": "course-info/resources.html#molecular-nanophotonics-group",
    "href": "course-info/resources.html#molecular-nanophotonics-group",
    "title": "Quellen",
    "section": "Molecular Nanophotonics Group",
    "text": "Molecular Nanophotonics Group\n\nMolecular Nanophotonics Group Website\nHypothesis Annotation Tool Invite",
    "crumbs": [
      "üìã Course Info",
      "Ressourcen"
    ]
  },
  {
    "objectID": "course-info/resources.html#additional-advanced-courses",
    "href": "course-info/resources.html#additional-advanced-courses",
    "title": "Quellen",
    "section": "Additional Advanced Courses",
    "text": "Additional Advanced Courses\n\nRosenow Group (Theory), Master Course on Statistical Mechanics of Deep Learning",
    "crumbs": [
      "üìã Course Info",
      "Ressourcen"
    ]
  },
  {
    "objectID": "course-info/resources.html#python-documentation",
    "href": "course-info/resources.html#python-documentation",
    "title": "Quellen",
    "section": "Python Documentation",
    "text": "Python Documentation\n\nPython\nMatplotlib\nPandas",
    "crumbs": [
      "üìã Course Info",
      "Ressourcen"
    ]
  },
  {
    "objectID": "course-info/resources.html#python-tutorials",
    "href": "course-info/resources.html#python-tutorials",
    "title": "Quellen",
    "section": "Python Tutorials",
    "text": "Python Tutorials\n\nIntroduction to Python for Science\nNice MatPlotLib tutorial",
    "crumbs": [
      "üìã Course Info",
      "Ressourcen"
    ]
  },
  {
    "objectID": "course-info/resources.html#julia-tutorial",
    "href": "course-info/resources.html#julia-tutorial",
    "title": "Quellen",
    "section": "Julia Tutorial",
    "text": "Julia Tutorial\n\nJulia Programming Language",
    "crumbs": [
      "üìã Course Info",
      "Ressourcen"
    ]
  },
  {
    "objectID": "course-info/resources.html#pluto-notebook",
    "href": "course-info/resources.html#pluto-notebook",
    "title": "Quellen",
    "section": "Pluto NoteBook",
    "text": "Pluto NoteBook\n\nPluto GitHub Webpage",
    "crumbs": [
      "üìã Course Info",
      "Ressourcen"
    ]
  },
  {
    "objectID": "course-info/how_to_quiz.html",
    "href": "course-info/how_to_quiz.html",
    "title": "Interactive Python Quiz",
    "section": "",
    "text": "In this quiz, you can write and execute Python code directly in your browser.\n\n\nWrite a function square(n) that returns the square of a number.\n\n\n\n\n\n# Write your Python code here\ndef square(n):\n    return n * n\n\nprint(square(5))\n\n\nRun Code"
  },
  {
    "objectID": "course-info/how_to_quiz.html#question-1",
    "href": "course-info/how_to_quiz.html#question-1",
    "title": "Interactive Python Quiz",
    "section": "",
    "text": "Write a function square(n) that returns the square of a number.\n\n\n\n\n\n# Write your Python code here\ndef square(n):\n    return n * n\n\nprint(square(5))\n\n\nRun Code"
  },
  {
    "objectID": "course-info/intructors.html",
    "href": "course-info/intructors.html",
    "title": "Instructor",
    "section": "",
    "text": "Linn√©str. 5, 04103 Leipzig\nOffice: 322\nPhone: +49 341 97 32571\nEmail: lastname@physik.uni-leipzig.de",
    "crumbs": [
      "üìã Course Info",
      "Vorlesender"
    ]
  },
  {
    "objectID": "course-info/intructors.html#prof.-dr.-frank-cichos",
    "href": "course-info/intructors.html#prof.-dr.-frank-cichos",
    "title": "Instructor",
    "section": "",
    "text": "Linn√©str. 5, 04103 Leipzig\nOffice: 322\nPhone: +49 341 97 32571\nEmail: lastname@physik.uni-leipzig.de",
    "crumbs": [
      "üìã Course Info",
      "Vorlesender"
    ]
  },
  {
    "objectID": "NiceFigures.html",
    "href": "NiceFigures.html",
    "title": "Einf√ºhrung in die Modellierung Physikalischer Prozesse",
    "section": "",
    "text": "import matplotlib as mpl\nimport matplotlib.font_manager as font_manager\nfrom IPython.core.display import HTML\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom directory_tree import display_tree\n\n\nplt.rcParams.update({'font.size': 12,\n                     'lines.linewidth': 1,\n                     'lines.markersize': 10,\n                     'axes.labelsize': 11,\n                     'xtick.labelsize' : 10,\n                     'ytick.labelsize' : 10,\n                     'xtick.top' : True,\n                     'xtick.direction' : 'in',\n                     'ytick.right' : True,\n                     'ytick.direction' : 'in',\n                     'figure.dpi': 150})\n\n\ndef get_size(w,h):\n    return((w/2.54,h/2.54))\n\n\nplt.figure(figsize=get_size(7,5))\nx=np.linspace(0,np.pi*4,200)\n\nplt.plot(x,np.sin(x),color='k')\nplt.xlabel(r\"angle $\\theta$ in [rad]\")\nplt.ylabel(r\"$\\sin(\\theta)$\")\nplt.tight_layout()\nplt.savefig(\"figure_example3.png\", transparent=True,dpi=300)\nplt.show()\n\n\n\n\n\n\n\n\n\ndef set_size(w,h, ax=None):\n    \"\"\" w, h: width, height in inches \"\"\"\n    if not ax: ax=plt.gca()\n    l = ax.figure.subplotpars.left\n    r = ax.figure.subplotpars.right\n    t = ax.figure.subplotpars.top\n    b = ax.figure.subplotpars.bottom\n    figw = float(w)/(r-l)\n    figh = float(h)/(t-b)\n    ax.figure.set_size_inches(figw, figh)\n\nfig=plt.figure(dpi=150)\nax=plt.axes()\nax.plot(x,np.sin(x),color='k')\nax.set_xlabel(r\"angle $\\theta$ in [rad]\")\nax.set_ylabel(r\"$\\sin(\\theta)$\")\nset_size(3,2)\nplt.savefig(\"figure_example2.pdf\", bbox_inches='tight', transparent=True)\nplt.show()\n\n\n\n\n\n\n\n\n\nfrom IPython.display import HTML, display\n\ndef make_html(fontname):\n    return \"&lt;p&gt;{font}: &lt;span style='font-family:{font}; font-size: 24px;'&gt;{font}&lt;/p&gt;\".format(font=fontname)\n\ncode = \"\\n\".join([make_html(font) for font in sorted(set([f.name for f in font_manager.fontManager.ttflist]))])\n\ndisplay(HTML(\"&lt;div style='column-count: 2;'&gt;{}&lt;/div&gt;\".format(code)))\n\n.Aqua Kana: .Aqua Kana\n.CJK Symbols Fallback HK: .CJK Symbols Fallback HK\n.Keyboard: .Keyboard\n.New York: .New York\n.SF Arabic: .SF Arabic\n.SF Arabic Rounded: .SF Arabic Rounded\n.SF Armenian: .SF Armenian\n.SF Armenian Rounded: .SF Armenian Rounded\n.SF Camera: .SF Camera\n.SF Compact: .SF Compact\n.SF Compact Rounded: .SF Compact Rounded\n.SF Georgian: .SF Georgian\n.SF Georgian Rounded: .SF Georgian Rounded\n.SF Hebrew: .SF Hebrew\n.SF Hebrew Rounded: .SF Hebrew Rounded\n.SF NS Mono: .SF NS Mono\n.SF NS Rounded: .SF NS Rounded\n.SF Soft Numeric: .SF Soft Numeric\n.ThonburiUI: .ThonburiUI\nAcademy Engraved LET: Academy Engraved LET\nAgency FB: Agency FB\nAl Bayan: Al Bayan\nAl Nile: Al Nile\nAl Tarikh: Al Tarikh\nAmerican Typewriter: American Typewriter\nAndale Mono: Andale Mono\nApple Braille: Apple Braille\nApple Chancery: Apple Chancery\nApple SD Gothic Neo: Apple SD Gothic Neo\nApple Symbols: Apple Symbols\nAppleGothic: AppleGothic\nAppleMyungjo: AppleMyungjo\nArial: Arial\nArial Black: Arial Black\nArial Hebrew: Arial Hebrew\nArial Narrow: Arial Narrow\nArial Rounded MT Bold: Arial Rounded MT Bold\nArial Unicode MS: Arial Unicode MS\nArtifakt Element: Artifakt Element\nAthelas: Athelas\nAvenir: Avenir\nAvenir Next: Avenir Next\nAvenir Next Condensed: Avenir Next Condensed\nAyuthaya: Ayuthaya\nBaghdad: Baghdad\nBangla MN: Bangla MN\nBangla Sangam MN: Bangla Sangam MN\nBaskerville: Baskerville\nBeirut: Beirut\nBig Caslon: Big Caslon\nBodoni 72: Bodoni 72\nBodoni 72 Oldstyle: Bodoni 72 Oldstyle\nBodoni 72 Smallcaps: Bodoni 72 Smallcaps\nBodoni Ornaments: Bodoni Ornaments\nBradley Hand: Bradley Hand\nBrush Script MT: Brush Script MT\nChalkboard: Chalkboard\nChalkboard SE: Chalkboard SE\nChalkduster: Chalkduster\nCharter: Charter\nCochin: Cochin\nComic Sans MS: Comic Sans MS\nCopperplate: Copperplate\nCorsiva Hebrew: Corsiva Hebrew\nCourier: Courier\nCourier New: Courier New\nDIN Alternate: DIN Alternate\nDIN Condensed: DIN Condensed\nDamascus: Damascus\nDecoType Naskh: DecoType Naskh\nDejaVu Sans: DejaVu Sans\nDejaVu Sans Display: DejaVu Sans Display\nDejaVu Sans Mono: DejaVu Sans Mono\nDejaVu Serif: DejaVu Serif\nDejaVu Serif Display: DejaVu Serif Display\nDevanagari MT: Devanagari MT\nDevanagari Sangam MN: Devanagari Sangam MN\nDidot: Didot\nDiwan Kufi: Diwan Kufi\nDiwan Thuluth: Diwan Thuluth\nEuphemia UCAS: Euphemia UCAS\nFarah: Farah\nFarisi: Farisi\nFutura: Futura\nGalvji: Galvji\nGeeza Pro: Geeza Pro\nGeneva: Geneva\nGeorgia: Georgia\nGill Sans: Gill Sans\nGujarati MT: Gujarati MT\nGujarati Sangam MN: Gujarati Sangam MN\nGurmukhi MN: Gurmukhi MN\nGurmukhi MT: Gurmukhi MT\nGurmukhi Sangam MN: Gurmukhi Sangam MN\nHeiti TC: Heiti TC\nHelvetica: Helvetica\nHelvetica Neue: Helvetica Neue\nHerculanum: Herculanum\nHiragino Maru Gothic Pro: Hiragino Maru Gothic Pro\nHiragino Mincho ProN: Hiragino Mincho ProN\nHiragino Sans: Hiragino Sans\nHiragino Sans GB: Hiragino Sans GB\nHoefler Text: Hoefler Text\nITF Devanagari: ITF Devanagari\nImpact: Impact\nInaiMathi: InaiMathi\nIowan Old Style: Iowan Old Style\nKailasa: Kailasa\nKannada MN: Kannada MN\nKannada Sangam MN: Kannada Sangam MN\nKefa: Kefa\nKhmer MN: Khmer MN\nKhmer Sangam MN: Khmer Sangam MN\nKohinoor Bangla: Kohinoor Bangla\nKohinoor Devanagari: Kohinoor Devanagari\nKohinoor Gujarati: Kohinoor Gujarati\nKohinoor Telugu: Kohinoor Telugu\nKokonor: Kokonor\nKrungthep: Krungthep\nKufiStandardGK: KufiStandardGK\nLao MN: Lao MN\nLao Sangam MN: Lao Sangam MN\nLucida Grande: Lucida Grande\nLuminari: Luminari\nMalayalam MN: Malayalam MN\nMalayalam Sangam MN: Malayalam Sangam MN\nMarion: Marion\nMarker Felt: Marker Felt\nMenlo: Menlo\nMicrosoft Sans Serif: Microsoft Sans Serif\nMishafi: Mishafi\nMishafi Gold: Mishafi Gold\nMonaco: Monaco\nMshtakan: Mshtakan\nMukta Mahee: Mukta Mahee\nMuna: Muna\nMyanmar MN: Myanmar MN\nMyanmar Sangam MN: Myanmar Sangam MN\nNadeem: Nadeem\nNew Peninim MT: New Peninim MT\nNoteworthy: Noteworthy\nNoto Nastaliq Urdu: Noto Nastaliq Urdu\nNoto Sans Adlam: Noto Sans Adlam\nNoto Sans Armenian: Noto Sans Armenian\nNoto Sans Avestan: Noto Sans Avestan\nNoto Sans Bamum: Noto Sans Bamum\nNoto Sans Bassa Vah: Noto Sans Bassa Vah\nNoto Sans Batak: Noto Sans Batak\nNoto Sans Bhaiksuki: Noto Sans Bhaiksuki\nNoto Sans Brahmi: Noto Sans Brahmi\nNoto Sans Buginese: Noto Sans Buginese\nNoto Sans Buhid: Noto Sans Buhid\nNoto Sans Canadian Aboriginal: Noto Sans Canadian Aboriginal\nNoto Sans Carian: Noto Sans Carian\nNoto Sans Caucasian Albanian: Noto Sans Caucasian Albanian\nNoto Sans Chakma: Noto Sans Chakma\nNoto Sans Cham: Noto Sans Cham\nNoto Sans Coptic: Noto Sans Coptic\nNoto Sans Cuneiform: Noto Sans Cuneiform\nNoto Sans Cypriot: Noto Sans Cypriot\nNoto Sans Duployan: Noto Sans Duployan\nNoto Sans Egyptian Hieroglyphs: Noto Sans Egyptian Hieroglyphs\nNoto Sans Elbasan: Noto Sans Elbasan\nNoto Sans Glagolitic: Noto Sans Glagolitic\nNoto Sans Gothic: Noto Sans Gothic\nNoto Sans Gunjala Gondi: Noto Sans Gunjala Gondi\nNoto Sans Hanifi Rohingya: Noto Sans Hanifi Rohingya\nNoto Sans Hanunoo: Noto Sans Hanunoo\nNoto Sans Hatran: Noto Sans Hatran\nNoto Sans Imperial Aramaic: Noto Sans Imperial Aramaic\nNoto Sans Inscriptional Pahlavi: Noto Sans Inscriptional Pahlavi\nNoto Sans Inscriptional Parthian: Noto Sans Inscriptional Parthian\nNoto Sans Javanese: Noto Sans Javanese\nNoto Sans Kaithi: Noto Sans Kaithi\nNoto Sans Kannada: Noto Sans Kannada\nNoto Sans Kayah Li: Noto Sans Kayah Li\nNoto Sans Kharoshthi: Noto Sans Kharoshthi\nNoto Sans Khojki: Noto Sans Khojki\nNoto Sans Khudawadi: Noto Sans Khudawadi\nNoto Sans Lepcha: Noto Sans Lepcha\nNoto Sans Limbu: Noto Sans Limbu\nNoto Sans Linear A: Noto Sans Linear A\nNoto Sans Linear B: Noto Sans Linear B\nNoto Sans Lisu: Noto Sans Lisu\nNoto Sans Lycian: Noto Sans Lycian\nNoto Sans Lydian: Noto Sans Lydian\nNoto Sans Mahajani: Noto Sans Mahajani\nNoto Sans Mandaic: Noto Sans Mandaic\nNoto Sans Manichaean: Noto Sans Manichaean\nNoto Sans Marchen: Noto Sans Marchen\nNoto Sans Masaram Gondi: Noto Sans Masaram Gondi\nNoto Sans Meetei Mayek: Noto Sans Meetei Mayek\nNoto Sans Mende Kikakui: Noto Sans Mende Kikakui\nNoto Sans Meroitic: Noto Sans Meroitic\nNoto Sans Miao: Noto Sans Miao\nNoto Sans Modi: Noto Sans Modi\nNoto Sans Mongolian: Noto Sans Mongolian\nNoto Sans Mro: Noto Sans Mro\nNoto Sans Multani: Noto Sans Multani\nNoto Sans Myanmar: Noto Sans Myanmar\nNoto Sans NKo: Noto Sans NKo\nNoto Sans Nabataean: Noto Sans Nabataean\nNoto Sans New Tai Lue: Noto Sans New Tai Lue\nNoto Sans Newa: Noto Sans Newa\nNoto Sans Ol Chiki: Noto Sans Ol Chiki\nNoto Sans Old Hungarian: Noto Sans Old Hungarian\nNoto Sans Old Italic: Noto Sans Old Italic\nNoto Sans Old North Arabian: Noto Sans Old North Arabian\nNoto Sans Old Permic: Noto Sans Old Permic\nNoto Sans Old Persian: Noto Sans Old Persian\nNoto Sans Old South Arabian: Noto Sans Old South Arabian\nNoto Sans Old Turkic: Noto Sans Old Turkic\nNoto Sans Oriya: Noto Sans Oriya\nNoto Sans Osage: Noto Sans Osage\nNoto Sans Osmanya: Noto Sans Osmanya\nNoto Sans Pahawh Hmong: Noto Sans Pahawh Hmong\nNoto Sans Palmyrene: Noto Sans Palmyrene\nNoto Sans Pau Cin Hau: Noto Sans Pau Cin Hau\nNoto Sans PhagsPa: Noto Sans PhagsPa\nNoto Sans Phoenician: Noto Sans Phoenician\nNoto Sans Psalter Pahlavi: Noto Sans Psalter Pahlavi\nNoto Sans Rejang: Noto Sans Rejang\nNoto Sans Samaritan: Noto Sans Samaritan\nNoto Sans Saurashtra: Noto Sans Saurashtra\nNoto Sans Sharada: Noto Sans Sharada\nNoto Sans Siddham: Noto Sans Siddham\nNoto Sans Sora Sompeng: Noto Sans Sora Sompeng\nNoto Sans Sundanese: Noto Sans Sundanese\nNoto Sans Syloti Nagri: Noto Sans Syloti Nagri\nNoto Sans Syriac: Noto Sans Syriac\nNoto Sans Tagalog: Noto Sans Tagalog\nNoto Sans Tagbanwa: Noto Sans Tagbanwa\nNoto Sans Tai Le: Noto Sans Tai Le\nNoto Sans Tai Tham: Noto Sans Tai Tham\nNoto Sans Tai Viet: Noto Sans Tai Viet\nNoto Sans Takri: Noto Sans Takri\nNoto Sans Thaana: Noto Sans Thaana\nNoto Sans Tifinagh: Noto Sans Tifinagh\nNoto Sans Tirhuta: Noto Sans Tirhuta\nNoto Sans Ugaritic: Noto Sans Ugaritic\nNoto Sans Vai: Noto Sans Vai\nNoto Sans Wancho: Noto Sans Wancho\nNoto Sans Warang Citi: Noto Sans Warang Citi\nNoto Sans Yi: Noto Sans Yi\nNoto Serif Ahom: Noto Serif Ahom\nNoto Serif Balinese: Noto Serif Balinese\nNoto Serif Hmong Nyiakeng: Noto Serif Hmong Nyiakeng\nNoto Serif Myanmar: Noto Serif Myanmar\nNoto Serif Yezidi: Noto Serif Yezidi\nOptima: Optima\nOriya MN: Oriya MN\nOriya Sangam MN: Oriya Sangam MN\nPT Mono: PT Mono\nPT Sans: PT Sans\nPT Serif: PT Serif\nPT Serif Caption: PT Serif Caption\nPalatino: Palatino\nPapyrus: Papyrus\nParty LET: Party LET\nPhosphate: Phosphate\nPlantagenet Cherokee: Plantagenet Cherokee\nRaanana: Raanana\nRockwell: Rockwell\nSF Grandezza: SF Grandezza\nSTIX Two Math: STIX Two Math\nSTIX Two Text: STIX Two Text\nSTIXGeneral: STIXGeneral\nSTIXIntegralsD: STIXIntegralsD\nSTIXIntegralsSm: STIXIntegralsSm\nSTIXIntegralsUp: STIXIntegralsUp\nSTIXIntegralsUpD: STIXIntegralsUpD\nSTIXIntegralsUpSm: STIXIntegralsUpSm\nSTIXNonUnicode: STIXNonUnicode\nSTIXSizeFiveSym: STIXSizeFiveSym\nSTIXSizeFourSym: STIXSizeFourSym\nSTIXSizeOneSym: STIXSizeOneSym\nSTIXSizeThreeSym: STIXSizeThreeSym\nSTIXSizeTwoSym: STIXSizeTwoSym\nSTIXVariants: STIXVariants\nSana: Sana\nSathu: Sathu\nSavoye LET: Savoye LET\nSeravek: Seravek\nShree Devanagari 714: Shree Devanagari 714\nSignPainter: SignPainter\nSilom: Silom\nSinhala MN: Sinhala MN\nSinhala Sangam MN: Sinhala Sangam MN\nSkia: Skia\nSnell Roundhand: Snell Roundhand\nSongti SC: Songti SC\nSukhumvit Set: Sukhumvit Set\nSuperclarendon: Superclarendon\nSymbol: Symbol\nSystem Font: System Font\nTahoma: Tahoma\nTamil MN: Tamil MN\nTamil Sangam MN: Tamil Sangam MN\nTelugu MN: Telugu MN\nTelugu Sangam MN: Telugu Sangam MN\nThonburi: Thonburi\nTimes: Times\nTimes New Roman: Times New Roman\nTrattatello: Trattatello\nTrebuchet MS: Trebuchet MS\nVerdana: Verdana\nWaseem: Waseem\nWebdings: Webdings\nWingdings: Wingdings\nWingdings 2: Wingdings 2\nWingdings 3: Wingdings 3\nZapf Dingbats: Zapf Dingbats\nZapfino: Zapfino\ncmb10: cmb10\ncmex10: cmex10\ncmmi10: cmmi10\ncmr10: cmr10\ncmss10: cmss10\ncmsy10: cmsy10\ncmtt10: cmtt10\n\n\n\ncmfont = font_manager.FontProperties(fname=mpl.get_data_path() + '/fonts/ttf/cmr10.ttf')\nplt.rcParams.update({'font.size': 12,\n                     'axes.titlesize': 12,\n                     'axes.labelsize': 12,\n                     'axes.labelpad': 12,\n                     'lines.linewidth': 1,\n                     'lines.markersize': 10,\n                     'xtick.labelsize' : 10,\n                     'ytick.labelsize' : 10,\n                     'xtick.top' : True,\n                     'xtick.direction' : 'in',\n                     'ytick.right' : True,\n                     'ytick.direction' : 'in',\n                     'font.family' : 'serif',\n                     'font.serif' : cmfont.get_name(),\n                     \"axes.formatter.use_mathtext\": True,\n                     'text.usetex': True,\n                     'mathtext.fontset' : 'cm'\n                    })\n\n\nx=np.linspace(0,np.pi,100)\n\n\nplt.figure(figsize=get_size(6,5),dpi=150)\nplt.plot(x,np.sin(x))\nplt.xlabel(r\"velocity $v$\")\nplt.ylabel(r\"position $r$\")\nplt.show()"
  },
  {
    "objectID": "course-info/assignments.html",
    "href": "course-info/assignments.html",
    "title": "√úbungsaufgaben",
    "section": "",
    "text": "Es werden insgesamt 6 √úbungsbl√§tter zur Verf√ºgung gestellt. Die √úbungsbl√§tter sind Teil der Pr√ºfungsleistung! Die √úbungsbl√§tter werden nicht benotet, aber die Bearbeitung ist f√ºr den erfolgreichen Abschluss des Moduls erforderlich. Genauere Informationen zur Wertung der √úbungsbl√§tter finden sie auf der Seite zur Pr√ºfung.\n\nBereitstellung und Abgabe der √úbungsaufgaben\n\nVer√∂ffentlichung: Jeden Dienstag um 13:00 Uhr\nAbgabefrist: Bis zum folgenden Dienstag um 12:00 Uhr\nBearbeitungszeitraum: Eine Woche (minus eine Stunde)\nPlattform: Moodle der Universit√§t\n\nSowohl f√ºr die Bearbeitung als auch f√ºr die Abgabe\n\nWichtig:\n\nAchten Sie auf die p√ºnktliche Abgabe innerhalb der angegebenen Frist.\nNach Ablauf der Frist ist die Aufgabe nicht mehr verf√ºgbar und kann nicht mehr eingereicht werden.\nAchten sie darauf, dass mehrmaliges Einreichen derselben Aufgabe die Punktzahl mit jeder Einreichung um 10% verringert",
    "crumbs": [
      "üìã Course Info",
      "√úbungsaufgaben"
    ]
  },
  {
    "objectID": "course-info/website.html",
    "href": "course-info/website.html",
    "title": "Diese Webseiten",
    "section": "",
    "text": "Diese Webseiten\nDiese Website enth√§lt alle Informationen, die f√ºr unseren Kurs Einf√ºhrung in die Modellierung Physikalischer Prozesse erforderlich sind. Sie werden hier jede Woche eine neue Vorlesung und eine neue Aufgabe finden. Die Vorlesungshefte werden von Videos begleitet, die den Inhalt der Vorlesung auf Englisch erkl√§ren, aber Sie k√∂nnen auch mit dem Lesen auskommen. Die Vorlesungen in Person, werden auf Deutsch stattfinden. Von diesen Webseiten aus werden Sie zu verschiedenen Ressourcen gef√ºhrt, die Sie nutzen k√∂nnen, um das Programmieren in Python zu lernen. Dabei werden wir einige gro√üartige Tools aus dem Internet nutzen, wie\n\nGoogle Colab Dienst, um auch Jupyter Notebooks (https://colab.research.google.com) zu hosten. Das Google Colab-Projekt bietet eine n√ºtzliche Umgebung zur gemeinsamen Nutzung von Notebooks.\n\n\n\ngoogle colab screen\n\n\nWenn Sie die folgende Website besuchen, werden Sie an mehreren Stellen das folgende Symbol sehen.\n![Substitution Name1]\nDieses Symbol zeigt an, dass diese Webseite auf einem Jupyter Notebook basiert. Anstatt nur die Website zu betrachten, k√∂nnen Sie auf das Symbol klicken und der Google Colab-Dienst wird ge√∂ffnet, damit Sie das Notizbuch interaktiv nutzen k√∂nnen. Google Colab √∂ffnet sich viel schneller als myBinder, aber die Notizb√ºcher sind f√ºr die Arbeit mit myBinder gemacht und nicht alle Funktionen funktionieren mit Colab. Ich arbeite jedoch an der Kompatibilit√§t.\nGitHub and GitHub Pages Dienst zum Hosting von Websites (https://github.com). GitHub ist ein gro√üartiger Ort, um Ihre kollaborativen Coding-Projekte einschlie√ülich Versionskontrolle zu hosten. In der oberen rechten Ecke finden Sie auch einen Link zum GitHub-Repository, in dem die Notebooks gehostet werden.\n\n\n\ngithub screen\n\n\nAnaconda Jupyter package f√ºr Notebooks auf dem eigenen Computer (https://www.anaconda.com/distribution/). Das Paket anaconda stellt Ihnen die Jupyter Notebook-Umgebung einschlie√ülich Python zur Verf√ºgung. Wenn Sie Jupyter zu Hause ohne Online-Zugang verwenden m√∂chten, ist dies ein gutes Paket zur Installation.\n\n\n\nanaconda screen"
  },
  {
    "objectID": "course-info/exam.html",
    "href": "course-info/exam.html",
    "title": "Pr√ºfung",
    "section": "",
    "text": "Die Pr√ºfungsleistung in diesem Modul ist eine Portfolio-Pr√ºfung und besteht aus zwei Portfolio-Teilen:\n\n√úbungsaufgaben:\n\n6 Serien von Aufgaben, die nicht benotet werden\nMindestens 50% der Gesamtpunktzahl aller √úbungsaufgaben muss erreicht werden\n\nZwei Tests:\n\nJeder Test dauert 45 Minuten\nFinden in Person w√§hrend zwei √úbungsseminare statt\nDie Tests werden vorher angek√ºndigt\nDie Punkte beider Tests werden addiert und ergeben eine Gesamtnote\n\n\nWichtige Hinweise: - Beide Portfolio-Teile (√úbungsaufgaben und Tests) m√ºssen bestanden werden, um das Modul erfolgreich abzuschlie√üen. - Die Gesamtnote der Tests entspricht der Abschlussnote des Moduls.",
    "crumbs": [
      "üìã Course Info",
      "Pr√ºfungen"
    ]
  },
  {
    "objectID": "course-info/exam.html#erstteilnehmer",
    "href": "course-info/exam.html#erstteilnehmer",
    "title": "Pr√ºfung",
    "section": "",
    "text": "Die Pr√ºfungsleistung in diesem Modul ist eine Portfolio-Pr√ºfung und besteht aus zwei Portfolio-Teilen:\n\n√úbungsaufgaben:\n\n6 Serien von Aufgaben, die nicht benotet werden\nMindestens 50% der Gesamtpunktzahl aller √úbungsaufgaben muss erreicht werden\n\nZwei Tests:\n\nJeder Test dauert 45 Minuten\nFinden in Person w√§hrend zwei √úbungsseminare statt\nDie Tests werden vorher angek√ºndigt\nDie Punkte beider Tests werden addiert und ergeben eine Gesamtnote\n\n\nWichtige Hinweise: - Beide Portfolio-Teile (√úbungsaufgaben und Tests) m√ºssen bestanden werden, um das Modul erfolgreich abzuschlie√üen. - Die Gesamtnote der Tests entspricht der Abschlussnote des Moduls.",
    "crumbs": [
      "üìã Course Info",
      "Pr√ºfungen"
    ]
  },
  {
    "objectID": "course-info/exam.html#wiederholer",
    "href": "course-info/exam.html#wiederholer",
    "title": "Pr√ºfung",
    "section": "Wiederholer",
    "text": "Wiederholer\nF√ºr Studierende, die das Modul bereits im WS 2023/24 belegt haben und nun wiederholen:\n\n√úbungsaufgaben:\n\nWenn Sie im WS 2023/24 ‚â•50% erreicht haben: Nur Projektabgabe erforderlich\nWenn Sie im WS 2023/24 &lt;50% erreicht haben: √úbungsaufgaben und Projektabgabe erforderlich\nEine Liste der erreichten √úbungspunkte wird im internen Bereich der MONA Webseite ver√∂ffentlicht\n\nEinschreibung:\n\nErneute Moduleinschreibung nicht notwendig\nF√ºr Moodle-Zugang: Kontaktieren Sie Andrea Kramer per Uni-E-Mail\n\nProjektabgabe f√ºr Wiederholer:\n\nFrist: 12.03.2025, 13:00 Uhr\nSp√§tere Abgaben werden nicht ber√ºcksichtigt",
    "crumbs": [
      "üìã Course Info",
      "Pr√ºfungen"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "EMPP",
    "section": "",
    "text": "Willkommen zum Kurs Einf√ºhrung in die Modellierung Physikalischer Prozesse!\nDie Programmiersprache Python ist f√ºr alle Arten von wissenschaftlichen und technischen Aufgaben n√ºtzlich. Sie k√∂nnen mit ihr Daten analysieren und darstellen. Sie k√∂nnen mit ihr auch wissenschaftliche Probleme numerisch l√∂sen, die analytisch nur schwer oder gar nicht zu l√∂sen sind. Python ist frei verf√ºgbar und wurde aufgrund seines modularen Aufbaus um eine nahezu unendliche Anzahl von Modulen f√ºr verschiedene Zwecke erweitert.\nDieser Kurs soll Sie in die Programmierung mit Python einf√ºhren. Er richtet sich eher an den Anf√§nger, wir hoffen aber, dass er auch f√ºr Fortgeschrittene interessant ist. Wir beginnen den Kurs mit einer Einf√ºhrung in die Jupyter Notebook-Umgebung, die wir w√§hrend des gesamten Kurses verwenden werden. Danach werden wir eine Einf√ºhrung in Python geben und Ihnen einige grundlegende Funktionen zeigen, wie z.B. das Plotten und Analysieren von Daten durch Kurvenanpassung, das Lesen und Schreiben von Dateien, was einige der Aufgaben sind, die Ihnen w√§hrend Ihres Physikstudiums begegnen werden. Wir zeigen Ihnen auch einige fortgeschrittene Themen wie die Animation in Jupyter und die Simulation von physikalischen Prozessen in\n\nMechanik\nElektrostatik\nWellen\nOptik\n\nFalls am Ende des Kurses Zeit bleibt, werden wir auch einen Blick auf Verfahren des maschinellen Lernens werfen, das mittlerweile auch in der Physik zu einem wichtigen Werkzeug geworden ist.\nWir werden keine umfassende Liste von numerischen Simulationsschemata pr√§sentieren, sondern die Beispiele nutzen, um Ihre Neugierde zu wecken. Da es leichte Unterschiede in der Syntax der verschiedenen Python-Versionen gibt, werden wir uns im Folgenden immer auf den Python 3-Standard beziehen.\nDer Kurs wird auf Deutsch gehalten werden. Die Webseiten, die Sie f√ºr den √úberblick zu Python zur Verf√ºgung gestellt bekommen, werden allerdings auf Englisch sein. √úbungsaufgaben werden werden auf Deutsch gestellt.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "WEEK1_CHANGES.html",
    "href": "WEEK1_CHANGES.html",
    "title": "Week 1 Restructuring - Summary of Changes",
    "section": "",
    "text": "Week 1 has been restructured to follow a physics-first, motivation-driven approach. Instead of overwhelming students with Jupyter documentation before they write any code, we now get them coding and visualizing physics immediately.\n\n\n\n\n\nWeek 1:\n  1. Jupyter Notebooks (350+ lines of technical documentation)\n  2. Variables & Numbers (technical Python details)\n  3. [Plotting way later in Week 4]\n\n\n\nWeek 1: Your First Physics Code\n  1. Setup: Jupyter Notebooks (streamlined, 15-20 min)\n  2. Quick Win: Plotting Your First Graph (moved from Week 4)\n  3. Variables & Numbers (What You Just Used) - with physics context\n\n\n\n\n\n\nBefore: - 350+ lines of comprehensive Jupyter documentation - Deep technical details about kernels, JSON format, nbconvert - Advanced features (magic commands, debugger, widgets) upfront - No physics motivation - Reference manual style\nAfter: - Streamlined to ~200 lines focused on getting started - Physics motivation first: Shows what students will create - Embedded example: Projectile motion plot in the introduction - First calculation: Gravitational potential energy (within 5 minutes) - Essential keyboard shortcuts only - Advanced topics moved to collapsible sections - Clear ‚ÄúNext Steps‚Äù pointing to plotting lesson\nKey Improvements: - ‚úÖ Shows physics visualization in first 2 minutes - ‚úÖ Students run their first physics calculation within 10 minutes - ‚úÖ Two types of cells explained with physics examples - ‚úÖ Practice exercise: Calculate kinetic energy with proper LaTeX documentation - ‚úÖ ‚ÄúTry It Yourself‚Äù section with free fall calculation - ‚úÖ Quick reference card for essential shortcuts\n\n\n\nStatus: File kept as-is but moved up in the course sequence\nWhy: This file already contains good content. By moving it to Week 1 position #2, students: - See visual results immediately (motivation!) - Learn by doing before learning theory - Understand why variables matter (they‚Äôll use them in plots)\nCurrent content includes: - Simple line plots - Anatomy of matplotlib figures - Axis labels, legends, error bars - Multiple plot types (scatter, histogram) - Physics examples throughout\n\n\n\nBefore: - Generic programming tutorial - No physics context - Technical type explanations - Reserved keywords warning with lambda mention but no physics connection\nAfter: - Opens with ‚ÄúWhat You Just Used!‚Äù - references the previous plotting lesson - Physics-motivated variable naming conventions - Real physics examples for each number type: - Integers: Particle counts, quantum numbers, timesteps - Floats: Mass, energy, position (with physical constants) - Complex: Wave functions, AC circuits, quantum mechanics - Physics constant examples (c, h, electron mass) - Scientific notation with astronomy/atomic scales - Practical tips: ‚ÄúWhy lambda_ instead of lambda‚Äù for wavelength - Complex numbers tied to quantum mechanics applications\nKey Improvements: - ‚úÖ Every code example uses physics variables (mass, velocity, energy) - ‚úÖ Explains when to use each type in physics context - ‚úÖ Real constants: Speed of light, Planck‚Äôs constant, electron mass - ‚úÖ Complex number section connected to quantum mechanics and wave functions - ‚úÖ Practical examples: Photon energy calculation, wave function probability density - ‚úÖ Tips box: ‚ÄúWhich Type for Physics?‚Äù table\n\n\n\n\n\n\nStudents see a beautiful physics plot in the first 2 minutes, not after hours of documentation reading.\n\n\n\nThey plot data before understanding all the theory. This is how physicists actually work in research.\n\n\n\nVariables are taught after students have used them, so they understand why they‚Äôre learning it.\n\n\n\nEvery example uses physics notation, units, and real-world constants. Students see Python as a physics tool, not just a programming language.\n\n\n\nWeek 1 focuses on three things: 1. Running Jupyter 2. Making plots 3. Understanding what variables are\nAdvanced topics (kernels, magic commands, etc.) are in collapsible sections for reference.\n\n\n\n\n\n\nHour 1: Read about Jupyter architecture\nHour 2: Learn about kernels and JSON format\nHour 3: Markdown syntax\nHour 4: Still reading documentation...\nHour 5: Finally start programming\nResult: \"This is boring, when do we do physics?\"\n\n\n\nMinute 1: \"Wow, look at that physics plot!\"\nMinute 10: \"I just calculated potential energy!\"\nMinute 30: \"I made my first graph!\"\nMinute 45: \"I can plot projectile motion!\"\nHour 1-2: \"Now I understand what variables are and why they matter\"\nResult: \"This is cool, I'm doing real physics!\"\n\n\n\n\n\nContent quality: All original material is preserved (moved to collapsible sections)\nDepth: Advanced users can still access detailed Jupyter documentation\nFile organization: All files remain in their original locations\nLater weeks: Only Week 1 structure was modified\n\n\n\n\nThe proposed _quarto.yml section for Week 1:\n- section: \"üöÄ Week 1: Your First Physics Code\"\n  contents:\n    - text: \"Setup: Jupyter Notebooks\"\n      href: lectures/lecture01/01-lecture01.qmd\n    - text: \"Quick Win: Plotting Your First Graph\"\n      href: lectures/lecture04/04-plotting.qmd  # MOVED UP!\n    - text: \"Variables & Numbers (What You Just Used)\"\n      href: lectures/lecture01/02-lecture01.qmd\n\n\n\n\n\n\n‚Üë Higher engagement in first week\n‚Üë ‚ÄúAha!‚Äù moments earlier\n‚Üë Confidence: ‚ÄúI can do this!‚Äù\n‚Üì Dropout in first two weeks\n\n\n\n\n\nBetter retention (learned in context)\nStronger connection between Python and physics\nMore independent experimentation\nClearer understanding of ‚Äúwhy‚Äù before ‚Äúhow‚Äù\n\n\n\n\n\n\n\n\nAdd a ‚ÄúWeek Overview‚Äù page for each week with learning objectives\nCreate a cheat sheet PDF for quick reference during lectures\nAdd more interactive exercises throughout the lessons\nInclude short video demos (5 min) showing key concepts\nStudent project gallery to showcase what‚Äôs possible\n\n\n\n\nApply similar principles to other weeks: - Week 2: Lead with Brownian Motion before classes - Week 4: Show planetary orbits before ODEs - Week 8: Wave animations before Fourier theory\n\n\n\n\n\nlectures/lecture01/01-lecture01.qmd - Completely restructured\nlectures/lecture01/02-lecture01.qmd - Enhanced with physics context\nlectures/lecture04/04-plotting.qmd - Moved up (content unchanged)\n\n\n\n\nBefore deploying to students: 1. ‚úÖ Run through Week 1 as a student would 2. ‚úÖ Time each section (should be ~2 hours total) 3. ‚úÖ Test all code examples in fresh Jupyter environment 4. ‚úÖ Verify all links work in the rendered Quarto site 5. ‚úÖ Ask a colleague to review for clarity\n\n\n\nBottom line: Week 1 is now exciting, physics-focused, and gets students creating visualizations in minutes instead of hours. The technical details are still there, but they‚Äôre optional reference material instead of required reading.\nStudents will leave Week 1 thinking ‚ÄúI can do physics with code!‚Äù instead of ‚ÄúI learned about Jupyter‚Äôs architecture.‚Äù\n\nDate of Changes: Generated during course restructuring consultation Philosophy: Physics first, technical details second, engagement always"
  },
  {
    "objectID": "WEEK1_CHANGES.html#overview",
    "href": "WEEK1_CHANGES.html#overview",
    "title": "Week 1 Restructuring - Summary of Changes",
    "section": "",
    "text": "Week 1 has been restructured to follow a physics-first, motivation-driven approach. Instead of overwhelming students with Jupyter documentation before they write any code, we now get them coding and visualizing physics immediately."
  },
  {
    "objectID": "WEEK1_CHANGES.html#new-week-1-structure",
    "href": "WEEK1_CHANGES.html#new-week-1-structure",
    "title": "Week 1 Restructuring - Summary of Changes",
    "section": "",
    "text": "Week 1:\n  1. Jupyter Notebooks (350+ lines of technical documentation)\n  2. Variables & Numbers (technical Python details)\n  3. [Plotting way later in Week 4]\n\n\n\nWeek 1: Your First Physics Code\n  1. Setup: Jupyter Notebooks (streamlined, 15-20 min)\n  2. Quick Win: Plotting Your First Graph (moved from Week 4)\n  3. Variables & Numbers (What You Just Used) - with physics context"
  },
  {
    "objectID": "WEEK1_CHANGES.html#key-changes-made",
    "href": "WEEK1_CHANGES.html#key-changes-made",
    "title": "Week 1 Restructuring - Summary of Changes",
    "section": "",
    "text": "Before: - 350+ lines of comprehensive Jupyter documentation - Deep technical details about kernels, JSON format, nbconvert - Advanced features (magic commands, debugger, widgets) upfront - No physics motivation - Reference manual style\nAfter: - Streamlined to ~200 lines focused on getting started - Physics motivation first: Shows what students will create - Embedded example: Projectile motion plot in the introduction - First calculation: Gravitational potential energy (within 5 minutes) - Essential keyboard shortcuts only - Advanced topics moved to collapsible sections - Clear ‚ÄúNext Steps‚Äù pointing to plotting lesson\nKey Improvements: - ‚úÖ Shows physics visualization in first 2 minutes - ‚úÖ Students run their first physics calculation within 10 minutes - ‚úÖ Two types of cells explained with physics examples - ‚úÖ Practice exercise: Calculate kinetic energy with proper LaTeX documentation - ‚úÖ ‚ÄúTry It Yourself‚Äù section with free fall calculation - ‚úÖ Quick reference card for essential shortcuts\n\n\n\nStatus: File kept as-is but moved up in the course sequence\nWhy: This file already contains good content. By moving it to Week 1 position #2, students: - See visual results immediately (motivation!) - Learn by doing before learning theory - Understand why variables matter (they‚Äôll use them in plots)\nCurrent content includes: - Simple line plots - Anatomy of matplotlib figures - Axis labels, legends, error bars - Multiple plot types (scatter, histogram) - Physics examples throughout\n\n\n\nBefore: - Generic programming tutorial - No physics context - Technical type explanations - Reserved keywords warning with lambda mention but no physics connection\nAfter: - Opens with ‚ÄúWhat You Just Used!‚Äù - references the previous plotting lesson - Physics-motivated variable naming conventions - Real physics examples for each number type: - Integers: Particle counts, quantum numbers, timesteps - Floats: Mass, energy, position (with physical constants) - Complex: Wave functions, AC circuits, quantum mechanics - Physics constant examples (c, h, electron mass) - Scientific notation with astronomy/atomic scales - Practical tips: ‚ÄúWhy lambda_ instead of lambda‚Äù for wavelength - Complex numbers tied to quantum mechanics applications\nKey Improvements: - ‚úÖ Every code example uses physics variables (mass, velocity, energy) - ‚úÖ Explains when to use each type in physics context - ‚úÖ Real constants: Speed of light, Planck‚Äôs constant, electron mass - ‚úÖ Complex number section connected to quantum mechanics and wave functions - ‚úÖ Practical examples: Photon energy calculation, wave function probability density - ‚úÖ Tips box: ‚ÄúWhich Type for Physics?‚Äù table"
  },
  {
    "objectID": "WEEK1_CHANGES.html#pedagogical-rationale",
    "href": "WEEK1_CHANGES.html#pedagogical-rationale",
    "title": "Week 1 Restructuring - Summary of Changes",
    "section": "",
    "text": "Students see a beautiful physics plot in the first 2 minutes, not after hours of documentation reading.\n\n\n\nThey plot data before understanding all the theory. This is how physicists actually work in research.\n\n\n\nVariables are taught after students have used them, so they understand why they‚Äôre learning it.\n\n\n\nEvery example uses physics notation, units, and real-world constants. Students see Python as a physics tool, not just a programming language.\n\n\n\nWeek 1 focuses on three things: 1. Running Jupyter 2. Making plots 3. Understanding what variables are\nAdvanced topics (kernels, magic commands, etc.) are in collapsible sections for reference."
  },
  {
    "objectID": "WEEK1_CHANGES.html#student-experience-comparison",
    "href": "WEEK1_CHANGES.html#student-experience-comparison",
    "title": "Week 1 Restructuring - Summary of Changes",
    "section": "",
    "text": "Hour 1: Read about Jupyter architecture\nHour 2: Learn about kernels and JSON format\nHour 3: Markdown syntax\nHour 4: Still reading documentation...\nHour 5: Finally start programming\nResult: \"This is boring, when do we do physics?\"\n\n\n\nMinute 1: \"Wow, look at that physics plot!\"\nMinute 10: \"I just calculated potential energy!\"\nMinute 30: \"I made my first graph!\"\nMinute 45: \"I can plot projectile motion!\"\nHour 1-2: \"Now I understand what variables are and why they matter\"\nResult: \"This is cool, I'm doing real physics!\""
  },
  {
    "objectID": "WEEK1_CHANGES.html#what-hasnt-changed",
    "href": "WEEK1_CHANGES.html#what-hasnt-changed",
    "title": "Week 1 Restructuring - Summary of Changes",
    "section": "",
    "text": "Content quality: All original material is preserved (moved to collapsible sections)\nDepth: Advanced users can still access detailed Jupyter documentation\nFile organization: All files remain in their original locations\nLater weeks: Only Week 1 structure was modified"
  },
  {
    "objectID": "WEEK1_CHANGES.html#integration-with-your-existing-_quarto.yml",
    "href": "WEEK1_CHANGES.html#integration-with-your-existing-_quarto.yml",
    "title": "Week 1 Restructuring - Summary of Changes",
    "section": "",
    "text": "The proposed _quarto.yml section for Week 1:\n- section: \"üöÄ Week 1: Your First Physics Code\"\n  contents:\n    - text: \"Setup: Jupyter Notebooks\"\n      href: lectures/lecture01/01-lecture01.qmd\n    - text: \"Quick Win: Plotting Your First Graph\"\n      href: lectures/lecture04/04-plotting.qmd  # MOVED UP!\n    - text: \"Variables & Numbers (What You Just Used)\"\n      href: lectures/lecture01/02-lecture01.qmd"
  },
  {
    "objectID": "WEEK1_CHANGES.html#expected-outcomes",
    "href": "WEEK1_CHANGES.html#expected-outcomes",
    "title": "Week 1 Restructuring - Summary of Changes",
    "section": "",
    "text": "‚Üë Higher engagement in first week\n‚Üë ‚ÄúAha!‚Äù moments earlier\n‚Üë Confidence: ‚ÄúI can do this!‚Äù\n‚Üì Dropout in first two weeks\n\n\n\n\n\nBetter retention (learned in context)\nStronger connection between Python and physics\nMore independent experimentation\nClearer understanding of ‚Äúwhy‚Äù before ‚Äúhow‚Äù"
  },
  {
    "objectID": "WEEK1_CHANGES.html#next-steps-optional",
    "href": "WEEK1_CHANGES.html#next-steps-optional",
    "title": "Week 1 Restructuring - Summary of Changes",
    "section": "",
    "text": "Add a ‚ÄúWeek Overview‚Äù page for each week with learning objectives\nCreate a cheat sheet PDF for quick reference during lectures\nAdd more interactive exercises throughout the lessons\nInclude short video demos (5 min) showing key concepts\nStudent project gallery to showcase what‚Äôs possible\n\n\n\n\nApply similar principles to other weeks: - Week 2: Lead with Brownian Motion before classes - Week 4: Show planetary orbits before ODEs - Week 8: Wave animations before Fourier theory"
  },
  {
    "objectID": "WEEK1_CHANGES.html#files-modified",
    "href": "WEEK1_CHANGES.html#files-modified",
    "title": "Week 1 Restructuring - Summary of Changes",
    "section": "",
    "text": "lectures/lecture01/01-lecture01.qmd - Completely restructured\nlectures/lecture01/02-lecture01.qmd - Enhanced with physics context\nlectures/lecture04/04-plotting.qmd - Moved up (content unchanged)"
  },
  {
    "objectID": "WEEK1_CHANGES.html#testing-recommendations",
    "href": "WEEK1_CHANGES.html#testing-recommendations",
    "title": "Week 1 Restructuring - Summary of Changes",
    "section": "",
    "text": "Before deploying to students: 1. ‚úÖ Run through Week 1 as a student would 2. ‚úÖ Time each section (should be ~2 hours total) 3. ‚úÖ Test all code examples in fresh Jupyter environment 4. ‚úÖ Verify all links work in the rendered Quarto site 5. ‚úÖ Ask a colleague to review for clarity"
  },
  {
    "objectID": "WEEK1_CHANGES.html#summary",
    "href": "WEEK1_CHANGES.html#summary",
    "title": "Week 1 Restructuring - Summary of Changes",
    "section": "",
    "text": "Bottom line: Week 1 is now exciting, physics-focused, and gets students creating visualizations in minutes instead of hours. The technical details are still there, but they‚Äôre optional reference material instead of required reading.\nStudents will leave Week 1 thinking ‚ÄúI can do physics with code!‚Äù instead of ‚ÄúI learned about Jupyter‚Äôs architecture.‚Äù\n\nDate of Changes: Generated during course restructuring consultation Philosophy: Physics first, technical details second, engagement always"
  },
  {
    "objectID": "seminars/seminar10/seminar11.html#what-are-neural-networks",
    "href": "seminars/seminar10/seminar11.html#what-are-neural-networks",
    "title": "Neural Networks",
    "section": "What are Neural Networks?",
    "text": "What are Neural Networks?\nNeural networks are computational models inspired by how our brains process information. Just like our brain consists of interconnected neurons that process and transmit signals, artificial neural networks consist of mathematical ‚Äúneurons‚Äù that process numerical information. They‚Äôre particularly powerful for:\n\nRecognizing patterns in data\nMaking predictions\nClassifying information\nSolving complex problems"
  },
  {
    "objectID": "seminars/seminar10/seminar11.html#why-neural-networks-in-physics",
    "href": "seminars/seminar10/seminar11.html#why-neural-networks-in-physics",
    "title": "Neural Networks",
    "section": "Why Neural Networks in Physics?",
    "text": "Why Neural Networks in Physics?\nIn physics, we often encounter problems where:\n\nTraditional mathematical models become too complex\nWe need to analyze large amounts of experimental data\nWe want to make predictions based on incomplete information\n\nNeural networks help us with these challenges! Some real-world applications include:\n\nParticle physics: Identifying particles in detector data\nAstronomy: Classifying galaxies\nMaterials science: Predicting material properties\nQuantum mechanics: Solving many-body problems\nBiological physics: Modeling neural activity\nActive matter: Predicting collective behavior"
  },
  {
    "objectID": "seminars/seminar10/seminar11.html#a-single-neuron-building-our-first-ai-unit",
    "href": "seminars/seminar10/seminar11.html#a-single-neuron-building-our-first-ai-unit",
    "title": "Neural Networks",
    "section": "A Single Neuron: Building Our First AI Unit",
    "text": "A Single Neuron: Building Our First AI Unit\n\nThe Big Picture\nBefore diving into the details, let‚Äôs understand what we‚Äôre trying to build. Imagine you‚Äôre creating a smart device that can recognize handwritten numbers. The most basic version of this device would be a single artificial neuron - think of it as an electronic version of a brain cell that can make simple yes/no decisions.\n\n\nFrom Biology to Mathematics\nJust like a biological neuron receives signals from other neurons, our artificial neuron processes numerical inputs through mathematical operations to produce a single output value.\nThe neuron performs three distinct steps:\n\nInput Weighting Each input value gets multiplied by a weight parameter:\n\n\\[\\begin{eqnarray}\nx_{1}\\rightarrow x_{1} w_{1}\\\\\nx_{2}\\rightarrow x_{2} w_{2}\n\\end{eqnarray}\\]\n\nBias Addition A bias value \\(b\\) is added to the weighted sum:\n\n\\[\\begin{equation}\nx_{1} w_{1}+ x_{2} w_{2}+b\n\\end{equation}\\]\n\nActivation Function The final step applies an activation function \\(\\sigma()\\):\n\n\\[\\begin{equation}\ny=\\sigma( x_{1} w_{1}+ x_{2} w_{2}+b)\n\\end{equation}\\]\nFor mathematical convenience, we can write this more compactly using vector notation:\n\\[\\begin{equation*}\n\\hat{y} = \\sigma(w^{\\rm T} x + b)\n\\end{equation*}\\]\nThe sigmoid function has the following mathematical form: \\[\\begin{equation*}\n\\sigma(z) = \\frac{1}{1+{\\rm e}^{-z}}\n\\end{equation*}\\]\nLet‚Äôs implement the sigmoid function and visualize how it transforms inputs:\n\n\n\n\n\n\n\n\n\n\n\n\nNow let‚Äôs see how a neuron processes inputs through these operations. Given:\n\\[\\begin{eqnarray}\nw=[0,1]\\\\\nb=4\n\\end{eqnarray}\\]\nAnd input values:\n\\[\\begin{eqnarray}\nx=[2,3]\n\\end{eqnarray}\\]\nThe computation becomes:\n\n\n\n\n\n\nFor computational efficiency, these calculations can be performed on multiple inputs simultaneously using matrix operations:\n\\[\\begin{equation*}\n\\hat{y} = \\sigma(w^{\\rm T} X + b)\n\\end{equation*}\\]"
  },
  {
    "objectID": "seminars/seminar10/seminar11.html#loss-function-measuring-our-networks-mistakes",
    "href": "seminars/seminar10/seminar11.html#loss-function-measuring-our-networks-mistakes",
    "title": "Neural Networks",
    "section": "Loss Function: Measuring Our Network‚Äôs Mistakes",
    "text": "Loss Function: Measuring Our Network‚Äôs Mistakes\n\nWhy Do We Need a Loss Function?\nJust like we need a way to measure error in physics experiments, we need a way to measure how wrong our neural network‚Äôs predictions are. The loss function serves this purpose - it tells us how far our predictions are from the true values.\n\n\nUnderstanding Cross-Entropy Loss\nWhile we could use simpler measures like mean squared error:\n\\[\\begin{equation}\nMSE(y,\\hat{y})=\\frac{1}{n}\\sum_{i=1}^{n}(y-\\hat{y})^2\n\\end{equation}\\]\nWe‚Äôll use a more sophisticated measure called cross-entropy loss. For a single training example, the formula is:\n\\[\\begin{equation*}\nL(y,\\hat{y}) = -y\\log(\\hat{y})-(1-y)\\log(1-\\hat{y})\n\\end{equation*}\\]\nPhysics Analogy: This is similar to entropy in thermodynamics - it measures the disorder or uncertainty in our predictions.\nWhen dealing with multiple training examples (\\(m\\) of them), we average the loss:\n\\[\\begin{equation*}\nL(Y,\\hat{Y}) = -\\frac{1}{m}\\sum_{i = 0}^{m}y^{(i)}\\log(\\hat{y}^{(i)})-(1-y^{(i)})\\log(1-\\hat{y}^{(i)})\n\\end{equation*}\\]\nLet‚Äôs implement this in code:\n\n\n\n\n\n\n\n\nTraining the Network: The Big Picture\nThe goal of training is to minimize this loss function. We do this by adjusting the weights and biases of our network. Let‚Äôs see how this works:\n\n\n\n\n\n\n\n\nBackward Propagation: Finding the Path to Improvement\nThe loss function \\(L\\) depends on all our weights and biases:\n\\[\nL(w_{1},w_{2},w_{3},\\ldots ,b_{1},b_{2},b_{3},\\ldots)\n\\]\nTo minimize the loss, we need to know how it changes when we adjust each weight. This is where partial derivatives come in:\n\\[\n\\frac{\\partial L}{\\partial w_j}\n\\]\nBreaking this down step by step, we use the chain rule:\n\\[\\begin{align*}\n\\frac{\\partial L}{\\partial w_j} = \\frac{\\partial L}{\\partial \\hat{y}}\\frac{\\partial \\hat{y}}{\\partial z}\\frac{\\partial z}{\\partial w_j}\n\\end{align*}\\]\nLet‚Äôs calculate each term:\n\n\\(\\partial L/\\partial\\hat{y}\\): \\[\\begin{align*}\n\\frac{\\partial L}{\\partial\\hat{y}} &= \\frac{\\partial}{\\partial\\hat{y}}\\left(-y\\log(\\hat{y})-(1-y)\\log(1-\\hat{y})\\right) \\\\\n&= -\\frac{y}{\\hat{y}} +\\frac{(1 - y)}{1-\\hat{y}} \\\\\n&= \\frac{\\hat{y} - y}{\\hat{y}(1-\\hat{y})}\n\\end{align*}\\]\n\\(\\partial \\hat{y}/\\partial z\\): \\[\\begin{align*}\n\\frac{\\partial }{\\partial z}\\sigma(z) &= \\sigma(z)(1-\\sigma(z)) \\\\\n&= \\hat{y}(1-\\hat{y})\n\\end{align*}\\]\n\\(\\partial z/\\partial w_j\\): \\[\\begin{align*}\n\\frac{\\partial }{\\partial w_j}(w^{\\rm T} x + b) = x_j\n\\end{align*}\\]\n\nPutting it all together: \\[\\begin{align*}\n\\frac{\\partial L}{\\partial w_j} = (\\hat{y} - y)x_j\n\\end{align*}\\]\nFor multiple training examples, in vector form: \\[\\begin{align*}\n\\frac{\\partial L}{\\partial w} = \\frac{1}{m} X(\\hat{y} - y)^{\\rm T}\n\\end{align*}\\]\nSimilarly for the bias: \\[\\begin{align*}\n\\frac{\\partial L}{\\partial b} = \\frac{1}{m}\\sum_{i=1}^{m}{(\\hat{y}^{(i)} - y^{(i)})}\n\\end{align*}\\]\n\n\nInteractive Example: Watching Gradients\n\n\n\n\n\n\n\n\nKey Points to Remember:\n\nThe loss function measures prediction errors\nCross-entropy loss is particularly suitable for classification problems\nGradients tell us how to adjust weights and biases\nThe chain rule helps us compute these gradients efficiently"
  },
  {
    "objectID": "seminars/seminar10/seminar11.html#training-the-network-putting-it-all-together",
    "href": "seminars/seminar10/seminar11.html#training-the-network-putting-it-all-together",
    "title": "Neural Networks",
    "section": "Training the Network: Putting It All Together",
    "text": "Training the Network: Putting It All Together\n\nStochastic Gradient Descent (SGD)\nNow that we understand how to compute gradients, we can use them to train our network. The basic idea is simple: 1. Calculate how wrong we are (loss) 2. Calculate how to improve (gradients) 3. Take a small step in the right direction\nThis process is called Stochastic Gradient Descent (SGD). The mathematical update rule is:\n\\[\nw\\leftarrow w-\\eta\\frac{\\partial L}{\\partial w}\n\\]\nwhere \\(\\eta\\) is the learning rate - a small number that controls how big our improvement steps are.\nPhysics Analogy: This is similar to finding the minimum of a potential well. The gradient tells us which way is ‚Äúdownhill‚Äù, and we take small steps in that direction.\n\n\nBuilding Our First Complete Network\nLet‚Äôs implement a complete training loop. We‚Äôll use: - Learning rate \\(\\eta = 1\\) - 200 training epochs (complete passes through the data)\n\n\n\n\n\n\n\n\nEvaluating Our Network: The Confusion Matrix\nTo understand how well our network performs, we use a confusion matrix. This shows: - True Positives (TP): Correctly predicted positive cases - False Positives (FP): Incorrectly predicted positive cases - True Negatives (TN): Correctly predicted negative cases - False Negatives (FN): Incorrectly predicted negative cases\n\n\n\nconfusion_matrix\n\n\nLet‚Äôs evaluate our model on the test data:\n\n\n\n\n\n\n\n\nTesting Individual Predictions\nLet‚Äôs visualize how our network performs on a single test image:\n\n\n\n\n\n\n\n\nUnderstanding the Results:\n\nThe confusion matrix shows us where our model makes mistakes\nThe classification report gives us metrics like:\n\nPrecision: How many of our positive predictions were correct\nRecall: How many actual positive cases did we catch\nF1-score: A balanced measure of precision and recall\n\n\n\n\nKey Points to Remember:\n\nTraining is an iterative process of:\n\nForward propagation\nLoss calculation\nBackward propagation\nParameter updates\n\nThe learning rate controls how quickly we update our parameters\nWe evaluate performance using confusion matrices and classification metrics"
  },
  {
    "objectID": "seminars/seminar05/mdsim.html",
    "href": "seminars/seminar05/mdsim.html",
    "title": "Step-by-Step Development of a Molecular Dynamics Simulation",
    "section": "",
    "text": "# %% Load  modules and initialize\nfrom typing_extensions import ParamSpec\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom IPython.display import clear_output\nimport matplotlib.patches as patches\nplt.rcParams.update({'font.size': 8,\n                     'lines.linewidth': 1,\n                     'lines.markersize': 10,\n                     'axes.labelsize': 10,\n                     'axes.titlesize': 10,\n                     'xtick.labelsize' : 10,\n                     'ytick.labelsize' : 10,\n                     'xtick.top' : True,\n                     'xtick.direction' : 'in',\n                     'ytick.right' : True,\n                     'ytick.direction' : 'in',\n                     'figure.facecolor' : 'white',})\n\ndef get_size(w,h):\n    return((w/2.54,h/2.54))\n\n\n# %% Load the atom class we did already in the previous seminar\nclass Atom:\n    def __init__(self, atom_id, atom_type, position, velocity=None, mass=None):\n        self.id = atom_id\n        self.type = atom_type\n        self.position = position\n        self.velocity = velocity if velocity is not None else np.random.randn(2)*20\n        self.mass = mass\n        self.force = np.zeros(2)\n\n\n    def add_force(self, force):\n        \"\"\"Add force contribution to total force on atom\"\"\"\n        self.force += force\n\n    def reset_force(self):\n        \"\"\"Reset force to zero at start of each step\"\"\"\n        self.force = np.zeros(2)\n\n    def update_position(self, dt):\n        \"\"\"First step of velocity Verlet: update position\"\"\"\n        self.position += self.velocity * dt + 0.5 * (self.force/self.mass) * dt**2\n\n    def update_velocity(self, dt, new_force):\n        \"\"\"Second step of velocity Verlet: update velocity using average force\"\"\"\n        self.velocity += 0.5 * (new_force + self.force)/self.mass * dt\n        self.force = new_force\n\n    def apply_periodic_boundaries(self, box_size):\n            \"\"\"Apply periodic boundary conditions\"\"\"\n            self.position = self.position % box_size\n\nclass ForceField:\n    def __init__(self):\n        self.parameters = {\n            'C': {'epsilon': 1.615, 'sigma': 1.36},\n            'H': {'epsilon': 1.0, 'sigma': 1.0 },\n            'O': {'epsilon': 1.846, 'sigma': 3.0},\n        }\n        self.bond_parameters = {\n            ('H', 'H'): {'k': 500.0, 'r0': 0.74},  # Example parameters for H2\n            ('O', 'H'): {'k': 550.0, 'r0': 0.96},  # Example parameters for OH bond\n        }\n        self.box_size = None\n\n    def calculate_bond_force(self, bond):\n        \"\"\"Calculate harmonic bond force\"\"\"\n        r = self.minimum_image_distance(bond.atom1.position, bond.atom2.position)\n        r_mag = np.linalg.norm(r)\n\n        # F = -k(r - r0)‚àô(r/|r|)\n        force_mag = -bond.k * (r_mag - bond.r0)\n        force = force_mag * r/r_mag\n        return force\n\n    def get_pair_parameters(self, type1, type2):\n        # Apply mixing rules when needed\n        eps1 = self.parameters[type1]['epsilon']\n        eps2 = self.parameters[type2]['epsilon']\n        sig1 = self.parameters[type1]['sigma']\n        sig2 = self.parameters[type2]['sigma']\n\n        # Lorentz-Berthelot mixing rules\n        epsilon = np.sqrt(eps1 * eps2)\n        sigma = (sig1 + sig2) / 2\n\n        return epsilon, sigma\n\n    def minimum_image_distance(self, pos1, pos2):\n        \"\"\"Calculate minimum image distance between two positions\"\"\"\n        delta = pos1 - pos2\n        # Apply minimum image convention\n        delta = delta - self.box_size * np.round(delta / self.box_size)\n        return delta\n\n    def calculate_lj_force(self, atom1, atom2):\n        epsilon, sigma = self.get_pair_parameters(atom1.type, atom2.type)\n        r = self.minimum_image_distance(atom1.position, atom2.position)\n        r_mag = np.linalg.norm(r)\n\n        # Add cutoff distance for stability\n        if r_mag &gt; 3.5*sigma:\n            return np.zeros(2)\n\n        force_mag = 24 * epsilon * (\n            2 * (sigma/r_mag)**13\n            - (sigma/r_mag)**7\n        )\n        force = force_mag * r/r_mag\n        return force\n\n\n# %% Diatomic Molecule Definition\nclass DiatomicMolecule:\n    def __init__(self, atom1, atom2, bond):\n        self.atom1 = atom1\n        self.atom2 = atom2\n        self.bond = bond\n\n\n# %% Define the MD Simulation master controller class\n\nclass MDSimulation:\n    def __init__(self, molecules, forcefield, timestep, box_size):\n        self.molecules = molecules\n        self.atoms = [atom for mol in molecules for atom in [mol.atom1, mol.atom2]]\n        self.forcefield = forcefield\n        self.forcefield.box_size = box_size\n        self.timestep = timestep\n        self.box_size = np.array(box_size)\n        self.energy_history = []\n\n\n    def calculate_forces(self):\n        # Reset all forces\n        for atom in self.atoms:\n            atom.reset_force()\n\n        # Calculate bonded forces\n        for molecule in self.molecules:\n            force = self.forcefield.calculate_bond_force(molecule.bond)\n            molecule.atom1.add_force(force)\n            molecule.atom2.add_force(-force)\n\n        # Calculate non-bonded forces between molecules\n        for i, mol1 in enumerate(self.molecules):\n            for mol2 in self.molecules[i+1:]:\n                # Calculate forces between atoms of different molecules\n                for atom1 in [mol1.atom1, mol1.atom2]:\n                    for atom2 in [mol2.atom1, mol2.atom2]:\n                        force = self.forcefield.calculate_lj_force(atom1, atom2)\n                        atom1.add_force(force)\n                        atom2.add_force(-force)\n\n    def update_positions_and_velocities(self):\n        # First step: Update positions using current forces\n        for atom in self.atoms:\n            atom.update_position(self.timestep)\n            # Apply periodic boundary conditions\n            atom.apply_periodic_boundaries(self.box_size)\n\n        # Recalculate forces with new positions\n        self.calculate_forces()\n\n        # Second step: Update velocities using average of old and new forces\n        for atom in self.atoms:\n            atom.update_velocity(self.timestep, atom.force)\n\n\n# %% Cell 6\ndef create_grid_atoms(num_atoms, box_size, type=\"H\",mass=1.0, random_offset=0.1):\n    box_size = np.array(box_size)\n\n    # Calculate grid dimensions\n    n = int(np.ceil(np.sqrt(num_atoms)))\n    spacing = np.min(box_size) / n\n\n    atoms = []\n    for i in range(num_atoms):\n        # Calculate grid position\n        row = i // n\n        col = i % n\n\n        # Base position\n        pos = np.array([col * spacing + spacing/2,\n                       row * spacing + spacing/2])\n\n        # Add random offset\n        pos += (np.random.rand(2) - 0.5) * spacing * random_offset\n\n        # Create atom\n        atoms.append(Atom(i, type, pos, mass=mass))\n\n    return atoms\n\n\n# %% Create diatomic Molecules\n#\ndef create_diatomic_molecules(num_molecules, box_size, type1=\"H\", type2=\"H\", mass1=1.0, mass2=1.0):\n    molecules = []\n    spacing = np.min(box_size) / np.ceil(np.sqrt(num_molecules))\n\n    for i in range(num_molecules):\n        # Calculate grid position for molecule center\n        row = i // int(np.ceil(np.sqrt(num_molecules)))\n        col = i % int(np.ceil(np.sqrt(num_molecules)))\n        center = np.array([col * spacing + spacing/2, row * spacing + spacing/2])\n\n        # Create atoms with small random displacement for initial bond length\n        displacement = np.random.randn(2) * 0.1\n        atom1 = Atom(2*i, type1, center + displacement, mass=mass1)\n        atom2 = Atom(2*i+1, type2, center - displacement, mass=mass2)\n\n        # Create bond\n        ff = ForceField()\n        bond_params = ff.bond_parameters[(type1, type2)]\n        bond = Bond(atom1, atom2, bond_params['k'], bond_params['r0'])\n\n        molecules.append(DiatomicMolecule(atom1, atom2, bond))\n\n    return molecules\n\n# %% Cell 7\ndef set_temperature(atoms, target_temperature):\n    N = len(atoms)      # number of atoms\n    Nf = 2 * N         # degrees of freedom in 2D\n\n    # Calculate current kinetic energy\n    current_ke = sum(0.5 * atom.mass * np.sum(atom.velocity**2) for atom in atoms)\n    current_temperature = 2 * current_ke / Nf  # kb = 1 in reduced units\n    print(current_temperature)\n    # Calculate scaling factor\n    scale_factor = np.sqrt(target_temperature / current_temperature)\n\n    # Scale velocities\n    for atom in atoms:\n        atom.velocity *= scale_factor\n\n\ndef initialize_velocities(atoms, temperature, seed=None):\n    if seed is not None:\n        np.random.seed(seed)\n\n    N = len(atoms)  # number of atoms\n    dim = 2         # 2D simulation\n\n    # Generate random velocities from normal distribution\n    velocities = np.random.normal(0, np.sqrt(temperature), size=(N, dim))\n\n    # Remove center of mass motion\n    total_momentum = np.sum([atom.mass * velocities[i] for i, atom in enumerate(atoms)], axis=0)\n    total_mass = np.sum([atom.mass for atom in atoms])\n    cm_velocity = total_momentum / total_mass\n\n    # Assign velocities to atoms\n    for i, atom in enumerate(atoms):\n        atom.velocity = velocities[i] - cm_velocity\n\n    # Scale velocities to exact temperature\n    set_temperature(atoms, temperature)\n\n    return atoms\n\n# %% run the simulation w\n\nT=5\ndt = 0.01\nbox_size = np.array([50.0, 50.0])\nnum_molecules = 100\nmolecules = create_diatomic_molecules(num_molecules, box_size, \"H\", \"H\")\nff = ForceField()\nsim = MDSimulation(molecules, ff, dt, box_size)\n\n# Initialize velocities for all atoms\natoms = [atom for mol in molecules for atom in [mol.atom1, mol.atom2]]\ninitialize_velocities(atoms, temperature=T)\n\nfig, ax = plt.subplots(1,1,figsize=(6,6))\n\nfor step in range(1000):\n    clear_output(wait=True)\n    set_temperature(atoms, target_temperature=T)\n    sim.update_positions_and_velocities()\n\n\n    positions = [atom.position for atom in sim.atoms]\n    x_coords = [pos[0] for pos in positions]\n    y_coords = [pos[1] for pos in positions]\n\n    circle=patches.Circle((x_coords[0],y_coords[0]),ff.parameters[atoms[0].type][\"sigma\"],edgecolor=\"white\",fill=False)\n    ax.add_patch(circle)\n    ax.scatter(x_coords, y_coords,color=\"red\")\n    ax.set_xlim(0, box_size[0])\n    ax.set_ylim(0, box_size[1])\n    ax.axis(\"off\")\n\n    display(fig)\n\n    ax.clear()\n# %% Cell 8\n#\n\nvx=np.array([atom.velocity for atom in atoms])\n\nvx.reshape(200,2)\nplt.hist(vx[:,0],bins=20)"
  },
  {
    "objectID": "seminars/seminar05/mdsim.html#here-is-the-complete-code-for-the-molecular-dynamics-simulation",
    "href": "seminars/seminar05/mdsim.html#here-is-the-complete-code-for-the-molecular-dynamics-simulation",
    "title": "Step-by-Step Development of a Molecular Dynamics Simulation",
    "section": "",
    "text": "# %% Load  modules and initialize\nfrom typing_extensions import ParamSpec\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom IPython.display import clear_output\nimport matplotlib.patches as patches\nplt.rcParams.update({'font.size': 8,\n                     'lines.linewidth': 1,\n                     'lines.markersize': 10,\n                     'axes.labelsize': 10,\n                     'axes.titlesize': 10,\n                     'xtick.labelsize' : 10,\n                     'ytick.labelsize' : 10,\n                     'xtick.top' : True,\n                     'xtick.direction' : 'in',\n                     'ytick.right' : True,\n                     'ytick.direction' : 'in',\n                     'figure.facecolor' : 'white',})\n\ndef get_size(w,h):\n    return((w/2.54,h/2.54))\n\n\n# %% Load the atom class we did already in the previous seminar\nclass Atom:\n    def __init__(self, atom_id, atom_type, position, velocity=None, mass=None):\n        self.id = atom_id\n        self.type = atom_type\n        self.position = position\n        self.velocity = velocity if velocity is not None else np.random.randn(2)*20\n        self.mass = mass\n        self.force = np.zeros(2)\n\n\n    def add_force(self, force):\n        \"\"\"Add force contribution to total force on atom\"\"\"\n        self.force += force\n\n    def reset_force(self):\n        \"\"\"Reset force to zero at start of each step\"\"\"\n        self.force = np.zeros(2)\n\n    def update_position(self, dt):\n        \"\"\"First step of velocity Verlet: update position\"\"\"\n        self.position += self.velocity * dt + 0.5 * (self.force/self.mass) * dt**2\n\n    def update_velocity(self, dt, new_force):\n        \"\"\"Second step of velocity Verlet: update velocity using average force\"\"\"\n        self.velocity += 0.5 * (new_force + self.force)/self.mass * dt\n        self.force = new_force\n\n    def apply_periodic_boundaries(self, box_size):\n            \"\"\"Apply periodic boundary conditions\"\"\"\n            self.position = self.position % box_size\n\nclass ForceField:\n    def __init__(self):\n        self.parameters = {\n            'C': {'epsilon': 1.615, 'sigma': 1.36},\n            'H': {'epsilon': 1.0, 'sigma': 1.0 },\n            'O': {'epsilon': 1.846, 'sigma': 3.0},\n        }\n        self.bond_parameters = {\n            ('H', 'H'): {'k': 500.0, 'r0': 0.74},  # Example parameters for H2\n            ('O', 'H'): {'k': 550.0, 'r0': 0.96},  # Example parameters for OH bond\n        }\n        self.box_size = None\n\n    def calculate_bond_force(self, bond):\n        \"\"\"Calculate harmonic bond force\"\"\"\n        r = self.minimum_image_distance(bond.atom1.position, bond.atom2.position)\n        r_mag = np.linalg.norm(r)\n\n        # F = -k(r - r0)‚àô(r/|r|)\n        force_mag = -bond.k * (r_mag - bond.r0)\n        force = force_mag * r/r_mag\n        return force\n\n    def get_pair_parameters(self, type1, type2):\n        # Apply mixing rules when needed\n        eps1 = self.parameters[type1]['epsilon']\n        eps2 = self.parameters[type2]['epsilon']\n        sig1 = self.parameters[type1]['sigma']\n        sig2 = self.parameters[type2]['sigma']\n\n        # Lorentz-Berthelot mixing rules\n        epsilon = np.sqrt(eps1 * eps2)\n        sigma = (sig1 + sig2) / 2\n\n        return epsilon, sigma\n\n    def minimum_image_distance(self, pos1, pos2):\n        \"\"\"Calculate minimum image distance between two positions\"\"\"\n        delta = pos1 - pos2\n        # Apply minimum image convention\n        delta = delta - self.box_size * np.round(delta / self.box_size)\n        return delta\n\n    def calculate_lj_force(self, atom1, atom2):\n        epsilon, sigma = self.get_pair_parameters(atom1.type, atom2.type)\n        r = self.minimum_image_distance(atom1.position, atom2.position)\n        r_mag = np.linalg.norm(r)\n\n        # Add cutoff distance for stability\n        if r_mag &gt; 3.5*sigma:\n            return np.zeros(2)\n\n        force_mag = 24 * epsilon * (\n            2 * (sigma/r_mag)**13\n            - (sigma/r_mag)**7\n        )\n        force = force_mag * r/r_mag\n        return force\n\n\n# %% Diatomic Molecule Definition\nclass DiatomicMolecule:\n    def __init__(self, atom1, atom2, bond):\n        self.atom1 = atom1\n        self.atom2 = atom2\n        self.bond = bond\n\n\n# %% Define the MD Simulation master controller class\n\nclass MDSimulation:\n    def __init__(self, molecules, forcefield, timestep, box_size):\n        self.molecules = molecules\n        self.atoms = [atom for mol in molecules for atom in [mol.atom1, mol.atom2]]\n        self.forcefield = forcefield\n        self.forcefield.box_size = box_size\n        self.timestep = timestep\n        self.box_size = np.array(box_size)\n        self.energy_history = []\n\n\n    def calculate_forces(self):\n        # Reset all forces\n        for atom in self.atoms:\n            atom.reset_force()\n\n        # Calculate bonded forces\n        for molecule in self.molecules:\n            force = self.forcefield.calculate_bond_force(molecule.bond)\n            molecule.atom1.add_force(force)\n            molecule.atom2.add_force(-force)\n\n        # Calculate non-bonded forces between molecules\n        for i, mol1 in enumerate(self.molecules):\n            for mol2 in self.molecules[i+1:]:\n                # Calculate forces between atoms of different molecules\n                for atom1 in [mol1.atom1, mol1.atom2]:\n                    for atom2 in [mol2.atom1, mol2.atom2]:\n                        force = self.forcefield.calculate_lj_force(atom1, atom2)\n                        atom1.add_force(force)\n                        atom2.add_force(-force)\n\n    def update_positions_and_velocities(self):\n        # First step: Update positions using current forces\n        for atom in self.atoms:\n            atom.update_position(self.timestep)\n            # Apply periodic boundary conditions\n            atom.apply_periodic_boundaries(self.box_size)\n\n        # Recalculate forces with new positions\n        self.calculate_forces()\n\n        # Second step: Update velocities using average of old and new forces\n        for atom in self.atoms:\n            atom.update_velocity(self.timestep, atom.force)\n\n\n# %% Cell 6\ndef create_grid_atoms(num_atoms, box_size, type=\"H\",mass=1.0, random_offset=0.1):\n    box_size = np.array(box_size)\n\n    # Calculate grid dimensions\n    n = int(np.ceil(np.sqrt(num_atoms)))\n    spacing = np.min(box_size) / n\n\n    atoms = []\n    for i in range(num_atoms):\n        # Calculate grid position\n        row = i // n\n        col = i % n\n\n        # Base position\n        pos = np.array([col * spacing + spacing/2,\n                       row * spacing + spacing/2])\n\n        # Add random offset\n        pos += (np.random.rand(2) - 0.5) * spacing * random_offset\n\n        # Create atom\n        atoms.append(Atom(i, type, pos, mass=mass))\n\n    return atoms\n\n\n# %% Create diatomic Molecules\n#\ndef create_diatomic_molecules(num_molecules, box_size, type1=\"H\", type2=\"H\", mass1=1.0, mass2=1.0):\n    molecules = []\n    spacing = np.min(box_size) / np.ceil(np.sqrt(num_molecules))\n\n    for i in range(num_molecules):\n        # Calculate grid position for molecule center\n        row = i // int(np.ceil(np.sqrt(num_molecules)))\n        col = i % int(np.ceil(np.sqrt(num_molecules)))\n        center = np.array([col * spacing + spacing/2, row * spacing + spacing/2])\n\n        # Create atoms with small random displacement for initial bond length\n        displacement = np.random.randn(2) * 0.1\n        atom1 = Atom(2*i, type1, center + displacement, mass=mass1)\n        atom2 = Atom(2*i+1, type2, center - displacement, mass=mass2)\n\n        # Create bond\n        ff = ForceField()\n        bond_params = ff.bond_parameters[(type1, type2)]\n        bond = Bond(atom1, atom2, bond_params['k'], bond_params['r0'])\n\n        molecules.append(DiatomicMolecule(atom1, atom2, bond))\n\n    return molecules\n\n# %% Cell 7\ndef set_temperature(atoms, target_temperature):\n    N = len(atoms)      # number of atoms\n    Nf = 2 * N         # degrees of freedom in 2D\n\n    # Calculate current kinetic energy\n    current_ke = sum(0.5 * atom.mass * np.sum(atom.velocity**2) for atom in atoms)\n    current_temperature = 2 * current_ke / Nf  # kb = 1 in reduced units\n    print(current_temperature)\n    # Calculate scaling factor\n    scale_factor = np.sqrt(target_temperature / current_temperature)\n\n    # Scale velocities\n    for atom in atoms:\n        atom.velocity *= scale_factor\n\n\ndef initialize_velocities(atoms, temperature, seed=None):\n    if seed is not None:\n        np.random.seed(seed)\n\n    N = len(atoms)  # number of atoms\n    dim = 2         # 2D simulation\n\n    # Generate random velocities from normal distribution\n    velocities = np.random.normal(0, np.sqrt(temperature), size=(N, dim))\n\n    # Remove center of mass motion\n    total_momentum = np.sum([atom.mass * velocities[i] for i, atom in enumerate(atoms)], axis=0)\n    total_mass = np.sum([atom.mass for atom in atoms])\n    cm_velocity = total_momentum / total_mass\n\n    # Assign velocities to atoms\n    for i, atom in enumerate(atoms):\n        atom.velocity = velocities[i] - cm_velocity\n\n    # Scale velocities to exact temperature\n    set_temperature(atoms, temperature)\n\n    return atoms\n\n# %% run the simulation w\n\nT=5\ndt = 0.01\nbox_size = np.array([50.0, 50.0])\nnum_molecules = 100\nmolecules = create_diatomic_molecules(num_molecules, box_size, \"H\", \"H\")\nff = ForceField()\nsim = MDSimulation(molecules, ff, dt, box_size)\n\n# Initialize velocities for all atoms\natoms = [atom for mol in molecules for atom in [mol.atom1, mol.atom2]]\ninitialize_velocities(atoms, temperature=T)\n\nfig, ax = plt.subplots(1,1,figsize=(6,6))\n\nfor step in range(1000):\n    clear_output(wait=True)\n    set_temperature(atoms, target_temperature=T)\n    sim.update_positions_and_velocities()\n\n\n    positions = [atom.position for atom in sim.atoms]\n    x_coords = [pos[0] for pos in positions]\n    y_coords = [pos[1] for pos in positions]\n\n    circle=patches.Circle((x_coords[0],y_coords[0]),ff.parameters[atoms[0].type][\"sigma\"],edgecolor=\"white\",fill=False)\n    ax.add_patch(circle)\n    ax.scatter(x_coords, y_coords,color=\"red\")\n    ax.set_xlim(0, box_size[0])\n    ax.set_ylim(0, box_size[1])\n    ax.axis(\"off\")\n\n    display(fig)\n\n    ax.clear()\n# %% Cell 8\n#\n\nvx=np.array([atom.velocity for atom in atoms])\n\nvx.reshape(200,2)\nplt.hist(vx[:,0],bins=20)"
  },
  {
    "objectID": "seminars/seminar05/md5.html",
    "href": "seminars/seminar05/md5.html",
    "title": "Step-by-Step Development of a Molecular Dynamics Simulation",
    "section": "",
    "text": "Previously we wrote our simulation with classes for the atoms, the force-field and the MD simulation.Now we want to implement the velocity initialization. We will use the Maxwell-Boltzmann distribution to generate random velocities for the particles in our system. This ensures that our system starts in a state of thermal equilibrium, reflecting the physical reality of molecular motion.\nThe Maxwell-Boltzmann distribution stands as a cornerstone principle in molecular dynamics (MD) simulations, providing us with a statistical description of particle velocities in a system at thermal equilibrium. This distribution emerged from the kinetic theory of gases and proves invaluable in understanding how molecules move and interact at various temperatures.\n\n\nAt its heart, the Maxwell-Boltzmann distribution tells us the probability of finding a particle moving at a particular velocity in a system at thermal equilibrium. The mathematical expression for this probability density \\(f(v)\\) is:\n\\[f(v) = \\sqrt{\\left(\\frac{m}{2\\pi k_B T}\\right)^3} 4\\pi v^2 \\exp\\left(-\\frac{mv^2}{2k_B T}\\right)\\]\nHere, \\(m\\) represents the particle mass, \\(k_B\\) is Boltzmann‚Äôs constant, \\(T\\) denotes the temperature in Kelvin, and \\(v\\) is the velocity magnitude. We can also write down the Maxwell-Boltzmann distribution in terms of the velocity components \\(v_x\\), \\(v_y\\), and \\(v_z\\). For each of these components, the distribution is given by\n\\[\nf(v_x) = \\sqrt{\\frac{m}{2\\pi k_B T}} \\exp\\left(-\\frac{m v_x^2}{2 k_B T}\\right)\n\\]\nThe Maxwell-Boltzmann distribution has the following properties\nThe mean velocity of the particles is of course zero as the system as a whole does not move. The mean magnitude of the velocity can be calculated from\n\\[\n\\bar{v}=\\int_0^{\\infty} v p(v) \\mathrm{d} v\n\\]\nwhich results in\n\\[\n\\bar{v}=\\sqrt{\\frac{8 k_{\\mathrm{B}} T}{\\pi m}}\n\\]\nWhat is also important is the mean squared velocity which can be calculated by\n\\[\n\\overline{v^2}=\\int_0^{\\infty} v^2 p(v) d v\n\\]\nsince this will provide the mean kinetic energy of the particles. This results in\n\\[\n\\overline{v^2}=\\frac{3 k_{\\mathrm{B}} T}{m}\n\\]\nThis is consisten with a kinetic energy of \\(1/2 k_{\\mathrm{B}} T\\) per degree of freedom.\nSince we use in MD simulations with Lennard-Jones atoms reduced units, we can also express the Maxwell-Boltzmann distribution in reduced units. The reduced temperature is defined as \\(T^{*}=k_{\\mathrm{B}} T / \\varepsilon\\) and the reduced velocity as \\(v^{*}=v / \\sqrt{\\varepsilon / m}\\). The reduced Maxwell-Boltzmann distribution is then\n\\[\nf(v^{*}) = \\sqrt{\\left(\\frac{1}{2\\pi T^{*}}\\right)^3} 4\\pi v^{*2} \\exp\\left(-\\frac{v^{2}}{2T^{*}}\\right)\n\\]\nOur goal is to generate random velocities for particles in our MD simulations that follow this distribution. This ensures that our system starts in a state of thermal equilibrium, reflecting the physical reality of molecular motion.\n\n\n\n\nviewof reducedTemp = Inputs.range([0.1, 5], {\n  step: 0.1,\n  value: 1.0,\n  label: \"Reduced Temperature (T*)\"\n})\n\n// Generate distribution data in reduced units\nfunction generateReducedData() {\n  const data = [];\n  // Generate points for reduced velocities from 0 to 5\n  for (let v = 0; v &lt;= 5; v += 0.05) {\n    const term1 = Math.sqrt((1 / (2 * Math.PI * reducedTemp)) ** 3);\n    const term2 = 4 * Math.PI * v * v;\n    const term3 = Math.exp((-v * v) / (2 * reducedTemp));\n    data.push({\n      velocity: v,\n      probability: term1 * term2 * term3\n    });\n  }\n  return data;\n}\n\nPlot.plot({\n  width: 400,\n  height: 400,\n  margin: 50,\n  grid: true,\n  style: {\n    fontSize: 16\n  },\n  x: {\n    label: \"Reduced Velocity (v*)\",\n    domain: [0, 5],\n  },\n  y: {\n    label: \"Probability Density\",\n  },\n  marks: [\n    Plot.line(generateReducedData(), {\n      x: \"velocity\",\n      y: \"probability\",\n      stroke: \"blue\"\n    })\n  ]\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe interactive plot above demonstrates how the Maxwell-Boltzmann distribution changes with temperature and molecular mass. Try adjusting the sliders to see how:\n\nIncreasing temperature broadens the distribution and shifts the peak to higher velocities\nIncreasing molecular mass narrows the distribution and shifts the peak to lower velocities\n\n\n\n\nWhen we begin an MD simulation, one of our first tasks is to assign initial velocities to all particles in our system. The Maxwell-Boltzmann distribution guides this process, ensuring that our initial configuration reflects physical reality. We typically generate random velocities following this distribution while ensuring that the total momentum of the system remains zero ‚Äì a condition that prevents our system from drifting as a whole.\n\n\n\nHere‚Äôs how we can implement velocity initialization following the Maxwell-Boltzmann distribution:\ndef initialize_velocities(atoms, temperature, seed=None):\n    if seed is not None:\n        np.random.seed(seed)\n\n    N = len(atoms)\n    dim = 2\n\n\n    velocities = np.random.normal(0, np.sqrt(temperature), size=(N, dim))\n\n\n    total_momentum = np.sum([atom.mass * velocities[i] for i, atom in enumerate(atoms)], axis=0)\n    total_mass = np.sum([atom.mass for atom in atoms])\n    cm_velocity = total_momentum / total_mass\n\n    for i, atom in enumerate(atoms):\n        atom.velocity = velocities[i] - cm_velocity\n\n    set_temperature(atoms, temperature)\n\n    return atoms\nIn molecular dynamics simulations, it is crucial to control the temperature of the system to ensure that it reflects the desired physical conditions. The temperature of a system in MD simulations is directly related to the kinetic energy of the particles. If the initial velocities of the particles do not correspond to the target temperature, the system will not accurately represent the intended thermodynamic state.\nScaling the velocities of the particles is a common technique to adjust the temperature of the system. By scaling the velocities, we can ensure that the kinetic energy‚Äîand hence the temperature‚Äîmatches the target value. This process is essential for initializing the system correctly and for maintaining the desired temperature during the simulation.\nThe provided code scales the velocities of the atoms to achieve the target temperature. Here‚Äôs a step-by-step explanation of the code:\n\ndef set_temperature(atoms, target_temperature):\n    N = len(atoms)      # number of atoms\n    Nf = 2 * N         # degrees of freedom in 2D\n\n    # Calculate current kinetic energy\n    current_ke = sum(0.5 * atom.mass * np.sum(atom.velocity**2) for atom in atoms)\n    current_temperature = 2 * current_ke / Nf  # kb = 1 in reduced units\n\n    # Calculate scaling factor\n    scale_factor = np.sqrt(target_temperature / current_temperature)\n\n    # Scale velocities\n    for atom in atoms:\n        atom.velocity *= scale_factor\n\nThis code snippet sets the temperature of the system to the target temperature by scaling the velocities of the atoms. Here‚Äôs a breakdown of the key steps:\n\nNumber of Atoms and Degrees of Freedom:\nN = len(atoms)      # number of atoms\nNf = 2 * N         # degrees of freedom in 2D\n\nN is the number of atoms in the system.\nNf is the number of degrees of freedom. In a 2D system, each atom has 2 degrees of freedom (one for each spatial dimension), so Nf = 2 * N.\n\nCalculate Current Kinetic Energy:\ncurrent_ke = sum(0.5 * atom.mass * np.sum(atom.velocity**2) for atom in atoms)\ncurrent_temperature = 2 * current_ke / Nf  # kb = 1 in reduced units\n\nThe current kinetic energy (current_ke) is calculated by summing the kinetic energy of each atom. The kinetic energy of an atom is given by ( m v^2 ), where m is the mass and v is the velocity.\nThe current temperature (current_temperature) is then calculated using the relation ( T = ). Here, the Boltzmann constant ( k_B ) is assumed to be 1 in reduced units.\n\nCalculate Scaling Factor:\nscale_factor = np.sqrt(target_temperature / current_temperature)\n\nThe scaling factor is calculated as the square root of the ratio of the target temperature to the current temperature. This factor will be used to scale the velocities of the atoms.\n\nScale Velocities:\nfor atom in atoms:\n    atom.velocity *= scale_factor\n\nThe velocities of all atoms are scaled by the calculated scaling factor. This adjustment ensures that the kinetic energy‚Äîand thus the temperature‚Äîof the system matches the target temperature."
  },
  {
    "objectID": "seminars/seminar05/md5.html#temperature-and-velocity-initialization",
    "href": "seminars/seminar05/md5.html#temperature-and-velocity-initialization",
    "title": "Step-by-Step Development of a Molecular Dynamics Simulation",
    "section": "",
    "text": "Previously we wrote our simulation with classes for the atoms, the force-field and the MD simulation.Now we want to implement the velocity initialization. We will use the Maxwell-Boltzmann distribution to generate random velocities for the particles in our system. This ensures that our system starts in a state of thermal equilibrium, reflecting the physical reality of molecular motion.\nThe Maxwell-Boltzmann distribution stands as a cornerstone principle in molecular dynamics (MD) simulations, providing us with a statistical description of particle velocities in a system at thermal equilibrium. This distribution emerged from the kinetic theory of gases and proves invaluable in understanding how molecules move and interact at various temperatures.\n\n\nAt its heart, the Maxwell-Boltzmann distribution tells us the probability of finding a particle moving at a particular velocity in a system at thermal equilibrium. The mathematical expression for this probability density \\(f(v)\\) is:\n\\[f(v) = \\sqrt{\\left(\\frac{m}{2\\pi k_B T}\\right)^3} 4\\pi v^2 \\exp\\left(-\\frac{mv^2}{2k_B T}\\right)\\]\nHere, \\(m\\) represents the particle mass, \\(k_B\\) is Boltzmann‚Äôs constant, \\(T\\) denotes the temperature in Kelvin, and \\(v\\) is the velocity magnitude. We can also write down the Maxwell-Boltzmann distribution in terms of the velocity components \\(v_x\\), \\(v_y\\), and \\(v_z\\). For each of these components, the distribution is given by\n\\[\nf(v_x) = \\sqrt{\\frac{m}{2\\pi k_B T}} \\exp\\left(-\\frac{m v_x^2}{2 k_B T}\\right)\n\\]\nThe Maxwell-Boltzmann distribution has the following properties\nThe mean velocity of the particles is of course zero as the system as a whole does not move. The mean magnitude of the velocity can be calculated from\n\\[\n\\bar{v}=\\int_0^{\\infty} v p(v) \\mathrm{d} v\n\\]\nwhich results in\n\\[\n\\bar{v}=\\sqrt{\\frac{8 k_{\\mathrm{B}} T}{\\pi m}}\n\\]\nWhat is also important is the mean squared velocity which can be calculated by\n\\[\n\\overline{v^2}=\\int_0^{\\infty} v^2 p(v) d v\n\\]\nsince this will provide the mean kinetic energy of the particles. This results in\n\\[\n\\overline{v^2}=\\frac{3 k_{\\mathrm{B}} T}{m}\n\\]\nThis is consisten with a kinetic energy of \\(1/2 k_{\\mathrm{B}} T\\) per degree of freedom.\nSince we use in MD simulations with Lennard-Jones atoms reduced units, we can also express the Maxwell-Boltzmann distribution in reduced units. The reduced temperature is defined as \\(T^{*}=k_{\\mathrm{B}} T / \\varepsilon\\) and the reduced velocity as \\(v^{*}=v / \\sqrt{\\varepsilon / m}\\). The reduced Maxwell-Boltzmann distribution is then\n\\[\nf(v^{*}) = \\sqrt{\\left(\\frac{1}{2\\pi T^{*}}\\right)^3} 4\\pi v^{*2} \\exp\\left(-\\frac{v^{2}}{2T^{*}}\\right)\n\\]\nOur goal is to generate random velocities for particles in our MD simulations that follow this distribution. This ensures that our system starts in a state of thermal equilibrium, reflecting the physical reality of molecular motion.\n\n\n\n\nviewof reducedTemp = Inputs.range([0.1, 5], {\n  step: 0.1,\n  value: 1.0,\n  label: \"Reduced Temperature (T*)\"\n})\n\n// Generate distribution data in reduced units\nfunction generateReducedData() {\n  const data = [];\n  // Generate points for reduced velocities from 0 to 5\n  for (let v = 0; v &lt;= 5; v += 0.05) {\n    const term1 = Math.sqrt((1 / (2 * Math.PI * reducedTemp)) ** 3);\n    const term2 = 4 * Math.PI * v * v;\n    const term3 = Math.exp((-v * v) / (2 * reducedTemp));\n    data.push({\n      velocity: v,\n      probability: term1 * term2 * term3\n    });\n  }\n  return data;\n}\n\nPlot.plot({\n  width: 400,\n  height: 400,\n  margin: 50,\n  grid: true,\n  style: {\n    fontSize: 16\n  },\n  x: {\n    label: \"Reduced Velocity (v*)\",\n    domain: [0, 5],\n  },\n  y: {\n    label: \"Probability Density\",\n  },\n  marks: [\n    Plot.line(generateReducedData(), {\n      x: \"velocity\",\n      y: \"probability\",\n      stroke: \"blue\"\n    })\n  ]\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe interactive plot above demonstrates how the Maxwell-Boltzmann distribution changes with temperature and molecular mass. Try adjusting the sliders to see how:\n\nIncreasing temperature broadens the distribution and shifts the peak to higher velocities\nIncreasing molecular mass narrows the distribution and shifts the peak to lower velocities\n\n\n\n\nWhen we begin an MD simulation, one of our first tasks is to assign initial velocities to all particles in our system. The Maxwell-Boltzmann distribution guides this process, ensuring that our initial configuration reflects physical reality. We typically generate random velocities following this distribution while ensuring that the total momentum of the system remains zero ‚Äì a condition that prevents our system from drifting as a whole.\n\n\n\nHere‚Äôs how we can implement velocity initialization following the Maxwell-Boltzmann distribution:\ndef initialize_velocities(atoms, temperature, seed=None):\n    if seed is not None:\n        np.random.seed(seed)\n\n    N = len(atoms)\n    dim = 2\n\n\n    velocities = np.random.normal(0, np.sqrt(temperature), size=(N, dim))\n\n\n    total_momentum = np.sum([atom.mass * velocities[i] for i, atom in enumerate(atoms)], axis=0)\n    total_mass = np.sum([atom.mass for atom in atoms])\n    cm_velocity = total_momentum / total_mass\n\n    for i, atom in enumerate(atoms):\n        atom.velocity = velocities[i] - cm_velocity\n\n    set_temperature(atoms, temperature)\n\n    return atoms\nIn molecular dynamics simulations, it is crucial to control the temperature of the system to ensure that it reflects the desired physical conditions. The temperature of a system in MD simulations is directly related to the kinetic energy of the particles. If the initial velocities of the particles do not correspond to the target temperature, the system will not accurately represent the intended thermodynamic state.\nScaling the velocities of the particles is a common technique to adjust the temperature of the system. By scaling the velocities, we can ensure that the kinetic energy‚Äîand hence the temperature‚Äîmatches the target value. This process is essential for initializing the system correctly and for maintaining the desired temperature during the simulation.\nThe provided code scales the velocities of the atoms to achieve the target temperature. Here‚Äôs a step-by-step explanation of the code:\n\ndef set_temperature(atoms, target_temperature):\n    N = len(atoms)      # number of atoms\n    Nf = 2 * N         # degrees of freedom in 2D\n\n    # Calculate current kinetic energy\n    current_ke = sum(0.5 * atom.mass * np.sum(atom.velocity**2) for atom in atoms)\n    current_temperature = 2 * current_ke / Nf  # kb = 1 in reduced units\n\n    # Calculate scaling factor\n    scale_factor = np.sqrt(target_temperature / current_temperature)\n\n    # Scale velocities\n    for atom in atoms:\n        atom.velocity *= scale_factor\n\nThis code snippet sets the temperature of the system to the target temperature by scaling the velocities of the atoms. Here‚Äôs a breakdown of the key steps:\n\nNumber of Atoms and Degrees of Freedom:\nN = len(atoms)      # number of atoms\nNf = 2 * N         # degrees of freedom in 2D\n\nN is the number of atoms in the system.\nNf is the number of degrees of freedom. In a 2D system, each atom has 2 degrees of freedom (one for each spatial dimension), so Nf = 2 * N.\n\nCalculate Current Kinetic Energy:\ncurrent_ke = sum(0.5 * atom.mass * np.sum(atom.velocity**2) for atom in atoms)\ncurrent_temperature = 2 * current_ke / Nf  # kb = 1 in reduced units\n\nThe current kinetic energy (current_ke) is calculated by summing the kinetic energy of each atom. The kinetic energy of an atom is given by ( m v^2 ), where m is the mass and v is the velocity.\nThe current temperature (current_temperature) is then calculated using the relation ( T = ). Here, the Boltzmann constant ( k_B ) is assumed to be 1 in reduced units.\n\nCalculate Scaling Factor:\nscale_factor = np.sqrt(target_temperature / current_temperature)\n\nThe scaling factor is calculated as the square root of the ratio of the target temperature to the current temperature. This factor will be used to scale the velocities of the atoms.\n\nScale Velocities:\nfor atom in atoms:\n    atom.velocity *= scale_factor\n\nThe velocities of all atoms are scaled by the calculated scaling factor. This adjustment ensures that the kinetic energy‚Äîand thus the temperature‚Äîof the system matches the target temperature."
  },
  {
    "objectID": "seminars/seminar05/md5.html#simulation-setup-and-initialization",
    "href": "seminars/seminar05/md5.html#simulation-setup-and-initialization",
    "title": "Step-by-Step Development of a Molecular Dynamics Simulation",
    "section": "Simulation Setup and Initialization",
    "text": "Simulation Setup and Initialization\nThis now completes our initial code for the MD simulation and we can put it all together to run a simulation.\nbox_size = np.array([50.0, 50.0])  # Box dimensions\nnum_atoms = 200\n\nT=5\ndt = 0.01\n\n# Create atoms and set initial velocities\natoms = create_grid_atoms(num_atoms, box_size, type=\"H\",mass=1.0, random_offset=0.1)\natoms = initialize_velocities(atoms, temperature=T)\n\n\n# Create force field\nff = ForceField()\n\n\n# Create simulation with periodic boundaries\nsim = MDSimulation(atoms, ff, dt, box_size)\n\nfig, ax = plt.subplots(1,1,figsize=(6,6))\n\nfor step in range(1000):\n    clear_output(wait=True)\n    set_temperature(atoms, target_temperature=T)\n    sim.update_positions_and_velocities()\n\n    positions = [atom.position for atom in sim.atoms]\n    x_coords = [pos[0] for pos in positions]\n    y_coords = [pos[1] for pos in positions]\n\n    circle=patches.Circle((x_coords[0],y_coords[0]),ff.parameters[atoms[0].type][\"sigma\"],edgecolor=\"white\",fill=False)\n    ax.add_patch(circle)\n    ax.scatter(x_coords, y_coords,color=\"red\")\n    ax.set_xlim(0, box_size[0])\n    ax.set_ylim(0, box_size[1])\n    ax.axis(\"off\")\n\n    display(fig)\n\n    ax.clear()"
  },
  {
    "objectID": "seminars/seminar02/md2.html",
    "href": "seminars/seminar02/md2.html",
    "title": "Step-by-Step Development of a Molecular Dynamics Simulation",
    "section": "",
    "text": "In the previous document, we learned about the key components of a molecular dynamics simulation: - The Lennard-Jones potential describing forces between atoms - The Velocity Verlet algorithm for updating positions and velocities\nNow we‚Äôll implement these concepts in code. To organize our simulation, we‚Äôll have to think about some issues:\n\n\nIn the previous example, we have assumed that the particle is in free fall. That means eventually it would bounce against the floor. In a real simulation, we need to consider boundary conditions as well. For example, if the particle hits the ground we could implement a simple reflection rule. This is called reflecting boundary conditions and would introduce some additional effects to the simulation. On the other side, one could make the system ‚Äúkind of‚Äù infinitely large by introducing periodic boundary conditions. This means that if a particle leaves the simulation box on one side, it re-enters on the opposite side. This is a common approach in molecular dynamics simulations.\n\n\n\nPerdiodic Boundary Conditions\n\n\n\n\n\n\n\n\nThe Minimum Image Convention in Molecular Dynamics\n\n\n\n\n\nWhen we simulate particles in a box with periodic boundary conditions (meaning particles that leave on one side reappear on the opposite side), we need to calculate the forces between them correctly. Imagine two particles near opposite edges of the box: one at position x=1 and another at x=9 in a box of length 10. Without the minimum image convention, we would calculate their distance as 8 units (9-1). However, due to the periodic boundaries, these particles could actually interact across the boundary, with a shorter distance of just 2 units! The minimum image convention automatically finds this shortest distance, ensuring that we calculate the forces between particles correctly. It‚Äôs like taking a shortcut across the periodic boundary instead of walking the longer path through the box.\n\n\n\n\n\n\nThe question we have to think about now is how to implement these formulas in a numerical simulation. The goal is to simulate the motion of many atoms in a box. Each atom is different and has its own position, velocity, and force. Consequently we need to store these quantities for each atom, though the structure in which we store them is the same for each atom. All atoms with their properties actually belong to the same class of objects. We can therefore use a very suitable concept of object-oriented programming, the class.\nA class in object-oriented programming is a blueprint for creating objects (a particular data structure), providing initial values for state (member variables or attributes), and implementations of behavior (member functions or methods). The class is a template for objects, and an object is an instance of a class. The class defines the properties and behavior common to all objects of the class. The objects are the instances of the class that contain the actual data.\nThink of the Atom class as a container for everything we need to know about a single atom:\n\nIts position (where is it?)\nIts velocity (how fast is it moving?)\nThe forces acting on it (what‚Äôs pushing or pulling it?)\nIts type (is it hydrogen, oxygen, etc.?)\nIts mass (how heavy is it?)\n\n\n\n\nWe also have a set of forces, that is acting between the atoms. These forces are calculated based on the positions of the atoms. The force fields are all the same for the atoms only the parameters are different. We can represent the force field as a class as well. We will first implement the Lennard-Jones potential in the class. Later we will implement more complex force fields. We will realize that we will later have to introduce different parameters for the Lenard Jones potential for different atom types. We will store these parameters in a dictionary. This dictionary will be part of the force field class and actually represent the Force Field.\nIf atoms are of the same type, they will have the same parameters. However, if they are of different types we will have to mix the parameters. This is done by the mixing rules. We will implement the Lorentz-Berthelot mixing rules. These rules are used to calculate the parameters for the interaction between two different atom types.\n\n\nFor two different atoms (A and B), the Lennard-Jones parameters \\(\\sigma\\) and \\(\\epsilon\\) are calculated using:\n\nArithmetic mean for \\(\\sigma\\) (Lorentz rule):\n\\[\\sigma_{AB} = \\frac{\\sigma_A + \\sigma_B}{2}\\]\nGeometric mean for \\(\\epsilon\\) (Berthelot rule):\n\\[\\epsilon_{AB} = \\sqrt{\\epsilon_A \\epsilon_B}\\]\n\nThese parameters are then used in the Lennard-Jones potential:\n\\[V_{LJ}(r) = 4\\epsilon_{AB}\\left[\\left(\\frac{\\sigma_{AB}}{r}\\right)^{12} - \\left(\\frac{\\sigma_{AB}}{r}\\right)^6\\right]\\]\n\n\n\n\nIn the previous example, we have started with a particle at rest. In a real simulation, we would like to start with a certain temperature. This means that the particles have a certain velocity distribution. We can introduce this by assigning random velocities to the particles. The velocities should be drawn from a Maxwell-Boltzmann distribution. This is a distribution that describes the velocity distribution of particles in at a certain temperature. The distribution is given by:\n\\[\nf_v\\left(v_x\\right)=\\sqrt{\\frac{m}{2 \\pi k_B T}} \\exp \\left[\\frac{-m v_x^2}{2 k_B T}\\right]\n\\]\nwhere \\(m\\) is the mass of the particle, \\(k_B\\) is Boltzmann‚Äôs constant, and \\(T\\) is the temperature. \\(v_x\\) is the velocity in the x-direction. The velocities in the y and z directions are drawn in the same way. The temperature of the system is related to the kinetic energy of the particles.\n\n\n\n\n\n\nMaxwell-Boltzmann Velocities in 3D\n\n\n\n\n\nThe probability distribution for the velocity magnitude in 3D is:\n\\[f(v) = 4\\pi v^2 \\left(\\frac{m}{2\\pi k_BT}\\right)^{3/2} \\exp\\left(-\\frac{mv^2}{2k_BT}\\right)\\]\n\nMean velocity magnitude:\n\\[\\langle v \\rangle = \\sqrt{\\frac{8k_BT}{\\pi m}}\\]\nMost probable velocity (peak of distribution):\n\\[v_{mp} = \\sqrt{\\frac{2k_BT}{m}}\\]\nRoot mean square velocity:\n\\[v_{rms} = \\sqrt{\\frac{3k_BT}{m}}\\]\n\nThese velocities can also be expressed in terms of the kinetic energy of the particles. The average kinetic energy per particle is:\n\\[\\langle E_{kin} \\rangle = \\frac{3}{2}k_BT\\]\nThen we can express the velocities as:\n\nMean velocity magnitude:\n\\[\\langle v \\rangle = \\sqrt{\\frac{8\\langle E_{kin} \\rangle}{3\\pi m}}\\]\nMost probable velocity:\n\\[v_{mp} = \\sqrt{\\frac{4\\langle E_{kin} \\rangle}{3m}}\\]\nRoot mean square velocity:\n\\[v_{rms} = \\sqrt{\\frac{2\\langle E_{kin} \\rangle}{m}}\\]\n\n\n\n\n\n\nCode\n# Constants\nkb = 1.380649e-23  # Boltzmann constant in J/K\nm_H = 1.6735575e-27  # Mass of hydrogen atom in kg\nT = 300  # Temperature in K\n\n# Velocity range for plotting\nv = np.linspace(-10000, 10000, 1000)  # m/s\nv_mag = np.linspace(0, 10000, 1000)  # m/s\n\n# Maxwell-Boltzmann distribution for x-component\ndef MB_1D(v, m, T):\n    return np.sqrt(m/(2*np.pi*kb*T)) * np.exp(-m*v**2/(2*kb*T))\n\n# Maxwell-Boltzmann distribution for velocity magnitude in 2D\ndef MB_2D_mag(v, m, T):\n    return v * m/(kb*T) * np.exp(-m*v**2/(2*kb*T))\n\n# Create figure\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=get_size(16, 8))\n\n# Plot x-component distribution\nax1.plot(v, MB_1D(v, m_H, T))\nax1.set_xlabel('Velocity [m/s]')\nax1.set_ylabel('Probability density')\n\n# Plot magnitude distribution\nax2.plot(v_mag, MB_2D_mag(v_mag, m_H, T))\nax2.set_xlabel('Velocity magnitude [m/s]')\nax2.set_ylabel('Probability density')\nax2.axvline(np.sqrt(kb*T/m_H), color='r', linestyle='--', label='Most probable velocity')\nax2.axvline(np.sqrt(2)*np.sqrt(kb*T/m_H), color='g', linestyle='--', label='Mean velocity')\n\nplt.tight_layout()\nplt.show()\n\n# Print most probable velocity\nv_mp_1D = 0  # Most probable velocity for 1D is zero\nv_mp_2D = np.sqrt(kb*T/m_H)  # Most probable velocity magnitude in 2D\nprint(f\"Most probable velocity magnitude in 2D: {v_mp_2D:.1f} m/s\")\nprint(f\"Mean velocity magnitude in 2D: {np.sqrt(2)*v_mp_2D:.1f} m/s\")\n\n\n\n\n\n\n\n\n\nMost probable velocity magnitude in 2D: 1573.2 m/s\nMean velocity magnitude in 2D: 2224.8 m/s\n\n\nThe temperature T in a 2D system is related to the kinetic energy by:\n\\[T = \\frac{2K}{N_f k_B}\\]\nwhere:\n\nK is the total kinetic energy: \\(K = \\sum_i \\frac{1}{2}m_i v_i^2\\)\n\\(N_f\\) is the number of degrees of freedom (2N in 2D, where N is number of particles)\n\\(k_B\\) is Boltzmann‚Äôs constant (often set to 1 in reduced units)\n\nTo scale to a target temperature \\(T_{target}\\), we multiply velocities by \\(\\sqrt{\\frac{T_{target}}{T_{current}}}\\)\n\n\n\nFinally, we need a class that controls the simulation. This class will contain the main loop of the simulation, where the integration algorithm is called in each time step. It will also contain the methods to calculate the forces between the atoms.\n\n\n\nBefore we implement all classes, we will first visualize the particles moving in a 2D box. We will use the matplotlib library to create an animation of the particles moving in the box. We will also implement periodic boundary conditions, so that particles that leave the box on one side re-enter on the opposite side.\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom IPython.display import clear_output\nfrom scipy.spatial.distance import cdist\n\nn_side =2\n\n1x = np.linspace(0.05, 0.95, n_side)\ny = np.linspace(0.05, 0.95, n_side)\n2xx, yy = np.meshgrid(x, y)\n3particles = np.vstack([xx.ravel(), yy.ravel()]).T\n\nvelocities = np.random.normal(scale=0.005, size=(n_side**2, 2))\n\nradius = 0.0177\nfig, ax = plt.subplots(figsize=(9,9))\n\nn_steps = 200\n\n4for _ in range(n_steps):\n5    clear_output(wait=True)\n\n    # Update particle positions based on their velocities\n    particles += velocities\n    # Apply periodic boundary conditions in x direction (wrap around at 0 and 1)\n    particles[:, 0] = particles[:, 0] % 1\n    # Apply periodic boundary conditions in y direction (wrap around at 0 and 1)\n    particles[:, 1] = particles[:, 1] % 1\n    # Calculate distances between all pairs of particles\n    distances = cdist(particles, particles)\n\n    # Calculate collisions using the upper triangle of the distance matrix\n    # distances &lt; 2*radius gives a boolean matrix where True means collision\n    # np.triu takes only the upper triangle to avoid counting collisions twice\n    collisions = np.triu(distances &lt; 2*radius, 1)\n\n    # Handle collisions between particles\n    for i, j in zip(*np.nonzero(collisions)):\n        # Exchange velocities between colliding particles (elastic collision)\n6        velocities[i], velocities[j] = velocities[j], velocities[i].copy()\n\n        # Calculate how much particles overlap\n        overlap = 2*radius - distances[i, j]\n\n        # Calculate unit vector pointing from j to i\n        direction = particles[i] - particles[j]\n        direction /= np.linalg.norm(direction)\n\n        # Move particles apart to prevent overlap\n        particles[i] += 0.5 * overlap * direction\n        particles[j] -= 0.5 * overlap * direction\n\n    ax.scatter(particles[:, 0], particles[:, 1], s=100, edgecolors='r', facecolors='none')\n\n\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.axis(\"off\")\n\n    display(fig)\n    plt.pause(0.01)\n\n    # Clear the current plot to prepare for next frame\n    ax.clear()\n\n1\n\nCreate a 1D array of x and y-coordinates for the particles.\n\n2\n\nCreate a meshgrid of x and y-coordinates.\n\n3\n\nFlatten the meshgrid to get a 2D array of particle positions.\n\n4\n\nSimulation loop\n\n5\n\nClear the output to display the animation in a single cell.\n\n6\n\nHandle collisions between particles by exchanging velocities and moving particles apart to prevent overlap. The exchange of velocities in your code works because of the conservation of momentum and energy:\n\n\n\nFor two particles of equal mass m in a head-on elastic collision: Before collision:\n\nMomentum: \\(p = mv_1 + mv_2\\)\nEnergy: \\(E = \\frac{1}{2}mv_1^2 + \\frac{1}{2}mv_2^2\\)\n\nAfter collision (with velocity exchange): - Momentum: \\(p = mv_2 + mv_1\\) (same as before!) - Energy: \\(E = \\frac{1}{2}mv_2^2 + \\frac{1}{2}mv_1^2\\) (same as before!)"
  },
  {
    "objectID": "seminars/seminar02/md2.html#from-theory-to-code",
    "href": "seminars/seminar02/md2.html#from-theory-to-code",
    "title": "Step-by-Step Development of a Molecular Dynamics Simulation",
    "section": "",
    "text": "In the previous document, we learned about the key components of a molecular dynamics simulation: - The Lennard-Jones potential describing forces between atoms - The Velocity Verlet algorithm for updating positions and velocities\nNow we‚Äôll implement these concepts in code. To organize our simulation, we‚Äôll have to think about some issues:\n\n\nIn the previous example, we have assumed that the particle is in free fall. That means eventually it would bounce against the floor. In a real simulation, we need to consider boundary conditions as well. For example, if the particle hits the ground we could implement a simple reflection rule. This is called reflecting boundary conditions and would introduce some additional effects to the simulation. On the other side, one could make the system ‚Äúkind of‚Äù infinitely large by introducing periodic boundary conditions. This means that if a particle leaves the simulation box on one side, it re-enters on the opposite side. This is a common approach in molecular dynamics simulations.\n\n\n\nPerdiodic Boundary Conditions\n\n\n\n\n\n\n\n\nThe Minimum Image Convention in Molecular Dynamics\n\n\n\n\n\nWhen we simulate particles in a box with periodic boundary conditions (meaning particles that leave on one side reappear on the opposite side), we need to calculate the forces between them correctly. Imagine two particles near opposite edges of the box: one at position x=1 and another at x=9 in a box of length 10. Without the minimum image convention, we would calculate their distance as 8 units (9-1). However, due to the periodic boundaries, these particles could actually interact across the boundary, with a shorter distance of just 2 units! The minimum image convention automatically finds this shortest distance, ensuring that we calculate the forces between particles correctly. It‚Äôs like taking a shortcut across the periodic boundary instead of walking the longer path through the box.\n\n\n\n\n\n\nThe question we have to think about now is how to implement these formulas in a numerical simulation. The goal is to simulate the motion of many atoms in a box. Each atom is different and has its own position, velocity, and force. Consequently we need to store these quantities for each atom, though the structure in which we store them is the same for each atom. All atoms with their properties actually belong to the same class of objects. We can therefore use a very suitable concept of object-oriented programming, the class.\nA class in object-oriented programming is a blueprint for creating objects (a particular data structure), providing initial values for state (member variables or attributes), and implementations of behavior (member functions or methods). The class is a template for objects, and an object is an instance of a class. The class defines the properties and behavior common to all objects of the class. The objects are the instances of the class that contain the actual data.\nThink of the Atom class as a container for everything we need to know about a single atom:\n\nIts position (where is it?)\nIts velocity (how fast is it moving?)\nThe forces acting on it (what‚Äôs pushing or pulling it?)\nIts type (is it hydrogen, oxygen, etc.?)\nIts mass (how heavy is it?)\n\n\n\n\nWe also have a set of forces, that is acting between the atoms. These forces are calculated based on the positions of the atoms. The force fields are all the same for the atoms only the parameters are different. We can represent the force field as a class as well. We will first implement the Lennard-Jones potential in the class. Later we will implement more complex force fields. We will realize that we will later have to introduce different parameters for the Lenard Jones potential for different atom types. We will store these parameters in a dictionary. This dictionary will be part of the force field class and actually represent the Force Field.\nIf atoms are of the same type, they will have the same parameters. However, if they are of different types we will have to mix the parameters. This is done by the mixing rules. We will implement the Lorentz-Berthelot mixing rules. These rules are used to calculate the parameters for the interaction between two different atom types.\n\n\nFor two different atoms (A and B), the Lennard-Jones parameters \\(\\sigma\\) and \\(\\epsilon\\) are calculated using:\n\nArithmetic mean for \\(\\sigma\\) (Lorentz rule):\n\\[\\sigma_{AB} = \\frac{\\sigma_A + \\sigma_B}{2}\\]\nGeometric mean for \\(\\epsilon\\) (Berthelot rule):\n\\[\\epsilon_{AB} = \\sqrt{\\epsilon_A \\epsilon_B}\\]\n\nThese parameters are then used in the Lennard-Jones potential:\n\\[V_{LJ}(r) = 4\\epsilon_{AB}\\left[\\left(\\frac{\\sigma_{AB}}{r}\\right)^{12} - \\left(\\frac{\\sigma_{AB}}{r}\\right)^6\\right]\\]\n\n\n\n\nIn the previous example, we have started with a particle at rest. In a real simulation, we would like to start with a certain temperature. This means that the particles have a certain velocity distribution. We can introduce this by assigning random velocities to the particles. The velocities should be drawn from a Maxwell-Boltzmann distribution. This is a distribution that describes the velocity distribution of particles in at a certain temperature. The distribution is given by:\n\\[\nf_v\\left(v_x\\right)=\\sqrt{\\frac{m}{2 \\pi k_B T}} \\exp \\left[\\frac{-m v_x^2}{2 k_B T}\\right]\n\\]\nwhere \\(m\\) is the mass of the particle, \\(k_B\\) is Boltzmann‚Äôs constant, and \\(T\\) is the temperature. \\(v_x\\) is the velocity in the x-direction. The velocities in the y and z directions are drawn in the same way. The temperature of the system is related to the kinetic energy of the particles.\n\n\n\n\n\n\nMaxwell-Boltzmann Velocities in 3D\n\n\n\n\n\nThe probability distribution for the velocity magnitude in 3D is:\n\\[f(v) = 4\\pi v^2 \\left(\\frac{m}{2\\pi k_BT}\\right)^{3/2} \\exp\\left(-\\frac{mv^2}{2k_BT}\\right)\\]\n\nMean velocity magnitude:\n\\[\\langle v \\rangle = \\sqrt{\\frac{8k_BT}{\\pi m}}\\]\nMost probable velocity (peak of distribution):\n\\[v_{mp} = \\sqrt{\\frac{2k_BT}{m}}\\]\nRoot mean square velocity:\n\\[v_{rms} = \\sqrt{\\frac{3k_BT}{m}}\\]\n\nThese velocities can also be expressed in terms of the kinetic energy of the particles. The average kinetic energy per particle is:\n\\[\\langle E_{kin} \\rangle = \\frac{3}{2}k_BT\\]\nThen we can express the velocities as:\n\nMean velocity magnitude:\n\\[\\langle v \\rangle = \\sqrt{\\frac{8\\langle E_{kin} \\rangle}{3\\pi m}}\\]\nMost probable velocity:\n\\[v_{mp} = \\sqrt{\\frac{4\\langle E_{kin} \\rangle}{3m}}\\]\nRoot mean square velocity:\n\\[v_{rms} = \\sqrt{\\frac{2\\langle E_{kin} \\rangle}{m}}\\]\n\n\n\n\n\n\nCode\n# Constants\nkb = 1.380649e-23  # Boltzmann constant in J/K\nm_H = 1.6735575e-27  # Mass of hydrogen atom in kg\nT = 300  # Temperature in K\n\n# Velocity range for plotting\nv = np.linspace(-10000, 10000, 1000)  # m/s\nv_mag = np.linspace(0, 10000, 1000)  # m/s\n\n# Maxwell-Boltzmann distribution for x-component\ndef MB_1D(v, m, T):\n    return np.sqrt(m/(2*np.pi*kb*T)) * np.exp(-m*v**2/(2*kb*T))\n\n# Maxwell-Boltzmann distribution for velocity magnitude in 2D\ndef MB_2D_mag(v, m, T):\n    return v * m/(kb*T) * np.exp(-m*v**2/(2*kb*T))\n\n# Create figure\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=get_size(16, 8))\n\n# Plot x-component distribution\nax1.plot(v, MB_1D(v, m_H, T))\nax1.set_xlabel('Velocity [m/s]')\nax1.set_ylabel('Probability density')\n\n# Plot magnitude distribution\nax2.plot(v_mag, MB_2D_mag(v_mag, m_H, T))\nax2.set_xlabel('Velocity magnitude [m/s]')\nax2.set_ylabel('Probability density')\nax2.axvline(np.sqrt(kb*T/m_H), color='r', linestyle='--', label='Most probable velocity')\nax2.axvline(np.sqrt(2)*np.sqrt(kb*T/m_H), color='g', linestyle='--', label='Mean velocity')\n\nplt.tight_layout()\nplt.show()\n\n# Print most probable velocity\nv_mp_1D = 0  # Most probable velocity for 1D is zero\nv_mp_2D = np.sqrt(kb*T/m_H)  # Most probable velocity magnitude in 2D\nprint(f\"Most probable velocity magnitude in 2D: {v_mp_2D:.1f} m/s\")\nprint(f\"Mean velocity magnitude in 2D: {np.sqrt(2)*v_mp_2D:.1f} m/s\")\n\n\n\n\n\n\n\n\n\nMost probable velocity magnitude in 2D: 1573.2 m/s\nMean velocity magnitude in 2D: 2224.8 m/s\n\n\nThe temperature T in a 2D system is related to the kinetic energy by:\n\\[T = \\frac{2K}{N_f k_B}\\]\nwhere:\n\nK is the total kinetic energy: \\(K = \\sum_i \\frac{1}{2}m_i v_i^2\\)\n\\(N_f\\) is the number of degrees of freedom (2N in 2D, where N is number of particles)\n\\(k_B\\) is Boltzmann‚Äôs constant (often set to 1 in reduced units)\n\nTo scale to a target temperature \\(T_{target}\\), we multiply velocities by \\(\\sqrt{\\frac{T_{target}}{T_{current}}}\\)\n\n\n\nFinally, we need a class that controls the simulation. This class will contain the main loop of the simulation, where the integration algorithm is called in each time step. It will also contain the methods to calculate the forces between the atoms.\n\n\n\nBefore we implement all classes, we will first visualize the particles moving in a 2D box. We will use the matplotlib library to create an animation of the particles moving in the box. We will also implement periodic boundary conditions, so that particles that leave the box on one side re-enter on the opposite side.\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom IPython.display import clear_output\nfrom scipy.spatial.distance import cdist\n\nn_side =2\n\n1x = np.linspace(0.05, 0.95, n_side)\ny = np.linspace(0.05, 0.95, n_side)\n2xx, yy = np.meshgrid(x, y)\n3particles = np.vstack([xx.ravel(), yy.ravel()]).T\n\nvelocities = np.random.normal(scale=0.005, size=(n_side**2, 2))\n\nradius = 0.0177\nfig, ax = plt.subplots(figsize=(9,9))\n\nn_steps = 200\n\n4for _ in range(n_steps):\n5    clear_output(wait=True)\n\n    # Update particle positions based on their velocities\n    particles += velocities\n    # Apply periodic boundary conditions in x direction (wrap around at 0 and 1)\n    particles[:, 0] = particles[:, 0] % 1\n    # Apply periodic boundary conditions in y direction (wrap around at 0 and 1)\n    particles[:, 1] = particles[:, 1] % 1\n    # Calculate distances between all pairs of particles\n    distances = cdist(particles, particles)\n\n    # Calculate collisions using the upper triangle of the distance matrix\n    # distances &lt; 2*radius gives a boolean matrix where True means collision\n    # np.triu takes only the upper triangle to avoid counting collisions twice\n    collisions = np.triu(distances &lt; 2*radius, 1)\n\n    # Handle collisions between particles\n    for i, j in zip(*np.nonzero(collisions)):\n        # Exchange velocities between colliding particles (elastic collision)\n6        velocities[i], velocities[j] = velocities[j], velocities[i].copy()\n\n        # Calculate how much particles overlap\n        overlap = 2*radius - distances[i, j]\n\n        # Calculate unit vector pointing from j to i\n        direction = particles[i] - particles[j]\n        direction /= np.linalg.norm(direction)\n\n        # Move particles apart to prevent overlap\n        particles[i] += 0.5 * overlap * direction\n        particles[j] -= 0.5 * overlap * direction\n\n    ax.scatter(particles[:, 0], particles[:, 1], s=100, edgecolors='r', facecolors='none')\n\n\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.axis(\"off\")\n\n    display(fig)\n    plt.pause(0.01)\n\n    # Clear the current plot to prepare for next frame\n    ax.clear()\n\n1\n\nCreate a 1D array of x and y-coordinates for the particles.\n\n2\n\nCreate a meshgrid of x and y-coordinates.\n\n3\n\nFlatten the meshgrid to get a 2D array of particle positions.\n\n4\n\nSimulation loop\n\n5\n\nClear the output to display the animation in a single cell.\n\n6\n\nHandle collisions between particles by exchanging velocities and moving particles apart to prevent overlap. The exchange of velocities in your code works because of the conservation of momentum and energy:\n\n\n\nFor two particles of equal mass m in a head-on elastic collision: Before collision:\n\nMomentum: \\(p = mv_1 + mv_2\\)\nEnergy: \\(E = \\frac{1}{2}mv_1^2 + \\frac{1}{2}mv_2^2\\)\n\nAfter collision (with velocity exchange): - Momentum: \\(p = mv_2 + mv_1\\) (same as before!) - Energy: \\(E = \\frac{1}{2}mv_2^2 + \\frac{1}{2}mv_1^2\\) (same as before!)"
  },
  {
    "objectID": "seminars/seminar03/MD Simulation.html",
    "href": "seminars/seminar03/MD Simulation.html",
    "title": "MD Simulation",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\nplt.rcParams.update({'font.size': 8,\n                     'lines.linewidth': 1,\n                     'lines.markersize': 10,\n                     'axes.labelsize': 10,\n                     'axes.titlesize': 10,\n                     'xtick.labelsize' : 10,\n                     'ytick.labelsize' : 10,\n                     'xtick.top' : True,\n                     'xtick.direction' : 'in',\n                     'ytick.right' : True,\n                     'ytick.direction' : 'in',})\n\ndef get_size(w,h):\n    return((w/2.54,h/2.54))"
  },
  {
    "objectID": "seminars/seminar03/MD Simulation.html#atom-class",
    "href": "seminars/seminar03/MD Simulation.html#atom-class",
    "title": "MD Simulation",
    "section": "Atom Class",
    "text": "Atom Class\n\nclass Atom:\n    def __init__(self, atom_id, atom_type, position, velocity=None, mass=None):\n        self.id = atom_id\n        self.type = atom_type\n        self.position = position\n        self.velocity = velocity if velocity is not None else np.random.randn(2)*20\n        self.mass = mass\n        self.force = np.zeros(2)\n\n\n    def add_force(self, force):\n        \"\"\"Add force contribution to total force on atom\"\"\"\n        self.force += force\n\n    def reset_force(self):\n        \"\"\"Reset force to zero at start of each step\"\"\"\n        self.force = np.zeros(2)\n\n    def update_position(self, dt):\n        \"\"\"First step of velocity Verlet: update position\"\"\"\n        self.position += self.velocity * dt + 0.5 * (self.force/self.mass) * dt**2\n\n    def update_velocity(self, dt, new_force):\n        \"\"\"Second step of velocity Verlet: update velocity using average force\"\"\"\n        self.velocity += 0.5 * (new_force + self.force)/self.mass * dt\n        self.force = new_force\n\n    def apply_periodic_boundaries(self, box_size):\n            \"\"\"Apply periodic boundary conditions\"\"\"\n            self.position = self.position % box_size\n\n\nclass ForceField:\n    def __init__(self):\n        self.parameters = {\n            'C': {'epsilon': 1.0, 'sigma': 3.4},\n            'H': {'epsilon': 1, 'sigma': 1},\n            'O': {'epsilon': 0.8, 'sigma': 3.0},\n        }\n        self.box_size = None  # Will be set when initializing the simulation\n\n    def get_pair_parameters(self, type1, type2):\n        # Apply mixing rules when needed\n        eps1 = self.parameters[type1]['epsilon']\n        eps2 = self.parameters[type2]['epsilon']\n        sig1 = self.parameters[type1]['sigma']\n        sig2 = self.parameters[type2]['sigma']\n\n        # Lorentz-Berthelot mixing rules\n        epsilon = np.sqrt(eps1 * eps2)\n        sigma = (sig1 + sig2) / 2\n\n        return epsilon, sigma\n\n    def minimum_image_distance(self, pos1, pos2):\n        \"\"\"Calculate minimum image distance between two positions\"\"\"\n        delta = pos1 - pos2\n        # Apply minimum image convention\n        delta = delta - self.box_size * np.round(delta / self.box_size)\n        return delta\n\n    def calculate_lj_force(self, atom1, atom2):\n        epsilon, sigma = self.get_pair_parameters(atom1.type, atom2.type)\n        r = self.minimum_image_distance(atom1.position, atom2.position)\n        r_mag = np.linalg.norm(r)\n\n        # Add cutoff distance for stability\n        if r_mag &gt; 2.5*sigma:\n            return np.zeros(2)\n\n        force_mag = 24 * epsilon * (\n            2 * (sigma/r_mag)**13\n            - (sigma/r_mag)**7\n        )\n        force = force_mag * r/r_mag\n        return force\n\n\nclass MDSimulation:\n    def __init__(self, atoms, forcefield, timestep, box_size):\n        self.atoms = atoms\n        self.forcefield = forcefield\n        self.forcefield.box_size = box_size  # Set box size in forcefield\n        self.timestep = timestep\n        self.box_size = np.array(box_size)\n        self.initial_energy = None\n        self.energy_history = []\n\n    def minimum_image_distance(self, pos1, pos2):\n        \"\"\"Calculate minimum image distance between two positions\"\"\"\n        delta = pos1 - pos2\n        # Apply minimum image convention\n        delta = delta - self.box_size * np.round(delta / self.box_size)\n        return delta\n\n    def calculate_forces(self):\n        # Reset all forces\n        for atom in self.atoms:\n            atom.reset_force()\n\n        # Calculate forces between all pairs\n        for i, atom1 in enumerate(self.atoms):\n            for atom2 in self.atoms[i+1:]:\n                force = self.forcefield.calculate_lj_force(atom1, atom2)\n                atom1.add_force(force)\n                atom2.add_force(-force)  # Newton's third law\n\n    def update_positions_and_velocities(self):\n        # First step: Update positions using current forces\n        for atom in self.atoms:\n            atom.update_position(self.timestep)\n            # Apply periodic boundary conditions\n            atom.apply_periodic_boundaries(self.box_size)\n\n        # Store current forces for velocity update\n        old_forces = {atom.id: atom.force.copy() for atom in self.atoms}\n\n        # Recalculate forces with new positions\n        self.calculate_forces()\n\n        # Second step: Update velocities using average of old and new forces\n        for atom in self.atoms:\n            atom.update_velocity(self.timestep, atom.force)\n\n\ndef create_grid_atoms(num_atoms, box_size, mass=1.0, random_offset=0.1):\n    box_size = np.array(box_size)\n\n    # Calculate grid dimensions\n    n = int(np.ceil(np.sqrt(num_atoms)))\n    spacing = np.min(box_size) / n\n\n    atoms = []\n    for i in range(num_atoms):\n        # Calculate grid position\n        row = i // n\n        col = i % n\n\n        # Base position\n        pos = np.array([col * spacing + spacing/2,\n                       row * spacing + spacing/2])\n\n        # Add random offset\n        pos += (np.random.rand(2) - 0.5) * spacing * random_offset\n\n        # Create atom\n        atoms.append(Atom(i, 'H', pos, mass=mass))\n\n    return atoms"
  },
  {
    "objectID": "seminars/seminar04/md4.html",
    "href": "seminars/seminar04/md4.html",
    "title": "Step-by-Step Development of a Molecular Dynamics Simulation",
    "section": "",
    "text": "In the last seminar we have defined the class Atom that represents an atom in the simulation. This time, we would like to a force field to the simulation. We will use for out simulations the Lennard-Jones potential that we have had a look at initiall. We will implement this force field in a class ForceField that will contain the parameters of the force field and the methods to calculate the forces between the atoms."
  },
  {
    "objectID": "seminars/seminar04/md4.html#the-forcefield-class",
    "href": "seminars/seminar04/md4.html#the-forcefield-class",
    "title": "Step-by-Step Development of a Molecular Dynamics Simulation",
    "section": "The ForceField Class",
    "text": "The ForceField Class\nThe force field is a class that contains the parameters of the force field and the methods to calculate the forces between the atoms. The class ForceField has the following attributes:\n\nsigma: The parameter sigma of the Lennard-Jones potential\nepsilon: The parameter epsilon of the Lennard-Jones potential\n\nThese parameters are specific for each atom type. We will store these parameters in a dictionary where the keys are the atom types and the values are dictionaries containing the parameters sigma and epsilon. The class ForceField also contains the box size of the simulation. This is needed to apply periodic boundary conditions.\nclass ForceField:\n    def __init__(self):\n        self.parameters = {\n            'C': {'epsilon': 1.615, 'sigma': 1.36},\n            'H': {'epsilon': 1.0, 'sigma': 1.0 },\n            'O': {'epsilon': 1.846, 'sigma': 3.0},\n        }\n        self.box_size = None  # Will be set when initializing the simulation\nYou will have certainly noticed that the parameters I defined do not correspond to the real values of the Lennard-Jones potential. Remember that the values for the hydrogen atom are typically\n\n\\(\\sigma \\approx 2.38\\) √Ö = \\(2.38 \\times 10^{-10}\\) meters\n\\(\\epsilon \\approx 0.0167\\) kcal/mol = \\(1.16 \\times 10^{-21}\\) joules\n\nThese are all small numbers and we will use larger values to make the simulation more stable. Actually, the Lenard-Jones potential provides a natural length and energy scale for the simulation. The length scale is the parameter \\(\\sigma\\) and the energy scale is the parameter \\(\\epsilon\\). We can therefore set \\(\\sigma_{LJ}=1\\) and \\(\\epsilon_{LJ}=1\\) and scale all other parameters accordingly. This is a common practice in molecular dynamics simulations.\nDue to this rescaling energy, temperature and time units are also not the same as in the real world. We will use the following units:\n\nEnergy: \\(\\epsilon_{LJ} = \\epsilon_{H}/\\epsilon_{H} = 1\\)\nLength: \\(\\sigma_{LJ} = 1\\)\nMass: \\(m_{LJ} = 1\\)\n\nThis means now that all energies, for example, have to be scales by _{H} also the thermal energy. As thermal energy is related to temperature, then the temperature of the Lennard-Jones system\n\\[\nT_{LJ}=\\frac{k_B T}{\\epsilon_{LJ}}\n\\]\nwhich is, in the case of using the hydrogen energy scale, \\(T_{LJ}=3.571\\). for \\(T=300\\, K\\). For the time scale, we have to consider the mass of the hydrogen atom. The time scale is given by\n\\[\nt_{LJ}=\\frac{t}{\\sigma}\\sqrt{\\frac{\\epsilon}{m_{H}}}\n\\]\nThus a time unit of \\(1\\, fs\\) corresponds to \\(t_{LJ}=0.099\\). Thus using a timestep of 0.01 in reduced units would correspond to a real world timestep of just 1 fs. The table below shows the conversion factors for the different units. Simulating a Lennard-Jones system in reduced units therefore allows you to rescale to a real systems with the help of these conversion factors.\n\\[\n\\begin{array}{c|c}\n\\hline \\mathrm{r}^* & \\mathrm{r} \\sigma^{-1} \\\\\n\\hline \\mathrm{~m}^* & \\mathrm{mM}^{-1} \\\\\n\\hline \\mathrm{t}^* & \\mathrm{t} \\sigma^{-1} \\sqrt{\\epsilon / M} \\\\\n\\hline \\mathrm{~T}^* & \\mathrm{k}_B T \\epsilon^{-1} \\\\\n\\hline \\mathrm{E}^* & \\mathrm{E} \\epsilon^{-1} \\\\\n\\hline \\mathrm{~F}^* & \\mathrm{~F} \\sigma \\epsilon^{-1} \\\\\n\\hline \\mathrm{P}^* & \\mathrm{P} \\sigma^3 \\epsilon^{-1} \\\\\n\\hline \\mathrm{v}^* & \\mathrm{v} \\sqrt{M / \\epsilon} \\\\\n\\hline \\rho^* & \\mathrm{~N} \\sigma^3 V^{-1} \\\\\n\\hline\n\\end{array}\n\\]\n\nApply mixing rules when needed\n\nget_pair_parameters\nWhen we looked at the Lennard-Jones potential we realized that it reflects the pair interaction between the same atoms. However, in a molecular dynamics simulation, we have different atoms interacting with each other. We need to define the parameters of the interaction between different atoms. This is done using mixing rules. The most common mixing rule is the Lorentz-Berthelot mixing rule. The parameters of the interaction between two different atoms are calculated as follows:\ndef get_pair_parameters(self, type1, type2):\n    # Apply mixing rules when needed\n    eps1 = self.parameters[type1]['epsilon']\n    eps2 = self.parameters[type2]['epsilon']\n    sig1 = self.parameters[type1]['sigma']\n    sig2 = self.parameters[type2]['sigma']\n\n    # Lorentz-Berthelot mixing rules\n    epsilon = np.sqrt(eps1 * eps2)\n    sigma = (sig1 + sig2) / 2\n\n    return epsilon, sigma\nWe therefore introduce the method get_pair_parameters that calculates the parameters of the Lennard-Jones potential between two different atoms. The method takes the atom types as arguments and returns the parameters epsilon and sigma of the Lennard-Jones potential between these two atoms. The method applies the Lorentz-Berthelot mixing rules to calculate the parameters. The method returns the parameters epsilon and sigma of the Lennard-Jones potential between the two atoms.\n\n\n\nApply minimum image convention\n\nminimum_image_distance\nSimilarly, we already realized that using a finite box size requires to introduce boundary conditions. We decided that periodic boundary conditions are actually most convinient. However, this is introducing a new problem. When we calculate the distance between two atoms, we have to consider the minimum image distance. This means that we have to consider the distance between two atoms in the nearest image. This is done by applying the minimum image convention. The method minimum_image_distance calculates the minimum image distance between two positions. The method takes the positions of the two atoms as arguments and returns the minimum image distance between the two positions. The method applies the minimum image convention to calculate the minimum image distance.\ndef minimum_image_distance(self, pos1, pos2):\n    \"\"\"Calculate minimum image distance between two positions\"\"\"\n    delta = pos1 - pos2\n    # Apply minimum image convention\n    delta = delta - self.box_size * np.round(delta / self.box_size)\n    return delta\n\n\n\nCalculate the Lennard-Jones force between two atoms\n\ncalculate_lj_force\nFinally we can calculate the Lennard-Jones force between two atoms. The method calculate_lj_force calculates the Lennard-Jones force between two atoms. The method takes the two atoms as arguments and returns the force between the two atoms. The method calculates the Lennard-Jones force between the two atoms using the Lennard-Jones potential. The method returns the force between the two atoms.\ndef calculate_lj_force(self, atom1, atom2):\n    epsilon, sigma = self.get_pair_parameters(atom1.type, atom2.type)\n    r = self.minimum_image_distance(atom1.position, atom2.position)\n    r_mag = np.linalg.norm(r)\n\n    # Add cutoff distance for stability\n    if r_mag &gt; 2.5*sigma:\n        return np.zeros(2)\n\n    force_mag = 24 * epsilon * (\n        2 * (sigma/r_mag)**13\n        - (sigma/r_mag)**7\n    )\n    force = force_mag * r/r_mag\n    return force\nWith these parts we have now a complete force field class which we can add to our simulation code.\n\n\n\n\n\n\nComplete ForceField class\n\n\n\n\n\nclass ForceField:\n    def __init__(self):\n        self.parameters = {\n            'C': {'epsilon': 1.615, 'sigma': 1.36},\n            'H': {'epsilon': 1.0, 'sigma': 1.0 },\n            'O': {'epsilon': 1.846, 'sigma': 3.0},\n        }\n        self.box_size = None  # Will be set when initializing the simulation\n\n    def get_pair_parameters(self, type1, type2):\n        # Apply mixing rules when needed\n        eps1 = self.parameters[type1]['epsilon']\n        eps2 = self.parameters[type2]['epsilon']\n        sig1 = self.parameters[type1]['sigma']\n        sig2 = self.parameters[type2]['sigma']\n\n        # Lorentz-Berthelot mixing rules\n        epsilon = np.sqrt(eps1 * eps2)\n        sigma = (sig1 + sig2) / 2\n\n        return epsilon, sigma\n\n    def minimum_image_distance(self, pos1, pos2):\n        \"\"\"Calculate minimum image distance between two positions\"\"\"\n        delta = pos1 - pos2\n        # Apply minimum image convention\n        delta = delta - self.box_size * np.round(delta / self.box_size)\n        return delta\n\n    def calculate_lj_force(self, atom1, atom2):\n        epsilon, sigma = self.get_pair_parameters(atom1.type, atom2.type)\n        r = self.minimum_image_distance(atom1.position, atom2.position)\n        r_mag = np.linalg.norm(r)\n\n        # Add cutoff distance for stability\n        if r_mag &gt; 2.5*sigma:\n            return np.zeros(2)\n\n        force_mag = 24 * epsilon * (\n            2 * (sigma/r_mag)**13\n            - (sigma/r_mag)**7\n        )\n        force = force_mag * r/r_mag\n        return force"
  },
  {
    "objectID": "seminars/seminar04/md4.html#md-simulation-class",
    "href": "seminars/seminar04/md4.html#md-simulation-class",
    "title": "Step-by-Step Development of a Molecular Dynamics Simulation",
    "section": "MD Simulation Class",
    "text": "MD Simulation Class\nThe last thing we need to do is to implement the MD simulation class. This class will be responsible for running the simulation. It is the controller of the simulation, who coordinates everything. By keeping this in a class you may even run several simulations simultaneously. This is not the case here, but it is a good practice to keep the simulation in a class.\n\nMDSimulation class constructor\nThis is just the constructor of the MD Simulation class. It takes the atoms, the force field, the timestep, and the box size as input. It initializes the simulation with the given parameters and sets the initial energy of the system to None. It also initializes an empty list to store the energy history of the system. The latter ones are not used for the moment but could be important later.\nclass MDSimulation:\n    def __init__(self, atoms, forcefield, timestep, box_size):\n        self.atoms = atoms\n        self.forcefield = forcefield\n        self.forcefield.box_size = box_size  # Set box size in forcefield\n        self.timestep = timestep\n        self.box_size = np.array(box_size)\n        self.initial_energy = None\n        self.energy_history = []\n\n\ncalculate_forces method\nThe calculate_forces method calculates the forces between all pairs of atoms in the system. It first resets all forces on the atoms to zero. Then, it calculates the forces between all pairs of atoms using the Lennard-Jones force calculation from the force field class. The method updates the forces on the atoms accordingly. The method does not return anything.\n    def calculate_forces(self):\n        # Reset all forces\n        for atom in self.atoms:\n            atom.reset_force()\n\n        # Calculate forces between all pairs\n        for i, atom1 in enumerate(self.atoms):\n            for atom2 in self.atoms[i+1:]:\n                force = self.forcefield.calculate_lj_force(atom1, atom2)\n                atom1.add_force(force)\n                atom2.add_force(-force)  # Newton's third law\n\n\nupdate_positions_and_velocities method\nThe update_positions_and_velocities method does exactly what its name says. It first of all updates the positions by calling the specific method of the atom. Then it is applying periodic boundary conditions. After that, it stores the current forces for the velocity update. Then it recalculates the forces with the new positions. Finally, it updates the velocities using the average of the old and new forces. The method does not return anything.\n    def update_positions_and_velocities(self):\n        # First step: Update positions using current forces\n        for atom in self.atoms:\n            atom.update_position(self.timestep)\n            # Apply periodic boundary conditions\n            atom.apply_periodic_boundaries(self.box_size)\n\n        # Store current forces for velocity update\n        old_forces = {atom.id: atom.force.copy() for atom in self.atoms}\n\n        # Recalculate forces with new positions\n        self.calculate_forces()\n\n        # Second step: Update velocities using average of old and new forces\n        for atom in self.atoms:\n            atom.update_velocity(self.timestep, atom.force)\nWith these methods, we have a complete simulation class that can run a molecular dynamics simulation for a given number of steps. The simulation class will keep track of the energy of the system at each step, which can be used to analyze the behavior of the system over time.\n\n\n\n\n\n\nComplete MDSimulation class\n\n\n\n\n\n\nclass MDSimulation:\n    def __init__(self, atoms, forcefield, timestep, box_size):\n        self.atoms = atoms\n        self.forcefield = forcefield\n        self.forcefield.box_size = box_size  # Set box size in forcefield\n        self.timestep = timestep\n        self.box_size = np.array(box_size)\n        self.initial_energy = None\n        self.energy_history = []\n\n\n    def calculate_forces(self):\n        # Reset all forces\n        for atom in self.atoms:\n            atom.reset_force()\n\n        # Calculate forces between all pairs\n        for i, atom1 in enumerate(self.atoms):\n            for atom2 in self.atoms[i+1:]:\n                force = self.forcefield.calculate_lj_force(atom1, atom2)\n                atom1.add_force(force)\n                atom2.add_force(-force)  # Newton's third law\n\n    def update_positions_and_velocities(self):\n        # First step: Update positions using current forces\n        for atom in self.atoms:\n            atom.update_position(self.timestep)\n            # Apply periodic boundary conditions\n            atom.apply_periodic_boundaries(self.box_size)\n\n        # Store current forces for velocity update\n        old_forces = {atom.id: atom.force.copy() for atom in self.atoms}\n\n        # Recalculate forces with new positions\n        self.calculate_forces()\n\n        # Second step: Update velocities using average of old and new forces\n        for atom in self.atoms:\n            atom.update_velocity(self.timestep, atom.force)\n\n\n\n\nNow we have the atom class, the force field class, and the simulation class. We can use these classes to run a molecular dynamics simulation of a simple Lennard-Jones system. In the next seminar, we still have to find a way to\n\ninitialize the positions of the atoms in an appropriate way\nto provide them with a velocity distribution that matches the temperature of the system\nto run the simulation and keep the temperature constant\nto trace the energy in the system over time"
  },
  {
    "objectID": "seminars/1_input_output.html",
    "href": "seminars/1_input_output.html",
    "title": "Input and output",
    "section": "",
    "text": "Python has a function called input for getting input from the user and assigning it a variable name.\n\nvalue=input(\"Tell me a number: \")\ntype(value)\n\nTell me a number:  78898.9\n\n\nstr\n\n\nThe value contains the keyboard input as expected, but it is a string. We want to use a number and not a string, so we need to convert it from a string to a number.\n\nv = eval(value)\ntype(v)\n\nfloat\n\n\n\n\n\nScreen output is possible by using the print command. The argument of the print function can be of different type.\n\n\nYou can format your output by modifying the string given to the print function by str.format(), The str contains text that is written to be the screen, as well as certain format specifiers contained in curly braces {}. The format function contains the list of variables that are to be printed.\n\nstring1 = \"How\"\nstring2 = \"are you my friend?\"\nint1 = 34\nint2 = 942885\nfloat1 = -3.0\nfloat2 = 3.141592653589793e-14\nprint(' ***')\n\nprint(string1)\nprint(string1 + ' ' + string2)\n\nprint(' 1. {} {}'.format(string1, string2)) \n\nprint(' 2. {0:s} {1:s}'.format(string1, string2))\nprint(' 3. {0:s} {0:s} {1:s} - {0:s} {1:s}'.format(string1, string2)) \n\nprint(' 4. {0:10s}{1:5s}'.format(string1, string2))\nprint(' ***')\nprint(int1, int2)\nprint(' 6. {0:d} {1:d}'.format(int1, int2)) \nprint(' 7. {0:8d} {1:10d}'.format(int1, int2)) \nprint(' ***')\nprint(' 8. {0:0.3f}'.format(float1))\nprint(' 9. {0:6.3f}'.format(float1)) \nprint('10. {0:8.3f}'.format(float1)) \nprint(2*' 11. {0:8.3f}'.format(float1))\nprint(' ***')\nprint('12. {0:0.3e}'.format(float2)) \nprint('13. {0:10.3e}'.format(float2)) \nprint('14. {0:10.3f}'.format(float2))\nprint(' ***')\nprint('15. 12345678901234567890')\nprint('16. {0:s}--{1:8d},{2:10.3e}'.format(string2, int1, float2))\n\n ***\nHow\nHow are you my friend?\n 1. How are you my friend?\n 2. How are you my friend?\n 3. How How are you my friend? - How are you my friend?\n 4. How       are you my friend?\n ***\n34 942885\n 6. 34 942885\n 7.       34     942885\n ***\n 8. -3.000\n 9. -3.000\n10.   -3.000\n 11.   -3.000 11.   -3.000\n ***\n12. 3.142e-14\n13.  3.142e-14\n14.      0.000\n ***\n15. 12345678901234567890\n16. are you my friend?--      34, 3.142e-14\n\n\n\n\n\nA very similar formatting can be achieved with the %operator.\n\nname = \"Frank\"\nprint(\"Hello, %s.\" % name)\n\nHello, Frank.\n\n\n\n\n\nFormatted string literals are the string literals that start with an f at the beginning and use curly braces {} to enclose the expressions that will be replaced with other values.\n\nname = \"Python Lecture\"\nnumber = 3\nfstring = f\"I'm here for the {number}. time and this {name} is awesome!\"\nprint(fstring)\n\nI'm here for the 3. time and this Python Lecture is awesome!\n\n\n\n\ntimes = 100\nfstring = f\"You just have to sent me {times:10.3f} Euros.\"\nprint(fstring)\n\nYou just have to sent me    100.000 Euros.\n\n\n\n\n\n\nFile input and output is one of the most important features. We will have a look at reading and writing of text files with numpy and pandas. Python itself also allows you to open files and the file object provides the methods read, write and close.\n\nimport numpy as np\n\nwith open('a.txt', 'r') as file_1,open('b.txt','r') as file_2:\n    for a,b in zip(file_1,file_2):\n        print(int(a)+int(b))\n\n\nfile_1.close()\nfile_2.close()\n\n10\n12\n14\n97\n9\n9\n\n\n\n\nMost of the time we want import numbers from text files. So direct connection to NumPy seems useful and we will study that first.\n\nimport numpy as np # don't forget to import numpy\n\n\n\nOften you would like to analyze data that you have stored in a text file. Consider, for example, the data file below for an experiment measuring the free fall of a mass.\nData for falling mass experiment\nDate: 16-Aug-2013\nData taken by Frank and Ralf\ndata point  time (sec)  height (mm) uncertainty (mm)\n0       0.0     180     3.5\n1       0.5     182     4.5\n2       1.0     178     4.0\n3       1.5     165     5.5\n4       2.0     160     2.5\n5       2.5     148     3.0\n6       3.0     136     2.5\nSuppose that the name of the text file is MyData.txt. Then we can read the data into four different arrays with the following NumPy statement:\n\ndataPt, time, height, error = np.loadtxt(\"MyData.txt\", skiprows=4 , unpack=True)\n\nIf you don‚Äôt want to read in all the columns of data, you can specify which columns to read in using the usecols key word. For example, the call\n\ntime, height = np.loadtxt(\"MyData.txt\", skiprows=5 , usecols = (1,2), unpack=True)\n\nreads in only columns 1 and 2; columns 0 and 3 are skipped.\n\n\n\nThere are plenty of ways to write data to a data file in Python. We will stick to one very simple one that‚Äôs suitable for writing data files in text format. It uses the NumPy savetxt routine, which is the counterpart of the loadtxt routine introduced in the previous section. The general form of the routine is\nsavetxt(filename, array, fmt=\"%0.18e\", delimiter=\" \", newline=\"\\n\", header=\"\", footer=\"\", comments=\"# \")\nWe illustrate savetext below with a script that first creates four arrays by reading in the data file MyData.txt, as discussed in the previous section, and then writes that same data set to another file MyDataOut.txt.\n\ndataPt, time, height, error = np.loadtxt(\"MyData.txt\", skiprows=5 , unpack=True)\n\n\nlist(zip(dataPt, time, height, error))\n\n[(1.0, 0.5, 182.0, 4.5),\n (2.0, 1.0, 178.0, 4.0),\n (3.0, 1.5, 165.0, 5.5),\n (4.0, 2.0, 160.0, 2.5),\n (5.0, 2.5, 148.0, 3.0),\n (6.0, 3.0, 136.0, 2.5)]\n\n\n\nnp.savetxt('MyDataOut.txt',list(zip(dataPt, time, height, error)), fmt=\"%12.3f\")\n\n\ncat MyDataOut.txt\n\n       1.000        0.500      182.000        4.500\n       2.000        1.000      178.000        4.000\n       3.000        1.500      165.000        5.500\n       4.000        2.000      160.000        2.500\n       5.000        2.500      148.000        3.000\n       6.000        3.000      136.000        2.500\n\n\n\n\n\n\nPandas is a software library written for the Python programming language. It is used for data manipulation and analysis. It provides special data structures and operations for the manipulation of numerical tables and time series and builds on top of numpy.\n\nEasy handling of missing data\nIntelligent label-based slicing, fancy indexing, and subsetting of large data sets\n\nThe data formats provided by the pandas module are used by several other modules, such as the trackpy which is a moduly for feature tracking and analysis in image series.\n\n\n\nimport pandas as pd # import the pandas module\n\nPandas provides two data structures\n\nSeries\nData Frames\n\nA Series is a one-dimensional labeled array capable of holding any data type (integers, strings, floating point numbers, Python objects, etc.). The axis labels are collectively referred to as the index.\n\nmy_simple_series = pd.Series(np.random.randn(7), index=['a', 'b', 'c', 'd', 'e','f','g'])\nmy_simple_series\n\na    1.160711\nb   -0.296427\nc    1.881074\nd   -1.197978\ne    0.280311\nf    1.538339\ng    1.681957\ndtype: float64\n\n\n\nmy_simple_series\n\n-0.2964266043928443\n\n\nThere is a whole lot of functionality built into pandas data types. You may of course also obtain the same functionality using numpy commands, but you may find the pandas abbrevations very useful.\n\nmy_simple_series.agg(['min','max','sum','mean']) # aggregate a number of properties into a single array\n\nmin    -1.523075\nmax     0.525265\nsum    -2.119315\nmean   -0.302759\ndtype: float64\n\n\nA DataFrame is a two-dimensional size-mutable, potentially heterogeneous tabular data structure with labeled axes (rows and columns). The example below shows how such a DataFrame can be generated from the scratch. In addition to the data supplied to the DataFrame method, an index column is generated when creating a DataFrame. As in the case of Series there is a whole lot of functionality integrated into the DataFrame data type which you may explore on the website.\n\ndf = pd.DataFrame()\n\n\ndf = pd.DataFrame(np.random.randint(low=0, high=10, size=(5, 5)),columns=['column 1', 'column 2', 'columns 3', 'column 4', 'column 5'])\ndf.head()\n\n\n\n\n\n\n\n\ncolumn 1\ncolumn 2\ncolumns 3\ncolumn 4\ncolumn 5\n\n\n\n\n0\n3\n9\n3\n7\n4\n\n\n1\n2\n2\n4\n6\n7\n\n\n2\n6\n1\n7\n4\n5\n\n\n3\n3\n4\n4\n3\n0\n\n\n4\n5\n6\n8\n0\n2\n\n\n\n\n\n\n\nDue to the labelling of the columns, each column may be accessed by its column label. Labeling by names improves readability considerably.\n\ndf['column 4']\n\n0    7\n1    6\n2    4\n3    3\n4    0\nName: column 4, dtype: int64\n\n\nIf you don‚Äôt like this format, you can always return to a simple numpy array with the as_matrix() method.\n\ndf.values\n\narray([[3, 9, 3, 7, 4],\n       [2, 2, 4, 6, 7],\n       [6, 1, 7, 4, 5],\n       [3, 4, 4, 3, 0],\n       [5, 6, 8, 0, 2]])\n\n\n\n\n\nDataFrames may also be populated by text files such as comma separated value files (short .csv). These files contain data in text format but also a column label, which can be read by the pandas method read_csv(). You can find an example below, which reads the data from the dust sensor on my balcony from April, 11th. You see the different columns, where P1 and P2 correspond to the PM10 and PM2.5 dust values in \\(\\mu g/m^3\\).\n\ndata = pd.DataFrame()\ndata = pd.read_csv(\"2018-04-11_sds011_sensor_12253.csv\",delimiter=\";\",parse_dates=False)\ndata.head()\n\n\n\n\n\n\n\n\nsensor_id\nsensor_type\nlocation\nlat\nlon\ntimestamp\nP1\ndurP1\nratioP1\nP2\ndurP2\nratioP2\n\n\n\n\n0\n12253\nSDS011\n6189\n52.527\n13.39\n2018-04-11T00:01:58\n25.87\nNaN\nNaN\n19.37\nNaN\nNaN\n\n\n1\n12253\nSDS011\n6189\n52.527\n13.39\n2018-04-11T00:04:24\n25.63\nNaN\nNaN\n20.53\nNaN\nNaN\n\n\n2\n12253\nSDS011\n6189\n52.527\n13.39\n2018-04-11T00:06:55\n26.30\nNaN\nNaN\n22.00\nNaN\nNaN\n\n\n3\n12253\nSDS011\n6189\n52.527\n13.39\n2018-04-11T00:09:23\n24.60\nNaN\nNaN\n20.30\nNaN\nNaN\n\n\n4\n12253\nSDS011\n6189\n52.527\n13.39\n2018-04-11T00:11:51\n25.17\nNaN\nNaN\n20.23\nNaN\nNaN\n\n\n\n\n\n\n\n\n(data['P1']/data['P2']).plot()"
  },
  {
    "objectID": "seminars/1_input_output.html#keyboard-input",
    "href": "seminars/1_input_output.html#keyboard-input",
    "title": "Input and output",
    "section": "",
    "text": "Python has a function called input for getting input from the user and assigning it a variable name.\n\nvalue=input(\"Tell me a number: \")\ntype(value)\n\nTell me a number:  78898.9\n\n\nstr\n\n\nThe value contains the keyboard input as expected, but it is a string. We want to use a number and not a string, so we need to convert it from a string to a number.\n\nv = eval(value)\ntype(v)\n\nfloat"
  },
  {
    "objectID": "seminars/1_input_output.html#screen-output",
    "href": "seminars/1_input_output.html#screen-output",
    "title": "Input and output",
    "section": "",
    "text": "Screen output is possible by using the print command. The argument of the print function can be of different type.\n\n\nYou can format your output by modifying the string given to the print function by str.format(), The str contains text that is written to be the screen, as well as certain format specifiers contained in curly braces {}. The format function contains the list of variables that are to be printed.\n\nstring1 = \"How\"\nstring2 = \"are you my friend?\"\nint1 = 34\nint2 = 942885\nfloat1 = -3.0\nfloat2 = 3.141592653589793e-14\nprint(' ***')\n\nprint(string1)\nprint(string1 + ' ' + string2)\n\nprint(' 1. {} {}'.format(string1, string2)) \n\nprint(' 2. {0:s} {1:s}'.format(string1, string2))\nprint(' 3. {0:s} {0:s} {1:s} - {0:s} {1:s}'.format(string1, string2)) \n\nprint(' 4. {0:10s}{1:5s}'.format(string1, string2))\nprint(' ***')\nprint(int1, int2)\nprint(' 6. {0:d} {1:d}'.format(int1, int2)) \nprint(' 7. {0:8d} {1:10d}'.format(int1, int2)) \nprint(' ***')\nprint(' 8. {0:0.3f}'.format(float1))\nprint(' 9. {0:6.3f}'.format(float1)) \nprint('10. {0:8.3f}'.format(float1)) \nprint(2*' 11. {0:8.3f}'.format(float1))\nprint(' ***')\nprint('12. {0:0.3e}'.format(float2)) \nprint('13. {0:10.3e}'.format(float2)) \nprint('14. {0:10.3f}'.format(float2))\nprint(' ***')\nprint('15. 12345678901234567890')\nprint('16. {0:s}--{1:8d},{2:10.3e}'.format(string2, int1, float2))\n\n ***\nHow\nHow are you my friend?\n 1. How are you my friend?\n 2. How are you my friend?\n 3. How How are you my friend? - How are you my friend?\n 4. How       are you my friend?\n ***\n34 942885\n 6. 34 942885\n 7.       34     942885\n ***\n 8. -3.000\n 9. -3.000\n10.   -3.000\n 11.   -3.000 11.   -3.000\n ***\n12. 3.142e-14\n13.  3.142e-14\n14.      0.000\n ***\n15. 12345678901234567890\n16. are you my friend?--      34, 3.142e-14\n\n\n\n\n\nA very similar formatting can be achieved with the %operator.\n\nname = \"Frank\"\nprint(\"Hello, %s.\" % name)\n\nHello, Frank.\n\n\n\n\n\nFormatted string literals are the string literals that start with an f at the beginning and use curly braces {} to enclose the expressions that will be replaced with other values.\n\nname = \"Python Lecture\"\nnumber = 3\nfstring = f\"I'm here for the {number}. time and this {name} is awesome!\"\nprint(fstring)\n\nI'm here for the 3. time and this Python Lecture is awesome!\n\n\n\n\ntimes = 100\nfstring = f\"You just have to sent me {times:10.3f} Euros.\"\nprint(fstring)\n\nYou just have to sent me    100.000 Euros."
  },
  {
    "objectID": "seminars/1_input_output.html#file-inputoutput",
    "href": "seminars/1_input_output.html#file-inputoutput",
    "title": "Input and output",
    "section": "",
    "text": "File input and output is one of the most important features. We will have a look at reading and writing of text files with numpy and pandas. Python itself also allows you to open files and the file object provides the methods read, write and close.\n\nimport numpy as np\n\nwith open('a.txt', 'r') as file_1,open('b.txt','r') as file_2:\n    for a,b in zip(file_1,file_2):\n        print(int(a)+int(b))\n\n\nfile_1.close()\nfile_2.close()\n\n10\n12\n14\n97\n9\n9\n\n\n\n\nMost of the time we want import numbers from text files. So direct connection to NumPy seems useful and we will study that first.\n\nimport numpy as np # don't forget to import numpy\n\n\n\nOften you would like to analyze data that you have stored in a text file. Consider, for example, the data file below for an experiment measuring the free fall of a mass.\nData for falling mass experiment\nDate: 16-Aug-2013\nData taken by Frank and Ralf\ndata point  time (sec)  height (mm) uncertainty (mm)\n0       0.0     180     3.5\n1       0.5     182     4.5\n2       1.0     178     4.0\n3       1.5     165     5.5\n4       2.0     160     2.5\n5       2.5     148     3.0\n6       3.0     136     2.5\nSuppose that the name of the text file is MyData.txt. Then we can read the data into four different arrays with the following NumPy statement:\n\ndataPt, time, height, error = np.loadtxt(\"MyData.txt\", skiprows=4 , unpack=True)\n\nIf you don‚Äôt want to read in all the columns of data, you can specify which columns to read in using the usecols key word. For example, the call\n\ntime, height = np.loadtxt(\"MyData.txt\", skiprows=5 , usecols = (1,2), unpack=True)\n\nreads in only columns 1 and 2; columns 0 and 3 are skipped.\n\n\n\nThere are plenty of ways to write data to a data file in Python. We will stick to one very simple one that‚Äôs suitable for writing data files in text format. It uses the NumPy savetxt routine, which is the counterpart of the loadtxt routine introduced in the previous section. The general form of the routine is\nsavetxt(filename, array, fmt=\"%0.18e\", delimiter=\" \", newline=\"\\n\", header=\"\", footer=\"\", comments=\"# \")\nWe illustrate savetext below with a script that first creates four arrays by reading in the data file MyData.txt, as discussed in the previous section, and then writes that same data set to another file MyDataOut.txt.\n\ndataPt, time, height, error = np.loadtxt(\"MyData.txt\", skiprows=5 , unpack=True)\n\n\nlist(zip(dataPt, time, height, error))\n\n[(1.0, 0.5, 182.0, 4.5),\n (2.0, 1.0, 178.0, 4.0),\n (3.0, 1.5, 165.0, 5.5),\n (4.0, 2.0, 160.0, 2.5),\n (5.0, 2.5, 148.0, 3.0),\n (6.0, 3.0, 136.0, 2.5)]\n\n\n\nnp.savetxt('MyDataOut.txt',list(zip(dataPt, time, height, error)), fmt=\"%12.3f\")\n\n\ncat MyDataOut.txt\n\n       1.000        0.500      182.000        4.500\n       2.000        1.000      178.000        4.000\n       3.000        1.500      165.000        5.500\n       4.000        2.000      160.000        2.500\n       5.000        2.500      148.000        3.000\n       6.000        3.000      136.000        2.500\n\n\n\n\n\n\nPandas is a software library written for the Python programming language. It is used for data manipulation and analysis. It provides special data structures and operations for the manipulation of numerical tables and time series and builds on top of numpy.\n\nEasy handling of missing data\nIntelligent label-based slicing, fancy indexing, and subsetting of large data sets\n\nThe data formats provided by the pandas module are used by several other modules, such as the trackpy which is a moduly for feature tracking and analysis in image series.\n\n\n\nimport pandas as pd # import the pandas module\n\nPandas provides two data structures\n\nSeries\nData Frames\n\nA Series is a one-dimensional labeled array capable of holding any data type (integers, strings, floating point numbers, Python objects, etc.). The axis labels are collectively referred to as the index.\n\nmy_simple_series = pd.Series(np.random.randn(7), index=['a', 'b', 'c', 'd', 'e','f','g'])\nmy_simple_series\n\na    1.160711\nb   -0.296427\nc    1.881074\nd   -1.197978\ne    0.280311\nf    1.538339\ng    1.681957\ndtype: float64\n\n\n\nmy_simple_series\n\n-0.2964266043928443\n\n\nThere is a whole lot of functionality built into pandas data types. You may of course also obtain the same functionality using numpy commands, but you may find the pandas abbrevations very useful.\n\nmy_simple_series.agg(['min','max','sum','mean']) # aggregate a number of properties into a single array\n\nmin    -1.523075\nmax     0.525265\nsum    -2.119315\nmean   -0.302759\ndtype: float64\n\n\nA DataFrame is a two-dimensional size-mutable, potentially heterogeneous tabular data structure with labeled axes (rows and columns). The example below shows how such a DataFrame can be generated from the scratch. In addition to the data supplied to the DataFrame method, an index column is generated when creating a DataFrame. As in the case of Series there is a whole lot of functionality integrated into the DataFrame data type which you may explore on the website.\n\ndf = pd.DataFrame()\n\n\ndf = pd.DataFrame(np.random.randint(low=0, high=10, size=(5, 5)),columns=['column 1', 'column 2', 'columns 3', 'column 4', 'column 5'])\ndf.head()\n\n\n\n\n\n\n\n\ncolumn 1\ncolumn 2\ncolumns 3\ncolumn 4\ncolumn 5\n\n\n\n\n0\n3\n9\n3\n7\n4\n\n\n1\n2\n2\n4\n6\n7\n\n\n2\n6\n1\n7\n4\n5\n\n\n3\n3\n4\n4\n3\n0\n\n\n4\n5\n6\n8\n0\n2\n\n\n\n\n\n\n\nDue to the labelling of the columns, each column may be accessed by its column label. Labeling by names improves readability considerably.\n\ndf['column 4']\n\n0    7\n1    6\n2    4\n3    3\n4    0\nName: column 4, dtype: int64\n\n\nIf you don‚Äôt like this format, you can always return to a simple numpy array with the as_matrix() method.\n\ndf.values\n\narray([[3, 9, 3, 7, 4],\n       [2, 2, 4, 6, 7],\n       [6, 1, 7, 4, 5],\n       [3, 4, 4, 3, 0],\n       [5, 6, 8, 0, 2]])\n\n\n\n\n\nDataFrames may also be populated by text files such as comma separated value files (short .csv). These files contain data in text format but also a column label, which can be read by the pandas method read_csv(). You can find an example below, which reads the data from the dust sensor on my balcony from April, 11th. You see the different columns, where P1 and P2 correspond to the PM10 and PM2.5 dust values in \\(\\mu g/m^3\\).\n\ndata = pd.DataFrame()\ndata = pd.read_csv(\"2018-04-11_sds011_sensor_12253.csv\",delimiter=\";\",parse_dates=False)\ndata.head()\n\n\n\n\n\n\n\n\nsensor_id\nsensor_type\nlocation\nlat\nlon\ntimestamp\nP1\ndurP1\nratioP1\nP2\ndurP2\nratioP2\n\n\n\n\n0\n12253\nSDS011\n6189\n52.527\n13.39\n2018-04-11T00:01:58\n25.87\nNaN\nNaN\n19.37\nNaN\nNaN\n\n\n1\n12253\nSDS011\n6189\n52.527\n13.39\n2018-04-11T00:04:24\n25.63\nNaN\nNaN\n20.53\nNaN\nNaN\n\n\n2\n12253\nSDS011\n6189\n52.527\n13.39\n2018-04-11T00:06:55\n26.30\nNaN\nNaN\n22.00\nNaN\nNaN\n\n\n3\n12253\nSDS011\n6189\n52.527\n13.39\n2018-04-11T00:09:23\n24.60\nNaN\nNaN\n20.30\nNaN\nNaN\n\n\n4\n12253\nSDS011\n6189\n52.527\n13.39\n2018-04-11T00:11:51\n25.17\nNaN\nNaN\n20.23\nNaN\nNaN\n\n\n\n\n\n\n\n\n(data['P1']/data['P2']).plot()"
  },
  {
    "objectID": "seminars/seminar01/01-seminar01.html",
    "href": "seminars/seminar01/01-seminar01.html",
    "title": "Seminar 1",
    "section": "",
    "text": "Calculate the average of all of the integers from 1 to 10.\n\n\n\n\n\n\n\nuse the sum() and len() functions\nn = range(1, 11)\n\n\n1n = range(1, 11)\n2sum(n)/len(n)\n\n1\n\ncreate the range of numbers from 1 to 10.\n\n2\n\ncalculate the sum of the numbers and divide by the number of elements in the list."
  },
  {
    "objectID": "seminars/seminar01/mdX.html",
    "href": "seminars/seminar01/mdX.html",
    "title": "Einf√ºhrung in die Modellierung Physikalischer Prozesse",
    "section": "",
    "text": "The Lennard-Jones potential describes the interaction between two atoms:\n\\[V_{LJ}(r) = 4\\epsilon \\left[\\left(\\frac{\\sigma}{r}\\right)^{12} - \\left(\\frac{\\sigma}{r}\\right)^6\\right]\\]\nThe corresponding force:\n\\[F_{LJ}(r) = -\\frac{dV_{LJ}}{dr} = 24\\epsilon \\left[2\\left(\\frac{\\sigma}{r}\\right)^{12} - \\left(\\frac{\\sigma}{r}\\right)^6\\right]\\frac{\\vec{r}}{r^2}\\]\nwhere: - \\(\\epsilon\\) is the depth of the potential well - \\(\\sigma\\) is the distance at which the potential is zero - \\(r\\) is the distance between particles\n\n\n\nimport numpy as np\n\ndef lennard_jones_force(pos1, pos2, epsilon=1.0, sigma=1.0):\n    r_vec = pos2 - pos1\n    r = np.linalg.norm(r_vec)\n\n    # Force magnitude\n    force_mag = 24 * epsilon * (2 * (sigma/r)**12 - (sigma/r)**6) / r\n\n    # Force vector\n    force_vec = force_mag * r_vec / r\n\n    return force_vec"
  },
  {
    "objectID": "seminars/seminar01/mdX.html#simple-atomic-system-with-lennard-jones-potential",
    "href": "seminars/seminar01/mdX.html#simple-atomic-system-with-lennard-jones-potential",
    "title": "Einf√ºhrung in die Modellierung Physikalischer Prozesse",
    "section": "",
    "text": "The Lennard-Jones potential describes the interaction between two atoms:\n\\[V_{LJ}(r) = 4\\epsilon \\left[\\left(\\frac{\\sigma}{r}\\right)^{12} - \\left(\\frac{\\sigma}{r}\\right)^6\\right]\\]\nThe corresponding force:\n\\[F_{LJ}(r) = -\\frac{dV_{LJ}}{dr} = 24\\epsilon \\left[2\\left(\\frac{\\sigma}{r}\\right)^{12} - \\left(\\frac{\\sigma}{r}\\right)^6\\right]\\frac{\\vec{r}}{r^2}\\]\nwhere: - \\(\\epsilon\\) is the depth of the potential well - \\(\\sigma\\) is the distance at which the potential is zero - \\(r\\) is the distance between particles\n\n\n\nimport numpy as np\n\ndef lennard_jones_force(pos1, pos2, epsilon=1.0, sigma=1.0):\n    r_vec = pos2 - pos1\n    r = np.linalg.norm(r_vec)\n\n    # Force magnitude\n    force_mag = 24 * epsilon * (2 * (sigma/r)**12 - (sigma/r)**6) / r\n\n    # Force vector\n    force_vec = force_mag * r_vec / r\n\n    return force_vec"
  },
  {
    "objectID": "seminars/seminar01/mdX.html#boundary-conditions",
    "href": "seminars/seminar01/mdX.html#boundary-conditions",
    "title": "Einf√ºhrung in die Modellierung Physikalischer Prozesse",
    "section": "2. Boundary Conditions",
    "text": "2. Boundary Conditions\n\n2.1 Periodic Boundary Conditions (PBC)\nParticles that exit one side of the box re-enter from the opposite side.\ndef apply_periodic_bc(positions, box_length):\n    return positions - box_length * np.floor(positions/box_length)\n\ndef minimum_image_distance(pos1, pos2, box_length):\n    dr = pos2 - pos1\n    dr = dr - box_length * np.round(dr/box_length)\n    return dr\n\n\n2.2 Reflective Boundaries\nParticles bounce off the walls:\ndef apply_reflective_bc(positions, velocities, box_length):\n    for i in range(len(positions)):\n        for dim in range(3):\n            if positions[i,dim] &lt; 0:\n                positions[i,dim] = -positions[i,dim]\n                velocities[i,dim] = -velocities[i,dim]\n            elif positions[i,dim] &gt; box_length:\n                positions[i,dim] = 2*box_length - positions[i,dim]\n                velocities[i,dim] = -velocities[i,dim]\n    return positions, velocities"
  },
  {
    "objectID": "seminars/seminar01/mdX.html#basic-simulation-loop",
    "href": "seminars/seminar01/mdX.html#basic-simulation-loop",
    "title": "Einf√ºhrung in die Modellierung Physikalischer Prozesse",
    "section": "3. Basic Simulation Loop",
    "text": "3. Basic Simulation Loop\n\n3.1 Initial Implementation with Just LJ Forces\nclass MDSimulation:\n    def __init__(self, positions, velocities, mass, box_length, dt):\n        self.positions = positions\n        self.velocities = velocities\n        self.mass = mass\n        self.box_length = box_length\n        self.dt = dt\n\n    def calculate_forces(self):\n        n_particles = len(self.positions)\n        forces = np.zeros_like(self.positions)\n\n        for i in range(n_particles):\n            for j in range(i+1, n_particles):\n                r_ij = minimum_image_distance(\n                    self.positions[i],\n                    self.positions[j],\n                    self.box_length\n                )\n                f_ij = lennard_jones_force(np.zeros(3), r_ij)\n                forces[i] += f_ij\n                forces[j] -= f_ij  # Newton's third law\n\n        return forces\n\n    def velocity_verlet_step(self):\n        # Calculate initial forces\n        forces = self.calculate_forces()\n\n        # Update positions\n        self.positions += self.velocities * self.dt + \\\n                         0.5 * forces / self.mass * self.dt**2\n\n        # Apply boundary conditions\n        self.positions = apply_periodic_bc(self.positions, self.box_length)\n\n        # Calculate new forces\n        new_forces = self.calculate_forces()\n\n        # Update velocities\n        self.velocities += 0.5 * (forces + new_forces) / self.mass * self.dt"
  },
  {
    "objectID": "seminars/seminar01/mdX.html#adding-molecular-forces",
    "href": "seminars/seminar01/mdX.html#adding-molecular-forces",
    "title": "Einf√ºhrung in die Modellierung Physikalischer Prozesse",
    "section": "4. Adding Molecular Forces",
    "text": "4. Adding Molecular Forces\n\n4.1 Bond Forces\nAdding harmonic bond potential:\n\\[V_{bond}(r) = \\frac{k}{2}(r - r_0)^2\\]\ndef bond_force(pos1, pos2, k_bond, r0):\n    r_vec = pos2 - pos1\n    r = np.linalg.norm(r_vec)\n    force_mag = -k_bond * (r - r0)\n    return force_mag * r_vec / r\n\n\n4.2 Angle Forces\nThree-body angle potential:\n\\[V_{angle}(\\theta) = \\frac{k_\\theta}{2}(\\theta - \\theta_0)^2\\]\ndef angle_force(pos1, pos2, pos3, k_angle, theta0):\n    # Calculate vectors\n    v1 = pos1 - pos2\n    v2 = pos3 - pos2\n\n    # Calculate angle\n    cos_theta = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n    theta = np.arccos(np.clip(cos_theta, -1.0, 1.0))\n\n    # Calculate forces (simplified version)\n    force_magnitude = -k_angle * (theta - theta0)\n\n    return force_magnitude * v1, -force_magnitude * v2\n\n\n4.3 Enhanced Simulation Class\nclass MolecularMDSimulation(MDSimulation):\n    def __init__(self, *args, bonds=None, angles=None):\n        super().__init__(*args)\n        self.bonds = bonds or []  # [(i, j, k, r0), ...]\n        self.angles = angles or []  # [(i, j, k, k_angle, theta0), ...]\n\n    def calculate_forces(self):\n        # Start with non-bonded forces\n        forces = super().calculate_forces()\n\n        # Add bond forces\n        for bond in self.bonds:\n            i, j, k_bond, r0 = bond\n            f_ij = bond_force(\n                self.positions[i],\n                self.positions[j],\n                k_bond, r0\n            )\n            forces[i] += f_ij\n            forces[j] -= f_ij\n\n        # Add angle forces\n        for angle in self.angles:\n            i, j, k, k_angle, theta0 = angle\n            f_i, f_k = angle_force(\n                self.positions[i],\n                self.positions[j],\n                self.positions[k],\n                k_angle, theta0\n            )\n            forces[i] += f_i\n            forces[k] += f_k\n            forces[j] -= (f_i + f_k)\n\n        return forces"
  },
  {
    "objectID": "seminars/seminar01/mdX.html#example-usage",
    "href": "seminars/seminar01/mdX.html#example-usage",
    "title": "Einf√ºhrung in die Modellierung Physikalischer Prozesse",
    "section": "5. Example Usage",
    "text": "5. Example Usage\n# Initialize system\nn_particles = 100\nbox_length = 10.0\npositions = np.random.rand(n_particles, 3) * box_length\nvelocities = np.zeros((n_particles, 3))\nmass = 1.0\ndt = 0.001\n\n# Create simulation\nsim = MolecularMDSimulation(\n    positions, velocities, mass, box_length, dt,\n    bonds=[(0, 1, 1000.0, 1.0)],  # Example bond\n    angles=[(0, 1, 2, 100.0, np.pi)]  # Example angle\n)\n\n# Run simulation\nn_steps = 1000\nfor step in range(n_steps):\n    sim.velocity_verlet_step()\nHere‚Äôs a suggested basic structure:\nclass Atom:\n    def __init__(self, atom_id, atom_type, position, velocity=None, mass=None):\n        self.id = atom_id          # unique identifier\n        self.type = atom_type      # e.g., 'H', 'C', 'O'\n        self.position = position   # numpy array [x, y, z]\n        self.velocity = velocity if velocity is not None else np.zeros(3)\n        self.mass = mass\n        self.force = np.zeros(3)   # current force on atom\n\n        # Optional attributes that might be useful later:\n        self.bonded_atoms = []     # list of atoms this atom is bonded to\n        self.charges = 0.0         # for electrostatic interactions\nThen you can later create classes for: 1. Bond (connects two Atom objects)\nclass Bond:\n    def __init__(self, atom1, atom2, k, r0):\n        self.atom1 = atom1\n        self.atom2 = atom2\n        self.k = k      # force constant\n        self.r0 = r0    # equilibrium distance\n\nAngle (three Atom objects)\n\nclass Angle:\n    def __init__(self, atom1, atom2, atom3, k, theta0):\n        self.atoms = [atom1, atom2, atom3]\n        self.k = k          # force constant\n        self.theta0 = theta0  # equilibrium angle\n\nDihedral (four Atom objects)\n\nThis modular approach makes it easier to: - Add features incrementally - Debug each interaction type separately - Keep track of connectivity - Calculate forces systematically\nclass Atom:\n    def __init__(self, atom_id, atom_type, position, velocity=None, mass=None):\n        self.id = atom_id\n        self.type = atom_type\n        self.position = position\n        self.velocity = velocity if velocity is not None else np.zeros(3)\n        self.mass = mass\n        self.force = np.zeros(3)\n\n    def add_force(self, force):\n        \"\"\"Add force contribution to total force on atom\"\"\"\n        self.force += force\n\n    def reset_force(self):\n        \"\"\"Reset force to zero at start of each step\"\"\"\n        self.force = np.zeros(3)\n\n    def update_position(self, dt):\n        \"\"\"First step of velocity Verlet: update position\"\"\"\n        self.position += self.velocity * dt + 0.5 * (self.force/self.mass) * dt**2\n\n    def update_velocity(self, dt, new_force):\n        \"\"\"Second step of velocity Verlet: update velocity using average force\"\"\"\n        self.velocity += 0.5 * (new_force + self.force)/self.mass * dt\n        self.force = new_force\n\nclass ForceField:\n    def __init__(self, sigma, epsilon):\n        self.sigma = sigma\n        self.epsilon = epsilon\n\n    def calculate_lj_force(self, atom1, atom2):\n        \"\"\"Calculate LJ force between two atoms\"\"\"\n        r = atom1.position - atom2.position\n        r_mag = np.linalg.norm(r)\n        # LJ force calculation\n        force = 24 * self.epsilon * (2 * (self.sigma/r_mag)**12\n                                   - (self.sigma/r_mag)**6) * r/r_mag**2\n        return force\n\nclass MDSimulation:\n    def __init__(self, atoms, forcefield):\n        self.atoms = atoms\n        self.forcefield = forcefield\n\n    def calculate_forces(self):\n        # Reset all forces\n        for atom in self.atoms:\n            atom.reset_force()\n\n        # Calculate forces between all pairs\n        for i, atom1 in enumerate(self.atoms):\n            for atom2 in self.atoms[i+1:]:\n                force = self.forcefield.calculate_lj_force(atom1, atom2)\n                atom1.add_force(force)\n                atom2.add_force(-force)  # Newton's third law\n\nNew lecture\nclass Atom: def init(self, atom_id, atom_type, position, velocity=None, mass=None): self.id = atom_id self.type = atom_type # e.g., ‚ÄòA‚Äô, ‚ÄòB‚Äô, etc. self.position = position self.velocity = velocity if velocity is not None else np.zeros(2) self.mass = mass self.force = np.zeros(2)\nclass ForceField: def init(self): # Dictionary to store interaction parameters between atom types self.pair_parameters = {}\ndef add_pair_parameters(self, type1, type2, epsilon, sigma):\n    \"\"\"Add interaction parameters for a pair of atom types\"\"\"\n    # Store parameters symmetrically\n    key = tuple(sorted([type1, type2]))\n    self.pair_parameters[key] = {'epsilon': epsilon, 'sigma': sigma}\n\ndef get_pair_parameters(self, type1, type2):\n    \"\"\"Get interaction parameters for a pair of atom types\"\"\"\n    key = tuple(sorted([type1, type2]))\n    if key not in self.pair_parameters:\n        raise ValueError(f\"No parameters defined for atom types {type1} and {type2}\")\n    return self.pair_parameters[key]\n\ndef calculate_lj_force(self, atom1, atom2, r_vec, r_mag):\n    \"\"\"Calculate LJ force with type-specific parameters\"\"\"\n    params = self.get_pair_parameters(atom1.type, atom2.type)\n    epsilon = params['epsilon']\n    sigma = params['sigma']\n\n    force_mag = 24.0 * epsilon * (2.0 * (sigma/r_mag)**13\n                                - (sigma/r_mag)**7)\n    return force_mag * r_vec / r_mag\n\n\n\n\n    def setup_simulation():\n        # Create force field and add parameters\n        ff = ForceField()\n\n        # Add parameters for different combinations\n        ff.add_pair_parameters('A', 'A', epsilon=1.0, sigma=1.0)  # A-A interaction\n        ff.add_pair_parameters('B', 'B', epsilon=0.5, sigma=1.2)  # B-B interaction\n        ff.add_pair_parameters('A', 'B', epsilon=0.7, sigma=1.1)  # A-B interaction\n\n        # Create atoms of different types\n        atoms = [\n            Atom(0, 'A', np.array([1.0, 1.0]), mass=1.0),\n            Atom(1, 'A', np.array([2.0, 2.0]), mass=1.0),\n            Atom(2, 'B', np.array([3.0, 3.0]), mass=1.5),\n            Atom(3, 'B', np.array([4.0, 4.0]), mass=1.5)\n        ]\n\n        return ff, atoms"
  },
  {
    "objectID": "seminars/seminar01/md1.html",
    "href": "seminars/seminar01/md1.html",
    "title": "Step-by-Step Development of a Molecular Dynamics Simulation",
    "section": "",
    "text": "Real molecular dynamics (MD) simulations are complex and computationally expensive but very cool, as they give you a glimpse into the world of atoms and molecules. Here, we will develop a simple MD simulation from scratch in Python. The goal is to understand the basic concepts and algorithms behind MD simulations and get something running which can be extended later but also what we are proud of at the end of the course.\nBefore we can start with implementing a simulation, we need to understand the basic concepts and algorithms behind MD simulations. The following sections will guide you through the development of a simple MD simulation."
  },
  {
    "objectID": "seminars/seminar01/md1.html#molecular-dynamics-simulations",
    "href": "seminars/seminar01/md1.html#molecular-dynamics-simulations",
    "title": "Step-by-Step Development of a Molecular Dynamics Simulation",
    "section": "",
    "text": "Real molecular dynamics (MD) simulations are complex and computationally expensive but very cool, as they give you a glimpse into the world of atoms and molecules. Here, we will develop a simple MD simulation from scratch in Python. The goal is to understand the basic concepts and algorithms behind MD simulations and get something running which can be extended later but also what we are proud of at the end of the course.\nBefore we can start with implementing a simulation, we need to understand the basic concepts and algorithms behind MD simulations. The following sections will guide you through the development of a simple MD simulation."
  },
  {
    "objectID": "seminars/seminar01/md1.html#basic-physical-concepts",
    "href": "seminars/seminar01/md1.html#basic-physical-concepts",
    "title": "Step-by-Step Development of a Molecular Dynamics Simulation",
    "section": "Basic Physical Concepts",
    "text": "Basic Physical Concepts\n\nNewton‚Äôs Equations of Motion\nThe motion of particles in a molecular dynamics simulation is governed by Newton‚Äôs equations of motion:\n\\[m_i \\frac{d^2\\vec{r}_i}{dt^2} = \\vec{F}_i\\]\nwhere:\n\n\\(m_i\\) is the mass of particle \\(i\\)\n\\(\\vec{r}_i\\) is the position of particle \\(i\\)\n\\(\\vec{F}_i\\) is the force acting on particle \\(i\\)\n\nThe force acting on a particle is the sum of all forces acting on it:\n\\[\\vec{F}_i = \\sum_{j \\neq i} \\vec{F}_{ij}\\]\nwhere \\(\\vec{F}_{ij}\\) is the force acting on particle \\(i\\) due to particle \\(j\\).\n\n\nPotential Energy Functions and Forces\nThe force \\(\\vec{F}_{ij}\\) is usually derived from a potential energy function and may result from a variety of interactions, such as:\n\nBonded interactions\n\nbond stretching \nbond angle bending \ntorsional interactions \n\nNon-bonded interactions\n\nelectrostatic interactions\nvan der Waals interactions\n\nExternal forces\n\nWe will implement some of them but not all of them.\n\nLennard-Jones Potential\nThe most common potential energy function used in MD simulations is the Lennard-Jones potential. It is belonging to the class of non-bonded interactions. The force and the potential energy of the Lennard-Jones potential are given by:\n\\[V_{LJ}(r) = 4\\epsilon \\left[\\left(\\frac{\\sigma}{r}\\right)^{12} - \\left(\\frac{\\sigma}{r}\\right)^6\\right]\\]\nand\n\\[F_{LJ}(r) = -\\frac{dV_{LJ}}{dr} = 24\\epsilon \\left[2\\left(\\frac{\\sigma}{r}\\right)^{12} - \\left(\\frac{\\sigma}{r}\\right)^6\\right]\\frac{\\vec{r}}{r^2}\\]\nwhere:\n\n\\(\\epsilon\\) is the depth of the potential well\n\\(\\sigma\\) is the distance at which the potential is zero\n\\(r\\) is the distance between particles\n\nThe Lenard Jones potential is good for describing the interaction of non-bonded atoms in a molecular system e.g.¬†in a gas or a liquid and is therefore well suited if we first want to simulate a gas or a liquid.\n\n\nCode\ndef lennard_jones(r, epsilon=1, sigma=1):\n    return 4 * epsilon * ((sigma/r)**12 - (sigma/r)**6)\n\nr = np.linspace(0.8, 3, 1000)\nV = lennard_jones(r)\n\nplt.figure(figsize=get_size(8, 6),dpi=150)\nplt.plot(r, V, 'b-', linewidth=2)\nplt.grid(True)\nplt.xlabel('r/œÉ')\nplt.ylabel('V/Œµ')\nplt.title('Lennard-Jones Potential')\nplt.axhline(y=0, color='k', linestyle='-', alpha=0.3)\nplt.ylim(-1.5, 3)\nplt.show()\n\n\n\n\n\n\n\n\n\nThe figure above shows the Lenard-Jones potential as a function of the distance between particles. The potential energy is zero at the equilibrium distance \\(r = \\sigma\\) and has a minimum at \\(r = 2^{1/6}\\sigma\\). The potential energy is positive for \\(r &lt; \\sigma\\) and negative for \\(r &gt; \\sigma\\).\n\n\n\n\n\n\nValues for atomic hydrogen\n\n\n\nFor atomic hydrogen (H), typical Lennard-Jones parameters are:\n\n\\(\\sigma \\approx 2.38\\) √Ö = \\(2.38 \\times 10^{-10}\\) meters\n\\(\\epsilon \\approx 0.0167\\) kcal/mol = \\(1.16 \\times 10^{-21}\\) joules\n\n\n\nLater, if we manage to advance to some more complicated systems, we may want to introduce:\n\nforce in bonds between two atoms\nforce in bond angles between three atoms\nforce in dihedral angles between four atoms\n\nBut for now, we will stick to the Lennard-Jones potential."
  },
  {
    "objectID": "seminars/seminar01/md1.html#integrating-newtons-euqation-of-motion",
    "href": "seminars/seminar01/md1.html#integrating-newtons-euqation-of-motion",
    "title": "Step-by-Step Development of a Molecular Dynamics Simulation",
    "section": "Integrating Newtons Euqation of Motion",
    "text": "Integrating Newtons Euqation of Motion\nWhen we have the forces on a particle we have in principle its acceleration. To get the velocity and the position of the particle we need to integrate the equations of motion. There are several methods to do this, but we will start with the simplest one, the Euler method.\n\nEuler Method\nTo obtain this one first needs to know about the Taylor expansion of a function in general. The Taylor expansion of a function \\(f(x)\\) around a point \\(x_0\\) is providing an approximation of the function in the vicinity of \\(x_0\\). It is given by:\n\\[f(x) = f(x_0) + f'(x_0)(x - x_0) + \\frac{1}{2}f''(x_0)(x - x_0)^2 + \\cdots\\]\nwhere \\(f'(x_0)\\) is the first derivative of \\(f(x)\\) at \\(x_0\\), \\(f''(x_0)\\) is the second derivative of \\(f(x)\\) at \\(x_0\\), and so on. We can demonstrate that by expanding a sine function around \\(x_0 = 0\\):\n\\[\\sin(x) = \\sin(0) + \\cos(0)x - \\frac{1}{2}\\sin(0)x^2 + \\cdots = x - \\frac{1}{6}x^3 + \\cdots\\]\nPlotting this yields:\n\n\nCode\nx = np.linspace(-2*np.pi, 2*np.pi, 1000)\ny = np.sin(x)\ny_taylor = x - 1/6*x**3\n\nplt.figure(figsize=get_size(8, 6),dpi=150)\nplt.plot(x, y, 'b-', label='sin(x)', linewidth=2)\nplt.plot(x, y_taylor, 'r--', label='Taylor expansion', linewidth=2)\nplt.grid(True)\nplt.xlabel('x')\nplt.ylabel('f(x)')\nplt.xlim(-2,2)\nplt.ylim(-2,2)\nplt.title('Taylor Expansion of sin(x)')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\nThe expansion is therefore a good approximation in a region close to \\(x_0\\).\n\n\nVelocity Verlet Algorithm\nThe velocity Verlet algorithm is a second-order algorithm that is more accurate than the Euler method. It can be derived from the Taylor expansion of the position and velocity vectors\n\\[\\mathbf{r}(t + \\Delta t) = \\mathbf{r}(t) + \\mathbf{v}(t)\\Delta t + \\frac{1}{2}\\frac{\\mathbf{F}(t)}{m}\\Delta t^2+ O(\\Delta t^3)\\]\nThe higher order terms in the Taylor expansion are neglected, which results in an error of order \\(\\Delta t^3\\). As compared to that the Euler method is obtained by neglecting the higher order terms in the Taylor expansion of the velocity vector:\n\\[\\mathbf{v}(t + \\Delta t) = \\mathbf{v}(t) + \\frac{\\mathbf{F}(t)}{m}\\Delta t + O(\\Delta t^2)\\]\nand is therefore only first order accurate with an error of order \\(\\Delta t^2\\).\nThe velocity Verlet algorithm consists of three steps:\n\nUpdate positions: \\(\\mathbf{r}(t + \\Delta t) = \\mathbf{r}(t) + \\mathbf{v}(t)\\Delta t + \\frac{1}{2}\\frac{\\mathbf{F}(t)}{m}\\Delta t^2\\)\nCalculate new forces: \\(\\mathbf{F}(t + \\Delta t) = \\mathbf{F}(\\mathbf{r}(t + \\Delta t))\\)\nUpdate velocities: \\(\\mathbf{v}(t + \\Delta t) = \\mathbf{v}(t) + \\frac{1}{2}\\frac{\\mathbf{F}(t) + \\mathbf{F}(t + \\Delta t)}{m}\\Delta t\\)\n\nwhere: - \\(\\mathbf{r}\\) is the position vector - \\(\\mathbf{v}\\) is the velocity vector - \\(\\mathbf{F}\\) is the force vector - \\(m\\) is the mass - \\(\\Delta t\\) is the timestep\n\n\nSimple Integration Example: Free Fall\nLet‚Äôs start and try to integrate the equation of motion for a particle in free fall with the help of the Velocity Verlet algorithm. The only force acting on the particle is gravity. The equation of motion is:\nNewton‚Äôs equation of motion: \\(\\mathbf{F} = m\\mathbf{a}\\)\nFor gravity: \\(\\mathbf{F} = -mg\\hat{\\mathbf{y}}\\)\nTherefore: \\(\\ddot{y} = -g\\)\nThe analytical solution is:\n\nPosition: \\(y(t) = y_0 + v_0t - \\frac{1}{2}gt^2\\)\nVelocity: \\(v(t) = v_0 - gt\\)\n\n\n\nCode\n# Parameters\n\ng = 9.81  # m/s^2\ndt = 0.01  # time step\nt_max = 2.0  # total simulation time\nsteps = int(t_max/dt)\n\n# Initial conditions\ny0 = 20.0  # initial height\nv0 = 0.0   # initial velocity\n\n\n# Arrays to store results\nt = np.zeros(steps)\ny = np.zeros(steps)\nv = np.zeros(steps)\na = np.zeros(steps)\n\n# Initial values\ny[0] = y0\nv[0] = v0\na[0] = -g\n\n# Velocity Verlet integration\nfor i in range(1, steps):\n    t[i] = i * dt\n    y[i] = y[i-1] + v[i-1] * dt + 0.5 * a[i-1] * dt**2  # update position\n    a_new = -g                                          # new acceleration (assuming constant gravity)\n    v[i] = v[i-1] + 0.5 * (a[i-1] + a_new) * dt         # update velocity\n    a[i] = a_new                                        # store new acceleration\n\ny_analytical = y0 + v0*t - 0.5*g*t**2\nplt.figure(figsize=get_size(8, 6), dpi=150)\nplt.plot(t, y)\nplt.plot(t, y_analytical, 'r--')\n\nplt.xlabel('Time (s)')\nplt.ylabel('Height (m)')\nplt.title('Free Fall Motion')\nplt.grid(True)\nplt.show()"
  },
  {
    "objectID": "seminars/seminar06/Report/Figures/Figure2/Figure2.html",
    "href": "seminars/seminar06/Report/Figures/Figure2/Figure2.html",
    "title": "Einf√ºhrung in die Modellierung Physikalischer Prozesse",
    "section": "",
    "text": "import matplotlib as mpl\nimport matplotlib.font_manager as font_manager\nfrom IPython.core.display import HTML\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom directory_tree import display_tree\n\n\nplt.rcParams.update({'font.size': 12,\n                     'lines.linewidth': 1,\n                     'lines.markersize': 10,\n                     'axes.labelsize': 11,\n                     'xtick.labelsize' : 10,\n                     'ytick.labelsize' : 10,\n                     'xtick.top' : True,\n                     'xtick.direction' : 'in',\n                     'ytick.right' : True,\n                     'ytick.direction' : 'in',}) \n\n%config InlineBackend.figure_format = 'retina'\n\n\ndef get_size(w,h):\n    return((w/2.54,h/2.54))\n\n\n# Generate fake experimental data\nx = np.linspace(0, 10, 100)\ny = np.sin(x) + np.random.normal(0, 0.2, size=100)\n\n# Set up the fancy plot\nfig, ax = plt.subplots(figsize=get_size(8, 6),dpi=150)\nax.plot(x, y, color='blue', linewidth=2, label='EXP',alpha=0.5)\n\n# Add some fancy elements to the plot\nax.fill_between(x, y, color='lightgray')\nax.scatter(x, y, color='blue', s=30, label='DATA ',alpha=0.5)\n\nax.set_xlabel('Time')\nax.set_ylabel('Measurement')\n\nax.legend(loc='lower right')\n\nax.tick_params(axis='both', which='major')\n\nax.grid(color='gray', linestyle='--', linewidth=0.5)\n\nax.annotate('Interesting\\nPoint', xy=(4.8, 0), xytext=(4.8, 0.7),\n            arrowprops=dict(facecolor='black', arrowstyle='-&gt;'),\n            fontsize=10, ha='center')\nplt.savefig(\"../figure2.pdf\",bbox_inches = 'tight')\nplt.show()"
  },
  {
    "objectID": "seminars/seminar06/Report/Text/paper.html",
    "href": "seminars/seminar06/Report/Text/paper.html",
    "title": "Einf√ºhrung in die Modellierung Physikalischer Prozesse",
    "section": "",
    "text": "{ ‚Äúcells‚Äù: [ { ‚Äúcell_type‚Äù: ‚Äúmarkdown‚Äù, ‚Äúmetadata‚Äù: {}, ‚Äúsource‚Äù: [ ‚Äú\\documentclass[aps,prl, 9pt,groupedaddress,twocolumn]{revtex4-1}‚Äù, ‚Äú%\\usepackage[USenglish]{babel} ‚Äù, ‚Äú\\usepackage{amsmath}‚Äù, ‚Äú\\usepackage{amsfonts}‚Äù, ‚Äú\\usepackage{graphicx}‚Äù, ‚Äú\\usepackage{xcolor}‚Äù, ‚Äú%\\usepackage{float}‚Äù, ‚Äú%\\bibliographystyle{apsrev4-1}‚Äù, ‚Äú%\\usepackage{hyperref}‚Äù, ‚Äú%\\usepackage{color}‚Äù, ‚Äú\\usepackage{float}‚Äù, ‚Äú‚Äù, ‚Äú‚Äù, ‚Äú\\begin{document}‚Äù, ‚Äú\\title{The Quirky Adventures of a Mischievous Teapot}‚Äù, ‚Äú‚Äù, ‚Äú\\author{Chat GPT}‚Äù, ‚Äú\\email{chatgpt@physik.uni-leipzig.de}‚Äù, ‚Äú\\homepage[]{http://www.uni-leipzig.de/~chatgpt}‚Äù, ‚Äú\\affiliation{Large Language Model Group, Institute of Artificial Physics, University of Leipzig, 04103 Leipzig, Germany}‚Äù, ‚Äú‚Äù, ‚Äú\\begin{abstract}‚Äù, ‚Äúthis whimsical exploration, we delve into the unexpected escapades of a mischievous teapot named Earl Grey. Equipped with a charming personality and an insatiable thirst for adventure, Earl Grey embarks on a quest that transcends the boundaries of the ordinary teapot life. From hosting wild tea parties in enchanted forests to engaging in sassy conversations with talking sugar cubes, Earl Grey‚Äôs escapades are nothing short of extraordinary.‚Äù, ‚Äúa series of unpredictable events, Earl Grey finds itself caught in a hilarious tea-stealing competition with a gang of misfit coffee mugs. As the rivalry intensifies, Earl Grey‚Äôs lid becomes a portal to an alternate dimension where gravity is topsy-turvy, and tea leaves dance to their own rhythm. Amidst the chaos, Earl Grey must navigate through a world of whimsy, dodging flying teaspoons and outsmarting gravity-defying tea leaves.‚Äù, ‚Äúa comedic blend of wit and charm, this abstract takes you on a hilarious journey that questions the norms of teapot life, celebrates the joy of spontaneity, and reminds us that even in the most unexpected circumstances, a steaming cup of tea can bring laughter and delight to the world.‚Äù, ‚Äúnote that this abstract is purely fictional and intended for entertainment purposes.‚Äù, ‚Äú\\end{abstract}‚Äù, ‚Äú‚Äù, ‚Äú\\maketitle‚Äù, ‚Äú‚Äù, ‚Äú\\input{content/01_introduction}‚Äù, ‚Äú‚Äù, ‚Äú\\input{content/02_theory}‚Äù, ‚Äú‚Äù, ‚Äú\\input{content/03_results}‚Äù, ‚Äú‚Äù, ‚Äú\\input{content/04_conclusions}‚Äù, ‚Äú‚Äù, ‚Äú‚Äù, ‚Äú‚Äù, ‚Äú\\end{document}‚Äù ] } ], ‚Äúmetadata‚Äù: { ‚Äúkernelspec‚Äù: { ‚Äúname‚Äù: ‚Äúpython3‚Äù, ‚Äúlanguage‚Äù: ‚Äúpython‚Äù, ‚Äúdisplay_name‚Äù: ‚ÄúPython 3 (ipykernel)‚Äù, ‚Äúpath‚Äù: ‚Äú/Users/fci/quarto_env/share/jupyter/kernels/python3‚Äù } }, ‚Äúnbformat‚Äù: 4, ‚Äúnbformat_minor‚Äù: 4 }"
  },
  {
    "objectID": "seminars/seminar09/md_vibration.html",
    "href": "seminars/seminar09/md_vibration.html",
    "title": "Step-by-Step Development of a Molecular Dynamics Simulation",
    "section": "",
    "text": "So far, we have already developed a basic molecular dynamics simulation for simple atoms and interactions by so-called van der Waals forces. Since we are already nearing the end of the course, we would at least like to add some more complexity to the simulation. In this seminar, we would like to make molecules by binding two atoms together. We will then simulate the vibration of these molecules by solving the equations of motion for the atoms."
  },
  {
    "objectID": "seminars/seminar09/md_vibration.html#bond-vibrations",
    "href": "seminars/seminar09/md_vibration.html#bond-vibrations",
    "title": "Step-by-Step Development of a Molecular Dynamics Simulation",
    "section": "Bond vibrations",
    "text": "Bond vibrations\nA bond vibration is modeled as a harmonic oscillator where two atoms are coupled by a spring force with spring constant \\(k\\). The bond force on atom \\(i\\) due to a bond with atom \\(j\\) is then given by\n\\[\\vec{F}_{bond}^i = -k(\\vec{r}_{ij} - \\vec{r}_0)\\]\nwhere \\(\\vec{r}_{ij}\\) is the vector between atom \\(i\\) and atom \\(j\\) and \\(\\vec{r}_0\\) is the equilibrium bond length vector. In reality bonds are not harmonic oscillators and deformations lead to a non-linear force curve. However, for small deviations from the equilibrium bond length, the harmonic approximation is quite good. The spring constant \\(k\\) determines the strength of the bond and therefore the frequency \\(\\omega\\) of the bond vibration\n\\[\\omega = \\sqrt{\\frac{k}{\\mu}}\\]\nwhere \\(\\mu = \\frac{m_1 m_2}{m_1 + m_2}\\) is the reduced mass of the two bonded atoms with masses \\(m_1\\) and \\(m_2\\).\n\nReduced units\nAs we have defined reduced units for our simulation based on the LJ parameters, we need to express the bond parameters in these units.\n\nBond length\nThe bond length \\(r_0\\) is expressed in terms of the Lennard-Jones length scale \\(\\sigma\\). For the bond between two hydrogen atoms, the equilibrium bond length is approximately \\(0.74\\sigma\\).\n\\[ r_{\\text{bond}}^* = \\frac{r_{\\text{bond}}}{\\sigma_{\\text{H}}} = \\frac{0.74}{1.0} = 0.74 \\]\n\n\nSpring constant\nThe spring constant \\(k\\) is expressed in reduced units based on the LJ energy scale \\(\\epsilon\\) and length scale \\(\\sigma\\). For a hydrogen molecule, the spring constant is approximately \\(440\\) in reduced units.\n\\[ k_{\\text{spring}}^* = \\frac{k \\sigma_{\\text{H}}^2}{\\epsilon_{\\text{H}}} \\]"
  },
  {
    "objectID": "seminars/seminar09/md_vibration.html#equations-of-motion",
    "href": "seminars/seminar09/md_vibration.html#equations-of-motion",
    "title": "Step-by-Step Development of a Molecular Dynamics Simulation",
    "section": "Equations of motion",
    "text": "Equations of motion\nThe equations of motion for the two atoms need to account for both the bond forces and the van der Waals forces. The total force on each atom is the sum of these contributions:\n\\[m_1 \\ddot{\\vec{r}}_1 = \\vec{F}_{bond}^1 + \\vec{F}_{vdW}^1\\]\n\\[m_2 \\ddot{\\vec{r}}_2 = \\vec{F}_{bond}^2 + \\vec{F}_{vdW}^2\\]\nwhere \\(\\vec{r}_1\\) and \\(\\vec{r}_2\\) are the positions of the two atoms, \\(\\vec{F}_{bond}\\) are the bond forces described above, and \\(\\vec{F}_{vdW}\\) are the van der Waals forces we implemented earlier. We can rewrite these equations as a system of first-order differential equations\n\\[\\dot{\\vec{v}}_1 = \\frac{\\vec{F}_{bond}^1 + \\vec{F}_{vdW}^1}{m_1}\\]\n\\[\\dot{\\vec{v}}_2 = \\frac{\\vec{F}_{bond}^2 + \\vec{F}_{vdW}^2}{m_2}\\]\n\\[\\dot{\\vec{r}}_1 = \\vec{v}_1\\]\n\\[\\dot{\\vec{r}}_2 = \\vec{v}_2\\]\nThe van der Waals forces act between atoms of different molecules while the bond forces act between atoms within the same molecule. Both types of forces are calculated at each timestep and combined to determine the total force on each atom."
  },
  {
    "objectID": "seminars/seminar09/md_vibration.html#implementation",
    "href": "seminars/seminar09/md_vibration.html#implementation",
    "title": "Step-by-Step Development of a Molecular Dynamics Simulation",
    "section": "Implementation",
    "text": "Implementation\n\nThe Bond class\nAs we wrote the simulation quite modular, we can now easily add the bond forces to the simulation. To do so, we will first introduce a new class Bond that will store the bond parameters and the atoms involved in the bond.\nclass Bond:\n    def __init__(self, atom1, atom2, k, r0):\n        self.atom1 = atom1\n        self.atom2 = atom2\n        self.k = k      # spring constant\n        self.r0 = r0    # equilibrium bond length\nThis bond class will be used to store the bond parameters for each bond in the simulation.\n\n\nThe DiatomicMolecule class\nWhile this is just a bond between two atoms, which can be also part of a more complicated molecule, we also need to define a molecule class that will store the atoms and bonds that make up the molecule.\nclass DiatomicMolecule:\n    def __init__(self, atom1, atom2, bond):\n        self.atom1 = atom1\n        self.atom2 = atom2\n        self.bond = bond\nThis class will store the two atoms and the bond between them.\n\n\nThe ForceField class update\nWe will also need to update the ForceField class to store the bond parameters and to calculate the bond forces. We will add a list of bonds to the force field and a method to calculate the bond forces.\nclass ForceField:\n    def __init__(self):\n        self.parameters = {\n            'C': {'epsilon': 1.615, 'sigma': 1.36},\n            'H': {'epsilon': 1.0, 'sigma': 1.0},\n            'O': {'epsilon': 1.846, 'sigma': 3.0},\n        }\n        self.bond_parameters = {\n            ('H', 'H'): {'k': 500.0, 'r0': 0.74},  # Example parameters for H2\n            ('O', 'H'): {'k': 550.0, 'r0': 0.96},  # Example parameters for OH bond\n        }\n        self.box_size = None\n\n    def calculate_bond_force(self, bond):\n        \"\"\"Calculate harmonic bond force\"\"\"\n        r = self.minimum_image_distance(bond.atom1.position, bond.atom2.position)\n        r_mag = np.linalg.norm(r)\n\n        # F = -k(r - r0)‚àô(r/|r|)\n        force_mag = -bond.k * (r_mag - bond.r0)\n        force = force_mag * r/r_mag\n        return force\n\n\n    # previous code goes here\nThe new addition provides the bond parameters\nself.bond_parameters = {\n    ('H', 'H'): {'k': 500.0, 'r0': 0.74},  # Example parameters for H2\n    ('O', 'H'): {'k': 550.0, 'r0': 0.96},  # Example parameters for OH bond\n}\nwhich are exemplary values for the bond between two hydrogen atoms and between an oxygen and a hydrogen atom. The method calculate_bond_force calculates the bond force between two atoms given a bond object.\ndef calculate_bond_force(self, bond):\n    \"\"\"Calculate harmonic bond force\"\"\"\n    r = self.minimum_image_distance(bond.atom1.position, bond.atom2.position)\n    r_mag = np.linalg.norm(r)\n\n    # F = -k(r - r0)‚àô(r/|r|)\n    force_mag = -bond.k * (r_mag - bond.r0)\n    force = force_mag * r/r_mag\n    return force\nAs a first step, this function calculates the distance vector between the two atoms and its magnitude. The force is then calculated as \\(F = -k(r - r_0) \\cdot (r/|r|)\\), where \\(r\\) is the distance vector, \\(r_0\\) is the equilibrium bond length, and \\(k\\) is the spring constant. The force is then returned as a vector."
  },
  {
    "objectID": "seminars/seminar09/md_vibration.html#md-simulation-class-update",
    "href": "seminars/seminar09/md_vibration.html#md-simulation-class-update",
    "title": "Step-by-Step Development of a Molecular Dynamics Simulation",
    "section": "MD Simulation class update",
    "text": "MD Simulation class update\nThe MDSimulation class is the controller of the simulation and needs to be updated to include the molecules and bond forces. We will add a list of molecules to the simulation and update the calculate_forces method to include the bond forces. The method to update the positions and velocities of the atoms will stay the same as we only need to add the bond forces to the total force calculation.\nclass MDSimulation:\n    def __init__(self, molecules, forcefield, timestep, box_size):\n        self.molecules = molecules\n        self.atoms = [atom for mol in molecules for atom in [mol.atom1, mol.atom2]]\n        self.forcefield = forcefield\n        self.forcefield.box_size = box_size\n        self.timestep = timestep\n        self.box_size = np.array(box_size)\n        self.energy_history = []\n\n    def calculate_forces(self):\n        # Reset all forces\n        for atom in self.atoms:\n            atom.reset_force()\n\n        # Calculate bonded forces\n        for molecule in self.molecules:\n            force = self.forcefield.calculate_bond_force(molecule.bond)\n            molecule.atom1.add_force(force)\n            molecule.atom2.add_force(-force)\n\n        # Calculate non-bonded forces between molecules\n        for i, mol1 in enumerate(self.molecules):\n            for mol2 in self.molecules[i+1:]:\n                # Calculate forces between atoms of different molecules\n                for atom1 in [mol1.atom1, mol1.atom2]:\n                    for atom2 in [mol2.atom1, mol2.atom2]:\n                        force = self.forcefield.calculate_lj_force(atom1, atom2)\n                        atom1.add_force(force)\n                        atom2.add_force(-force)\n\n    # def update_positions_and_velocities(self):\nThe constructor of the MDSimulation class now takes a list of molecules as an argument. The list of atoms is created by flattening the list of atoms in each molecule. This is all we need in the constructor.\nThe calculate_forces method now calculates the bond forces for each molecule and adds them to the atoms. The non-bonded forces are calculated as before. The methodupdate_positions_and_velocities will remain the same as we only need to add the bond forces to the total force calculation."
  },
  {
    "objectID": "seminars/seminar09/md_vibration.html#create-a-diatomic-molecule",
    "href": "seminars/seminar09/md_vibration.html#create-a-diatomic-molecule",
    "title": "Step-by-Step Development of a Molecular Dynamics Simulation",
    "section": "Create a diatomic molecule",
    "text": "Create a diatomic molecule\nFinally, we need something to create the diatomic molecules for out simulation. We will write a function that creates a number of diatomic molecules with a given box size and atom types. The function will create the atoms at random positions with a small displacement from the center of a grid and create a bond between them.\n```python\ndef create_diatomic_molecules(num_molecules, box_size, type1=\"H\", type2=\"H\", mass1=1.0, mass2=1.0):\n    molecules = []\n    spacing = np.min(box_size) / np.ceil(np.sqrt(num_molecules))\n\n    for i in range(num_molecules):\n        # Calculate grid position for molecule center\n        row = i // int(np.ceil(np.sqrt(num_molecules)))\n        col = i % int(np.ceil(np.sqrt(num_molecules)))\n        center = np.array([col * spacing + spacing/2, row * spacing + spacing/2])\n\n        # Create atoms with small random displacement for initial bond length\n        displacement = np.random.randn(2) * 0.1\n        atom1 = Atom(2*i, type1, center + displacement, mass=mass1)\n        atom2 = Atom(2*i+1, type2, center - displacement, mass=mass2)\n\n        # Create bond\n        ff = ForceField()\n        bond_params = ff.bond_parameters[(type1, type2)]\n        bond = Bond(atom1, atom2, bond_params['k'], bond_params['r0'])\n\n        molecules.append(DiatomicMolecule(atom1, atom2, bond))\n\n    return molecules"
  },
  {
    "objectID": "seminars/seminar09/md_vibration.html#md-simulation",
    "href": "seminars/seminar09/md_vibration.html#md-simulation",
    "title": "Step-by-Step Development of a Molecular Dynamics Simulation",
    "section": "MD Simulation",
    "text": "MD Simulation\nIn the last step we need to initialize the simulation with the diatomic molecules and run the simulation.\n## Initialize simulation as before\n\nbox_size = np.array([50.0, 50.0])\nnum_molecules = 100\nmolecules = create_diatomic_molecules(num_molecules, box_size, \"H\", \"H\")\nff = ForceField()\nsim = MDSimulation(molecules, ff, 0.001, box_size)\n\n# Initialize velocities for all atoms\natoms = [atom for mol in molecules for atom in [mol.atom1, mol.atom2]]\ninitialize_velocities(atoms, temperature=5.0)\n\n## rest of the simulation goes here"
  },
  {
    "objectID": "seminars/seminar09/md_vibration.html#summary",
    "href": "seminars/seminar09/md_vibration.html#summary",
    "title": "Step-by-Step Development of a Molecular Dynamics Simulation",
    "section": "Summary",
    "text": "Summary\nIn this module, we extended our molecular dynamics simulation to include diatomic molecules with bond vibrations. We added several new components:\n\nA Bond class to model the harmonic bond between two atoms, implementing Hooke‚Äôs law for the bond force\nA DiatomicMolecule class to manage pairs of bonded atoms\nUpdates to the ForceField class to include bond parameters and force calculations\nModifications to the MDSimulation class to handle both bonded and non-bonded interactions\n\nThe bond vibrations are modeled as harmonic oscillators with a spring constant k and equilibrium bond length \\(r_0\\). The total forces on each atom now include both the van der Waals forces between molecules and the bond forces within molecules. We provided functions to create and initialize diatomic molecules in a simulation box, setting up a foundation for simulating more complex molecular systems.\nThe implementation maintains the modular structure of our previous code while adding the capability to simulate molecular vibrations, bringing us closer to modeling real molecular systems."
  },
  {
    "objectID": "seminars/seminar09/seminar9.html",
    "href": "seminars/seminar09/seminar9.html",
    "title": "Seminar Coding Exercises 2",
    "section": "",
    "text": "Example1: Damped Oscillator\n\n\n\nCreate a simple simulation of a damped oscillator using a class structure. Include basic methods to calculate and plot the motion. This introduces both classes and simple differential equations. The damped oscillator is a classic physics problem that demonstrates how energy is dissipated in real systems through friction or air resistance. The motion follows an exponentially decaying sinusoidal pattern, determined by the mass, spring constant, and damping coefficient. We‚Äôll use a class to encapsulate these properties and provide methods to analyze the system‚Äôs behavior over time.\nTime estimate: 20 minutes\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nYou‚Äôll need to:\n\nUse np.linspace() to create time array from 0 to t_max\nCalculate position for each time point using self.position()\nCreate a figure using plt.figure()\nPlot time vs position using plt.plot()\nAdd labels, title, and grid\nShow the plot using plt.show()\n\n\n\n\n\n\n\n\n\n\n\n\nNote"
  },
  {
    "objectID": "lectures/lecture04/2_particle_in_a_box.html",
    "href": "lectures/lecture04/2_particle_in_a_box.html",
    "title": "Particle in a box",
    "section": "",
    "text": "Let‚Äôs apply the whole thing to the problem of a particle in a box. This means, we look at a quantum mechanical object in a potential well.\nThe problem is sketched below.\nWe need to define this rectangular box with zero potential energy inside the box and finite potential energy outside. Since the quantum mechanical object is a wave, we expect that only certain standing waves of particular wavelength can exist inside the box. These waves are connected to certain probability densities of finding the particle at certain positions and specific energy values. These are the energy levels, which are often characteristic of the quantum realm."
  },
  {
    "objectID": "lectures/lecture04/2_particle_in_a_box.html#definition-of-the-problem",
    "href": "lectures/lecture04/2_particle_in_a_box.html#definition-of-the-problem",
    "title": "Particle in a box",
    "section": "Definition of the problem",
    "text": "Definition of the problem\nBefore we start, we need to define some quantities:\n\nwe will study a box of d=1 nm in width in a domain of L=5 nm\nwe will use N=1001 points for our \\(x_{i}\\)\nour potential energy shall have a barrier height of 1 eV\nthe potential energy inside the box will be zero\n\n\n\n\n\n\n\n\nPotential energy\nWe first define the diagonal potential energy matrix.\n\n\n\n\n\n\n\n\nKinetic energy\nNext are the derivatives of the kinetic energy matrix.\n\n\n\n\n\n\nAn finally the total Hamilton operator matrix.\n\n\n\n\n\n\n\n\nSolution\nThe last step is to solve the system of coupled equations usering the eigsh method of the scipy module. We can already anticipate that we get multiple solution, e.g.¬†multiple wavelength that fit inside the box. So there must be a certain number of eigenvalues. The method eigsh allows to specify the number of eigenvalues and eigenfunctions \\(n\\) we would like to calculate.\n\n\n\n\n\n\n\n\nPlotting\n\n\n\n\n\n\nThe diagram shows the corresponding energy states (the eigenvalues of the solution) and the value \\(|\\Psi|^2\\), which gives the probability to find the particle inside the box. The latter shows, that in contrast to what we expect from classical theory, where we would expect the particle to be with equal probability found at all positions inside the box, we get in quantum mechanics only certain positions at which we would find the particle. Also, the higher the energy state, the more equally is the particle distributed over the box. For a finite box depth, however, we get only a finite number of energy states in which the particle is bound. A second interesting observation here is that the particle has a finite probability to enter the potential barrier. Especially for the higher energy states, the wavefunction decays exponentially into the barrier. This is similar to the evanescent wave we studied during the last lecture.\n\n\nEnergies of bound states\nIn the case of the particle in a box only certain energies are allowed. The energies which correspond to these distributions are increasing nonlinearly with its index. Below we plot the energy as a function of the index of the energy value. This index is called quantum number as we can enumerate the solutions in quantum mechanics. The graph shows that the energy of the bound states increases with the square of the quantum number, i.e.¬†\\(E_{n}\\propto n^2\\)."
  },
  {
    "objectID": "lectures/lecture04/2_particle_in_a_box.html#where-to-go-from-here",
    "href": "lectures/lecture04/2_particle_in_a_box.html#where-to-go-from-here",
    "title": "Particle in a box",
    "section": "Where to go from here?",
    "text": "Where to go from here?\nYou may try at this point to create two closely spaced potential wells, e.g.¬†two of 1 nm width with a distance of 0.1 nm or with a distance of 2 nm. You should see that for large distances of the wells the energy values in the individual wells are the same, while for the smaller distance they split up into two due to the interaction.\n\n\n\nDouble Well"
  },
  {
    "objectID": "lectures/lecture04/04-plotting copy.html",
    "href": "lectures/lecture04/04-plotting copy.html",
    "title": "Plotting",
    "section": "",
    "text": "Data visualization through plotting is a crucial tool for analyzing and interpreting scientific data and theoretical predictions. While plotting capabilities are not built into Python‚Äôs core, they are available through various external library modules. Matplotlib is widely recognized as the de facto standard for plotting in Python. However, several other powerful plotting libraries exist, including PlotLy, Seaborn, and Bokeh, each offering unique features and capabilities for data visualization.\nAs Matplotlib is an external library (actually a collection of libraries), it must be imported into any script that uses it. While Matplotlib relies heavily on NumPy, importing NumPy separately is not always necessary for basic plotting. However, for most scientific applications, you‚Äôll likely use both. To create 2D plots, you typically start by importing Matplotlib‚Äôs pyplot module:\nThis import introduces the implicit interface of pyplot for creating figures and plots. Matplotlib offers two main interfaces:\nWe will use most of the the the pyplot interface as in the examples below. The section Additional Plotting will refer to the explicit programming of figures.\nWe can set some of the parameters for the appearance of graphs globally. In case you still want to modify a part of it, you can set individual parameters later during plotting. The command used here is the\nfunction, which takes a dictionary with the specific parameters as key."
  },
  {
    "objectID": "lectures/lecture04/04-plotting copy.html#simple-plotting",
    "href": "lectures/lecture04/04-plotting copy.html#simple-plotting",
    "title": "Plotting",
    "section": "Simple Plotting",
    "text": "Simple Plotting\nMatplotlib offers multiple levels of functionality for creating plots. Throughout this section, we‚Äôll primarily focus on using commands that leverage default settings. This approach simplifies the process, as Matplotlib automatically handles much of the graph layout. These high-level commands are ideal for quickly creating effective visualizations without delving into intricate details. At the end of this section, we‚Äôll briefly touch upon more advanced techniques that provide greater control over plot elements and layout.\n\nAnatomy of a Line Plot\nTo create a basic line plot, use the following command:\nplt.plot(x, y)\nBy default, this generates a line plot. However, you can customize the appearance by adjusting various parameters within the plot() function. For instance, you can modify it to resemble a scatter plot by changing certain arguments. The versatility of this command allows for a range of visual representations beyond simple line plots.\nLet‚Äôs create a simple line plot of the sine function over the interval [0, 4œÄ]. We‚Äôll use NumPy to generate the x-values and calculate the corresponding y-values. The following code snippet demonstrates this process:\n1x = np.linspace(0, 4.*np.pi, 100)\n2y = np.sin(x)\n\n3plt.figure(figsize=(4,3))\n4plt.plot(x, y)\n5plt.tight_layout()\n6plt.show()\n\n1\n\nCreate an array of 100 values between 0 and 4œÄ.\n\n2\n\nCalculate the sine of each value in the array.\n\n3\n\ncreate a new figure\n\n4\n\nplot the data\n\n5\n\nautomatically adjust the layout\n\n6\n\nshow the figure\n\n\nHere is the code in a Python cell:\n\n\n\n\n\n\nTry to change the values of the x and y arrays and see how the plot changes.\n\n\n\n\n\n\nWhy use plt.tight_layout()\n\n\n\n\n\nplt.tight_layout() is a very useful function in Matplotlib that automatically adjusts the spacing between plot elements to prevent overlapping and ensure that all elements fit within the figure area. Here‚Äôs what it does:\n\nPadding Adjustment: It adjusts the padding between and around subplots to prevent overlapping of axis labels, titles, and other elements.\nSubplot Spacing: It optimizes the space between multiple subplots in a figure.\nText Accommodation: It ensures that all text elements (like titles, labels, and legends) fit within the figure without being cut off.\nMargin Adjustment: It adjusts the margins around the entire figure to make sure everything fits neatly.\nAutomatic Resizing: If necessary, it can slightly resize subplot areas to accommodate all elements.\nLegend Positioning: It takes into account the presence and position of legends when adjusting layouts.\n\nKey benefits of using plt.tight_layout():\n\nIt saves time in manual adjustment of plot elements.\nIt helps create more professional-looking and readable plots.\nIt‚Äôs particularly useful when creating figures with multiple subplots or when saving figures to files.\n\nYou typically call plt.tight_layout() just before plt.show() or plt.savefig(). For example:\nplt.figure()\n# ... (your plotting code here)\nplt.tight_layout()\nplt.show()\n\n\n\n\nAxis Labels\nTo enhance the clarity and interpretability of our plots, it‚Äôs crucial to provide context through proper labeling. Let‚Äôs add descriptive axis labels to our diagram, a practice that significantly improves the readability and comprehension of the data being presented.\nplt.xlabel('x-label')\nplt.ylabel('y-label')\n\n\n\n\n\n\n\n\nLegends\nplt.plot(..., label=r'$\\sin(x)$')\nplt.legend(loc='lower left')\n\n\n\n\n\n\n\n\nPlots with error bars\nWhen plotting experimental data it is customary to include error bars that indicate graphically the degree of uncertainty that exists in the measurement of each data point. The MatPlotLib function errorbar plots data with error bars attached. It can be used in a way that either replaces or augments the plot function. Both vertical and horizontal error bars can be displayed. The figure below illustrates the use of error bars.\n\n\n\n\n\n\n\n\nSaving figures\nTo save a figure to a file we can use the savefig method in the Figure class. Matplotlib can generate high-quality output in a number formats, including PNG, JPG, EPS, SVG, PGF and PDF. For scientific papers, I recommend using PDF whenever possible. (LaTeX documents compiled with pdflatex can include PDFs using the includegraphics command). In some cases, PGF can also be good alternative."
  },
  {
    "objectID": "lectures/lecture04/04-plotting copy.html#other-plot-types",
    "href": "lectures/lecture04/04-plotting copy.html#other-plot-types",
    "title": "Plotting",
    "section": "Other Plot Types",
    "text": "Other Plot Types\n\nScatter plot\nIf you prefer to use symbols for plotting just use the\nplt.scatter(x,y)\ncommand of pylab. Note that the scatter command requires a x and y values and you can set the marker symbol (see an overview of the marker symbols).\n\n\n\n\n\n\n\n\nHistograms\nA very useful plotting command is also the hist command. It generates a histogram of the data provided. A histogram is a graphical representation of the distribution of numerical data. It is an estimate of the probability distribution of a continuous variable. To construct a histogram, the first step is to ‚Äúbin‚Äù the range of values‚Äîthat is, divide the entire range of values into a series of intervals‚Äîand then count how many values fall into each interval. The bins are usually specified as consecutive, non-overlapping intervals of a variable. The bins must be adjacent, and are often (but not required to be) of equal size.\nWhen using the histogram function, you have flexibility in how the data is grouped. If you only provide the dataset, the function will automatically determine appropriate bins. However, you can also specify custom bins by passing an array of intervals using the syntax hist(data, bins=b), where b is your custom array of bin edges. To normalize the histogram so that the total area under it equals 1, you can set the density parameter to True. It‚Äôs worth noting that the histogram function doesn‚Äôt just create a visual representation; it also returns useful information such as the count of data points in each bin and the bin edges themselves.\n\n\n\n\n\n\nPhysics Interlude- Probability density for finding an oscillating particle\n\n\n\nLet‚Äôs integrate histogram plotting with a fundamental physics concept: the simple harmonic oscillator in one dimension. This system is described by a specific equation of motion:\n\\[\\begin{equation}\n\\ddot{x}(t) = -\\omega^2 x(t)\n\\end{equation}\\]\nFor an initial elongation \\(\\Delta x\\) at \\(t=0\\), the solution is:\n\\[\\begin{equation}\nx(t) = \\Delta x \\cos(\\omega t)\n\\end{equation}\\]\nTo calculate the probability of finding the spring at a certain elongation, we need to consider the time spent at different positions. The time \\(dt\\) spent in the interval [\\(x(t)\\), \\(x(t)+dx\\)] depends on the speed:\n\\[\\begin{equation}\nv(t) = \\frac{dx}{dt} = -\\omega \\Delta x \\sin(\\omega t)\n\\end{equation}\\]\nThe probability of finding the oscillator in a certain interval is the fraction of time spent in this interval, normalized by half the oscillation period \\(T/2\\):\n\\[\\begin{equation}\n\\frac{dt}{T/2} = \\frac{1}{T/2}\\frac{dx}{v(t)} = \\frac{1}{T/2}\\frac{-dx}{\\omega \\Delta x \\sin(\\omega t)}\n\\end{equation}\\]\nGiven that \\(\\omega = 2\\pi/T\\), we can derive the probability density:\n\\[\\begin{equation}\np(x)dx = \\frac{1}{\\pi \\Delta x}\\frac{dx}{\\sqrt{1-\\left(\\frac{x(t)}{\\Delta x}\\right)^2}}\n\\end{equation}\\]\nThis probability density reveals that the spring is more likely to be found at elongations where its speed is low. This principle extends to non-equilibrium physics, where entities moving with variable speed are more likely to be found in locations where they move slowly.\nWe can visualize this using the histogram function. By evaluating the position at equidistant times using the equation of motion and creating a histogram of these positions, we can represent the probability of finding the oscillator at certain positions. When properly normalized, this histogram will reflect the theoretical probability density we derived.\n\n\n\n\n\n\n\n\n\n\nSetting plotting limits and excluding data\nIf you want to zoom in to s specific region of a plot you can set the limits of the individual axes.\n\n\n\n\n\n\n\n\nMasked arrays\nSometimes you encounter situations, when you wish to mask some of the data of your plot, because they are not showing real data as the vertical lines in the plot above. For this purpose, you can mask the data arrays in various ways to not show up. The example below uses the\nnp.ma.masked_where()\nfunction of NumPy, which takes a condition as the first argument and what should be returned if that condition is fulfilled.\n\n\n\n\n\n\nIf you look at the resulting array, you will find, that the entries have not been removed but replaced by --, so the values are not existent and thefore not plotted.\n\n\n\n\n\n\n\nLogarithmic plots\n\n\n\n\n\nData sets can span many orders of magnitude from fractional quantities much smaller than unity to values much larger than unity. In such cases it is often useful to plot the data on logarithmic axes.\n\nSemi-log plots\nFor data sets that vary exponentially in the independent variable, it is often useful to use one or more logarithmic axes. Radioactive decay of unstable nuclei, for example, exhibits an exponential decrease in the number of particles emitted from the nuclei as a function of time.\nMatPlotLib provides two functions for making semi-logarithmic plots, semilogx and semilogy, for creating plots with logarithmic x and y axes, with linear y and x axes, respectively. We illustrate their use in the program below, which made the above plots.\n\n\n\n\n\n\n\n\nLog-log plots\nMatPlotLib can also make log-log or double-logarithmic plots using the function loglog. It is useful when both the \\(x\\) and \\(y\\) data span many orders of magnitude. Data that are described by a power law \\(y=Ax^b\\), where \\(A\\) and \\(b\\) are constants, appear as straight lines when plotted on a log-log plot. Again, the loglog function works just like the plot function but with logarithmic axes.\n\n\n\n\n\n\n\n\n\n\n\n\nCombined plots\nYou can combine multiple data with the same axes by stacking multiple plots.\n\n\n\n\n\n\n\n\nArranging multiple plots\nOften you want to create two or more graphs and place them next to one another, generally because they are related to each other in some way.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnimations\n\n\n\n\n\nMatplotlib can also be used to create animations. The FuncAnimation class makes it easy to create animations by repeatedly calling a function to update the plot. The following example shows a simple pendulum animation.\n\n\n\n\n\n\n\n\n\n\n\nSimple contour plot\n\n\n\n\n\n\nPhysics Interlude\n\n\n\n\n\n\nContour and Density Plots\nA contour plots are useful tools to study two dimensional data, meaning \\(Z(X,Y)\\). A contour plots the lines of constant value of the function \\(Z\\).\n\n\nUnderstanding Wave Interference\nImagine throwing two stones into a pond. Each stone creates circular waves that spread out. When these waves meet, they create interesting patterns - this is called interference. Let‚Äôs explore this using physics and Python!\n\nWhat is a Wave?\nA wave can be described mathematically. For our example, we‚Äôll look at spherical waves (like those in the pond). Each wave has: - An amplitude (how tall the wave is) - A wavelength (distance between wave peaks) - A frequency (how fast it oscillates)\n\n\nMathematical Description\nFor a single wave source, we can write: \\[\\begin{equation}\nU(r)=e^{-i\\,k r}\n\\end{equation}\\]\nWhere: - \\(k\\) is related to the wavelength (\\(k = 2\\pi/\\lambda\\)) - \\(r\\) is the distance from the source - We‚Äôve simplified by ignoring how the wave gets smaller as it travels (\\(1/r\\) term)\n\n\nTwo Wave Sources\nWhen we have two wave sources (like two stones dropped in the pond): 1. Each source creates its own wave 2. The waves combine where they meet 3. The total wave is the sum of both waves\n\n\n\ninterference\n\n\nMathematically: \\[\\begin{equation}\nU_{total} = e^{-i\\,k r_1} + e^{-i\\,k r_2}\n\\end{equation}\\]\nWhere \\(r_1\\) and \\(r_2\\) are the distances from each source.\n\n\nWhat We See (Intensity)\nWhat we actually see is the intensity of the combined waves:\n\\[\\begin{equation}\n\\text{Intensity} \\propto |U_{total}|^2\n\\end{equation}\\]\nThis will show us where the waves:\n\nAdd up (bright regions - constructive interference)\nCancel out (dark regions - destructive interference)\n\nLet‚Äôs create a Python program to visualize this!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nColor contour plot\n\n\n\n\n\n\n\n\nImage plot\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdvanced Plotting - Explicit Version\n\n\n\n\n\nAdvanced Plotting - Explicit Version\nWhile we have so far largely relied on the default setting and the automatic arrangement of plots, there is also a way to precisely design your plot. Python provides the tools of object oriented programming and thus modules provide classes which can be instanced into objects. This explicit interfaces allows you to control all details without the automatisms of pyplot.\nThe figure below, which is taken from the matplotlib documentation website shows the sets of commands and the objects in the figure, the commands refer to. It is a nice reference, when creating a figure.\n\n\n\nanatomy of a figure\n\n\n\nPlots with Multiple Spines\nSometimes it is very useful to plot different quantities in the same plot with the same x-axis but with different y-axes. Here is some example, where each line plot has its own y-axis.\n\n\n\n\n\n\n\n\nInsets\nInsets are plots within plots using their own axes. We therefore need to create two axes systems, if we want to have a main plot and and inset.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSpine axis\n\n\n\n\n\n\n\n\nPolar plot\n\n\n\n\n\n\n\n\nText annotation\nAnnotating text in matplotlib figures can be done using the text function. It supports LaTeX formatting just like axis label texts and titles:\n\n\n\n\n\n\n\n\n3D Plotting\nMatplotlib was initially designed with only two-dimensional plotting in mind. Around the time of the 1.0 release, some three-dimensional plotting utilities were built on top of Matplotlib‚Äôs two-dimensional display, and the result is a convenient (if somewhat limited) set of tools for three-dimensional data visualization. Three-dimensional plots are enabled by importing the mplot3d toolkit, included with the main Matplotlib installation:\n\n\n\n\n\n\nOnce this submodule is imported, a three-dimensional axes can be created by passing the keyword projection=‚Äò3d‚Äô to any of the normal axes creation routines:\n\nProjection Scence\n\n\n\n\n\n\nWith this three-dimensional axes enabled, we can now plot a variety of three-dimensional plot types. Three-dimensional plotting is one of the functionalities that benefits immensely from viewing figures interactively rather than statically in the notebook; recall that to use interactive figures, you can use %matplotlib notebook rather than %matplotlib inline when running this code.\n\n\nLine Plotting in 3D\nfrom sets of (x, y, z) triples. In analogy with the more common two-dimensional plots discussed earlier, these can be created using the ax.plot3D and ax.scatter3D functions. The call signature for these is nearly identical to that of their two-dimensional counterparts, so you can refer to Simple Line Plots and Simple Scatter Plots for more information on controlling the output. Here we‚Äôll plot a trigonometric spiral, along with some points drawn randomly near the line:\n\n\n\n\n\n\nNotice that by default, the scatter points have their transparency adjusted to give a sense of depth on the page. While the three-dimensional effect is sometimes difficult to see within a static image, an interactive view can lead to some nice intuition about the layout of the points. Use the scatter3D or the plot3D method to plot a random walk in 3-dimensions in your exercise.\n\n\nSurface Plotting\nA surface plot is like a wireframe plot, but each face of the wireframe is a filled polygon. Adding a colormap to the filled polygons can aid perception of the topology of the surface being visualized:"
  },
  {
    "objectID": "lectures/lecture04/04-plotting copy.html#contour-and-density-plots",
    "href": "lectures/lecture04/04-plotting copy.html#contour-and-density-plots",
    "title": "Plotting",
    "section": "Contour and Density Plots",
    "text": "Contour and Density Plots\nA contour plots are useful tools to study two dimensional data, meaning \\(Z(X,Y)\\). A contour plots the lines of constant value of the function \\(Z\\)."
  },
  {
    "objectID": "lectures/lecture04/04-plotting copy.html#understanding-wave-interference",
    "href": "lectures/lecture04/04-plotting copy.html#understanding-wave-interference",
    "title": "Plotting",
    "section": "Understanding Wave Interference",
    "text": "Understanding Wave Interference\nImagine throwing two stones into a pond. Each stone creates circular waves that spread out. When these waves meet, they create interesting patterns - this is called interference. Let‚Äôs explore this using physics and Python!\n\nWhat is a Wave?\nA wave can be described mathematically. For our example, we‚Äôll look at spherical waves (like those in the pond). Each wave has: - An amplitude (how tall the wave is) - A wavelength (distance between wave peaks) - A frequency (how fast it oscillates)\n\n\nMathematical Description\nFor a single wave source, we can write: \\[\\begin{equation}\nU(r)=e^{-i\\,k r}\n\\end{equation}\\]\nWhere: - \\(k\\) is related to the wavelength (\\(k = 2\\pi/\\lambda\\)) - \\(r\\) is the distance from the source - We‚Äôve simplified by ignoring how the wave gets smaller as it travels (\\(1/r\\) term)\n\n\nTwo Wave Sources\nWhen we have two wave sources (like two stones dropped in the pond): 1. Each source creates its own wave 2. The waves combine where they meet 3. The total wave is the sum of both waves\n\n\n\ninterference\n\n\nMathematically: \\[\\begin{equation}\nU_{total} = e^{-i\\,k r_1} + e^{-i\\,k r_2}\n\\end{equation}\\]\nWhere \\(r_1\\) and \\(r_2\\) are the distances from each source.\n\n\nWhat We See (Intensity)\nWhat we actually see is the intensity of the combined waves:\n\\[\\begin{equation}\n\\text{Intensity} \\propto |U_{total}|^2\n\\end{equation}\\]\nThis will show us where the waves:\n\nAdd up (bright regions - constructive interference)\nCancel out (dark regions - destructive interference)\n\nLet‚Äôs create a Python program to visualize this!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nColor contour plot\n\n\n\n\n\n\n\n\nImage plot"
  },
  {
    "objectID": "lectures/lecture04/04-plotting copy.html#advanced-plotting---explicit-version",
    "href": "lectures/lecture04/04-plotting copy.html#advanced-plotting---explicit-version",
    "title": "Plotting",
    "section": "Advanced Plotting - Explicit Version",
    "text": "Advanced Plotting - Explicit Version\nWhile we have so far largely relied on the default setting and the automatic arrangement of plots, there is also a way to precisely design your plot. Python provides the tools of object oriented programming and thus modules provide classes which can be instanced into objects. This explicit interfaces allows you to control all details without the automatisms of pyplot.\nThe figure below, which is taken from the matplotlib documentation website shows the sets of commands and the objects in the figure, the commands refer to. It is a nice reference, when creating a figure.\n\n\n\nanatomy of a figure\n\n\n\nPlots with Multiple Spines\nSometimes it is very useful to plot different quantities in the same plot with the same x-axis but with different y-axes. Here is some example, where each line plot has its own y-axis.\n\n\n\n\n\n\n\n\nInsets\nInsets are plots within plots using their own axes. We therefore need to create two axes systems, if we want to have a main plot and and inset.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSpine axis\n\n\n\n\n\n\n\n\nPolar plot\n\n\n\n\n\n\n\n\nText annotation\nAnnotating text in matplotlib figures can be done using the text function. It supports LaTeX formatting just like axis label texts and titles:\n\n\n\n\n\n\n\n\n3D Plotting\nMatplotlib was initially designed with only two-dimensional plotting in mind. Around the time of the 1.0 release, some three-dimensional plotting utilities were built on top of Matplotlib‚Äôs two-dimensional display, and the result is a convenient (if somewhat limited) set of tools for three-dimensional data visualization. Three-dimensional plots are enabled by importing the mplot3d toolkit, included with the main Matplotlib installation:\n\n\n\n\n\n\nOnce this submodule is imported, a three-dimensional axes can be created by passing the keyword projection=‚Äò3d‚Äô to any of the normal axes creation routines:\n\nProjection Scence\n\n\n\n\n\n\nWith this three-dimensional axes enabled, we can now plot a variety of three-dimensional plot types. Three-dimensional plotting is one of the functionalities that benefits immensely from viewing figures interactively rather than statically in the notebook; recall that to use interactive figures, you can use %matplotlib notebook rather than %matplotlib inline when running this code.\n\n\nLine Plotting in 3D\nfrom sets of (x, y, z) triples. In analogy with the more common two-dimensional plots discussed earlier, these can be created using the ax.plot3D and ax.scatter3D functions. The call signature for these is nearly identical to that of their two-dimensional counterparts, so you can refer to Simple Line Plots and Simple Scatter Plots for more information on controlling the output. Here we‚Äôll plot a trigonometric spiral, along with some points drawn randomly near the line:\n\n\n\n\n\n\nNotice that by default, the scatter points have their transparency adjusted to give a sense of depth on the page. While the three-dimensional effect is sometimes difficult to see within a static image, an interactive view can lead to some nice intuition about the layout of the points. Use the scatter3D or the plot3D method to plot a random walk in 3-dimensions in your exercise.\n\n\nSurface Plotting\nA surface plot is like a wireframe plot, but each face of the wireframe is a filled polygon. Adding a colormap to the filled polygons can aid perception of the topology of the surface being visualized:"
  },
  {
    "objectID": "lectures/lecture04/01-lecture04.html",
    "href": "lectures/lecture04/01-lecture04.html",
    "title": "Lecture 4",
    "section": "",
    "text": "Introduction to loops for numerical integration (e.g., trapezoidal rule).\nFunctions for calculating work, power, and energy.\n\n\n\n\n\nWriting Python code to calculate the work done by a variable force (e.g., spring force) using numerical integration.\nSimulating energy conservation in a closed system (e.g., pendulum).\nVisualization: Plotting energy vs.¬†time for the system.\nHomework: Modify the code to simulate a different system, such as a mass-spring system.\n\n\n\n\n    \n    \n    D3.js Shaded Spheres"
  },
  {
    "objectID": "lectures/lecture04/01-lecture04.html#work-power-energy",
    "href": "lectures/lecture04/01-lecture04.html#work-power-energy",
    "title": "Lecture 4",
    "section": "",
    "text": "Introduction to loops for numerical integration (e.g., trapezoidal rule).\nFunctions for calculating work, power, and energy.\n\n\n\n\n\nWriting Python code to calculate the work done by a variable force (e.g., spring force) using numerical integration.\nSimulating energy conservation in a closed system (e.g., pendulum).\nVisualization: Plotting energy vs.¬†time for the system.\nHomework: Modify the code to simulate a different system, such as a mass-spring system.\n\n\n\n\n    \n    \n    D3.js Shaded Spheres"
  },
  {
    "objectID": "lectures/lecture03/01-lecture03.html",
    "href": "lectures/lecture03/01-lecture03.html",
    "title": "Lecture 3",
    "section": "",
    "text": "Lists and arrays (introduction to numpy for numerical operations).\nBasic vector operations using numpy.\n\n\n\n\n\n\n\nNumpy Array\n\n\n\nThe NumPy array, formally called ndarray in NumPy documentation, is the real workhorse of data structures for scientific and engineering applications. The NumPy array is similar to a list but where all the elements of the list are of the same type. The elements of a NumPy array are usually numbers, but can also be booleans, strings, or other objects. When the elements are numbers, they must all be of the same type. For example, they might be all integers or all floating point numbers. NumPy arrays are more efficient than Python lists for storing and manipulating data.\n\n\n\n\n\n\n\n\n\n\nThere are a number of ways to initialize new numpy arrays, for example from\n\na Python list or tuples using np.array\nusing functions that are dedicated to generating numpy arrays, such as arange, linspace, etc.\nreading data from files which will be covered in the files section of this course.\n\n\n\nFor example, to create new vector and matrix arrays from Python lists we can use the numpy.array function. This is demonstrated in the following cells:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFor larger arrays it is inpractical to initialize the data manually, using explicit python lists. Instead we can use one of the many functions in numpy that generate arrays of different forms and shapes. Some of the more common are:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlinspace\n\n\n\nThe linspace function creates an array of N evenly spaced points between a starting point and an ending point. The form of the function is linspace(start, stop, N).If the third argument N is omitted,then N=50. The function linspace always includes the end points.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlogspace\n\n\n\nlogspace is doing equivelent things with logaritmic spacing. The function logspace generates an array of N points between decades 10^start and 10^stop. The form of the function is logspace(start, stop, N). If the third argument N is omitted, then N=50. The function logspace always includes the end points.\n\n\n\n\n\n\n\n\nOther types of array creation techniques are listed below. Try around with these commands to get a feeling what they do.\n\n\n\n\n\n\nmgrid\n\n\n\nmgrid generates a multi-dimensional matrix with increasing value entries, for example in columns and rows. The arguments are similar to arange and linspace.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndiag\n\n\n\ndiag generates a diagonal matrix with the list supplied to it as the diagonal values. The values can be also offset from the main diagonal by using the optional argument k. If k is positive, the diagonal is above the main diagonal, if negative, below the main diagonal.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nzeros and ones\n\n\n\nzeros and ones creates a matrix with the dimensions given in the argument and filled with 0 or 1. The argument is a tuple with the dimensions of the matrix. For example, np.zeros((3,3)) creates a 3x3 matrix filled with zeros.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSlicing is the name for extracting part of an array by the syntax M[lower:upper:step]. When any of these are unspecified, they default to the values lower=0, upper=size of dimension, step=1. We can also use negative indices to count from the end of the array. Here are some examples:\n\n\n\n\n\n\n\n\n\n\n\n\nAny of the three parameters in M[lower:upper:step] can be ommited.\n\n\n\n\n\n\n\n\n\n\n\n\nNegative indices counts from the end of the array (positive index from the begining) and can be used in any of the three slicing parameters. Here are some examples:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIndex slicing works exactly the same way for multidimensional arrays. We can slice along each axis independently. Here are some examples:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDifferences\n\n\n\nSlicing can be effectively used to calculate differences for example for the calculation of derivatives. Here the position \\(y_i\\) of an object has been measured at times \\(t_i\\) and stored in an array each. We wish to calculate the average velocity at the times \\(t_{i}\\) from the arrays by the formula\n\\[\\begin{equation}\n  v_{i}=\\frac{y_i-y_{i-1}}{t_{i}-t_{i-1}}\n  \\end{equation}\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArrays can be reshaped into any form, which contains the same number of elements. For example, a 4-element array can be reshaped into a 2x2 array, or a 2x2 array can be reshaped into a 4-element array. Here are some examples:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWith newaxis, we can insert new dimensions in an array, for example converting a vector to a column or row matrix. Here are some examples:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUsing function repeat, tile, vstack, hstack, and concatenate we can create larger vectors and matrices from smaller ones by repeating or stacking. Please try the individual functions yourself in your notebook. We wont discuss them in detail here.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConcatenate joins arrays along an existing axis. Here are some examples:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhstack and vstack stack arrays horizontally and vertically. Here are some examples:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAll kinds of mathematical operations can be carried out on arrays. Typically these operation act element wise as seen from the examples below where a is an array of numbers from 0 to 9.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOperation between multiple vectors allow in particular very quick operations. The operations address then elements of the same index. These operations are called vector operations since the concern the whole array at the same time. The product between two vectors results therefore not in a dot product, which gives one number but in an array of multiplied elements.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nxxw\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSimulating and plotting the trajectory of a projectile under the influence of gravity (2D motion).\nIntroduction to vector addition and resolving vectors into components.\nVisualization: Plotting the path of the projectile and velocity vectors.\nHomework: Simulate projectile motion with air resistance (optional for advanced students)."
  },
  {
    "objectID": "lectures/lecture03/01-lecture03.html#creating-numpy-arrays",
    "href": "lectures/lecture03/01-lecture03.html#creating-numpy-arrays",
    "title": "Lecture 3",
    "section": "",
    "text": "There are a number of ways to initialize new numpy arrays, for example from\n\na Python list or tuples using np.array\nusing functions that are dedicated to generating numpy arrays, such as arange, linspace, etc.\nreading data from files which will be covered in the files section of this course.\n\n\n\nFor example, to create new vector and matrix arrays from Python lists we can use the numpy.array function. This is demonstrated in the following cells:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFor larger arrays it is inpractical to initialize the data manually, using explicit python lists. Instead we can use one of the many functions in numpy that generate arrays of different forms and shapes. Some of the more common are:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlinspace\n\n\n\nThe linspace function creates an array of N evenly spaced points between a starting point and an ending point. The form of the function is linspace(start, stop, N).If the third argument N is omitted,then N=50. The function linspace always includes the end points.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlogspace\n\n\n\nlogspace is doing equivelent things with logaritmic spacing. The function logspace generates an array of N points between decades 10^start and 10^stop. The form of the function is logspace(start, stop, N). If the third argument N is omitted, then N=50. The function logspace always includes the end points.\n\n\n\n\n\n\n\n\nOther types of array creation techniques are listed below. Try around with these commands to get a feeling what they do.\n\n\n\n\n\n\nmgrid\n\n\n\nmgrid generates a multi-dimensional matrix with increasing value entries, for example in columns and rows. The arguments are similar to arange and linspace.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndiag\n\n\n\ndiag generates a diagonal matrix with the list supplied to it as the diagonal values. The values can be also offset from the main diagonal by using the optional argument k. If k is positive, the diagonal is above the main diagonal, if negative, below the main diagonal.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nzeros and ones\n\n\n\nzeros and ones creates a matrix with the dimensions given in the argument and filled with 0 or 1. The argument is a tuple with the dimensions of the matrix. For example, np.zeros((3,3)) creates a 3x3 matrix filled with zeros."
  },
  {
    "objectID": "lectures/lecture03/01-lecture03.html#manipulating-numpy-arrays",
    "href": "lectures/lecture03/01-lecture03.html#manipulating-numpy-arrays",
    "title": "Lecture 3",
    "section": "",
    "text": "Slicing is the name for extracting part of an array by the syntax M[lower:upper:step]. When any of these are unspecified, they default to the values lower=0, upper=size of dimension, step=1. We can also use negative indices to count from the end of the array. Here are some examples:\n\n\n\n\n\n\n\n\n\n\n\n\nAny of the three parameters in M[lower:upper:step] can be ommited.\n\n\n\n\n\n\n\n\n\n\n\n\nNegative indices counts from the end of the array (positive index from the begining) and can be used in any of the three slicing parameters. Here are some examples:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIndex slicing works exactly the same way for multidimensional arrays. We can slice along each axis independently. Here are some examples:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDifferences\n\n\n\nSlicing can be effectively used to calculate differences for example for the calculation of derivatives. Here the position \\(y_i\\) of an object has been measured at times \\(t_i\\) and stored in an array each. We wish to calculate the average velocity at the times \\(t_{i}\\) from the arrays by the formula\n\\[\\begin{equation}\n  v_{i}=\\frac{y_i-y_{i-1}}{t_{i}-t_{i-1}}\n  \\end{equation}\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArrays can be reshaped into any form, which contains the same number of elements. For example, a 4-element array can be reshaped into a 2x2 array, or a 2x2 array can be reshaped into a 4-element array. Here are some examples:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWith newaxis, we can insert new dimensions in an array, for example converting a vector to a column or row matrix. Here are some examples:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUsing function repeat, tile, vstack, hstack, and concatenate we can create larger vectors and matrices from smaller ones by repeating or stacking. Please try the individual functions yourself in your notebook. We wont discuss them in detail here.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConcatenate joins arrays along an existing axis. Here are some examples:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhstack and vstack stack arrays horizontally and vertically. Here are some examples:"
  },
  {
    "objectID": "lectures/lecture03/01-lecture03.html#applying-mathematical-functions",
    "href": "lectures/lecture03/01-lecture03.html#applying-mathematical-functions",
    "title": "Lecture 3",
    "section": "",
    "text": "All kinds of mathematical operations can be carried out on arrays. Typically these operation act element wise as seen from the examples below where a is an array of numbers from 0 to 9.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOperation between multiple vectors allow in particular very quick operations. The operations address then elements of the same index. These operations are called vector operations since the concern the whole array at the same time. The product between two vectors results therefore not in a dot product, which gives one number but in an array of multiplied elements.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nxxw"
  },
  {
    "objectID": "lectures/lecture03/01-lecture03.html#application",
    "href": "lectures/lecture03/01-lecture03.html#application",
    "title": "Lecture 3",
    "section": "",
    "text": "Simulating and plotting the trajectory of a projectile under the influence of gravity (2D motion).\nIntroduction to vector addition and resolving vectors into components.\nVisualization: Plotting the path of the projectile and velocity vectors.\nHomework: Simulate projectile motion with air resistance (optional for advanced students)."
  },
  {
    "objectID": "lectures/lecture02/datatypes_quiz.html",
    "href": "lectures/lecture02/datatypes_quiz.html",
    "title": "Datatypes Quiz",
    "section": "",
    "text": "Test your knowledge of Python data types with this interactive quiz!\n\n\nWhat is the output of len(\"Hello, World!\")?\n\n\n\n\n\n\n\n10\n11\n13\n14\n\nWhat is the result of [1, 2, 3] + [4, 5]?\n\n\n\n\n\n\n\n(1, 2, 3, 4, 5)\n[1, 2, 3, 4, 5]\n[5, 7, 8]\nError\n\nWhich of the following creates an empty dictionary?\n\n{}\n[]\n()\nBoth {} and dict()\n\nWhat is the output of set([1, 2, 2, 3, 3, 3])?\n\n\n\n\n\n\n\n[1, 2, 2, 3, 3, 3]\n{1, 2, 3}\n{1, 2, 2, 3, 3, 3}\nError\n\nWhat is the result of \"Hello\" * 3?\n\n\n\n\n\n\n\nHello Hello Hello\nHelloHelloHello\nHello3\nError\n\n\n\n\n\n\n\n\n\nClick to reveal answers\n\n\n\n\n\n\n13\n[1, 2, 3, 4, 5]\nBoth {} and dict()\n{1, 2, 3}\nHelloHelloHello"
  },
  {
    "objectID": "lectures/lecture02/datatypes_quiz.html#python-data-types-quiz",
    "href": "lectures/lecture02/datatypes_quiz.html#python-data-types-quiz",
    "title": "Datatypes Quiz",
    "section": "",
    "text": "Test your knowledge of Python data types with this interactive quiz!\n\n\nWhat is the output of len(\"Hello, World!\")?\n\n\n\n\n\n\n\n10\n11\n13\n14\n\nWhat is the result of [1, 2, 3] + [4, 5]?\n\n\n\n\n\n\n\n(1, 2, 3, 4, 5)\n[1, 2, 3, 4, 5]\n[5, 7, 8]\nError\n\nWhich of the following creates an empty dictionary?\n\n{}\n[]\n()\nBoth {} and dict()\n\nWhat is the output of set([1, 2, 2, 3, 3, 3])?\n\n\n\n\n\n\n\n[1, 2, 2, 3, 3, 3]\n{1, 2, 3}\n{1, 2, 2, 3, 3, 3}\nError\n\nWhat is the result of \"Hello\" * 3?\n\n\n\n\n\n\n\nHello Hello Hello\nHelloHelloHello\nHello3\nError\n\n\n\n\n\n\n\n\n\nClick to reveal answers\n\n\n\n\n\n\n13\n[1, 2, 3, 4, 5]\nBoth {} and dict()\n{1, 2, 3}\nHelloHelloHello"
  },
  {
    "objectID": "lectures/lecture02/05-lecture02.html",
    "href": "lectures/lecture02/05-lecture02.html",
    "title": "Matplotlib Cheat Sheet",
    "section": "",
    "text": "import matplotlib.pyplot as plt\nimport numpy as np\n\n# Create a new figure\nplt.figure(figsize=(width, height))\n\n# Create a plot\nplt.plot(x, y, 'bo-')  # Blue line with circle markers\n\n# Set labels and title\nplt.xlabel('X-axis label')\nplt.ylabel('Y-axis label')\nplt.title('Plot Title')\n\n# Add a legend\nplt.legend(['Label'], loc='best')\n\n# Show the plot\nplt.show()\n\n\n\n\nLine plot: plt.plot(x, y)\nScatter plot: plt.scatter(x, y)\nBar plot: plt.bar(x, height)\nHistogram: plt.hist(data, bins=10)\nBox plot: plt.boxplot(data)\nErrorbar plot: plt.errorbar(x, y, yerr=error)\n\n\n\n\n\nSet axis limits: plt.xlim(xmin, xmax), plt.ylim(ymin, ymax)\nSet axis scales: plt.xscale('log'), plt.yscale('log')\nSet tick marks: plt.xticks(ticks, labels), plt.yticks(ticks, labels)\nAdd a grid: plt.grid(True)\nChange line style: plt.plot(x, y, linestyle='--', color='r', linewidth=2)\nChange marker style: plt.plot(x, y, marker='o', markersize=5)\n\n\n\n\n\nSubplots: fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,5))\nPlot on specific axes: ax1.plot(x, y)\n\n\n\n\nplt.savefig('filename.png', dpi=300, bbox_inches='tight')\n\n\n\n\nContour plot: plt.contour(X, Y, Z)\n3D plot:\nfrom mpl_toolkits.mplot3d import Axes3D\nfig = plt.figure()\nax = fig.add_subplot(111, projection='3d')\nax.plot_surface(X, Y, Z)\n\n\n\n\n\nAdjust layout: plt.tight_layout()\nSet style: plt.style.use('ggplot')\nColormap: plt.imshow(data, cmap='viridis')\n\n\n\n\n\nColors: ‚Äòb‚Äô (blue), ‚Äòg‚Äô (green), ‚Äòr‚Äô (red), ‚Äòc‚Äô (cyan), ‚Äòm‚Äô (magenta), ‚Äòy‚Äô (yellow), ‚Äòk‚Äô (black), ‚Äòw‚Äô (white)\nMarkers: ‚Äò.‚Äô (point), ‚Äòo‚Äô (circle), ‚Äòs‚Äô (square), ‚Äò^‚Äô (triangle up), ‚Äòv‚Äô (triangle down)\nLinestyles: ‚Äò-‚Äô (solid), ‚Äò‚Äì‚Äô (dashed), ‚Äò:‚Äô (dotted), ‚Äò-.‚Äô (dash-dot)\n\nRemember to always check the Matplotlib documentation for the most up-to-date and detailed information!"
  },
  {
    "objectID": "lectures/lecture02/05-lecture02.html#basic-plot-setup",
    "href": "lectures/lecture02/05-lecture02.html#basic-plot-setup",
    "title": "Matplotlib Cheat Sheet",
    "section": "",
    "text": "import matplotlib.pyplot as plt\nimport numpy as np\n\n# Create a new figure\nplt.figure(figsize=(width, height))\n\n# Create a plot\nplt.plot(x, y, 'bo-')  # Blue line with circle markers\n\n# Set labels and title\nplt.xlabel('X-axis label')\nplt.ylabel('Y-axis label')\nplt.title('Plot Title')\n\n# Add a legend\nplt.legend(['Label'], loc='best')\n\n# Show the plot\nplt.show()"
  },
  {
    "objectID": "lectures/lecture02/05-lecture02.html#common-plot-types",
    "href": "lectures/lecture02/05-lecture02.html#common-plot-types",
    "title": "Matplotlib Cheat Sheet",
    "section": "",
    "text": "Line plot: plt.plot(x, y)\nScatter plot: plt.scatter(x, y)\nBar plot: plt.bar(x, height)\nHistogram: plt.hist(data, bins=10)\nBox plot: plt.boxplot(data)\nErrorbar plot: plt.errorbar(x, y, yerr=error)"
  },
  {
    "objectID": "lectures/lecture02/05-lecture02.html#customization",
    "href": "lectures/lecture02/05-lecture02.html#customization",
    "title": "Matplotlib Cheat Sheet",
    "section": "",
    "text": "Set axis limits: plt.xlim(xmin, xmax), plt.ylim(ymin, ymax)\nSet axis scales: plt.xscale('log'), plt.yscale('log')\nSet tick marks: plt.xticks(ticks, labels), plt.yticks(ticks, labels)\nAdd a grid: plt.grid(True)\nChange line style: plt.plot(x, y, linestyle='--', color='r', linewidth=2)\nChange marker style: plt.plot(x, y, marker='o', markersize=5)"
  },
  {
    "objectID": "lectures/lecture02/05-lecture02.html#multiple-plots",
    "href": "lectures/lecture02/05-lecture02.html#multiple-plots",
    "title": "Matplotlib Cheat Sheet",
    "section": "",
    "text": "Subplots: fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,5))\nPlot on specific axes: ax1.plot(x, y)"
  },
  {
    "objectID": "lectures/lecture02/05-lecture02.html#saving-plots",
    "href": "lectures/lecture02/05-lecture02.html#saving-plots",
    "title": "Matplotlib Cheat Sheet",
    "section": "",
    "text": "plt.savefig('filename.png', dpi=300, bbox_inches='tight')"
  },
  {
    "objectID": "lectures/lecture02/05-lecture02.html#advanced-plots",
    "href": "lectures/lecture02/05-lecture02.html#advanced-plots",
    "title": "Matplotlib Cheat Sheet",
    "section": "",
    "text": "Contour plot: plt.contour(X, Y, Z)\n3D plot:\nfrom mpl_toolkits.mplot3d import Axes3D\nfig = plt.figure()\nax = fig.add_subplot(111, projection='3d')\nax.plot_surface(X, Y, Z)"
  },
  {
    "objectID": "lectures/lecture02/05-lecture02.html#useful-settings",
    "href": "lectures/lecture02/05-lecture02.html#useful-settings",
    "title": "Matplotlib Cheat Sheet",
    "section": "",
    "text": "Adjust layout: plt.tight_layout()\nSet style: plt.style.use('ggplot')\nColormap: plt.imshow(data, cmap='viridis')"
  },
  {
    "objectID": "lectures/lecture02/05-lecture02.html#common-parameters",
    "href": "lectures/lecture02/05-lecture02.html#common-parameters",
    "title": "Matplotlib Cheat Sheet",
    "section": "",
    "text": "Colors: ‚Äòb‚Äô (blue), ‚Äòg‚Äô (green), ‚Äòr‚Äô (red), ‚Äòc‚Äô (cyan), ‚Äòm‚Äô (magenta), ‚Äòy‚Äô (yellow), ‚Äòk‚Äô (black), ‚Äòw‚Äô (white)\nMarkers: ‚Äò.‚Äô (point), ‚Äòo‚Äô (circle), ‚Äòs‚Äô (square), ‚Äò^‚Äô (triangle up), ‚Äòv‚Äô (triangle down)\nLinestyles: ‚Äò-‚Äô (solid), ‚Äò‚Äì‚Äô (dashed), ‚Äò:‚Äô (dotted), ‚Äò-.‚Äô (dash-dot)\n\nRemember to always check the Matplotlib documentation for the most up-to-date and detailed information!"
  },
  {
    "objectID": "lectures/lecture02/01-summary02.html",
    "href": "lectures/lecture02/01-summary02.html",
    "title": "Einf√ºhrung in die Modellierung Physikalischer Prozesse",
    "section": "",
    "text": "Click to expand Python Basics Cheat Sheet\n\n\n\n\n\n\n\n\n\ndef function_name(parameter1: type, parameter2: type) -&gt; return_type:\n    # function body\n    return value\n\n\n\nresult = function_name(argument1, argument2)\n\n\n\n\n\n\nfor item in sequence:\n    # code to be executed for each item\nExample:\nfor i in range(1, 11):\n    print(i)\n\n\n\nwhile condition:\n    # code to be executed while condition is true\n    # remember to update the condition\nExample:\ni = 1\nwhile i &lt;= 10:\n    print(i)\n    i += 1\n\n\n\n\n\n\nif condition:\n    # code to be executed if condition is true\n\n\n\nif condition:\n    # code to be executed if condition is true\nelse:\n    # code to be executed if condition is false\n\n\n\nif condition1:\n    # code for condition1\nelif condition2:\n    # code for condition2\nelse:\n    # code if no conditions are true\n\n\n\n\n\nUse descriptive function names\nSpecify parameter and return types for clarity\nIndent properly in loops and conditional statements\nRemember to increment counters in while loops\nUse range() for numeric loops in for statements\nConsider multiple conditions with elif for complex logic"
  },
  {
    "objectID": "lectures/lecture02/01-summary02.html#python-basics-cheat-sheet",
    "href": "lectures/lecture02/01-summary02.html#python-basics-cheat-sheet",
    "title": "Einf√ºhrung in die Modellierung Physikalischer Prozesse",
    "section": "",
    "text": "Click to expand Python Basics Cheat Sheet\n\n\n\n\n\n\n\n\n\ndef function_name(parameter1: type, parameter2: type) -&gt; return_type:\n    # function body\n    return value\n\n\n\nresult = function_name(argument1, argument2)\n\n\n\n\n\n\nfor item in sequence:\n    # code to be executed for each item\nExample:\nfor i in range(1, 11):\n    print(i)\n\n\n\nwhile condition:\n    # code to be executed while condition is true\n    # remember to update the condition\nExample:\ni = 1\nwhile i &lt;= 10:\n    print(i)\n    i += 1\n\n\n\n\n\n\nif condition:\n    # code to be executed if condition is true\n\n\n\nif condition:\n    # code to be executed if condition is true\nelse:\n    # code to be executed if condition is false\n\n\n\nif condition1:\n    # code for condition1\nelif condition2:\n    # code for condition2\nelse:\n    # code if no conditions are true\n\n\n\n\n\nUse descriptive function names\nSpecify parameter and return types for clarity\nIndent properly in loops and conditional statements\nRemember to increment counters in while loops\nUse range() for numeric loops in for statements\nConsider multiple conditions with elif for complex logic"
  },
  {
    "objectID": "lectures/lecture02/01-summary02.html#functions",
    "href": "lectures/lecture02/01-summary02.html#functions",
    "title": "Einf√ºhrung in die Modellierung Physikalischer Prozesse",
    "section": "",
    "text": "def function_name(parameter1: type, parameter2: type) -&gt; return_type:\n    # function body\n    return value\n\n\n\nresult = function_name(argument1, argument2)"
  },
  {
    "objectID": "lectures/lecture02/01-summary02.html#loops",
    "href": "lectures/lecture02/01-summary02.html#loops",
    "title": "Einf√ºhrung in die Modellierung Physikalischer Prozesse",
    "section": "",
    "text": "for item in sequence:\n    # code to be executed for each item\nExample:\nfor i in range(1, 11):\n    print(i)\n\n\n\nwhile condition:\n    # code to be executed while condition is true\n    # remember to update the condition\nExample:\ni = 1\nwhile i &lt;= 10:\n    print(i)\n    i += 1"
  },
  {
    "objectID": "lectures/lecture02/01-summary02.html#conditional-statements",
    "href": "lectures/lecture02/01-summary02.html#conditional-statements",
    "title": "Einf√ºhrung in die Modellierung Physikalischer Prozesse",
    "section": "",
    "text": "if condition:\n    # code to be executed if condition is true\n\n\n\nif condition:\n    # code to be executed if condition is true\nelse:\n    # code to be executed if condition is false\n\n\n\nif condition1:\n    # code for condition1\nelif condition2:\n    # code for condition2\nelse:\n    # code if no conditions are true"
  },
  {
    "objectID": "lectures/lecture02/01-summary02.html#tips",
    "href": "lectures/lecture02/01-summary02.html#tips",
    "title": "Einf√ºhrung in die Modellierung Physikalischer Prozesse",
    "section": "",
    "text": "Use descriptive function names\nSpecify parameter and return types for clarity\nIndent properly in loops and conditional statements\nRemember to increment counters in while loops\nUse range() for numeric loops in for statements\nConsider multiple conditions with elif for complex logic"
  },
  {
    "objectID": "lectures/lecture05/2_brownian_motion.html",
    "href": "lectures/lecture05/2_brownian_motion.html",
    "title": "Brownian Motion",
    "section": "",
    "text": "We will apply our newly acquired knowledge about classes to simulate Brownian motion. This task aligns perfectly with the principles of object-oriented programming, as each Brownian particle (or colloid) can be represented as an object instantiated from the same class, albeit with different properties. For instance, some particles might be larger while others are smaller. We have already touched on some aspects of this in previous lectures."
  },
  {
    "objectID": "lectures/lecture05/2_brownian_motion.html#brownian-motion",
    "href": "lectures/lecture05/2_brownian_motion.html#brownian-motion",
    "title": "Brownian Motion",
    "section": "Brownian Motion",
    "text": "Brownian Motion\n\nWhat is Brownian Motion?\nImagine a dust particle floating in water. If you look at it under a microscope, you‚Äôll see it moving in a random, zigzag pattern. This is Brownian motion!\n\n\nWhy Does This Happen?\nWhen we observe Brownian motion, we‚Äôre seeing the effects of countless molecular collisions. Water isn‚Äôt just a smooth, continuous fluid - it‚Äôs made up of countless tiny molecules that are in constant motion. These water molecules are continuously colliding with our particle from all directions. Each individual collision causes the particle to move just a tiny bit, barely noticeable on its own. However, when millions of these tiny collisions happen every second from random directions, they create the distinctive zigzag motion we observe.\n\n\nThe Simplified Math Behind It\nWhen our particle moves:\n\nEach step is random in direction\nThe size of each step depends on:\n\nTemperature (warmer = more movement)\nTime between steps\nA property called the ‚Äúdiffusion coefficient‚Äù (D)\n\n\n\n\nHow We Can Simulate This?\nIn Python, we can simulate these random steps using random number. These random numbers can be generated with the numpy library. Numpy provides a number of different functions that provide random numbers from different distributions. For Brownian motion, we use a special distribution called the ‚Äúnormal distribution‚Äù.\nstep_size = np.sqrt(2 * D * time_step)\ndx = random_number * step_size  # Random step in x direction\ndy = random_number * step_size  # Random step in y direction\n\nnew_x = old_x + dx\nnew_y = old_y + dy\nWhere:\n\nD is how easily the particle moves (diffusion coefficient)\ntime_step is how often we update the position\nrandom_number is chosen from a special ‚Äúnormal distribution‚Äù\n\n\n\n\n\n\n\nTip\n\n\n\nWhen simulating Brownian motion, we use np.random.normal to generate random steps following this distribution. The normal distribution is characterized by two parameters: the mean and the standard deviation. The mean is the average value, and the standard deviation is a measure of how spread out the values are. For Brownian motion, we use a standard deviation that depends on the diffusion coefficient and the time step. The standard deviation \\(\\sigma=\\sqrt{2D \\Delta t}\\) determines the typical step size, which we can use as a parameter in the normal distribution.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdvanced Mathematical Details\n\n\n\n\n\nThe Brownian motion of a colloidal particle results from collisions with surrounding solvent molecules. These collisions lead to a probability distribution described by:\n\\[\np(x,\\Delta t)=\\frac{1}{\\sqrt{4\\pi D \\Delta t}}e^{-\\frac{x^2}{4D \\Delta t}}\n\\]\nwhere: - \\(D\\) is the diffusion coefficient - \\(\\Delta t\\) is the time step - The variance is \\(\\sigma^2=2D \\Delta t\\)\nThis distribution emerges from the central limit theorem, as shown by Lindenberg and L√©vy, when considering many infinitesimally small random steps.\nThe evolution of the probability density function \\(p(x,t)\\) is governed by the diffusion equation:\n\\[\n\\frac{\\partial p}{\\partial t}=D\\frac{\\partial^2 p}{\\partial x^2}\n\\]\nThis partial differential equation, also known as Fick‚Äôs second law, describes how the concentration of particles evolves over time due to diffusive processes. The Gaussian distribution above is the fundamental solution (Green‚Äôs function) of this diffusion equation, representing how an initially localized distribution spreads out over time.\nThe connection between the microscopic random motion and the macroscopic diffusion equation was first established by Einstein in his 1905 paper on Brownian motion, providing one of the earliest quantitative links between statistical mechanics and thermodynamics."
  },
  {
    "objectID": "lectures/lecture05/2_brownian_motion.html#why-use-a-class",
    "href": "lectures/lecture05/2_brownian_motion.html#why-use-a-class",
    "title": "Brownian Motion",
    "section": "Why Use a Class?",
    "text": "Why Use a Class?\nA class is perfect for this physics simulation because each colloidal particle:\n\nHas specific properties\n\nSize (radius)\nCurrent position\nMovement history\nDiffusion coefficient\n\nFollows certain behaviors\n\nMoves randomly (Brownian motion)\nUpdates its position over time\nKeeps track of where it‚Äôs been\n\nCan exist alongside other particles\n\nMany particles can move independently\nEach particle keeps track of its own properties\nParticles can have different sizes\n\nNeeds to track its state over time\n\nRemember previous positions\nCalculate distances moved\nMaintain its own trajectory\n\n\nThis natural mapping between real particles and code objects makes classes an ideal choice for our simulation."
  },
  {
    "objectID": "lectures/lecture05/2_brownian_motion.html#class-design",
    "href": "lectures/lecture05/2_brownian_motion.html#class-design",
    "title": "Brownian Motion",
    "section": "Class Design",
    "text": "Class Design\nLet‚Äôs design a Python class to simulate colloidal particles undergoing Brownian motion. This object-oriented approach will help us manage multiple particles with different properties and behaviors.\n\nClass-Level Properties\nThe Colloid class will maintain information shared by all particles:\n\nA counter for the total number of particles\nThe physical constant \\(k_B T/(6\\pi\\eta) = 2.2√ó10^{-19}\\) (combining temperature and fluid properties)\n\n\n\nClass Methods\nThe class will provide these shared functions:\n\nhow_many(): Reports the total number of particles\n__str__: Creates a readable description of a particle‚Äôs properties\n\n\n\nInstance Properties\nEach individual particle object will have:\n\nRadius (R)\nPosition history (x and y coordinates)\nUnique identifier (index)\nDiffusion coefficient (\\(D = k_B T/(6\\pi\\eta R)\\))\n\n\n\nInstance Methods\nEach particle will be able to:\n\nsim_trajectory(): Generate a complete motion path\nupdate(dt): Calculate one step of Brownian motion\nget_trajectory(): Return its movement history\nget_D(): Provide its diffusion coefficient\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nNote that the function sim_trajectory is actually calling the function update of the same object to generate the whole trajectory at once."
  },
  {
    "objectID": "lectures/lecture05/2_brownian_motion.html#simulating",
    "href": "lectures/lecture05/2_brownian_motion.html#simulating",
    "title": "Brownian Motion",
    "section": "Simulating",
    "text": "Simulating\nWith the help of this Colloid class, we would like to carry out simulations of Brownian motion of multiple particles. The simulations shall\n\ntake n=200 particles\nhave N=200 trajectory points each\nstart all at 0,0\nparticle objects should be stored in a list p_list"
  },
  {
    "objectID": "lectures/lecture05/2_brownian_motion.html#plotting-the-trajectories",
    "href": "lectures/lecture05/2_brownian_motion.html#plotting-the-trajectories",
    "title": "Brownian Motion",
    "section": "Plotting the trajectories",
    "text": "Plotting the trajectories\nThe next step is to plot all the trajectories."
  },
  {
    "objectID": "lectures/lecture05/2_brownian_motion.html#characterizing-the-brownian-motion",
    "href": "lectures/lecture05/2_brownian_motion.html#characterizing-the-brownian-motion",
    "title": "Brownian Motion",
    "section": "Characterizing the Brownian motion",
    "text": "Characterizing the Brownian motion\nNow that we have a number of trajectories, we can analyze the motion of our Brownian particles.\n\nCalculate the particle speed\nOne way is to calculate its speed by measuring how far it traveled within a certain time \\(n\\, dt\\), where \\(dt\\) is the timestep of out simulation. We can do that as\n\\[\\begin{equation}\nv(n dt) = \\frac{&lt;\\sqrt{(x_{i+n}-x_{i})^2+(y_{i+n}-y_{i})^2}&gt;}{n\\,dt}\n\\end{equation}\\]\nThe angular brackets on the top take care of the fact that we can measure the distance traveled within a certain time \\(n\\, dt\\) several times along a trajectory.\nThese values can be used to calculate a mean speed. Note that there is not an equal amount of data pairs for all separations available. For \\(n=1\\) there are 5 distances available. For \\(n=5\\), however, only 1. This changes the statistical accuracy of the mean.\n\n\n\n\n\n\nThe result of this analysis shows, that each particle has an apparent speed which seems to increase with decreasing time of observation or which decreases with increasing time. This would mean that there is some friction at work, which slows down the particle in time, but this is apparently not true. Also an infinite speed at zero time appears to be unphysical. The correct answer is just that the speed is no good measure to characterize the motion of a Brownian particle.\n\n\nCalculate the particle mean squared displacement\nA better way to characterize the motion of a Brownian particle is the mean squared displacement, as we have already mentioned it in previous lectures. We may compare our simulation now to the theoretical prediction, which is\n\\[\\begin{equation}\n\\langle \\Delta r^{2}(t)\\rangle=2 d D t\n\\end{equation}\\]\nwhere \\(d\\) is the dimension of the random walk, which is \\(d=2\\) in our case.\n\n\n\n\n\n\nThe results show that the mean squared displacement of the individual particles follows on average the theoretical predictions of a linear growth in time. That means, we are able to read the diffusion coefficient from the slope of the MSD of the individual particles if recorded in a simulation or an experiment.\nYet, each individual MSD is deviating strongly from the theoretical prediction especially at large times. This is due to the fact mentioned earlier that our simulation (or experimental) data only has a limited number of data points, while the theoretical prediction is made for the limit of infinite data points.\n\n\n\n\n\n\nAnalysis of MSD data\n\n\n\nSingle particle tracking, either in the experiment or in numerical simulations can therefore only deliver an estimate of the diffusion coefficient and care should be taken when using the whole MSD to obtain the diffusion coefficient. One typically uses only a short fraction of the whole MSD data at short times."
  },
  {
    "objectID": "lectures/lecture05/01-lecture05.html",
    "href": "lectures/lecture05/01-lecture05.html",
    "title": "Lecture 5",
    "section": "",
    "text": "Introduction to classes in Python (optional, for organizing code).\nRotational kinematics and dynamics (moment of inertia, angular momentum).\n\n\n\n\n\nSimulating the motion of a rotating object (e.g., a spinning disk) and calculating its angular momentum.\nVisualizing the effect of torque on the object‚Äôs rotation.\nHomework: Extend the simulation to include the effect of external forces, such as friction."
  },
  {
    "objectID": "lectures/lecture05/01-lecture05.html#angular-momentum-and-rotational-motion",
    "href": "lectures/lecture05/01-lecture05.html#angular-momentum-and-rotational-motion",
    "title": "Lecture 5",
    "section": "",
    "text": "Introduction to classes in Python (optional, for organizing code).\nRotational kinematics and dynamics (moment of inertia, angular momentum).\n\n\n\n\n\nSimulating the motion of a rotating object (e.g., a spinning disk) and calculating its angular momentum.\nVisualizing the effect of torque on the object‚Äôs rotation.\nHomework: Extend the simulation to include the effect of external forces, such as friction."
  },
  {
    "objectID": "lectures/lecture10/DampedOscillation.html",
    "href": "lectures/lecture10/DampedOscillation.html",
    "title": "Appendix: Fourier Analysis of a damped oscillation",
    "section": "",
    "text": "Consider a generalised description of the oscillation by\n\\[\\begin{equation}\n    f(t)=a(t)\\cos(\\omega_S t)\n\\end{equation}\\]\nWhere \\(a(t)\\) is the time varying amplitude. This product of two functions can be treated with the help of the so-called convolution theorem. A convolution is represented by\n\\[\\begin{equation}\\label{eq:convint}\n    f(t)*g(t)=\\int_{-\\infty}^{\\infty} f(\\tau)g(t-\\tau)d\\tau\n\\end{equation}\\]\nwhich means, that one sums up all contributions of a function \\(g(t)\\) centered at a time value of \\(\\tau\\) with amplitude \\(f(\\tau)\\). Convolutions play an important role for example in optics, where the microscope resolution function convolutes the structural images of all objects.\nThis convolution integral can be transformed into a product of the Fourier transforms \\((\\mathscr{F}\\)) of both functions\n\\[\\begin{equation}\n    H(\\omega)G(\\omega)=\\mathscr{F}(f*g)\n\\end{equation}\\]\nSo the product of the Fourier transform of the individual functions in the product is the same as the Fourier transform of the convolution integral Eq. \\(\\ref{eq:convint}\\).\nWhat is relevant in the discussed case of the oscillating guitar string is the inverse relation of the convolution theorem\n\\[\\begin{equation}\n    H(\\omega)*G(\\omega)=\\mathscr{F}(f(t) g(t))\n\\end{equation}\\]\nThis means that the Fourier transform of a product of two functions is equivalent to a convolution of the Fourier transforms of the individual functions.\nThe convolution integral of the Fourier transformed function then corresponds to\n\\[\\begin{equation}\\label{eq:inverse_conv}\n    H(\\omega)*G(\\omega)=\\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^{\\infty} F(\\Omega)G(\\omega-\\Omega)d\\Omega\n\\end{equation}\\]\nUsing this relation and\n\\[\\begin{equation}\n    H(\\omega)=\\mathscr{F}(\\cos(\\omega_S t))\n\\end{equation}\\]\nand\n\\[\\begin{equation}\n    G(\\omega)=\\mathscr{F}(\\Theta(t) e^{-t/\\tau})\n\\end{equation}\\]\nI can compute all types of amplitude modulated harmonic oscillations in Fourier space. In particular, the Fourier transform \\(\\mathscr{F}\\) of a harmonic function \\(\\cos(\\omega_S t)\\) results in a so-called delta function (\\(\\delta(t)\\))\n\\[\\begin{equation}\\label{eq:cosineft}\n    H(\\omega)=\\mathscr{F}(\\cos(\\omega_S t))=\\sqrt{\\frac{\\pi}{2}} \\delta(\\omega+\\omega_S)-\\sqrt{\\frac{\\pi}{2}} \\delta(\\omega+\\omega_S)\n\\end{equation}\\]\nThe \\(\\delta\\)-function has the properties as described in section \\(\\ref{sec:delta}\\).\n\\[\\begin{equation}\\label{eq:lorentz}\n    G(\\omega)=\\mathscr{F}(\\Theta(t)e^{-t/\\tau})=\\frac{1}{\\sqrt{2\\pi}}\\frac{i \\tau}{(i-\\tau\\omega)}\n\\end{equation}\\]\nThe squared magnitude of Eq. \\(\\ref{eq:lorentz}\\) yields a Lorentzian lineshape\n\\[\\begin{equation}\n    |G(\\omega)|^{2}=\\frac{1}{2 \\pi} \\frac{\\tau^2}{1+\\tau^{2}\\omega^{2}}\n\\end{equation}\\]\nfor the frequency spectrum, which is very common in physics. This Lorentzian function has a maximum at \\(\\omega=0\\) with \\(|G(\\omega)|^2=\\tau^2/2\\pi\\).\nWith the help of Eq. \\(\\ref{eq:cosineft}\\) and Eq. \\(\\ref{eq:lorentz}\\) I can write the convolution integral \\(\\ref{eq:inverse_conv}\\) as\n\\[\\begin{equation}\\label{Delta Functions}\n    H(\\omega)*G(\\omega)=\\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^{\\infty}  \\sqrt{\\frac{\\pi}{2}} [\\delta(\\Omega-\\omega_S) + \\delta(\\Omega+\\omega_S)] \\frac{1}{\\sqrt{2\\pi}}\\frac{i \\tau}{(i-\\tau (\\omega-\\Omega))} d\\Omega\n\\end{equation}\\]\nThe integration can be carried out using the integration rule in Eq. \\(\\ref{delta}\\) for the delta function which leaves me with the integral of the function displayed in Eq. \\(\\ref{Delta Functions}\\) as equal to\n\\[\\begin{equation}\\label{Hallo}\n    F(\\omega)= H(\\omega)*G(\\omega)=\\frac{1}{\\sqrt{2\\pi}}\\cdot\\frac{\\sqrt\\pi}{\\sqrt2 \\sqrt{2\\pi}}\\left [\\frac{i\\tau}{(i-\\tau(\\omega-\\omega_S))} + \\frac{i\\tau}{(i-\\tau(\\omega+\\omega_S))}\\right ]\n\\end{equation}\\]\nThis yields\n\\[\\begin{equation}\nF(\\omega)=\\frac{1}{\\sqrt{2\\pi}}\\frac{1/\\tau+i\\omega}{(1/\\tau+i\\omega)^2+\\omega_S^2}\n\\end{equation}\\]"
  },
  {
    "objectID": "lectures/lecture10/2_planetary_motion.html#physical-model",
    "href": "lectures/lecture10/2_planetary_motion.html#physical-model",
    "title": "Planetary Motion",
    "section": "Physical Model",
    "text": "Physical Model\nThe motion of planets around the Sun is a classic problem in physics that beautifully demonstrates Newton‚Äôs laws of motion and universal gravitation. While this motion might seem very different from a spring pendulum, the mathematical description is surprisingly similar. The main difference is that instead of a spring force, we now have gravity as our central force.\nIn both cases, we describe the motion using two coordinates: the distance from the center (\\(r\\)) and an angle (\\(\\theta\\)). For planetary motion, \\(r\\) is the distance between the planet and the Sun, and \\(\\theta\\) describes the planet‚Äôs angular position in its orbit.\nThe equations of motion contain two parts: The first equation describes the radial acceleration (\\(\\ddot{r}\\)), and the second describes the angular acceleration (\\(\\ddot{\\theta}\\)):\n\\[\\begin{eqnarray}\n\\ddot{r}&=&r\\dot{\\theta}^2-\\frac{G\\, M}{r^2}\\\\\n\\ddot{\\theta}&=&-\\frac{1}{r}2\\dot{r}\\dot{\\theta}\n\\end{eqnarray}\\]\nIn the first equation, the term \\(r\\dot{\\theta}^2\\) represents the centrifugal effect - the tendency of the planet to move away from the Sun due to its orbital motion. The term \\(-\\frac{G\\, M}{r^2}\\) is Newton‚Äôs gravitational force (divided by mass), pulling the planet toward the Sun. \\(G\\) is the gravitational constant, and \\(M\\) is the mass of the Sun.\nThe second equation describes how the angular motion changes. The term \\(2\\dot{r}\\dot{\\theta}\\) represents the coupling between radial and angular motion - as the planet moves closer to or farther from the Sun, its angular velocity must change to conserve angular momentum, similar to how an ice skater spins faster when pulling their arms in.\nThe solution to these equations gives us the famous orbital equation:\n\\[\nr(\\theta)=\\frac{p}{1+\\epsilon \\cos(\\theta)}\n\\]\nThis is the equation of a conic section, where \\(p\\) and \\(\\epsilon\\) determine the orbit‚Äôs shape. The parameter \\(p\\) is related to the angular momentum \\(L\\):\n\\[\\begin{equation}\np=\\frac{L^2}{G M m^2}\n\\end{equation}\\]\nThe eccentricity \\(\\epsilon\\) depends on both the energy \\(E\\) and angular momentum \\(L\\):\n\\[\\begin{equation}\n\\epsilon=\\sqrt{1+\\frac{2\\frac{E}{m}\\frac{L^2}{m^2}}{G^2M^2}}\n\\end{equation}\\]\nWhen \\(0 &lt; \\epsilon &lt; 1\\), we get an elliptical orbit (the case for all planets in our solar system). A perfect circle occurs when \\(\\epsilon = 0\\). These equations, derived by Newton and studied by Kepler, explain not only planetary orbits but also the paths of comets, artificial satellites, and many other celestial objects."
  },
  {
    "objectID": "lectures/lecture10/2_planetary_motion.html#numerical-solution",
    "href": "lectures/lecture10/2_planetary_motion.html#numerical-solution",
    "title": "Planetary Motion",
    "section": "Numerical Solution",
    "text": "Numerical Solution\nFor the numerical solution, we will use the odeint function from the scipy.integrate module. This function solves ordinary differential equations (ODEs) given an initial state and a time array. We will integrate the equations of motion for a planet with an initial radius \\(r_0\\), radial velocity \\(v_0\\), angle \\(\\theta_0\\), and angular velocity \\(\\omega_0\\).\n\nInitial Parameters: Planets\nWe first define the initial parameters for the planet‚Äôs motion. We set the mass of the Sun \\(M=1\\) and the mass of the planet \\(m=1\\) for simplicity. The gravitational constant \\(G\\) is set to \\(4\\pi^2\\) to simplify the equations. We also define the initial radius \\(r_0\\), radial velocity \\(v_0\\), angle \\(\\theta_0\\), and angular velocity \\(\\omega_0\\).\n\n\n\n\n\n\n\n\nSolution: Planets\nT\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlotting: Planets\nWe can now plot the numerical solution of the planetary motion. The black dashed line represents the analytical solution for the orbit of the planet. The black solid line shows the numerical solution obtained by integrating the equations of motion.\n\nTrajectory\n\n\n\n\n\n\n\n\nEnergy\nFinally, we can plot the total energy of the planet as a function of time. The total energy is the sum of the kinetic and potential energy of the planet. We can see that the energy is conserved over time, as expected for a system with no external forces."
  },
  {
    "objectID": "lectures/lecture07/1_differentiation.html",
    "href": "lectures/lecture07/1_differentiation.html",
    "title": "Numerical Differentiation",
    "section": "",
    "text": "While we did introduce derivatives shortly already when exploring the slicing of arrays, we will now look at the numerical differentiation in more detail. This will require again a little bit of math."
  },
  {
    "objectID": "lectures/lecture07/1_differentiation.html#first-order-derivative",
    "href": "lectures/lecture07/1_differentiation.html#first-order-derivative",
    "title": "Numerical Differentiation",
    "section": "First Order Derivative",
    "text": "First Order Derivative\nOur previous method of finding the derivative was based on the definition of the derivative itself. The derivative of a function \\(f(x)\\) at a point \\(x\\) is defined as the limit of the difference quotient as the interval \\(\\Delta x\\) goes to zero:\n\\[\nf^{\\prime}(x) = \\lim_{\\Delta x \\rightarrow 0} \\frac{f(x + \\Delta x) - f(x)}{\\Delta x}\n\\]\nIf we do not take the limit, we can approximate the derivative by:\n\\[\nf^{\\prime}_{i} \\approx \\frac{f_{i+1} - f_{i}}{\\Delta x}\n\\]\nHere, we look to the right of the current position \\(i\\) and divide by the interval \\(\\Delta x\\). It is not difficult to see that the resulting local error \\(\\delta\\) at each step is given by:\n\\[\n\\delta = f_{i+1} - f_{i} - \\Delta x f^{\\prime}(x_i) = \\frac{1}{2} \\Delta x^2 f^{\\prime \\prime}(x_i) + O(\\Delta x^3)\n\\]\nIt can be seen that the error is proportional to the square of the interval \\(\\Delta x\\). This is the reason why the method is called first order accurate. The error is of the order of \\(\\Delta x^{2}\\).\nA better expression can be found using the Taylor expansion around the position \\(x_0\\):\n\\[\nf(x) = f(x_{0}) + (x - x_0) f^{\\prime}(x) + \\frac{(x - x_0)^2}{2!} f^{\\prime\\prime}(x) + \\frac{(x - x_0)^3}{3!} f^{(3)}(x) + \\ldots\n\\]\nIn discrete notation, this gives:\n\\[\nf_{i+1} = f_{i} + \\Delta x f_{i}^{\\prime} + \\frac{\\Delta x^2}{2!} f_{i}^{\\prime\\prime} + \\frac{\\Delta x^3}{3!} f_{i}^{(3)} + \\ldots\n\\]\nThe same can be done to obtain the function value at \\(i-1\\):\n\\[\nf_{i-1} = f_{i} - \\Delta x f_{i}^{\\prime} + \\frac{\\Delta x^2}{2!} f_{i}^{\\prime\\prime} - \\frac{\\Delta x^3}{3!} f_{i}^{(3)} + \\ldots\n\\]\nSubtracting these two equations, we get:\n\\[\nf_{i+1} - f_{i-1} = 2 \\Delta x f_{i}^{\\prime} + O(\\Delta x^3)\n\\]\nsuch that the second order term in \\(\\Delta x\\) disappears. Neglecting the higher-order terms, we have\n\\[\nf^{\\prime}_{i} \\approx \\frac{f_{i+1} - f_{i-1}}{2 \\Delta x}\n\\]\nan thus have a first order derivative which is even more accurate than the one obtained from the definition of the derivative.\nWe can continue that type of derivation now to obtain higher order approximation of the first derivative with better accuracy. For that purpose you may calculate now \\(f_{i\\pm 2}\\) and combining that with \\(f_{i+1}-f_{i-1}\\) will lead to\n\\[\\begin{equation}\nf_{i}^{\\prime}=\\frac{1}{12 \\Delta x}(f_{i-2}-8f_{i-1}+8f_{i+1}-f_{i+2})\n\\end{equation}\\]\nThis can be used to give even better values for the first derivative.\nLet`s try out one of the formulas in the following code cell. We will write a function that calculates the derivative of a given function at a given position \\(x\\). The function will take the function \\(f\\) as and argument, which is new to us. We will also introduce a small interval \\(h=\\Delta x\\) which will be used to calculate the derivative. The function will return the derivative of the function at the given position \\(x\\).\n\n\n\n\n\n\nNote that the definition contains additional parameters *params which are passed to the function f. This is a general way to pass additional parameters to the function f which is used in the definition of the derivative.\nWe will try to calculate the derivative of the \\(\\sin(x)\\) function:\n\n\n\n\n\n\nWe can plot this and nicely obtain our cosine function\n\n\n\n\n\n\n\nMatrix Version of the First Derivative\nIf we supply the above function with an array of positions \\(x_{i}\\) at which we would like to calculate the derivative, we obtain an array of derivative values. We can also write this procedure in a different way, which will be helpful for solving differential equations later.\nIf we consider the above finite difference formulas for a set of positions \\(x_{i}\\), we can represent the first derivative at these positions by a matrix operation as well:\n\\[\nf^{\\prime} = \\frac{1}{\\Delta x}\n\\begin{bmatrix}\n-1 & 1  & 0 & 0 & 0 & 0\\\\\n0 & -1 & 1 & 0 & 0 & 0\\\\\n0 & 0  & -1 & 1 & 0 & 0\\\\\n0 & 0  & 0  & -1 & 1 & 0\\\\\n0 & 0  & 0  &  0 & -1 & 1\\\\\n0 & 0  & 0  &  0 &  0 & -1\\\\\n\\end{bmatrix}\n\\begin{bmatrix}\nf_{1}\\\\\nf_{2}\\\\\nf_{3}\\\\\nf_{4}\\\\\nf_{5}\\\\\nf_{6}\\\\\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n\\frac{f_{2} - f_{1}}{\\Delta x}\\\\\n\\frac{f_{3} - f_{2}}{\\Delta x}\\\\\n\\frac{f_{4} - f_{3}}{\\Delta x}\\\\\n\\frac{f_{5} - f_{4}}{\\Delta x}\\\\\n\\frac{f_{6} - f_{5}}{\\Delta x}\\\\\n\\frac{0 - f_{6}}{\\Delta x}\\\\\n\\end{bmatrix}\n\\]\nNote that here we took the derivative only to the right side! Each row of the matrix, when multiplied by the vector containing the function values, gives the derivative of the function \\(f\\) at the corresponding position \\(x_{i}\\). The resulting vector represents the derivative in a certain position region.\nWe will demonstrate how to generate such a matrix with the SciPy module below."
  },
  {
    "objectID": "lectures/lecture07/1_differentiation.html#second-order-derivative",
    "href": "lectures/lecture07/1_differentiation.html#second-order-derivative",
    "title": "Numerical Differentiation",
    "section": "Second order derivative",
    "text": "Second order derivative\nWhile we did before calculate the first derivative, we can also calculate the second derivative of a function. In the previous calculations we evaluated \\(f_{i+1} - f_{i-1}\\). We can now also use the sum of both to arrive at\n\\[\\begin{equation}\nf_{i}^{\\prime\\prime}\\approx \\frac{f_{i-1}-2f_{i}+f_{i+1}}{\\Delta x^2}\n\\end{equation}\\]\nwhich gives the basic equation for calculating the second order derivative and the next order may be obtained from\n\\[\\begin{equation}\nf_{i}^{\\prime\\prime}\\approx \\frac{1}{12 \\Delta x^{2}}(-f_{i-2}+16f_{i-1}-30 f_{i}+16f_{i+1}-f_{i+2})\n\\end{equation}\\]\nwhich is again better than our previous formula, yet needs more function values to be calculated."
  },
  {
    "objectID": "lectures/lecture07/1_differentiation.html#scipy-module",
    "href": "lectures/lecture07/1_differentiation.html#scipy-module",
    "title": "Numerical Differentiation",
    "section": "SciPy Module",
    "text": "SciPy Module\nOf course, we are not the first to define some functions for calculating the derivative of functions numerically. This is already implemented in different modules. One module is the above mentioned SciPy module.\nThe SciPy module provides the method derivative, which we can call with\nderivative(f,x,dx=1.0,n=1):\nThis will calculate the n\\(th\\) derivative of the function \\(f\\) at the position \\(x\\) with a intervall \\(dx=1.0\\) (default value).\n\n\n\n\n\n\nWe also have the option to define the order parameter, which is not the order of the derivative but rather the number of points used to calculate the derivative according to our scheme earlier.\n\n\n\n\n\n\n\nMatrix Version\nThe SciPy module allows us to construct matrices as mentioned above. We will need the diags method from the SciPy module for that purpose.\n\n\n\n\n\n\nLet‚Äôs assume we want to calculate the derivative of the sin function at certain positions.\n\n\n\n\n\n\nThe diags function uses a set of numbers that should be distributed along the diagonals of the matrix. If you supply a list like in the example below, the numbers are distributed using the offsets as defined in the second list. The shape keyword defines the shape of the matrix. Try the example in the next cell with the .todense() suffix. This converts the otherwise unreadable sparse output to a readable matrix form.\n\n\n\n\n\n\nTo comply with our previous definition of \\(N=100\\) data points and the interval \\(\\Delta x\\), we define:\n\n\n\n\n\n\nThe derivative is then simply a matrix-vector multiplication, which is done either by np.dot(m,y) or just by the @ operator.\n\n\n\n\n\n\nLet‚Äôs plot the original function and its numerical derivative.\n\n\n\n\n\n\nCheck for yourself that the following line of code will calculate the second derivative.\n\n\n\n\n\n\nLet‚Äôs plot the original function and its second numerical derivative.\n\n\n\n\n\n\nThis demonstrates how to use the SciPy module to construct matrices for numerical differentiation and how to apply these matrices to compute first and second derivatives.\n\n\n\n\n\n\nApplications of the Matrix Method\n\n\n\n\n\nThe matrix method for computing derivatives is particularly useful in several contexts, especially in numerical analysis and computational mathematics. Here are some key applications:\n\nSolving Differential Equations:\n\nOrdinary Differential Equations (ODEs): The matrix method can be used to discretize ODEs, transforming them into a system of linear equations that can be solved using linear algebra techniques.\nPartial Differential Equations (PDEs): Similarly, PDEs can be discretized using finite difference methods, where derivatives are approximated by matrix operations. This is essential in fields like fluid dynamics, heat transfer, and electromagnetics.\n\nNumerical Differentiation:\n\nThe matrix method provides a systematic way to approximate derivatives of functions given discrete data points. This is useful in data analysis, signal processing, and any application where you need to estimate the rate of change from sampled data.\n\nStability and Accuracy Analysis:\n\nBy representing derivative operations as matrices, it becomes easier to analyze the stability and accuracy of numerical schemes. This is crucial for ensuring that numerical solutions to differential equations are reliable.\n\nOptimization Problems:\n\nIn optimization, especially in gradient-based methods, the matrix method can be used to compute gradients and Hessians efficiently. This is important in machine learning, operations research, and various engineering disciplines.\n\nFinite Element Analysis (FEA):\n\nIn FEA, the matrix method is used to approximate derivatives and integrals over complex geometries. This is widely used in structural engineering, biomechanics, and materials science.\n\nControl Theory:\n\nIn control theory, especially in the design and analysis of control systems, the matrix method can be used to model and simulate the behavior of dynamic systems."
  },
  {
    "objectID": "lectures/lecture09/2_coupled_pendula.html",
    "href": "lectures/lecture09/2_coupled_pendula.html",
    "title": "Coupled Pendula",
    "section": "",
    "text": "We will continue our course with some physical problems, we are going to tackle. One of the more extensive solutions will consider two coupled pendula. This belongs to the class of coupled oscillators, which are extremely important. They will later yield propagating waves. They are important for phonons, i.e.¬†coupled vibration of atoms in solids, but there are also many other axamples. One can realize the coupled oscillation on different ways. He we will do that not with spring oscillators, by with pendula."
  },
  {
    "objectID": "lectures/lecture09/2_coupled_pendula.html#description-of-the-problem",
    "href": "lectures/lecture09/2_coupled_pendula.html#description-of-the-problem",
    "title": "Coupled Pendula",
    "section": "Description of the problem",
    "text": "Description of the problem\n\nSketch\nThe image below depicts the sitution we would like to cover in our first project. These are two pendula, which have the length \\(L_{1}\\) and \\(L_{2}\\). Both are coupled with a spring of spring constant \\(k\\), which is relaxed, when both pendula are at rest. You may want to include a generalized version where the spring is mounted at a distance \\(c\\) from the turning points of the pendula.\nIf you develop the equation of motion, write down as a sum of torques. Use one equation of motion for each pendulum. The result will be two coupled differential equations for the angular coordinates. They are solved by the scipy odeint function without any friction.\n\n\n\n\n\n\nFigure¬†1: Sketch of the two coupled pendula.\n\n\n\n\n\nEquations of motion\nThe equations of motion of the two coupled pendula have the following form:\n\\[\\begin{eqnarray}\nI_{1}\\ddot{\\theta_{1}}&=&-m_{1}gL_{1}\\sin(\\theta_{1})-kc^2[\\sin(\\theta_{1})-\\sin(\\theta_{2})]\\\\\nI_{2}\\ddot{\\theta_{2}}&=&-m_{2}gL_{2}\\sin(\\theta_{2})+kc^2[\\sin(\\theta_{1})-\\sin(\\theta_{2})]\n\\end{eqnarray}\\]\nHere, \\(\\theta_{1}, \\theta_{2}\\) measure the angle of the two pendula with the length \\(L_{1},L_{2}\\). \\(k\\) is the spring constant of the spring coupling both pendula. If you use a variable coupling position of the spring name the length of the coupling from the turning point \\(c\\)."
  },
  {
    "objectID": "lectures/lecture09/2_coupled_pendula.html#solving-the-problem",
    "href": "lectures/lecture09/2_coupled_pendula.html#solving-the-problem",
    "title": "Coupled Pendula",
    "section": "Solving the problem",
    "text": "Solving the problem\n\nSetting up the function\nIn our previous lecture, we used the odeint function of scipy to solve the driven damped harmonic oscillator. Remeber that we used the array\nstate[0] -&gt; position\nstate[1] -&gt; velocity\nto exchange position and velocity with the solver via the function that defines the physical problem\ndef SHO(state, time):\n    g0 = state[1]               -&gt;velocity\n    g1 = -k/m * state [0]       -&gt;acceleration\n    return np.array([g0, g1])\nfor a coupled system of different equations, we can now extend the state array. In the case of the coupled system of equations it has the following structure\ndef SHO(state, time):\n    g0 = how the velocity of object 1 depends on the velocities of all objects\n    g1 = how the acceleration of object 1 depends on the acceleration of all objects\n    g2 = how the velocity of object 2 depends on the velocities of all objects\n    g3 = how the acceleration of object 2 depends on the acceleration of all objects\n    return np.array([g0, g1])\nSo the state vector just gets longer and the coupling is in the definition of the velocities and accelerations. The results are then the positions and velocities of the objects. Use this type of scheme to define the problem and write a function, which returns the state of the objects as before.\n\n\n\n\n\n\n\n\nDefine initial parameters\nWe want to define some parameters of the pendula\n\nlength of the pendulum 1, \\(L_1\\)=3\nlength of the pendulum 2, \\(L_2\\)=3\ngravitational acceleration, \\(g=9.81\\)\nmass at the end of the pendula, \\(m=1\\)\ndistance where the coupling spring is mounted, \\(c=2\\)\nspring constant of the coupling spring, \\(k=5\\)\n\n\n\n\n\n\n\nAs compared to our previous problem of a damped driven pendulum, where we had two initial conditions for the second order differential equation, we have now two second order differential equation. We therefore need 4 initial parameters, which are the initial elongations of both pendula and their corresponding initial angular velocities We will notice, that the solution,i.e.¬†the motion of the pendula, will strongly depend on the initial conditions.\n\n\n\n\n\n\n\n\nSolve the equation of motion\nWe have to define a timeperiod over which we would like to obtain the solution. We use here a period of 400s where we calculate the solution at 10000 points along the 400s.\n\n\n\n\n\n\nWe are now ready to calculate the solution. Finally, we extract also the angles of the individual pendula, their angular velocities and the position of the point masses at the end of the pendulum. This can be then readily used to create some animation.\n\n\n\n\n\n\n\n\nPlotting\nFirst, get some impression of how the angles change over time.\n\n\n\n\n\n\n\n\nAnimation\nThe plot of the angles over time is not always giving a good insight. With our knowledge about animations, we may easily animate the motion of the two pendula as well. Yet, the animation code will not work in the website version. But you may copy and paste the code to your own Jupyter Notebook environment.\n\n\n\n\n\n\nFor the physics, it has neven been interesting to define at which distance the pendula are mounted at a ceiling for example. For drawing them we have to do that together with some additional parameters, which define for example the position of where to draw in the canvas and the conversion of meters to pixels.\n\n\n\n\n\n\nThe function below will do the drawing for us. We define a function such that we can create a background animation with a thread. Note that we have inserted sleep(t[1]-t[0]) at the end. The drawing of the 4 objects will be pretty fast so that we can wait a certain amount of time until we display the next frame. That means at the end, that our simulation will run in real time.\n\n\n\n\n\n\n\n\n\n\n\n\nLooks pretty slow, but remember the pendula are 3 meters long."
  },
  {
    "objectID": "lectures/lecture09/2_coupled_pendula.html#normal-modes",
    "href": "lectures/lecture09/2_coupled_pendula.html#normal-modes",
    "title": "Coupled Pendula",
    "section": "Normal Modes",
    "text": "Normal Modes\nWe will not cover all the physical details here, but you might remember your mechanis lectures, that two coupled oscillators show distinct modes of motion, which we would call the normal modes. Four two coupled pendula there are two normal modes, where both pendula move with the same frequency. We may force the system into one of its normal modes, by specifying its initial conditions properly.\n\nIn-phase motion\nThe first one, will create an in-phase motion of the two pendula by setting their initial elongation equal, i.e.¬†\\(\\theta_{1}(t=0)=\\theta_{2}(t=0)\\). Both pendula then oscillate with their natural frequency and the coupling spring is never elongated.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOut-of-phase motion\nThe second one, will create a motion in which the two pendula are out-of-phase by a phase angle of \\(\\pi\\) , i.e.¬†\\(\\theta_{1}(t=0)=-\\theta_{2}(t=0)\\). Both pendula then oscillate with a frequency higher than their natural frequency. This is due to the fact that there is a higher restoring force due to the action of the spring.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBeat case\nThe last case is not a normal mode but represents a more general case. We start with two different initial angles, i.e.¬†\\(\\theta_{1}(t=0)=\\pi/12\\) and \\(\\theta_{2}(t=0)=0\\). This is the so-called beat case, where the pendula exchange energy. The oscillation, which is at the beginning in only in the first pendulum is then transfer to the second one. This transfer of energy is continuously occurring from one pendulum to the other since there‚Äôs nowhere for the energy to go. From this point it‚Äôs easily to recognize how the wife is generated. In a set of many coupled pendula one pendulum is starting to oscillate and is transferring it‚Äôs energy to the next one and then to the next one and then to the next one and this way the energy is propagating along all oscillators.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nComputation of energy (here for the beat case)\nAfter we have had a look at the motion of the individual pendula, we may also check, the energies in the system. We have to calculate the potential and kinetic energies of the pendula and we should not forget the potential energy stored in the spring.\n\nPotential energy of the pendula\nThe potential energy plot below nicely shows the exchange of energy between the two pendula in the beat case.\n\n\n\n\n\n\n\n\nPotential energy of the spring\n\n\n\n\n\n\n\n\nKinetic energies\n\n\n\n\n\n\n\n\nTotal energy\nAs the total energy in the system shall nbe conserved, the sum of all energy contributions should yield a flat line.\n\n\n\n\n\n\n\n\nTotal energy exchange of the pendula\nWhile the plot above Shows the total energy of both pendula we may now have a look at the total energy in each pendulum. The plots clearly show that the energy is exchanged between the two pendula. The residual ripples on the curve results from the fact that we here exclude the potential energy stored in the spring."
  },
  {
    "objectID": "lectures/lecture08/2_integration.html",
    "href": "lectures/lecture08/2_integration.html",
    "title": "Numerical Integration",
    "section": "",
    "text": "This lecture covers numerical integration methods, which are essential for computing definite integrals of functions. We‚Äôll explore three different methods with increasing accuracy: the Box method, Trapezoid method, and Simpson‚Äôs method."
  },
  {
    "objectID": "lectures/lecture08/2_integration.html#box-method-rectangle-method",
    "href": "lectures/lecture08/2_integration.html#box-method-rectangle-method",
    "title": "Numerical Integration",
    "section": "Box Method (Rectangle Method)",
    "text": "Box Method (Rectangle Method)\n\n\n\nBox Method Illustration\n\n\nThe Box method is the simplest approach for numerical integration. It approximates the function in each interval \\(\\Delta x\\) with a constant value taken at the left endpoint of the interval.\n\\[\\begin{equation}\n\\int_{a}^{b} f(x) dx \\approx \\sum_{i=1}^{N} f(x_{i}) \\Delta x\n\\end{equation}\\]"
  },
  {
    "objectID": "lectures/lecture08/2_integration.html#trapezoid-method",
    "href": "lectures/lecture08/2_integration.html#trapezoid-method",
    "title": "Numerical Integration",
    "section": "Trapezoid Method",
    "text": "Trapezoid Method\n\n\n\nTrapezoid Method Illustration\n\n\nThe Trapezoid method improves upon the Box method by approximating the function with linear segments between points.\n\\[\\begin{equation}\n\\int_{a}^{b} f(x) dx \\approx \\sum_{i=1}^{N} \\frac{f(x_i) + f(x_{i-1})}{2} \\Delta x\n\\end{equation}\\]"
  },
  {
    "objectID": "lectures/lecture08/2_integration.html#simpsons-method",
    "href": "lectures/lecture08/2_integration.html#simpsons-method",
    "title": "Numerical Integration",
    "section": "Simpson‚Äôs Method",
    "text": "Simpson‚Äôs Method\n\n\n\nSimpson‚Äôs Method Illustration\n\n\nSimpson‚Äôs method provides higher accuracy by approximating the function with parabolic segments.\n\\[\\begin{equation}\n\\int_{a}^{b} f(x) dx \\approx \\frac{\\Delta x}{3} \\sum_{i=1}^{(N-1)/2} \\left(f(x_{i-1}) + 4f(x_i) + f(x_{i+1})\\right)\n\\end{equation}\\]\n\n\n\n\n\n\n\n\n\n\n\n\nSimpson‚Äôs Rule for Numerical Integration\n\n\n\n\n\nSimpson‚Äôs Rule is a method for numerical integration that approximates the definite integral of a function by using quadratic polynomials.\n\nFor an integral \\(\\int_a^b f(x)dx\\), Simpson‚Äôs Rule fits a quadratic function through three points:\n\n\\(f(a)\\)\n\\(f(\\frac{a+b}{2})\\)\n\\(f(b)\\)\n\nLet‚Äôs define:\n\n\\(h = \\frac{b-a}{2}\\)\n\\(x_0 = a\\)\n\\(x_1 = \\frac{a+b}{2}\\)\n\\(x_2 = b\\)\n\nThe quadratic approximation has the form: \\[P(x) = Ax^2 + Bx + C\\]\nThis polynomial must satisfy: \\[f(x_0) = Ax_0^2 + Bx_0 + C\\] \\[f(x_1) = Ax_1^2 + Bx_1 + C\\] \\[f(x_2) = Ax_2^2 + Bx_2 + C\\]\nUsing Lagrange interpolation: \\[P(x) = f(x_0)L_0(x) + f(x_1)L_1(x) + f(x_2)L_2(x)\\]\nwhere \\(L_0\\), \\(L_1\\), \\(L_2\\) are the Lagrange basis functions.\n\n\nFinal Formula\nThe integration of this polynomial leads to Simpson‚Äôs Rule:\n\\[\\int_a^b f(x)dx \\approx \\frac{h}{3}[f(a) + 4f(\\frac{a+b}{2}) + f(b)]\\]\n\n\nError Term\nThe error in Simpson‚Äôs Rule is proportional to:\n\\[-\\frac{h^5}{90}f^{(4)}(\\xi)\\]\nfor some \\(\\xi \\in [a,b]\\)\n\n\nComposite Simpson‚Äôs Rule\nFor better accuracy, we can divide the interval into \\(n\\) subintervals (where \\(n\\) is even):\n\\[\\int_a^b f(x)dx \\approx \\frac{h}{3}[f(x_0) + 4\\sum_{i=1}^{n/2}f(x_{2i-1}) + 2\\sum_{i=1}^{n/2-1}f(x_{2i}) + f(x_n)]\\]\nwhere \\(h = \\frac{b-a}{n}\\)\nThe method is particularly effective for integrating functions that can be well-approximated by quadratic polynomials over small intervals."
  },
  {
    "objectID": "lectures/lecture08/2_integration.html#comparison-of-methods",
    "href": "lectures/lecture08/2_integration.html#comparison-of-methods",
    "title": "Numerical Integration",
    "section": "Comparison of Methods",
    "text": "Comparison of Methods\nLet‚Äôs compare the accuracy of all three methods:"
  },
  {
    "objectID": "lectures/lecture08/2_integration.html#error-analysis",
    "href": "lectures/lecture08/2_integration.html#error-analysis",
    "title": "Numerical Integration",
    "section": "Error Analysis",
    "text": "Error Analysis\nThe three methods have different convergence rates:\n\nBox Method: Error ‚àù \\(\\Delta x\\) (linear convergence)\nTrapezoid Method: Error ‚àù \\(\\Delta x^2\\) (quadratic convergence)\nSimpson‚Äôs Method: Error ‚àù \\(\\Delta x^4\\) (fourth-order convergence)\n\nThis explains why Simpson‚Äôs method typically achieves higher accuracy with fewer points. For example, doubling the number of points in Simpson‚Äôs method reduces the error by a factor of 16"
  },
  {
    "objectID": "lectures/lecture06/1_curve_fitting.html",
    "href": "lectures/lecture06/1_curve_fitting.html",
    "title": "Curve fitting",
    "section": "",
    "text": "Let‚Äôs take a break from physics-related topics and explore another crucial area: curve fitting. We‚Äôll focus on demonstrating how to apply the least-squares method to fit a quadratic function with three parameters to experimental data. It‚Äôs worth noting that this approach can be applied to more complex functions or even simpler linear models.\nBefore diving into the fitting process, it‚Äôs essential to consider how to best estimate your model parameters. In some cases, you may be able to derive explicit estimators for the parameters, which can simplify the fitting procedure. Therefore, it‚Äôs advisable to carefully consider your approach before beginning the actual fitting process.\nFor those who want to delve deeper into this subject, you might find it interesting to explore concepts like maximum likelihood estimation. This method offers an alternative approach to parameter estimation and can provide valuable insights in certain scenarios."
  },
  {
    "objectID": "lectures/lecture06/1_curve_fitting.html#idea",
    "href": "lectures/lecture06/1_curve_fitting.html#idea",
    "title": "Curve fitting",
    "section": "Idea",
    "text": "Idea\nIn experimental physics, we often collect data points to understand the underlying physical phenomena. This process involves fitting a mathematical model to the experimental data.\nThe data typically comes as a series of paired points:\n\n\n\nx-data\ny-data\n\n\n\n\n\\(x_{1}\\)\n\\(y_{1}\\)\n\n\n\\(x_{2}\\)\n\\(y_{2}\\)\n\n\n‚Ä¶\n‚Ä¶\n\n\n\\(x_{N}\\)\n\\(y_{N}\\)\n\n\n\nEach point \\(\\{x_i, y_i\\}\\) may represent the result of multiple independent measurements. For instance, \\(y_1\\) could be the mean of several measurements \\(y_{1,j}\\):\n\\[y_1 = \\frac{1}{N}\\sum_{j=1}^N y_{1,j}\\]\nWhen these measurements have an uncertainty \\(\\sigma\\) for individual readings, the sum of all measurements has a variance of \\(N\\sigma^2\\) and a standard deviation of \\(\\sqrt{N}\\sigma\\). Consequently, the mean value has an associated error (standard deviation) known as the Standard Error of the Mean (SEOM):\n\\[\\sigma_{SEOM} = \\frac{\\sigma}{\\sqrt{N}}\\]\nThis SEOM is crucial in physics measurements.\nIt‚Äôs also important to note the definition of variance:\n\\[\\sigma_1^2 = \\frac{1}{N} \\sum_{j=1}^N (y_{1,j} - y_1)^2\\]\nThis statistical framework forms the basis for analyzing experimental data and fitting mathematical models to understand the underlying physics."
  },
  {
    "objectID": "lectures/lecture06/1_curve_fitting.html#least-squares",
    "href": "lectures/lecture06/1_curve_fitting.html#least-squares",
    "title": "Curve fitting",
    "section": "Least squares",
    "text": "Least squares\nIn experimental physics, we often collect data points to understand the underlying physical phenomena. To make sense of this data, we fit a mathematical model to it. One common method for fitting data is the least squares method.\n\nWhy use least squares fitting?\nThe goal of least squares fitting is to find the set of parameters for our model that best describes the data. This is done by minimizing the differences (or residuals) between the observed data points and the model‚Äôs predictions.\n\n\nGaussian uncertainty and probability\nWhen we take measurements, there is always some uncertainty. Often, this uncertainty can be modeled using a Gaussian (normal) distribution. This distribution is characterized by its mean (average value) and standard deviation (a measure of the spread of the data).\nIf we describe our data with a model function, which delivers a function value \\(f(x_{i},a)\\) for a set of parameters \\(a\\) at the position \\(x_{i}\\), the Gaussian uncertainty dictates a probability of finding a data value \\(y_{i}\\):\n\\[\\begin{equation}\np_{y_{i}}=\\frac{1}{\\sqrt{2\\pi}\\sigma_{i}}\\exp\\left(-\\frac{(y_{i}-f(x_{i},a))^2}{2\\sigma_{i}^2}\\right)\n\\end{equation}\\]\nHere, \\(\\sigma_{i}\\) represents the uncertainty in the measurement \\(y_{i}\\).\n\n\nCombining probabilities for multiple data points\nTo understand how well our model fits all the data points, we need to consider the combined probability of observing all the data points. This is done by multiplying the individual probabilities:\n\\[\\begin{equation}\np(y_{1},\\ldots,y_{N})=\\prod_{i=1}^{N}\\frac{1}{\\sqrt{2\\pi}\\sigma_{i}}\\exp\\left(-\\frac{(y_{i}-f(x_{i},a))^2}{2\\sigma_{i}^2}\\right)\n\\end{equation}\\]\n\n\nMaximizing the joint probability\nThe best fit of the model to the data is achieved when this joint probability is maximized. To simplify the calculations, we take the logarithm of the joint probability:\n\\[\\begin{equation}\n\\ln(p(y_{1},\\ldots,y_{N}))=-\\frac{1}{2}\\sum_{i=1}^{N}\\left( \\frac{y_{i}-f(x_{i},a)}{\\sigma_{i}}\\right)^2 - \\sum_{i=1}^{N}\\ln\\left( \\sigma_{i}\\sqrt{2\\pi}\\right)\n\\end{equation}\\]\nThe first term on the right side (except the factor 1/2) is the least squared deviation, also known as \\(\\chi^{2}\\):\n\\[\\begin{equation}\n\\chi^{2} =\\sum_{i=1}^{N}\\left( \\frac{y_{i}-f(x_{i},a)}{\\sigma_{i}}\\right)^2\n\\end{equation}\\]\nThe second term is just a constant value given by the uncertainties of our experimental data."
  },
  {
    "objectID": "lectures/lecture06/1_curve_fitting.html#data",
    "href": "lectures/lecture06/1_curve_fitting.html#data",
    "title": "Curve fitting",
    "section": "Data",
    "text": "Data\nLet‚Äôs have a look at the meaning of this equation. Let‚Äôs assume we measure the trajectory of a ball that has been thrown at an angle \\(\\alpha\\) with an initial velocity \\(v_{0}\\). We have collected data points by measuring the height of the ball above the ground at equally spaced distances from the throwing person.\n\n\n\n\n    \n    \n    \n        \n        \n        \n        \n        \n        \n        \n        \n    \n    \n   \n    \n      \n  \n        \n    \n    \n  \n        \n    \n    \n  \n        \n    \n      \n  \n        \n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n        \n    \n\n\n    Loading ITables v2.5.2 from the internet...\n    (need help?)\n    \n\n\n\n\nThe table above shows the measured data points \\(y_{i}\\) at the position \\(x_{i}\\) with the associated uncertainties \\(\\sigma_{i}\\).\nWe can plot the data and expect, of course, a parabola. Therefore, we model our experimental data with a parabola like\n\\[\\begin{equation}\ny = ax^2 + bx + c\n\\end{equation}\\]\nwhere the parameter \\(a\\) must be negative since the parabola is inverted.\nI have created an interactive plot with an interact widget, as this allows you to play around with the parameters. The value of \\(\\chi^2\\) is also included in the legend, so you can get an impression of how good your fit of the data is.\n\nviewof aSlider = Inputs.range([-4, 0], { label: \"a\", step: 0.01, value: -1.7 });\nviewof bSlider = Inputs.range([-2, 2], { label: \"b\", step: 0.01, value: 1.3 });\nviewof cSlider = Inputs.range([-2, 2], { label: \"c\", step: 0.01, value: 1.0 });\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfiltered = transpose(data);\n// Create the plot\n\nxValues = Array.from({ length: 100 }, (_, i) =&gt; i / 100);\nparabolaData = xValues.map(x =&gt; ({ x, y: parabola(x, aSlider, bSlider, cSlider) }));\n\n\nparabola = (x, a, b, c) =&gt; a * x**2 + b * x + c\n\ncalculateChiSquared = (data, a, b, c) =&gt; {\n  let chisq = 0\n  let x= data.map(d =&gt; d.x)\n  let y= data.map(d =&gt; d.y)\n  let err= data.map(d =&gt; d.error)\n  for (let i = 0; i &lt; x.length; i++) {\n    let y_model = parabola(x[i], a, b, c)\n    chisq += ((y[i] - y_model) / err[i])**2\n  }\n  return chisq\n}\n\nchisq = calculateChiSquared(filtered, aSlider, bSlider, cSlider)\n\nPlot.plot({\n  marks: [\n    Plot.dot(filtered, { x: \"x\", y: \"y\" }),\n    Plot.ruleY(filtered, { x: \"x\", y1: d =&gt; d.y - d.error, y2: d =&gt; d.y + d.error }),\n    Plot.line(parabolaData, { x: \"x\", y: \"y\" }),\n    Plot.text([{ x: 0.8, y: 1.5, label: `œá¬≤: ${chisq.toFixed(2)}` }], {\n          x: \"x\",\n          y: \"y\",\n          text: \"label\",\n          dy: -10, // Adjust vertical position if needed\n          fill: \"black\", // Set text color\n          fontSize: 16\n        }),\n    Plot.frame()\n  ],\n  x: {\n    label: \"X Axis\",\n    labelAnchor: \"center\",\n    labelOffset: 35,\n    grid: true,\n    tickFormat: \".2f\", // Format ticks to 2 decimal places\n    domain: [0, 1]\n  },\n  y: {\n    label: \"Y Axis\",\n    grid: true,\n    tickFormat: \".2f\", // Format ticks to 2 decimal places\n    labelAnchor: \"center\",  // Center the label on its axis\n    labelAngle: -90,\n    labelOffset: 60,\n    domain: [0, 2],\n  },\n  width: 400,\n  height: 400,\n  marginLeft: 100,\n  marginBottom: 40,\n  style: {\n    fontSize: \"14px\",          // This sets the base font size\n    \"axis.label\": {\n      fontSize: \"18px\",        // This sets the font size for axis labels\n      fontWeight: \"bold\"       // Optionally make it bold\n    },\n    \"axis.tick\": {\n      fontSize: \"14px\"         // This sets the font size for tick labels\n    }\n  },\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe have that troubling point at the right edge with a large uncertainty. However, since the value of \\(\\chi^2\\) divides the deviation by the uncertainty \\(\\sigma_{i}\\), the weight for this point overall in the \\(\\chi^2\\) is smaller than for the other points.\n\\[\\begin{equation}\n\\chi^{2}=\\sum_{i=1}^{N}\\left( \\frac{y_{i}-f(x_{i},a)}{\\sigma_{i}}\\right)^2\n\\end{equation}\\]\nYou may simply check the effect by changing the uncertainty of the last data points in the error array."
  },
  {
    "objectID": "lectures/lecture06/1_curve_fitting.html#least-square-fitting",
    "href": "lectures/lecture06/1_curve_fitting.html#least-square-fitting",
    "title": "Curve fitting",
    "section": "Least square fitting",
    "text": "Least square fitting\nTo find the best fit of the model to the experimental data, we use the least squares method. This method minimizes the sum of the squared differences between the observed data points and the model‚Äôs predictions.\nMathematically, we achieve this by minimizing the least squares, i.e., finding the parameters \\(a\\) that minimize the following expression:\n\\[\\begin{equation}\n\\frac{d\\chi^{2}}{da}=\\sum_{i=1}^{N}\\frac{1}{\\sigma_{i}^2}\\frac{df(x_{i},a)}{da}[y_{i}-f(x_{i},a)]=0\n\\end{equation}\\]\nThis kind of least squares minimization is done by fitting software using different types of algorithms.\n\nFitting with SciPy\nLet‚Äôs do some fitting using the SciPy library, which is a powerful tool for scientific computing in Python. We will use the curve_fit method from the optimize sub-module of SciPy.\nFirst, we need to define the model function we would like to fit to the data. In this case, we will use our parabola function:\n\n\n\n\n\n\nNext, we need to provide initial guesses for the parameters. These initial guesses help the fitting algorithm start the search for the optimal parameters:\n\n\n\n\n\n\nWe then call the curve_fit function to perform the fitting:\n\n\n\n\n\n\n\n\n\n\n\n\ncurve_fit Function\n\n\n\n\n\nThe curve_fit function is used to fit a model function to data. It finds the optimal parameters for the model function that minimize the sum of the squared residuals between the observed data and the model‚Äôs predictions.\n\nParameters\n\nparabola:\n\nThis is the model function that you want to fit to the data. In this case, parabola is a function that represents a quadratic equation of the form ( y = ax^2 + bx + c ).\n\nx_data:\n\nThis is the array of independent variable data points (the x-values).\n\ny_data:\n\nThis is the array of dependent variable data points (the y-values).\n\nsigma=err:\n\nThis parameter specifies the uncertainties (standard deviations) of the y-data points. The err array contains the uncertainties for each y-data point. These uncertainties are used to weight the residuals in the least squares optimization.\n\np0=init_guess:\n\nThis parameter provides the initial guesses for the parameters of the model function. The init_guess array contains the initial guesses for the parameters ( a ), ( b ), and ( c ). Providing good initial guesses can help the optimization algorithm converge more quickly and accurately.\n\nabsolute_sigma=True:\n\nThis parameter indicates whether the provided sigma values are absolute uncertainties. If absolute_sigma is set to True, the sigma values are treated as absolute uncertainties. If absolute_sigma is set to False, the sigma values are treated as relative uncertainties, and the covariance matrix of the parameters will be scaled accordingly.\n\n\n\n\nReturn Value\nThe curve_fit function returns two values:\n\npopt:\n\nAn array containing the optimal values for the parameters of the model function that minimize the sum of the squared residuals.\n\npcov:\n\nThe covariance matrix of the optimal parameters. The diagonal elements of this matrix provide the variances of the parameter estimates, and the off-diagonal elements provide the covariances between the parameter estimates.\n\n\n\n\n\n\nThe fit variable contains the results of the fitting process. It is composed of various results, which we can split into the fitted parameters and the covariance matrix:\n\n\n\n\n\n\nThe ans variable contains the fitted parameters fit_a, fit_b, and fit_c, while the cov variable contains the covariance matrix. Let‚Äôs have a look at the fit and the \\(\\chi^{2}\\) value first:\n\n\n\n\n\n\nWe can then plot the fitted curve along with the original data points and the \\(\\chi^{2}\\) value:\n\n\n\n\n\n\n\n\n\\(\\chi\\)-squared value\nThe value of \\(\\chi^2\\) gives you a measure of the quality of the fit. We can judge the quality by calculating the expectation value of \\(\\chi^2\\):\n\\[\\begin{equation}\n\\langle \\chi^{2}\\rangle =\\sum_{i=1}^{N} \\frac{\\langle (y_{i}-f(x_{i},a) )^2\\rangle }{\\sigma_{i}^2}=\\sum_{i=1}^{N} \\frac{\\sigma_{i}^2}{\\sigma_{i}^2}=N\n\\end{equation}\\]\nSo, the mean of the least squared deviation increases with the number of data points. Therefore:\n\n\\(\\chi^{2} \\gg N\\) means that the fit is bad.\n\\(\\chi^{2} &lt; N\\) means that the uncertainties are wrong.\n\nThe first case may occur if you don‚Äôt have a good fit to your data, for example, if you are using the wrong model. The second case typically occurs if you don‚Äôt have accurate estimates of the uncertainties and you assume all uncertainties to be constant.\nIt is really important to have a good estimate of the uncertainties and to include them in your fit. If you include the uncertainties in your fit, it is called a weighted fit. If you don‚Äôt include the uncertainties (meaning you keep them constant), it is called an unweighted fit.\nFor our fit above, we obtain a \\(\\chi^{2}\\) which is on the order of \\(N=10\\), which tells you that I have created the data with reasonable accuracy.\n\n\nResiduals\nAnother way to assess the quality of the fit is by looking at the residuals. Residuals are defined as the deviation of the data from the model for the best fit:\n\\[\\begin{equation}\nr_i = y_i - f(x_{i},a)\n\\end{equation}\\]\nThe residuals can also be expressed as the percentage of the deviation of the data from the fit:\n\\[\\begin{equation}\nr_i = 100 \\left( \\frac{y_i - f(x_{i},a)}{y_i} \\right)\n\\end{equation}\\]\n\n\nImportance of Residuals\nResiduals are important because they provide insight into how well the model fits the data. If the residuals show only statistical fluctuations around zero, then the fit and likely also the model are good. However, if there are systematic patterns in the residuals, it may indicate that the model is not adequately capturing the underlying relationship in the data.\n\n\nVisualizing Residuals\nLet‚Äôs visualize the residuals to better understand their distribution. We will plot the residuals as a function of the independent variable \\(x\\).\n\n\n\n\n\n\n\n\n\n\n\n\nCommon Patterns in Residuals\n\n\n\n\n\nRandom Fluctuations Around Zero:\n\nIf the residuals are randomly scattered around zero, it suggests that the model is a good fit for the data.\n\nSystematic Patterns:\n\nIf the residuals show a systematic pattern (e.g., a trend or periodicity), it may indicate that the model is not capturing some aspect of the data. This could suggest the need for a more complex model.\n\nIncreasing or Decreasing Trends:\n\nIf the residuals increase or decrease with \\(x\\), it may indicate heteroscedasticity (non-constant variance) or that a different functional form is needed."
  },
  {
    "objectID": "lectures/lecture06/1_curve_fitting.html#covariance-matrix",
    "href": "lectures/lecture06/1_curve_fitting.html#covariance-matrix",
    "title": "Curve fitting",
    "section": "Covariance Matrix",
    "text": "Covariance Matrix\nIn the previous sections, we discussed how to fit a model to experimental data and assess the quality of the fit using residuals. Now, let‚Äôs take a closer look at the uncertainties in the fit parameters and how they are related to each other. This is where the covariance matrix comes into play.\n\nPurpose of the Covariance Matrix\nThe covariance matrix provides important information about the uncertainties in the fit parameters and how these uncertainties are related to each other. It helps us understand the precision of the parameter estimates and whether the parameters are independent or correlated.\n\n\nUnderstanding Covariance\nCovariance is a measure of how much two random variables change together. If the covariance between two variables is positive, it means that they tend to increase or decrease together. If the covariance is negative, it means that one variable tends to increase when the other decreases. If the covariance is zero, it means that the variables are independent.\n\n\nCovariance Matrix in Curve Fitting\nWhen we fit a model to data, we obtain estimates for the parameters of the model. These estimates have uncertainties due to the measurement errors in the data. The covariance matrix quantifies these uncertainties and the relationships between them.\nFor a model with three parameters \\((a, b, c)\\), the covariance matrix is a \\(3 \\times 3\\) matrix that looks like this:\n\\[\\begin{equation}\n{\\rm cov}(p_{i}, p_{j}) =\n\\begin{bmatrix}\n\\sigma_{aa}^{2} & \\sigma_{ab}^{2} & \\sigma_{ac}^{2} \\\\\n\\sigma_{ba}^{2} & \\sigma_{bb}^{2} & \\sigma_{bc}^{2} \\\\\n\\sigma_{ca}^{2} & \\sigma_{cb}^{2} & \\sigma_{cc}^{2}\n\\end{bmatrix}\n\\end{equation}\\]\nThe diagonal elements provide the variances (squared uncertainties) of the fit parameters, while the off-diagonal elements describe the covariances between the parameters.\n\n\nExample\nLet‚Äôs calculate the covariance matrix for our fitted model and interpret the results.\n\n\n\n\n\n\n\n\nInterpreting the Covariance Matrix\nThe covariance matrix provides valuable information about the uncertainties in the fit parameters:\n\nDiagonal Elements: The diagonal elements represent the variances of the parameters. The square root of these values gives the standard deviations (uncertainties) of the parameters.\nOff-Diagonal Elements: The off-diagonal elements represent the covariances between the parameters. If these values are large, it indicates that the parameters are correlated.\n\n\n\nGenerating Synthetic Data\nTo better understand the covariance matrix, let‚Äôs generate synthetic data and fit the model to each dataset. This will help us visualize the uncertainties in the parameters.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCorrelation Matrix\nTo better understand the relationships between the parameters, we can normalize the covariance matrix to obtain the correlation matrix. The correlation matrix has values between -1 and 1, where 1 indicates perfect positive correlation, -1 indicates perfect negative correlation, and 0 indicates no correlation.\n\n\n\n\n\n\n\n\nVisualizing the Covariance and Correlation\nLet‚Äôs visualize the covariance and correlation between the parameters using scatter plots.\n\n\n\n\n\n\nBy examining the covariance and correlation matrices, we can gain a deeper understanding of the uncertainties in the fit parameters and how they are related to each other.\n\n\nImproving the Model\nIf we find that the parameters are highly correlated, we might want to find a better model containing more independent parameters. For example, we can write down a different model:\n\\[\\begin{equation}\ny = a(x - b)^2 + c\n\\end{equation}\\]\nThis model also contains three parameters, but the parameter \\(b\\) directly refers to the maximum of our parabola, while the parameter \\(a\\) denotes its curvature.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe see from the covariance matrix that the new model has a smaller correlation of the parameters with each other.\n\n\n\n\n\n\nThis is also expressed by our correlation matrix.\n\n\n\n\n\n\nBy examining the covariance and correlation matrices, we can gain valuable insights into the uncertainties in the fit parameters and how to improve our model."
  },
  {
    "objectID": "lectures/lecture06/1_input_output.html",
    "href": "lectures/lecture06/1_input_output.html",
    "title": "Input and output",
    "section": "",
    "text": "To try out all of the functions of todays notebook, we will need to use the embedded JupyterLite notebook. To use the notebook, click ob File -&gt; Open from URL and paste the following link into the input field:\nhttps://raw.githubusercontent.com/fcichos/EMPP24/refs/heads/main/seminars/1_input_output.ipynb\nTo download the data files, click ob File -&gt; Open from URL and paste the following links into the input field:\nhttps://raw.githubusercontent.com/fcichos/EMPP24/refs/heads/main/seminars/MyData.txt\nhttps://raw.githubusercontent.com/fcichos/EMPP24/refs/heads/main/seminars/2018-04-11_sds011_sensor_12253.csv\nhttps://raw.githubusercontent.com/fcichos/EMPP24/refs/heads/main/seminars/2018-04-12_sds011_sensor_12253.csv\nYou should then have 3 data files and one notebook. You can then go into fullscreen mode.\nFull Screen"
  },
  {
    "objectID": "lectures/lecture01/01-plotting-basics.html",
    "href": "lectures/lecture01/01-plotting-basics.html",
    "title": "Plotting Basics",
    "section": "",
    "text": "As physicists, we need to visualize our data and calculations. A good plot can:\n\nReveal patterns and relationships\nMake predictions visible\nCommunicate results effectively\nHelp us understand complex phenomena\n\nPython‚Äôs Matplotlib library is the standard tool for creating scientific plots.",
    "crumbs": [
      "üöÄ Week 1: Your First Physics Code",
      "Quick Win: Plotting Your First Graph"
    ]
  },
  {
    "objectID": "lectures/lecture01/01-plotting-basics.html#why-plotting-matters-in-physics",
    "href": "lectures/lecture01/01-plotting-basics.html#why-plotting-matters-in-physics",
    "title": "Plotting Basics",
    "section": "",
    "text": "As physicists, we need to visualize our data and calculations. A good plot can:\n\nReveal patterns and relationships\nMake predictions visible\nCommunicate results effectively\nHelp us understand complex phenomena\n\nPython‚Äôs Matplotlib library is the standard tool for creating scientific plots.",
    "crumbs": [
      "üöÄ Week 1: Your First Physics Code",
      "Quick Win: Plotting Your First Graph"
    ]
  },
  {
    "objectID": "lectures/lecture01/01-plotting-basics.html#getting-started-with-matplotlib",
    "href": "lectures/lecture01/01-plotting-basics.html#getting-started-with-matplotlib",
    "title": "Plotting Basics",
    "section": "Getting Started with Matplotlib",
    "text": "Getting Started with Matplotlib\nMatplotlib is not built into Python - we need to import it:\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n\n\n\n\n\nConvention\n\n\n\nWe import matplotlib.pyplot as plt - this is the standard shorthand used everywhere in Python!",
    "crumbs": [
      "üöÄ Week 1: Your First Physics Code",
      "Quick Win: Plotting Your First Graph"
    ]
  },
  {
    "objectID": "lectures/lecture01/01-plotting-basics.html#your-first-plot",
    "href": "lectures/lecture01/01-plotting-basics.html#your-first-plot",
    "title": "Plotting Basics",
    "section": "Your First Plot",
    "text": "Your First Plot\nThe most basic plotting command is:\nplt.plot(x, y)\nplt.show()\nLet‚Äôs plot a sine wave:\n\n\n\n\n\n\n\n\n\n\n\n\nWhat This Does\n\n\n\n\nnp.linspace(0, 4*np.pi, 100): Creates 100 evenly-spaced points from 0 to 4œÄ\nplt.figure(figsize=(6, 4)): Creates a new figure that‚Äôs 6√ó4 inches\nplt.plot(x, y): Plots y versus x\nplt.show(): Displays the plot",
    "crumbs": [
      "üöÄ Week 1: Your First Physics Code",
      "Quick Win: Plotting Your First Graph"
    ]
  },
  {
    "objectID": "lectures/lecture01/01-plotting-basics.html#adding-labels",
    "href": "lectures/lecture01/01-plotting-basics.html#adding-labels",
    "title": "Plotting Basics",
    "section": "Adding Labels",
    "text": "Adding Labels\nA plot without labels is useless! Always add: - x-axis label: What‚Äôs on the horizontal axis? - y-axis label: What‚Äôs on the vertical axis? - Title: What does this plot show?\n\n\n\n\n\n\n\n\n\n\n\n\nUsing LaTeX in Labels\n\n\n\nYou can use mathematical notation in labels with LaTeX syntax:\nplt.xlabel(r'$\\theta$ (radians)')  # Greek letters\nplt.ylabel(r'$\\sin(\\theta)$')      # Math expressions\nThe r before the string means ‚Äúraw string‚Äù - it treats backslashes literally.",
    "crumbs": [
      "üöÄ Week 1: Your First Physics Code",
      "Quick Win: Plotting Your First Graph"
    ]
  },
  {
    "objectID": "lectures/lecture01/01-plotting-basics.html#physics-example-projectile-motion",
    "href": "lectures/lecture01/01-plotting-basics.html#physics-example-projectile-motion",
    "title": "Plotting Basics",
    "section": "Physics Example: Projectile Motion",
    "text": "Physics Example: Projectile Motion\nLet‚Äôs plot something more physics-y! A ball launched at 45¬∞:\n\n\n\n\n\n\n\n\n\n\n\n\nWhat‚Äôs New?\n\n\n\n\nplt.grid(True, alpha=0.3): Adds a grid (alpha=0.3 makes it semi-transparent)\nPhysics equations turned into beautiful visualization!",
    "crumbs": [
      "üöÄ Week 1: Your First Physics Code",
      "Quick Win: Plotting Your First Graph"
    ]
  },
  {
    "objectID": "lectures/lecture01/01-plotting-basics.html#customizing-your-plot",
    "href": "lectures/lecture01/01-plotting-basics.html#customizing-your-plot",
    "title": "Plotting Basics",
    "section": "Customizing Your Plot",
    "text": "Customizing Your Plot\nYou can control colors, line styles, and markers:\n\nColor and Line Style Options\nplt.plot(x, y, 'r-')   # red solid line\nplt.plot(x, y, 'b--')  # blue dashed line\nplt.plot(x, y, 'go')   # green circles\nplt.plot(x, y, 'k:')   # black dotted line\nColor codes: r (red), g (green), b (blue), k (black), c (cyan), m (magenta), y (yellow)\nLine styles: - (solid), -- (dashed), : (dotted), -. (dash-dot)\nMarkers: o (circle), s (square), ^ (triangle), * (star), + (plus)\n\n\nExample",
    "crumbs": [
      "üöÄ Week 1: Your First Physics Code",
      "Quick Win: Plotting Your First Graph"
    ]
  },
  {
    "objectID": "lectures/lecture01/01-plotting-basics.html#adding-a-legend",
    "href": "lectures/lecture01/01-plotting-basics.html#adding-a-legend",
    "title": "Plotting Basics",
    "section": "Adding a Legend",
    "text": "Adding a Legend\nWhen you have multiple lines, use a legend to identify them:\n\n\n\n\n\n\n\n\n\n\n\n\nLegend Locations\n\n\n\nCommon locations: 'upper right', 'upper left', 'lower right', 'lower left', 'center', 'best' (automatic)",
    "crumbs": [
      "üöÄ Week 1: Your First Physics Code",
      "Quick Win: Plotting Your First Graph"
    ]
  },
  {
    "objectID": "lectures/lecture01/01-plotting-basics.html#physics-example-damped-oscillator",
    "href": "lectures/lecture01/01-plotting-basics.html#physics-example-damped-oscillator",
    "title": "Plotting Basics",
    "section": "Physics Example: Damped Oscillator",
    "text": "Physics Example: Damped Oscillator\nLet‚Äôs visualize different damping regimes:",
    "crumbs": [
      "üöÄ Week 1: Your First Physics Code",
      "Quick Win: Plotting Your First Graph"
    ]
  },
  {
    "objectID": "lectures/lecture01/01-plotting-basics.html#plotting-data-points-not-just-lines",
    "href": "lectures/lecture01/01-plotting-basics.html#plotting-data-points-not-just-lines",
    "title": "Plotting Basics",
    "section": "Plotting Data Points (Not Just Lines)",
    "text": "Plotting Data Points (Not Just Lines)\nSometimes you want to show discrete data points:\n\n\n\n\n\n\n\n\n\n\n\n\nMarkers Without Lines\n\n\n\nUse 'ro' (red circles) to plot only markers without connecting lines. Use 'r-o' to plot both line and markers.",
    "crumbs": [
      "üöÄ Week 1: Your First Physics Code",
      "Quick Win: Plotting Your First Graph"
    ]
  },
  {
    "objectID": "lectures/lecture01/01-plotting-basics.html#saving-your-plots",
    "href": "lectures/lecture01/01-plotting-basics.html#saving-your-plots",
    "title": "Plotting Basics",
    "section": "Saving Your Plots",
    "text": "Saving Your Plots\nTo save a plot to a file:\nplt.savefig('my_plot.png')        # PNG format\nplt.savefig('my_plot.pdf')        # PDF format (best for papers!)\nplt.savefig('my_plot.png', dpi=300)  # High resolution PNG\nAlways save before plt.show()!\n\n\n\n\n\n\n\n\n\n\n\n\nFile Formats\n\n\n\n\nPDF: Best for inclusion in LaTeX documents and papers\nPNG: Good for presentations and web\nSVG: Vector format, good for editing in Inkscape/Illustrator",
    "crumbs": [
      "üöÄ Week 1: Your First Physics Code",
      "Quick Win: Plotting Your First Graph"
    ]
  },
  {
    "objectID": "lectures/lecture01/01-plotting-basics.html#quick-reference-essential-commands",
    "href": "lectures/lecture01/01-plotting-basics.html#quick-reference-essential-commands",
    "title": "Plotting Basics",
    "section": "Quick Reference: Essential Commands",
    "text": "Quick Reference: Essential Commands\n# Setup\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Create plot\nplt.figure(figsize=(6, 4))\nplt.plot(x, y, 'b-', linewidth=2, label='My Data')\n\n# Labels and title\nplt.xlabel('X Label')\nplt.ylabel('Y Label')\nplt.title('My Plot')\n\n# Extras\nplt.legend(loc='best')\nplt.grid(True, alpha=0.3)\n\n# Save and show\nplt.savefig('filename.pdf')\nplt.show()",
    "crumbs": [
      "üöÄ Week 1: Your First Physics Code",
      "Quick Win: Plotting Your First Graph"
    ]
  },
  {
    "objectID": "lectures/lecture01/01-plotting-basics.html#practice-exercises",
    "href": "lectures/lecture01/01-plotting-basics.html#practice-exercises",
    "title": "Plotting Basics",
    "section": "Practice Exercises üéØ",
    "text": "Practice Exercises üéØ\n\nExercise 1: Free Fall Velocity\nPlot the velocity of a falling object: \\(v = gt\\)\n\nUse time from 0 to 5 seconds\nSet \\(g = 9.81\\) m/s¬≤\nAdd proper labels and title\nUse a red line with linewidth=2\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\ng = 9.81\nt = np.linspace(0, 5, 100)\nv = g * t\n\nplt.figure(figsize=(6, 4))\nplt.plot(t, v, 'r-', linewidth=2)\nplt.xlabel('Time (s)')\nplt.ylabel('Velocity (m/s)')\nplt.title('Free Fall Velocity')\nplt.grid(True, alpha=0.3)\nplt.show()\n\n\n\n\n\nExercise 2: Kinetic Energy vs Velocity\nPlot kinetic energy as a function of velocity for a 1000 kg car.\n\n\\(E_k = \\frac{1}{2}mv^2\\)\nVelocity from 0 to 40 m/s\nAdd labels with proper units\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nm = 1000  # kg\nv = np.linspace(0, 40, 100)\nE_k = 0.5 * m * v**2\n\nplt.figure(figsize=(6, 4))\nplt.plot(v, E_k/1000, 'b-', linewidth=2)  # Convert to kJ\nplt.xlabel('Velocity (m/s)')\nplt.ylabel('Kinetic Energy (kJ)')\nplt.title('Kinetic Energy of a 1000 kg Car')\nplt.grid(True, alpha=0.3)\nplt.show()\n\n\n\n\n\nExercise 3: Compare Trajectories\nPlot projectile trajectories for launch angles of 30¬∞, 45¬∞, and 60¬∞ on the same plot.\n\nUse \\(v_0 = 20\\) m/s for all\nAdd a legend\nUse different colors for each angle\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nv0 = 20.0\ng = 9.81\nangles = [30, 45, 60]\ncolors = ['r', 'b', 'g']\n\nplt.figure(figsize=(8, 5))\n\nfor angle, color in zip(angles, colors):\n    theta = np.radians(angle)\n    t_max = 2 * v0 * np.sin(theta) / g\n    t = np.linspace(0, t_max, 100)\n    x = v0 * np.cos(theta) * t\n    y = v0 * np.sin(theta) * t - 0.5 * g * t**2\n    plt.plot(x, y, color=color, linewidth=2, label=f'{angle}¬∞')\n\nplt.xlabel('Horizontal Distance (m)')\nplt.ylabel('Height (m)')\nplt.title('Projectile Trajectories at Different Angles')\nplt.legend(loc='upper right')\nplt.grid(True, alpha=0.3)\nplt.show()",
    "crumbs": [
      "üöÄ Week 1: Your First Physics Code",
      "Quick Win: Plotting Your First Graph"
    ]
  },
  {
    "objectID": "lectures/lecture01/01-plotting-basics.html#common-mistakes-to-avoid",
    "href": "lectures/lecture01/01-plotting-basics.html#common-mistakes-to-avoid",
    "title": "Plotting Basics",
    "section": "Common Mistakes to Avoid ‚ö†Ô∏è",
    "text": "Common Mistakes to Avoid ‚ö†Ô∏è\n\nForgetting plt.show(): Your plot won‚Äôt display!\nNo labels: Always label axes and add a title\nSaving after showing: Use plt.savefig() BEFORE plt.show()\nToo many points: 100-500 points is usually enough for smooth curves\nUgly default sizes: Always set figsize for better proportions",
    "crumbs": [
      "üöÄ Week 1: Your First Physics Code",
      "Quick Win: Plotting Your First Graph"
    ]
  },
  {
    "objectID": "lectures/lecture01/01-plotting-basics.html#whats-next",
    "href": "lectures/lecture01/01-plotting-basics.html#whats-next",
    "title": "Plotting Basics",
    "section": "What‚Äôs Next?",
    "text": "What‚Äôs Next?\nYou now know the basics of plotting! In later lectures, you‚Äôll learn:\n\nScatter plots and histograms (Lecture 4)\nLogarithmic plots for exponential data\nMultiple subplots in one figure\nContour and 3D plots for multivariable functions\nAnimations for time-dependent phenomena\n\nBut these basics will get you through 90% of your physics plotting needs! üéâ",
    "crumbs": [
      "üöÄ Week 1: Your First Physics Code",
      "Quick Win: Plotting Your First Graph"
    ]
  },
  {
    "objectID": "lectures/lecture01/01-plotting-basics.html#summary",
    "href": "lectures/lecture01/01-plotting-basics.html#summary",
    "title": "Plotting Basics",
    "section": "Summary ‚úÖ",
    "text": "Summary ‚úÖ\nEssential Matplotlib Commands:\nplt.figure(figsize=(6,4))     # Create new figure\nplt.plot(x, y, 'b-')          # Plot data\nplt.xlabel('label')           # X-axis label\nplt.ylabel('label')           # Y-axis label\nplt.title('title')            # Title\nplt.legend()                  # Add legend\nplt.grid(True)                # Add grid\nplt.savefig('file.pdf')       # Save figure\nplt.show()                    # Display plot\nRemember: Good plots communicate clearly. Always include labels, units, and legends!",
    "crumbs": [
      "üöÄ Week 1: Your First Physics Code",
      "Quick Win: Plotting Your First Graph"
    ]
  },
  {
    "objectID": "lectures/lecture01/02-summary01.html",
    "href": "lectures/lecture01/02-summary01.html",
    "title": "Einf√ºhrung in die Modellierung Physikalischer Prozesse",
    "section": "",
    "text": "Click to expand Python Basics Cheat Sheet\n\n\n\n\n\n\n\n\n\nx = 1.0  # Assigns 1.0 to variable x\nmy_variable = \"Hello\"  # Assigns string \"Hello\"\n\n\n\nUse a-z, A-Z, 0-9, and _\nStart with letter or underscore\nCase-sensitive\nAvoid reserved keywords\n\n\n\n\n\n\n\n\nType\nExample\nDescription\n\n\n\n\nint\n5\nWhole numbers\n\n\nfloat\n3.14\nDecimal numbers\n\n\ncomplex\n2 + 3j\nReal + imaginary\n\n\nbool\nTrue\nLogical values\n\n\n\n\n\n\nint_num = int(3.14)    # 3\nfloat_num = float(5)   # 5.0\nstr_num = str(42)      # \"42\"\n\n\n\n\na, b = 10, 3\nsum_result = a + b   # Addition\ndiff_result = a - b  # Subtraction\nprod_result = a * b  # Multiplication\ndiv_result = a / b   # Division (float)\nint_div_result = a // b  # Integer division\nmod_result = a % b   # Modulus\npower_result = a ** b  # Exponentiation\n\n\n\nc = 2 + 4j\nreal_part = c.real     # 2.0\nimag_part = c.imag     # 4.0\nconjugate = c.conjugate()  # 2 - 4j\n\n\n\ntype(variable)  # Returns type\nisinstance(variable, type)  # Checks type\n\n\n\nimport math\n\nsqrt_result = math.sqrt(16)\nlog_result = math.log(100, 10)\nsin_result = math.sin(math.pi/2)"
  },
  {
    "objectID": "lectures/lecture01/02-summary01.html#python-basics-cheat-sheet",
    "href": "lectures/lecture01/02-summary01.html#python-basics-cheat-sheet",
    "title": "Einf√ºhrung in die Modellierung Physikalischer Prozesse",
    "section": "",
    "text": "Click to expand Python Basics Cheat Sheet\n\n\n\n\n\n\n\n\n\nx = 1.0  # Assigns 1.0 to variable x\nmy_variable = \"Hello\"  # Assigns string \"Hello\"\n\n\n\nUse a-z, A-Z, 0-9, and _\nStart with letter or underscore\nCase-sensitive\nAvoid reserved keywords\n\n\n\n\n\n\n\n\nType\nExample\nDescription\n\n\n\n\nint\n5\nWhole numbers\n\n\nfloat\n3.14\nDecimal numbers\n\n\ncomplex\n2 + 3j\nReal + imaginary\n\n\nbool\nTrue\nLogical values\n\n\n\n\n\n\nint_num = int(3.14)    # 3\nfloat_num = float(5)   # 5.0\nstr_num = str(42)      # \"42\"\n\n\n\n\na, b = 10, 3\nsum_result = a + b   # Addition\ndiff_result = a - b  # Subtraction\nprod_result = a * b  # Multiplication\ndiv_result = a / b   # Division (float)\nint_div_result = a // b  # Integer division\nmod_result = a % b   # Modulus\npower_result = a ** b  # Exponentiation\n\n\n\nc = 2 + 4j\nreal_part = c.real     # 2.0\nimag_part = c.imag     # 4.0\nconjugate = c.conjugate()  # 2 - 4j\n\n\n\ntype(variable)  # Returns type\nisinstance(variable, type)  # Checks type\n\n\n\nimport math\n\nsqrt_result = math.sqrt(16)\nlog_result = math.log(100, 10)\nsin_result = math.sin(math.pi/2)"
  },
  {
    "objectID": "lectures/lecture01/02-lecture01.html",
    "href": "lectures/lecture01/02-lecture01.html",
    "title": "Variables & Numbers",
    "section": "",
    "text": "In the previous lessons, you created plots and calculations using code like:\nm = 2.0    # mass\ng = 9.81   # gravity\nh = 10.0   # height\nE_pot = m * g * h\nBut what exactly are m, g, and h? These are variables - containers that store values you can use in calculations.\n\n\n\n\n\n\nWhy Variables Matter in Physics\n\n\n\nIn physics, we work with:\n\nPhysical quantities: mass, velocity, energy, time\nConstants: gravitational acceleration, speed of light, Planck‚Äôs constant\nCalculated results: kinetic energy, momentum, force\n\nVariables let us store these values and use them in equations, just like in mathematical physics notation!",
    "crumbs": [
      "üöÄ Week 1: Your First Physics Code",
      "Variables & Numbers (What You Just Used)"
    ]
  },
  {
    "objectID": "lectures/lecture01/02-lecture01.html#what-you-just-used",
    "href": "lectures/lecture01/02-lecture01.html#what-you-just-used",
    "title": "Variables & Numbers",
    "section": "",
    "text": "In the previous lessons, you created plots and calculations using code like:\nm = 2.0    # mass\ng = 9.81   # gravity\nh = 10.0   # height\nE_pot = m * g * h\nBut what exactly are m, g, and h? These are variables - containers that store values you can use in calculations.\n\n\n\n\n\n\nWhy Variables Matter in Physics\n\n\n\nIn physics, we work with:\n\nPhysical quantities: mass, velocity, energy, time\nConstants: gravitational acceleration, speed of light, Planck‚Äôs constant\nCalculated results: kinetic energy, momentum, force\n\nVariables let us store these values and use them in equations, just like in mathematical physics notation!",
    "crumbs": [
      "üöÄ Week 1: Your First Physics Code",
      "Variables & Numbers (What You Just Used)"
    ]
  },
  {
    "objectID": "lectures/lecture01/02-lecture01.html#variables-in-python",
    "href": "lectures/lecture01/02-lecture01.html#variables-in-python",
    "title": "Variables & Numbers",
    "section": "Variables in Python",
    "text": "Variables in Python\n\nSymbol Names\nIn physics, we use symbols like \\(m\\) for mass, \\(v\\) for velocity, and \\(F\\) for force. Python variable names work similarly, but with some rules.\nVariable names in Python can include alphanumerical characters a-z, A-Z, 0-9, and the special character _. Normal variable names must start with a letter or an underscore. By convention, variable names typically start with a lower-case letter, while Class names start with a capital letter and internal variables start with an underscore.\n\n\n\n\n\n\nPhysics Variable Naming Tips\n\n\n\nGood physics variable names: - m, mass for mass - v, velocity for velocity - E_kin, E_pot for kinetic and potential energy - theta, phi for angles (Greek letters spelled out) - g for gravitational acceleration - c for speed of light\nDescriptive names for clarity: - electron_mass instead of just m when you have multiple masses - initial_velocity, final_velocity instead of v1, v2\n\n\n\n\n\n\n\n\nReserved Keywords\n\n\n\nThere are a number of Python keywords that cannot be used as variable names because Python uses them for other things. These keywords are:\nand, as, assert, break, class, continue, def, del, elif, else, except, exec, finally, for, from, global, if, import, in, is, lambda, not, or, pass, print, raise, return, try, while, with, yield\nImportant for physics: The keyword lambda cannot be used as a variable name (common for wavelength). Use lambda_ or wavelength instead!\n\n\n\n\nVariable Assignment\nThe assignment operator in Python is =. Python is a dynamically typed language, so we do not need to specify the type of a variable when we create one.\nLet‚Äôs assign some physics values:\n\n\n\n\n\n\nImportant: In Python, = means assignment, not equality! - Math: \\(F = ma\\) (force equals mass times acceleration) - Python: F = m * a (calculate m*a and store in F)\nAlthough not explicitly specified, a variable does have a type associated with it (e.g., integer, float, string). The type is derived from the value that was assigned to it. To determine the type of a variable, we can use the type function.\n\n\n\n\n\n\nMost physics calculations use floats (floating-point numbers) because they have decimal points.\nIf we assign a new value to a variable, its type can change.\n\n\n\n\n\n\nIf we try to use a variable that has not yet been defined, we get a NameError error.\n\n\n\n\n\n\nCommon Mistake\n\n\n\nTrying to use a variable before defining it:\nE_kin = 0.5 * m * v**2  # ERROR if m and v aren't defined yet!\nAlways define variables before using them in calculations.",
    "crumbs": [
      "üöÄ Week 1: Your First Physics Code",
      "Variables & Numbers (What You Just Used)"
    ]
  },
  {
    "objectID": "lectures/lecture01/02-lecture01.html#number-types",
    "href": "lectures/lecture01/02-lecture01.html#number-types",
    "title": "Variables & Numbers",
    "section": "Number Types",
    "text": "Number Types\nPython supports various number types, including integers, floating-point numbers, and complex numbers. In physics, you‚Äôll primarily use floats for continuous quantities and integers for counting (like number of particles, timesteps, etc.).\n\n\n\n\n\n\nWhich Type for Physics?\n\n\n\n\nFloats: Mass, energy, position, velocity, time ‚Üí anything with units and decimals\nIntegers: Particle counts, loop iterations, array indices\nComplex: Quantum mechanics, wave functions, AC circuits\n\n\n\n\nComparison of Number Types\n\n\n\n\n\n\n\n\n\nType\nExample\nDescription\nPhysics Use Cases\n\n\n\n\nint\n42\nWhole numbers\nParticle count, quantum number \\(n\\), array index\n\n\nfloat\n3.14159\nDecimal numbers (15-17 digit precision)\nMass, energy, position, velocity, time\n\n\ncomplex\n2 + 3j\nNumbers with real and imaginary parts\nWave functions \\(\\psi\\), AC impedance\n\n\nbool\nTrue / False\nLogical values\nCollision detection, boundary conditions\n\n\n\n\n\n\n\n\n\nExamples for Number Types\n\n\n\n\n\n\nIntegers\nInteger Representation: Integers are whole numbers without a decimal point.\n\n\n\n\n\n\nPhysics Example:\n\n\n\n\n\n\nBinary, Octal, and Hexadecimal: Integers can be represented in different bases:\n\n\n\n\n\n\n\n\nFloating Point Numbers\nFloating Point Representation: Numbers with a decimal point are treated as floating-point values. This is what you‚Äôll use most in physics!\n\n\n\n\n\n\nScientific Notation:\n\n\n\n\n\n\nMaximum Float Value: Python handles large floats, converting them to infinity if they exceed the maximum representable value (~10¬≥‚Å∞‚Å∏).\n\n\n\n\n\n\n\n\n\n\n\n\nFloat Precision in Physics\n\n\n\nFloats have ~15-17 significant digits. This is usually more than enough for physics calculations, but be aware:\ng = 9.81                    # Good enough for most problems\ng_precise = 9.80665         # Standard gravity (more digits)\nFor most undergraduate physics, 3-4 significant figures are sufficient!\n\n\n\n\nComplex Numbers\nComplex Number Representation: Complex numbers have a real and an imaginary part. Essential in quantum mechanics and AC circuit analysis!\n\n\n\n\n\n\n\n\n\n\n\n\nPhysics Applications\n\n\n\nQuantum Mechanics: Wave functions are complex: \\(\\psi = a + bi\\)\nAC Circuits: Impedance \\(Z = R + iX\\) where \\(R\\) is resistance, \\(X\\) is reactance\nWave Propagation: \\(E = E_0 e^{i(kx - \\omega t)}\\)\n\n\n\nAccessors for Complex Numbers:\n\nc.real: Real part of the complex number.\nc.imag: Imaginary part of the complex number.\n\n\n\n\n\n\n\n\nComplex Conjugate: Use the .conjugate() method to get the complex conjugate (important for calculating probabilities in QM: \\(|\\psi|^2 = \\psi \\cdot \\psi^*\\)).\n\n\n\n\n\n\nAbsolute Value (Magnitude):",
    "crumbs": [
      "üöÄ Week 1: Your First Physics Code",
      "Variables & Numbers (What You Just Used)"
    ]
  },
  {
    "objectID": "lectures/lecture12/3_diffusion_equation copy.html",
    "href": "lectures/lecture12/3_diffusion_equation copy.html",
    "title": "Diffusion equation",
    "section": "",
    "text": "diffusionViz = {\n  const width = 800, height = 400;\n  const margin = {top: 30, right: 30, bottom: 30, left: 40};\n\n  // Grid parameters\n  const nx = 20;  // number of spatial points\n  const nt = 10;  // number of time points\n  const dx = 1.0/(nx-1);\n  const dt = 0.1;\n  const D = 0.1;\n\n  // Create SVG\n  const svg = d3.create(\"svg\")\n    .attr(\"width\", width)\n    .attr(\"height\", height);\n\n  // Setup scales\n  const xScale = d3.scaleLinear()\n    .domain([0, 1])\n    .range([margin.left, width - margin.right]);\n\n  const yScale = d3.scaleLinear()\n    .domain([0, (nt-1)*dt])\n    .range([margin.top, height - margin.bottom]);\n\n  // Draw grid\n  for(let i = 0; i &lt; nx; i++) {\n    svg.append(\"line\")\n      .attr(\"x1\", xScale(i*dx))\n      .attr(\"y1\", margin.top)\n      .attr(\"x2\", xScale(i*dx))\n      .attr(\"y2\", height - margin.bottom)\n      .attr(\"stroke\", \"#ddd\")\n      .attr(\"stroke-width\", 1);\n  }\n\n  for(let j = 0; j &lt; nt; j++) {\n    svg.append(\"line\")\n      .attr(\"x1\", margin.left)\n      .attr(\"y1\", yScale(j*dt))\n      .attr(\"x2\", width - margin.right)\n      .attr(\"y2\", yScale(j*dt))\n      .attr(\"stroke\", \"#ddd\")\n      .attr(\"stroke-width\", 1);\n  }\n\n  // Create solution array\n  let u = Array(nt).fill().map(() =&gt; Array(nx).fill(0));\n\n  // Initial condition (Gaussian)\n  u[0] = Array.from({length: nx}, (_, i) =&gt; {\n    const x = i*dx;\n    const sigma = 0.1, mu = 0.5;\n    const exponent = -Math.pow(x-mu, 2)/(2*Math.pow(sigma, 2));\n    return Math.exp(exponent);\n  });\n\n  // Compute solution\n  for(let j = 0; j &lt; nt-1; j++) {\n    for(let i = 1; i &lt; nx-1; i++) {\n      u[j+1][i] = u[j][i] + D*dt/(dx*dx)*(u[j][i+1] - 2*u[j][i] + u[j][i-1]);\n    }\n  }\n\n  // Draw solution points\n  const points = svg.append(\"g\");\n  let currentTime = 0;\n\n  function update() {\n    // Clear previous points\n    points.selectAll(\"*\").remove();\n\n    // Draw all points up to current time\n    for(let j = 0; j &lt;= currentTime; j++) {\n      for(let i = 0; i &lt; nx; i++) {\n        points.append(\"circle\")\n          .attr(\"cx\", xScale(i*dx))\n          .attr(\"cy\", yScale(j*dt))\n          .attr(\"r\", 3)\n          .attr(\"fill\", u[j][i] &gt; 0.1 ? \"steelblue\" : \"#ddd\");\n      }\n    }\n\n    // Highlight current computation points\n    if(currentTime &lt; nt-1) {\n      for(let i = 1; i &lt; nx-1; i++) {\n        // Previous time points (inputs)\n        points.append(\"circle\")\n          .attr(\"cx\", xScale((i-1)*dx))\n          .attr(\"cy\", yScale(currentTime*dt))\n          .attr(\"r\", 5)\n          .attr(\"fill\", \"orange\");\n\n        points.append(\"circle\")\n          .attr(\"cx\", xScale(i*dx))\n          .attr(\"cy\", yScale(currentTime*dt))\n          .attr(\"r\", 5)\n          .attr(\"fill\", \"orange\");\n\n        points.append(\"circle\")\n          .attr(\"cx\", xScale((i+1)*dx))\n          .attr(\"cy\", yScale(currentTime*dt))\n          .attr(\"r\", 5)\n          .attr(\"fill\", \"orange\");\n\n        // Current point being computed\n        points.append(\"circle\")\n          .attr(\"cx\", xScale(i*dx))\n          .attr(\"cy\", yScale((currentTime+1)*dt))\n          .attr(\"r\", 5)\n          .attr(\"fill\", \"red\");\n      }\n    }\n\n    currentTime = (currentTime + 1) % nt;\n  }\n\n  // Add axes\n  svg.append(\"g\")\n    .attr(\"transform\", `translate(0,${height - margin.bottom})`)\n    .call(d3.axisBottom(xScale).ticks(nx-1));\n\n  svg.append(\"g\")\n    .attr(\"transform\", `translate(${margin.left},0)`)\n    .call(d3.axisLeft(yScale).ticks(nt-1));\n\n  // Add labels\n  svg.append(\"text\")\n    .attr(\"x\", width/2)\n    .attr(\"y\", height - 5)\n    .attr(\"text-anchor\", \"middle\")\n    .text(\"Space (x)\");\n\n  svg.append(\"text\")\n    .attr(\"transform\", \"rotate(-90)\")\n    .attr(\"x\", -height/2)\n    .attr(\"y\", 15)\n    .attr(\"text-anchor\", \"middle\")\n    .text(\"Time (t)\");\n\n  d3.interval(update, 1000);\n\n  return svg.node();\n}"
  },
  {
    "objectID": "lectures/lecture12/wave_equation.html",
    "href": "lectures/lecture12/wave_equation.html",
    "title": "Einf√ºhrung in die Modellierung Physikalischer Prozesse",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import sparse\n\n# Parameters\nL = 1.0        # length of string\nT = 2.0        # total time\nc = 1.0        # wave speed\nnx = 100       # spatial points\nnt = 1000      # time points\ndx = L/nx\ndt = T/nt\n\n# Check stability (CFL condition)\nif c*dt/dx &gt; 1:\n    print(\"Warning: Solution may be unstable!\")\n\n# Initialize arrays\nx = np.linspace(0, L, nx)\nt = np.linspace(0, T, nt)\n\n# Initial conditions (for example, a Gaussian pulse)\nu = np.exp(-(x-L/2)**2/0.01)  # initial displacement\nv = np.zeros_like(x)           # initial velocity\n\n# Create matrices for spatial derivatives\ndiagonals = [[1], [-2], [1]]\noffsets = [-1, 0, 1]\nD2 = sparse.diags(diagonals, offsets, shape=(nx-2, nx-2))/(dx**2)\n\n# Time stepping matrices\nI = sparse.eye(nx-2)\nA = I - (c*dt/2)**2 * D2\nB = 2*I + (c*dt)**2 * D2\n\n# Arrays to store solution\nu_history = np.zeros((nt, nx))\nu_history[0, 1:-1] = u[1:-1]\n\n# First time step (using forward difference)\nu_history[1, 1:-1] = u[1:-1] + dt*v[1:-1] + (c*dt)**2/2 * D2.dot(u[1:-1])\n\n# Main time-stepping loop\nfor n in range(1, nt-1):\n    # Solve for next time step\n    rhs = B.dot(u_history[n, 1:-1]) - A.dot(u_history[n-1, 1:-1])\n    u_history[n+1, 1:-1] = sparse.linalg.spsolve(A, rhs)\n\n# Plot results\nplt.figure(figsize=(10, 6))\nplt.imshow(u_history, aspect='auto', extent=[0, L, T, 0])\nplt.colorbar(label='Displacement')\nplt.xlabel('Position')\nplt.ylabel('Time')\nplt.title('Wave Equation Solution')\nplt.show()\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.sparse import diags\nfrom scipy.sparse.linalg import solve\n\ndef crank_nicolson_wave(L=1.0, T=1.0, nx=100, nt=1000, c=1.0):\n    \"\"\"\n    Solve the wave equation using Crank-Nicolson scheme\n    ‚àÇ¬≤u/‚àÇt¬≤ = c¬≤(‚àÇ¬≤u/‚àÇx¬≤)\n\n    Parameters:\n    L: length of spatial domain\n    T: total time\n    nx: number of spatial points\n    nt: number of time points\n    c: wave speed\n    \"\"\"\n\n    # Set up grid\n    dx = L/nx\n    dt = T/nt\n    x = np.linspace(0, L, nx+1)\n    t = np.linspace(0, T, nt+1)\n\n    # Compute stability parameter\n    r = (c*dt/dx)**2\n\n    # Initialize solution array\n    u = np.zeros((nt+1, nx+1))\n\n    # Initial condition (plane wave)\n    k = 2*np.pi/L  # wavenumber\n    u[0,:] = np.sin(k*x)  # Initial displacement\n\n    # Initial velocity\n    u[1,:] = u[0,:] + c*k*np.cos(k*x)*dt\n\n    # Set up matrices for implicit scheme\n    main_diag = 2*(1-r)*np.ones(nx-1)\n    off_diag = r*np.ones(nx-2)\n\n    A = diags([off_diag, main_diag, off_diag], [-1, 0, 1], format='csc')\n\n    # Time stepping\n    for n in range(1, nt):\n        # Right hand side\n        b = 2*u[n,1:-1] - u[n-1,1:-1]\n\n        # Solve system\n        u[n+1,1:-1] = solve(A, b)\n\n        # Apply boundary conditions (periodic)\n        u[n+1,0] = u[n+1,-2]\n        u[n+1,-1] = u[n+1,1]\n\n    return x, t, u\n\n# Run simulation\nL = 1.0  # Length of domain\nT = 1.0  # Total time\nnx = 100  # Number of spatial points\nnt = 1000  # Number of time points\nc = 1.0   # Wave speed\n\nx, t, u = crank_nicolson_wave(L, T, nx, nt, c)\n\n# Plot results at specific times\nplt.figure(figsize=(12, 8))\ntimes = [0, 0.25, 0.5, 0.75, 1.0]  # Times at which to show solution\nfor time in times:\n    time_index = int(time * nt/T)\n    plt.plot(x, u[time_index,:], label=f't = {time:.2f}')\n\nplt.xlabel('Position (z)')\nplt.ylabel('Electric field amplitude (E)')\nplt.title('Electromagnetic Wave Propagation')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n# Optional: Print maximum amplitude at each time for stability check\nprint(\"\\nMaximum amplitudes at selected times:\")\nfor time in times:\n    time_index = int(time * nt/T)\n    print(f\"t = {time:.2f}: {np.max(np.abs(u[time_index,:])):.6f}\")"
  },
  {
    "objectID": "lectures/lecture15/lecture15a.html",
    "href": "lectures/lecture15/lecture15a.html",
    "title": "Repetition Differential Equations",
    "section": "",
    "text": "In today‚Äôs lecture, we will review and expand upon the numerical methods for solving differential equations that you‚Äôve encountered in your mathematics courses. This is particularly important for physics students, as differential equations are the language in which many physical laws are written. Whether we‚Äôre dealing with \\(F = ma\\) in classical mechanics, Maxwell‚Äôs equations in electromagnetism, or Schr√∂dinger‚Äôs equation in quantum mechanics, the ability to solve differential equations is essential.\nWhile analytical solutions are elegant and preferred when available, many real-world physical problems require numerical approaches. We will focus on numerical methods that you can implement yourself, starting with the simplest approaches and building up to more sophisticated techniques.\nTo begin this review, we will first have a look back at the Taylor expansion of a function \\(f(t)\\) around a point \\(t_0\\):\n\\[\nf(t) = f(t_{0}) + (t - t_0) f^{\\prime}(t_0) + \\frac{(t - t_0)^2}{2!} f^{\\prime\\prime}(t_0) + \\frac{(t - t_0)^3}{3!} f^{(3)}(t_0) + \\ldots\n\\]\nwhich tells us that the function \\(f(t)\\) can be approximated by a polynomial of increasing order around the point \\(t_0\\). The first term is the value of the function at \\(t_0\\), the second term is the slope of the function at \\(t_0\\), the third term is the curvature of the function at \\(t_0\\), and so on.\nThe Taylor expansion is the basis for many numerical methods for solving differential equations. The simplest of these methods is the Euler method, which approximates the function by a straight line. We will start with the Euler method and then move on to more advanced techniques like the improved Euler method."
  },
  {
    "objectID": "lectures/lecture15/lecture15a.html#euler-method",
    "href": "lectures/lecture15/lecture15a.html#euler-method",
    "title": "Repetition Differential Equations",
    "section": "Euler Method",
    "text": "Euler Method\nIf we truncate the series at the first term, we get the linear approximation of the function:\n\\[\nf(t) \\approx f(t_{0}) + (t - t_0) f^{\\prime}(t)= f(t_{0}) + \\Delta t f^{\\prime}(t)\n\\]\nThis is the equation of a straight line with slope \\(f^{\\prime}(t)\\) and intercept \\(f(t_0)\\) and we abbreviated \\(\\Delta t = t - t_0\\).\n\nEuler Method for Radioactive Decay\nWe would like to try the method with some simple first order problem, which is the radioactive decay. The decay of a radioactive nucleus is described by the first-order differential equation:\n\\[\n\\frac{dN(t)}{dt} = -k N(t)\n\\]\nwhere \\(k\\) is a decay constant. If \\(N(t)\\) is the number of radioactive nuclei at time \\(t\\), the equation tells us that the rate of decay is proportional to the number of nuclei present and some rate constant \\(k\\). The solution to this differential equation is:\n\\[\nN(t) = N(0) e^{-kt}\n\\]\nwhere \\(N(0)\\) is the number of nuclei at time \\(t=0\\). We therefore need to know some initial condition, which we define as \\(N(0) = 100\\). Comparing to our Taylor expansion, we can see that \\(N=f(t)\\) and the slope of the function is \\(f^{\\prime}(t) = -kN(t)\\). Further we have the value of the function at \\(t_0 = 0\\). We can now use the linear approximation to solve the ODE numerically. Inserting the values into the linear approximation, we get:\n\\[\nN(t + \\Delta t) = N(t) + \\Delta t f^{\\prime}(t)\n\\]\nWe can now implement the Euler method to solve the ODE numerically.\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution Radioactive Decay\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImproved Euler Method\nWhile the above code is what we did fo the simples numerical integration, you can now modify the code inside the euler function to implement any improved Euler method. An improved Euler method (also called Heun‚Äôs method) is based on averaging the slopes at two points. To understand why this works better than the simple Euler method, let‚Äôs look at the Taylor expansion again around \\(t_0\\):\n\\[\nf(t_0 + \\Delta t) \\approx f(t_0) + \\Delta t f'(t_0)\n\\]\nWe can improve this simple formula by taking the avarage of the derivative at \\(t_0\\) and the derivative at the predicted point \\(t_0 + \\Delta t\\):\n\\[\nf(t_0 + \\Delta t) \\approx f(t_0) + \\frac{\\Delta t}{2} (f'(t_0) + f'(t_0 + \\Delta t))\n\\]\nThis effectively now introduces the curvature of the function at \\(t_0\\) into the approximation. We can see this by expanding the improved Euler method in a Taylor series. The first derivative at \\(t_0\\) is \\(f'(t_0)\\), and the derivative at the predicted point \\(f'(t_0 + \\Delta t)\\) can be expanded as \\(f'(t_0) + \\Delta t f''(t_0)\\). When we average these two derivatives and multiply by \\(\\Delta t\\), we get \\(\\Delta t f'(t_0) + \\frac{\\Delta t^2}{2} f''(t_0)\\), which matches the first two terms in the Taylor expansion. This is why the improved Euler method has an error of order \\(O(\\Delta t^2)\\) compared to \\(O(\\Delta t)\\) for the simple Euler method.\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution Radioactive Decay Improved Euler\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis already provides a very good approximation to the analytical solution.\n\n\nHigher order differential equations\nThe above methods can be easily extended to higher order differential equations. For example, the second order differential equation\n\\[\n\\frac{d^2 y}{dt^2} = -k^2 y\n\\]\ncan be converted into two first order differential equations by introducing a new variable \\(v = \\frac{dy}{dt}\\):\n\\[\n\\begin{align}\n\\frac{dy}{dt} &= v \\\\\n\\frac{dv}{dt} &= -k^2 y\n\\end{align}\n\\]\nWe can now use the improved Euler method to solve these two equations simultaneously. The code below shows how to solve the above second order differential equation.\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution Harmonic Oscillator"
  },
  {
    "objectID": "lectures/lecture15/lecture15a.html#solving-coupled-differential-equations",
    "href": "lectures/lecture15/lecture15a.html#solving-coupled-differential-equations",
    "title": "Repetition Differential Equations",
    "section": "Solving Coupled Differential Equations",
    "text": "Solving Coupled Differential Equations\nWe may also solve systems of coupled differential equations such as the Lotka-Volterra equations which describe predator-prey dynamics. In this system, we have two populations \\(x(t)\\) (prey) and \\(y(t)\\) (predators) that interact according to:\n\\[\n\\begin{align}\n\\frac{dx}{dt} &= \\alpha x - \\beta xy \\\\\n\\frac{dy}{dt} &= \\delta xy - \\gamma y\n\\end{align}\n\\]\nwhere \\(\\alpha\\), \\(\\beta\\), \\(\\gamma\\), and \\(\\delta\\) are positive constants representing the interaction between the species. Here \\(\\alpha\\) is the growth rate of prey in absence of predators, \\(\\beta\\) is the rate at which predators eat prey, \\(\\delta\\) is the efficiency of turning eaten prey into new predators, and \\(\\gamma\\) is the death rate of predators in absence of prey.\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution Lotka-Volterra\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Lotka-Volterra equations show the cyclic behavior of predator-prey populations. The prey population grows until it reaches a maximum, at which point the predator population increases due to the abundance of prey. The predators then reduce the prey population, leading to a decrease in the predator population. This cycle continues indefinitely, demonstrating the complex dynamics of ecological systems.\n\n\n\n\n\n\nThe population values below 1 mean that we have less than one individual in our population, which is not physically meaningful in a biological context. Our model treats populations as continuous variables, but real populations consist of discrete individuals. When the numerical solution shows population values less than 1, this indicates that the model has entered a regime where its continuous approximation breaks down and we should instead use a discrete model that can properly handle individual organisms. In practice, once a population drops below 1, we should consider it extinct.\nThis limitation of continuous models is particularly important in conservation biology and population management, where understanding the threshold for population viability is crucial. When modeling endangered species or small populations, we often need to switch to discrete population models or include additional factors like demographic stochasticity that become important at low population numbers."
  },
  {
    "objectID": "lectures/lecture14/3_huygens_principle.html",
    "href": "lectures/lecture14/3_huygens_principle.html",
    "title": "Huygens principle",
    "section": "",
    "text": "Huygens‚Äô principle is a theorem from wave optics that states that each point in space experiencing an electromagnetic wave acts as a source of spherical waves. This means that any wave can be expanded into a superposition of spherical waves, which is fundamental to phenomena like Mie scattering. While the classical understanding is that accelerated charges are the source of electromagnetic waves, Huygens‚Äô principle provides a powerful mathematical framework for describing wave propagation and diffraction effects."
  },
  {
    "objectID": "lectures/lecture14/3_huygens_principle.html#diffraction-pattern-of-a-single-slit",
    "href": "lectures/lecture14/3_huygens_principle.html#diffraction-pattern-of-a-single-slit",
    "title": "Huygens principle",
    "section": "Diffraction pattern of a single slit",
    "text": "Diffraction pattern of a single slit\nLet‚Äôs use Huygens principle to understand how waves behave when they pass through a small opening like a slit. We can do this by treating many points along the slit as sources of waves, and seeing how these waves combine. This will help us understand diffraction - what happens when waves bend around edges. Remember the function we wrote down the last lecture, i.e.\n\\[\\begin{equation}\nE=\\frac{E_{0}}{|\\vec{r}-\\vec{r}_{0}|}e^{i k|\\vec{r}-\\vec{r}_{0}|} e^{-i\\omega t}\n\\end{equation}\\]\nthat describes the spherical wave. We can use this as a python function\n\n\n\n\n\n\nto calculate the electric field at a point in space. Let‚Äôs show first of all that we can reconstruct a plane wave from many spherical waves. We can do this by summing up many spherical waves with the same wavevector \\(\\vec{k}\\) but different positions \\(\\vec{r}_{0}\\). The code below does this for a plane wave propagating in the z-direction.\n\n\n\n\n\n\nThe result nicely shows the emergence of a plane wave from a sum of spherical waves. The intensity pattern is almost constant in the x-z plane, which is what we expect from a plane wave. The samll deviations are the result of the limited number of sources we used to sum up the spherical waves.\nWe now want to do the same but only over a limited range of x. This is what we would do for a single slit. The code below does this for a single slit of width \\(d=2\\) ¬µm. The next cell defines the space for our calculation again. The value of \\(d\\) denotes the slit width, which we want to vary to see the effect of changing slit width vs.¬†wavelength, which we chose to be \\(\\lambda=532\\) nm.\n\n\n\n\n\n\nThe next cell sums up the electric field of 200 spherical waves in the x-z plane, similar to the plane_wave_sum() function above but limited to sources within the slit width, such that we can plot the intensity or the field in space. Like the plane wave example, this demonstrates how multiple spherical waves combine, but now with sources constrained to a finite region.\n\n\n\n\n\n\nLet us plot the wavefronts and the intensity pattern in space. As the intensity decays strongly with distance from the slit, we do that by taking the log of the intensity. The left plot shows the real part of the field, revealing the wave fronts as they emerge from the slit and propagate outward. The right plot shows the logarithm of the intensity pattern, which helps visualize how the light spreads out as it diffracts through the slit opening. The wave fronts start planar at the slit but gradually curve outward, while the intensity pattern shows characteristic diffraction fringes."
  },
  {
    "objectID": "lectures/lecture14/3_huygens_principle.html#farfield-vs.-nearfield",
    "href": "lectures/lecture14/3_huygens_principle.html#farfield-vs.-nearfield",
    "title": "Huygens principle",
    "section": "Farfield vs.¬†nearfield",
    "text": "Farfield vs.¬†nearfield\nWhen light passes through a slit, the pattern of light we observe depends on how far away we measure it from the slit. We can divide this into two regions: the ‚Äúnear field‚Äù (at distance \\(r \\sim \\lambda\\)) and the ‚Äúfar field‚Äù (at distance \\(r \\gg \\lambda\\)). In the near field, which is typically within a few wavelengths \\(\\lambda\\) from the slit, the light pattern closely resembles the shape of the slit itself. However, in the far field, which is at distances \\(r \\gg \\lambda\\), the light spreads out significantly and creates distinctive patterns of bright and dark bands. This spreading out of light is called diffraction. To demonstrate this difference, let‚Äôs look at two distances: a near field measurement at \\(r = 1\\) ¬µm from the slit, and a far field measurement at \\(r = 100\\) ¬µm away. These measurements will show how dramatically different the light patterns can be in these two regions.\n\n\n\n\n\n\nThe two plots below show the drastic difference between the diffraction pattern in the near field and the far field. The near field resembles indeed the shadow picture, while the far field intensity pattern is considerable wider than the slit. This even becomes worse, if we make the slit narrower."
  },
  {
    "objectID": "lectures/lecture14/3_huygens_principle.html#comparison-to-the-analytical-solution",
    "href": "lectures/lecture14/3_huygens_principle.html#comparison-to-the-analytical-solution",
    "title": "Huygens principle",
    "section": "Comparison to the analytical solution",
    "text": "Comparison to the analytical solution\nNow that we understand how to calculate the diffraction pattern by adding up many Huygens sources (those spherical waves we created above), we can compare this to what physicists have worked out mathematically. When physicists solve this problem on paper, they do essentially the same thing we did in our code - they add up the contributions from many points along the slit, each acting as a source of waves. After doing all the math (which involves some complex calculus we won‚Äôt worry about now), they get a relatively simple formula for the intensity pattern far from the slit:\n\\[\\begin{equation}\nI=I_{0}\\left (\\frac{\\sin(\\delta)}{\\delta}\\right )^2\n\\end{equation}\\]\nwhere \\[\\begin{equation}\n\\delta=\\frac{\\pi d}{\\lambda}\\sin(\\theta)\n\\end{equation}\\]\nHere, \\(I_0\\) is just the maximum intensity, \\(d\\) is the width of our slit, \\(\\lambda\\) is the wavelength of light we‚Äôre using, and \\(\\theta\\) is the angle away from the center of the pattern (imagine drawing a line from the slit to any point on our screen - \\(\\theta\\) is the angle between this line and the straight-ahead direction). Let‚Äôs see how well this mathematical formula matches up with our numerical calculation where we added up all those Huygens sources one by one.\n\n\n\n\n\n\n\n\n\n\n\n\nThe plot below compares two ways of calculating the same thing: the black dotted line shows our numerical simulation using 200 point sources of waves, while the solid black line shows the mathematical formula that physicists derived. As you can see, they match quite well! This tells us that our computer simulation using Huygens‚Äô principle (adding up lots of wave sources) gives nearly the same result as the mathematical solution.\nAn interesting question to consider is: how many wave sources do we need to get an accurate result? Right now we‚Äôre using 200 sources spread across the width of the slit, but would 100 be enough? What about 1000? You can modify the code above to try different numbers of sources and see how it affects the accuracy of the simulation compared to the mathematical solution. This helps us understand how many ‚Äúpoints‚Äù of light we need to consider to get a good approximation of reality.\n\n\n\n\n\n\nLet‚Äôs explore how changing different parameters affects our diffraction pattern! Two key things we can adjust are:\n\nThe wavelength of light (Œª) - try using red light (650nm) versus blue light (450nm)\nThe width of the slit (d) - what happens when you make it wider or narrower?\n\nYou can modify these values in the code above and observe how the pattern changes. What patterns do you notice? Does the diffraction spread out more or less when you use longer wavelengths? What about with wider slits?\nAn even more interesting case is when we have multiple slits side by side - this is called a diffraction grating. Diffraction gratings are used in many real-world applications, from spectrometers that analyze starlight to the rainbow patterns you see on DVDs and CDs.\nLet‚Äôs look at what happens with 10 slits in a row, each separated by a distance D. The mathematical formula for this gets a bit more complicated, but it‚Äôs just combining two effects:\n\nThe single-slit diffraction pattern we saw before (the sin(Œ¥)/Œ¥ term)\nA new term that accounts for how the waves from multiple slits interfere (the sin(NŒ≥)/sin(Œ≥) term)\n\nHere‚Äôs the full formula for the intensity pattern:\n\\[\\begin{equation}\nI=I_{0}\\left (\\frac{\\sin(\\delta)}{\\delta}\\right )^2\\left (\\frac{\\sin(N\\gamma)}{\\sin(\\gamma)}\\right )^2\n\\end{equation}\\]\nwhere\n\\[\\begin{equation}\n  \\gamma=\\frac{\\pi D}{\\lambda}\\sin(\\theta)\n\\end{equation}\\]\nN is the number of slits (10 in our case), D is the distance between slits, and the other terms are the same as before.\nTry modifying the code to simulate this multiple-slit case! Some questions to consider:\n\nWhat happens when you change the spacing D between slits?\nHow does the pattern change if you use more or fewer slits?\nCan you explain why a CD or DVD creates rainbow patterns in sunlight based on what you‚Äôve learned about diffraction gratings?"
  },
  {
    "objectID": "lectures/lecture14/3_huygens_principle.html#focus-pattern-of-a-spherical-mirror",
    "href": "lectures/lecture14/3_huygens_principle.html#focus-pattern-of-a-spherical-mirror",
    "title": "Huygens principle",
    "section": "Focus pattern of a spherical mirror",
    "text": "Focus pattern of a spherical mirror\nHuygens‚Äô principle can also be used to understand how light reflects off a spherical mirror. When light hits a mirror, it reflects off at an angle equal to the angle of incidence. This means that the light rays all converge at a single point called the focal point \\(f\\). We can use Huygens‚Äô principle to understand how this happens by treating each point on the mirror as a source of waves. The code below calculates the electric field at a point in space due to a spherical mirror with radius of curvature \\(R = 10\\) ¬µm.\n\n\n\n\n\n\nThe two images show the field and the intensity pattern of the spherical mirror. The field plot shows the wavefronts converging at the focal point, while the intensity plot shows the bright spot at the focal point where the light rays all converge. The spot in the center is the focal point. The intensity pattern is called the point-spread function of the mirror, and it tells us how light from a point source will spread out after reflecting off the mirror."
  },
  {
    "objectID": "lectures/lecture13/4_repetition.html",
    "href": "lectures/lecture13/4_repetition.html",
    "title": "Repetition Meshgrid and Vector Fields",
    "section": "",
    "text": "This time, the exercises are a bit more complicated and perhaps only for the more advanced. You may, however, do some training with the easier repetitions before and come back and test yourself. We will focus on creating visualizations of vector fields using meshgrids and quiver plots. Vector fields are used to represent the spatial distribution of physical quantities like electric fields, fluid velocities, or magnetic fields. By visualizing vector fields, we can gain insights into the behavior of these quantities in different regions of space.\nNote that matplotlib and numpy are already imported and may be used with plt and np respectively.\n\n\n\n\n\n\nSelf-Exercise 1: Electric Field of a Point Charge\n\n\n\nCreate a 2D vector field plot of the electric field from a point charge located at the origin. The electric field vectors should point radially outward from the charge, with magnitude proportional to 1/r¬≤. This visualization helps understand the spatial distribution of electric fields.\nThe electric field is given by: \\(\\vec{E}(\\vec{r}) = \\frac{q}{4\\pi\\epsilon_0} \\frac{\\vec{r}}{r^3}\\)\nwhere:\n\n\\(\\vec{E}\\) is the electric field vector\n\\(q\\) is the charge\n\\(\\epsilon_0\\) is the permittivity of free space\n\\(\\vec{r}\\) is the position vector\n\\(r\\) is the distance from the charge\n\nLook up the plt.quiver() function in the Matplotlib documentation for plotting vector fields or check out the hint.\n\n\n\n\n\n\n\n\nUse np.meshgrid(x, y) to create X, Y grids\nCalculate R = sqrt(X¬≤ + Y¬≤) for distance\nCalculate Ex = X/R¬≥ and Ey = Y/R¬≥\nUse plt.quiver(X, Y, Ex, Ey) for the vector field\nRemember to avoid division by zero at the origin\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSelf-Exercise 2: Standing Wave Pattern\n\n\n\nVisualize a 2D standing wave pattern that might occur in a square membrane (like a drum head). This type of visualization is useful in understanding wave modes in musical instruments or quantum mechanical systems.\nThe wave function is given by: \\(\\psi(x,y,t) = \\sin(mx)\\cos(ny)\\)\nwhere: - \\(m, n\\) are mode numbers (integers) - \\(x, y\\) are positions on the membrane - \\(\\psi\\) is the displacement amplitude\n\n\n\n\n\n\n\n\nUse np.meshgrid(x, y) to create X, Y grids\nTry different mode numbers (m, n) for different patterns\nUse plt.contourf() for filled contours\nAdd a colorbar to show amplitude scale\nLook up the matplotlib plotting of surfaces with ax = plt.subplot(122, projection='3d') surf = ax.plot_surface()\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSelf-Exercise 3: Quantum Wave Packet\n\n\n\nCreate a 3D visualization of a Gaussian wave packet, which represents a localized quantum particle. This type of visualization is fundamental in understanding quantum mechanical states and probability distributions.\nThe wave function is given by: \\(\\psi(x,y) = A\\exp\\left(-\\frac{(x-x_0)^2 + (y-y_0)^2}{2\\sigma^2}\\right)\\)\nwhere: - \\(A\\) is the amplitude - \\((x_0, y_0)\\) is the center position - \\(\\sigma\\) is the width of the packet\n\n\n\n\n\n\n\n\nUse np.meshgrid(x, y) to create X, Y grids\nCalculate œà using the Gaussian formula\nCreate both a 3D surface plot and a 2D probability density plot\nUse as the probability density is |œà|¬≤\nLook up the matplotlib plotting of surfaces with ax = plt.subplot(133, projection='3d') surf = ax.plot_surface(X, Y, prob_density, cmap='viridis')\n\n\n\n\n\n\n\n\n\nSolution"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "References"
  }
]