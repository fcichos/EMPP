[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introduction to Computer-based Physical Modeling",
    "section": "",
    "text": "1 Willkommen zum Kurs Einführung in die Modellierung Physikalischer Prozesse!\nDie Programmiersprache Python ist für alle Arten von wissenschaftlichen und technischen Aufgaben nützlich. Sie können mit ihr Daten analysieren und darstellen. Sie können mit ihr auch wissenschaftliche Probleme numerisch lösen, die analytisch nur schwer oder gar nicht zu lösen sind. Python ist frei verfügbar und wurde aufgrund seines modularen Aufbaus um eine nahezu unendliche Anzahl von Modulen für verschiedene Zwecke erweitert.\nDieser Kurs soll Sie in die Programmierung mit Python einführen. Er richtet sich eher an den Anfänger, wir hoffen aber, dass er auch für Fortgeschrittene interessant ist. Wir beginnen den Kurs mit einer Einführung in die Jupyter Notebook-Umgebung, die wir während des gesamten Kurses verwenden werden. Danach werden wir eine Einführung in Python geben und Ihnen einige grundlegende Funktionen zeigen, wie z.B. das Plotten und Analysieren von Daten durch Kurvenanpassung, das Lesen und Schreiben von Dateien, was einige der Aufgaben sind, die Ihnen während Ihres Physikstudiums begegnen werden. Wir zeigen Ihnen auch einige fortgeschrittene Themen wie die Animation in Jupyter und die Simulation von physikalischen Prozessen in\n\nMechanik\nElektrostatik\nWellen\nOptik\n\nFalls am Ende des Kurses Zeit bleibt, werden wir auch einen Blick auf Verfahren des maschinellen Lernens werfen, das mittlerweile auch in der Physik zu einem wichtigen Werkzeug geworden ist.\nWir werden keine umfassende Liste von numerischen Simulationsschemata präsentieren, sondern die Beispiele nutzen, um Ihre Neugierde zu wecken. Da es leichte Unterschiede in der Syntax der verschiedenen Python-Versionen gibt, werden wir uns im Folgenden immer auf den Python 3-Standard beziehen.\nDer Kurs wird auf Deutsch gehalten werden. Die Webseiten, die Sie für den Überblick zu Python zur Verfügung gestellt bekommen, werden allerdings auf Englisch sein. Übungsaufgaben werden werden auf Deutsch gestellt.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>EMPP 2024</span>"
    ]
  },
  {
    "objectID": "lectures/lecture01/01-lecture01.html",
    "href": "lectures/lecture01/01-lecture01.html",
    "title": "2  Jupyter Notebooks",
    "section": "",
    "text": "2.1 What is Jupyter Notebook?\nA Jupyter Notebook is a web browser based interactive computing environment that enables users to create documents that include code to be executed, results from the executed code such as plots and images,and finally also an additional documentation in form of markdown text including equations in LaTeX.\nThese documents provide a complete and self-contained record of a computation that can be converted to various formats and shared with others using email, version control systems (like git/GitHub) or nbviewer.jupyter.org.",
    "crumbs": [
      "Lecture 1",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Jupyter Notebooks</span>"
    ]
  },
  {
    "objectID": "lectures/lecture01/01-lecture01.html#what-is-jupyter-notebook",
    "href": "lectures/lecture01/01-lecture01.html#what-is-jupyter-notebook",
    "title": "2  Jupyter Notebooks",
    "section": "",
    "text": "2.1.1 Key Components of a Notebook\nThe Jupyter Notebook ecosystem consists of three main components:\n\nNotebook Editor\nKernels\nNotebook Documents\n\nLet’s explore each of these components in detail:\n\n2.1.1.1 Notebook Editor\nThe Notebook editor is an interactive web-based application for creating and editing notebook documents. It enables users to write and run code, add rich text, and multimedia content. When running Jupyter on a server, users typically use either the classic Jupyter Notebook interface or JupyterLab, an advanced version with more features.\nKey features of the Notebook editor include:\n\nCode Editing: Write and edit code in individual cells.\nCode Execution: Run code cells in any order and display computation results in various formats (HTML, LaTeX, PNG, SVG, PDF).\nInteractive Widgets: Create and use JavaScript widgets that connect user interface controls to kernel-side computations.\nRich Text: Add documentation using Markdown markup language, including LaTeX equations.\n\n\n\n\n\n\n\nAdvance Notebook Editor Info\n\n\n\n\n\nThe Notebook editor in Jupyter offers several advanced features:\n\nCell Metadata: Each cell has associated metadata that can be used to control its behavior. This includes tags for slideshows, hiding code cells, and controlling cell execution.\nMagic Commands: Special commands prefixed with % (line magics) or %% (cell magics) that provide additional functionality, such as timing code execution or displaying plots inline.\nAuto-completion: The editor provides context-aware auto-completion for Python code, helping users write code more efficiently.\nCode Folding: Users can collapse long code blocks for better readability.\nMultiple Cursors: Advanced editing with multiple cursors for simultaneous editing at different locations.\nSplit View: The ability to split the notebook view, allowing users to work on different parts of the notebook simultaneously.\nVariable Inspector: A tool to inspect and manage variables in the kernel’s memory.\nIntegrated Debugger: Some Jupyter environments offer an integrated debugger for step-by-step code execution and inspection.\n\n\n\n\n\n\n\n2.1.2 Kernels\nKernels are the computational engines that execute the code contained in a notebook. They are separate processes that run independently of the notebook editor.\nKey responsibilities of kernels include: * Executing user code * Returning computation results to the notebook editor * Handling computations for interactive widgets * Providing features like tab completion and introspection\n\n\n\n\n\n\nAdvanced Kernel Info\n\n\n\n\n\nJupyter notebooks are language-agnostic. Different kernels can be installed to support various programming languages such as Python, R, Julia, and many others. The default kernel runs Python code, but users can select different kernels for each notebook via the Kernel menu.\nKernels communicate with the notebook editor using a JSON-based protocol over ZeroMQ/WebSockets. For more technical details, see the messaging specification.\nEach kernel runs in its own environment, which can be customized to include specific libraries and dependencies. This allows users to create isolated environments for different projects, ensuring that dependencies do not conflict.\nKernels also support interactive features such as:\n\nTab Completion: Provides suggestions for variable names, functions, and methods as you type, improving coding efficiency.\nIntrospection: Allows users to inspect objects, view documentation, and understand the structure of code elements.\nRich Output: Supports various output formats, including text, images, videos, and interactive widgets, enhancing the interactivity of notebooks.\n\nAdvanced users can create custom kernels to support additional languages or specialized computing environments. This involves writing a kernel specification and implementing the necessary communication protocols.\nFor managing kernels, Jupyter provides several commands and options:\n\nStarting a Kernel: Automatically starts when a notebook is opened.\nInterrupting a Kernel: Stops the execution of the current code cell, useful for halting long-running computations.\nRestarting a Kernel: Clears the kernel’s memory and restarts it, useful for resetting the environment or recovering from errors.\nShutting Down a Kernel: Stops the kernel and frees up system resources.\n\nUsers can also monitor kernel activity and resource usage through the Jupyter interface, ensuring efficient and effective use of computational resources.\n\n\n\n\n\n2.1.3 JupyterLab Example\nThe following is an example of a JupyterLab interface with a notebook editor, code cells, markdown cells, and a kernel selector:\nFull Screen\n\n\n\n\n\n2.1.4 Notebook Documents\nNotebook documents are self-contained files that encapsulate all content created in the notebook editor. They include code inputs/outputs, Markdown text, equations, images, and other media. Each document is associated with a specific kernel and serves as both a human-readable record of analysis and an executable script to reproduce the work.\nCharacteristics of notebook documents:\n\nFile Extension: Notebooks are stored as files with a .ipynb extension.\nStructure: Notebooks consist of a linear sequence of cells, which can be one of three types:\n\nCode cells: Contain executable code and its output.\nMarkdown cells: Contain formatted text, including LaTeX equations.\nRaw cells: Contain unformatted text, preserved when converting notebooks to other formats.\n\n\n\n\n\n\n\n\nAdvanced Notebook Documents Info\n\n\n\n\n\n\nVersion Control: Notebook documents can be version controlled using systems like Git. This allows users to track changes, collaborate with others, and revert to previous versions if needed. Tools like nbdime provide diff and merge capabilities specifically designed for Jupyter Notebooks.\nCell Tags: Cells in a notebook can be tagged with metadata to control their behavior during execution, export, or presentation. For example, tags can be used to hide input or output, skip execution, or designate cells as slides in a presentation.\nInteractive Widgets: Notebook documents can include interactive widgets that allow users to manipulate parameters and visualize changes in real-time. This is particularly useful for data exploration and interactive simulations.\nExtensions: The Jupyter ecosystem supports a wide range of extensions that enhance the functionality of notebook documents. These extensions can add features like spell checking, code formatting, and integration with external tools and services.\nSecurity: Notebook documents can include code that executes on the user’s machine, which poses security risks. Jupyter provides mechanisms to sanitize notebooks and prevent the execution of untrusted code. Users should be cautious when opening notebooks from unknown sources.\nCollaboration: Jupyter Notebooks can be shared and collaboratively edited in real-time using platforms like Google Colab, Microsoft Azure Notebooks, and JupyterHub. These platforms provide cloud-based environments where multiple users can work on the same notebook simultaneously.\nCustomization: Users can customize the appearance and behavior of notebook documents using CSS and JavaScript. This allows for the creation of tailored interfaces and enhanced user experiences.\nExport Options: In addition to static formats, notebooks can be exported to interactive formats like dashboards and web applications. Tools like Voila convert notebooks into standalone web applications that can be shared and deployed.\nProvenance: Notebooks can include provenance information that tracks the origin and history of data and computations. This is important for reproducibility and transparency in scientific research.\nDocumentation: Notebook documents can serve as comprehensive documentation for projects, combining code, results, and narrative text. This makes them valuable for teaching, tutorials, and sharing research findings.\nPerformance: Large notebooks with many cells and outputs can become slow and unwieldy. Techniques like cell output clearing, using lightweight data formats, and splitting notebooks into smaller parts can help maintain performance.\nIntegration: Jupyter Notebooks can integrate with a wide range of data sources, libraries, and tools. This includes databases, cloud storage, machine learning frameworks, and visualization libraries, making them a versatile tool for data science and research.\nInternal Format: Notebook files are JSON text files with binary data encoded in base64, making them easy to manipulate programmatically.\nExportability: Notebooks can be exported to various static formats (HTML, reStructuredText, LaTeX, PDF, slide shows) using Jupyter’s nbconvert utility.\nSharing: Notebooks can be shared via nbviewer, which renders notebooks from public URLs or GitHub as static web pages, allowing others to view the content without installing Jupyter.\n\n\n\n\nThis integrated system of editor, kernels, and documents makes Jupyter Notebooks a powerful tool for interactive computing, data analysis, and sharing of computational narratives.",
    "crumbs": [
      "Lecture 1",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Jupyter Notebooks</span>"
    ]
  },
  {
    "objectID": "lectures/lecture01/01-lecture01.html#using-the-notebook-editor",
    "href": "lectures/lecture01/01-lecture01.html#using-the-notebook-editor",
    "title": "2  Jupyter Notebooks",
    "section": "2.2 Using the Notebook Editor",
    "text": "2.2 Using the Notebook Editor\n\n\n\nJupyter Notebook Editor\n\n\nThe Jupyter Notebook editor provides an interactive environment for writing code, creating visualizations, and documenting computational workflows. It consists of a web-based interface that allows users to create and edit notebook documents containing code, text, equations, images, and interactive elements. A Jupyter Notebook provides an interface with essentially two modes of operation:\n\nedit mode the mode where you edit a cells content.\ncommand mode the mode where you execute the cells content.\n\nIn the more advanced version of JupyterLab you can also have a presentation mode where you can present your notebook as a slideshow.\n\n2.2.1 Edit mode\nEdit mode is indicated by a blue cell border and a prompt showing in the editor area when a cell is selected. You can enter edit mode by pressing Enter or using the mouse to click on a cell’s editor area.\n\n\n\nEdit Mode\n\n\nWhen a cell is in edit mode, you can type into the cell, like a normal text editor\n\n\n2.2.2 Command mode\nCommand mode is indicated by a grey cell border with a blue left margin. When you are in command mode, you are able to edit the notebook as a whole, but not type into individual cells. Most importantly, in command mode, the keyboard is mapped to a set of shortcuts that let you perform notebook and cell actions efficiently.\n\n\n\nCommand Mode\n\n\nIf you have a hardware keyboard connected to your iOS device, you can use Jupyter keyboard shortcuts. The modal user interface of the Jupyter Notebook has been optimized for efficient keyboard usage. This is made possible by having two different sets of keyboard shortcuts: one set that is active in edit mode and another in command mode.\n\n\n2.2.3 Keyboard navigation\nIn edit mode, most of the keyboard is dedicated to typing into the cell’s editor area. Thus, in edit mode there are relatively few shortcuts available. In command mode, the entire keyboard is available for shortcuts, so there are many more. Most important ones are:\n\nSwitch command and edit mods: Enter for edit mode, and Esc or Control for command mode.\nBasic navigation: ↑/k, ↓/j\nRun or render currently selected cell: Shift+Enter or Control+Enter\nSaving the notebook: s\nChange Cell types: y to make it a code cell, m for markdown and r for raw\nInserting new cells: a to insert above, b to insert below\nManipulating cells using pasteboard: x for cut, c for copy, v for paste, d for delete and z for undo delete\nKernel operations: i to interrupt and 0 to restart\n\n\n\n2.2.4 Running code\nCode cells allow you to enter and run code. Run a code cell by pressing the ▶︎ button in the bottom-right panel, or Control+Enter on your hardware keyboard.\n\n\n23752636\n\n\nThere are a couple of keyboard shortcuts for running code:\n\nControl+Enter run the current cell and enters command mode.\nShift+Enter runs the current cell and moves selection to the one below.\nOption+Enter runs the current cell and inserts a new one below.",
    "crumbs": [
      "Lecture 1",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Jupyter Notebooks</span>"
    ]
  },
  {
    "objectID": "lectures/lecture01/01-lecture01.html#managing-the-kernel",
    "href": "lectures/lecture01/01-lecture01.html#managing-the-kernel",
    "title": "2  Jupyter Notebooks",
    "section": "2.3 Managing the kernel",
    "text": "2.3 Managing the kernel\nCode is run in a separate process called the kernel, which can be interrupted or restarted. You can see kernel indicator in the top-right corner reporting current kernel state: ⚪︎ means kernel is ready to execute code, and ⚫︎ means kernel is currently busy. Tapping kernel indicator will open kernel menu, where you can reconnect, interrupt or restart kernel.\nTry running the following cell — kernel indicator will switch from ⚪︎ to ⚫︎, i.e. reporting kernel as “busy”. This means that you won’t be able to run any new cells until current execution finishes, or until kernel is interrupted. You can then go to kernel menu by tapping the kernel indicator and select “Interrupt”.",
    "crumbs": [
      "Lecture 1",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Jupyter Notebooks</span>"
    ]
  },
  {
    "objectID": "lectures/lecture01/01-lecture01.html#markdown-in-notebooks",
    "href": "lectures/lecture01/01-lecture01.html#markdown-in-notebooks",
    "title": "2  Jupyter Notebooks",
    "section": "2.4 Markdown in Notebooks",
    "text": "2.4 Markdown in Notebooks\nText can be added to Jupyter Notebooks using Markdown cells. This is extremely useful providing a complete documentation of your calculations or simulations. In this way, everything really becomes an notebook. You can change the cell type to Markdown by using the “Cell Actions” menu, or with a hardware keyboard shortcut m. Markdown is a popular markup language that is a superset of HTML. Its specification can be found here:\nhttps://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet\nMarkdown cells can either be rendered or unrendered.\nWhen they are rendered, you will see a nice formatted representation of the cell’s contents.\nWhen they are unrendered, you will see the raw text source of the cell. To render the selected cell, click the ▶︎ button or shift+ enter. To unrender, select the markdown cell, and press enter or just double click.\n\n2.4.1 Markdown basics\nBelow are some basic markdown examples, in its rendered form. If you which to access how to create specific appearances, double click the individual cells to put the into an unrendered edit mode.\nYou can make text italic or bold. You can build nested itemized or enumerated lists:\n\nFirst item\n\nFirst subitem\n\nFirst sub-subitem\n\nSecond subitem\n\nFirst subitem of second subitem\nSecond subitem of second subitem\n\n\nSecond item\n\nFirst subitem\n\nThird item\n\nFirst subitem\n\n\nNow another list:\n\nHere we go\n\nSublist\n\nSublist\n\n\nThere we go\nNow this\n\nHere is a blockquote:\n\nBeautiful is better than ugly. Explicit is better than implicit. Simple is better than complex. Complex is better than complicated. Flat is better than nested. Sparse is better than dense. Readability counts. Special cases aren’t special enough to break the rules. Namespaces are one honking great idea – let’s do more of those!\n\nAnd Web links:\nJupyter’s website\n\n\n2.4.2 Headings\nYou can add headings by starting a line with one (or multiple) # followed by a space and the title of your section. The number of # you use will determine the size of the heading\n# Heading 1\n# Heading 2\n## Heading 2.1\n## Heading 2.2\n### Heading 2.2.1\n\n\n2.4.3 Embedded code\nYou can embed code meant for illustration instead of execution in Python:\ndef f(x):\n    \"\"\"a docstring\"\"\"\n    return x**2\n\n\n2.4.4 LaTeX equations\nCourtesy of MathJax, you can include mathematical expressions both inline: \\(e^{i\\pi} + 1 = 0\\) and displayed:\n\\[e^x=\\sum_{i=0}^\\infty \\frac{1}{i!}x^i\\]\nInline expressions can be added by surrounding the latex code with $:\n$e^{i\\pi} + 1 = 0$\nExpressions on their own line are surrounded by $$:\n$$e^x=\\sum_{i=0}^\\infty \\frac{1}{i!}x^i$$\n\n\n2.4.5 Images\nImages may be also directly integrated into a Markdown block.\nTo include images use\n![alternative text](url)\nfor example\n\n\n\nalternative text\n\n\n\n\n2.4.6 Videos\nTo include videos, we use HTML code like\n&lt;video src=\"mov/movie.mp4\" width=\"320\" height=\"200\" controls preload&gt;&lt;/video&gt;\nin the Markdown cell. This works with videos stored locally.\n\n\nYou can embed YouTube Videos as well by using the IPython module.",
    "crumbs": [
      "Lecture 1",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Jupyter Notebooks</span>"
    ]
  },
  {
    "objectID": "lectures/lecture01/02-lecture01.html",
    "href": "lectures/lecture01/02-lecture01.html",
    "title": "3  Variables & Numbers",
    "section": "",
    "text": "3.1 Variables in Python",
    "crumbs": [
      "Lecture 1",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Variables & Numbers</span>"
    ]
  },
  {
    "objectID": "lectures/lecture01/02-lecture01.html#variables-in-python",
    "href": "lectures/lecture01/02-lecture01.html#variables-in-python",
    "title": "3  Variables & Numbers",
    "section": "",
    "text": "3.1.1 Symbol Names\nVariable names in Python can include alphanumerical characters a-z, A-Z, 0-9, and the special character _. Normal variable names must start with a letter or an underscore. By convention, variable names typically start with a lower-case letter, while Class names start with a capital letter and internal variables start with an underscore.\n\n\n\n\n\n\nReserved Keywords\n\n\n\nThere are a number of Python keywords that cannot be used as variable names because Python uses them for other things. These keywords are:\nand, as, assert, break, class, continue, def, del, elif, else, except, exec, finally, for, from, global, if, import, in, is, lambda, not, or, pass, print, raise, return, try, while, with, yield\nBe aware of the keyword lambda, which could easily be a natural variable name in a scientific program. However, as a reserved keyword, it cannot be used as a variable name.\n\n\n\n\n3.1.2 Variable Assignment\nThe assignment operator in Python is =. Python is a dynamically typed language, so we do not need to specify the type of a variable when we create one.\nAssigning a value to a new variable creates the variable:\n\n\n\n\n\n\nAlthough not explicitly specified, a variable does have a type associated with it (e.g., integer, float, string). The type is derived from the value that was assigned to it. To determine the type of a variable, we can use the type function.\n\n\n\n\n\n\nIf we assign a new value to a variable, its type can change.\n\n\n\n\n\n\n\n\n\n\n\n\nIf we try to use a variable that has not yet been defined, we get a NameError error.",
    "crumbs": [
      "Lecture 1",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Variables & Numbers</span>"
    ]
  },
  {
    "objectID": "lectures/lecture01/02-lecture01.html#number-types",
    "href": "lectures/lecture01/02-lecture01.html#number-types",
    "title": "3  Variables & Numbers",
    "section": "3.2 Number Types",
    "text": "3.2 Number Types\nPython supports various number types, including integers, floating-point numbers, and complex numbers. These are some of the basic building blocks of doing arithmetic in any programming language. We will discuss each of these types in more detail.\n\n3.2.1 Comparison of Number Types\n\n\n\n\n\n\n\n\n\n\nType\nExample\nDescription\nLimits\nUse Cases\n\n\n\n\nint\n42\nWhole numbers\nUnlimited precision (bounded by available memory)\nCounting, indexing\n\n\nfloat\n3.14159\nDecimal numbers\nTypically ±1.8e308 with 15-17 digits of precision (64-bit)\nScientific calculations, prices\n\n\ncomplex\n2 + 3j\nNumbers with real and imaginary parts\nSame as float for both real and imaginary parts\nSignal processing, electrical engineering\n\n\nbool\nTrue / False\nLogical values\nOnly two values: True (1) and False (0)\nConditional operations, flags\n\n\n\n\n\n\n\n\n\nExamples for Number Types\n\n\n\n\n\n\n3.2.2 Integers\nInteger Representation: Integers are whole numbers without a decimal point.\n\n\n\n\n\n\nBinary, Octal, and Hexadecimal: Integers can be represented in different bases:\n\n\n\n\n\n\n\n\n3.2.3 Floating Point Numbers\nFloating Point Representation: Numbers with a decimal point are treated as floating-point values.\n\n\n\n\n\n\nMaximum Float Value: Python handles large floats, converting them to infinity if they exceed the maximum representable value.\n\n\n\n\n\n\n\n\n3.2.4 Complex Numbers\nComplex Number Representation: Complex numbers have a real and an imaginary part.\n\n\n\n\n\n\n\nAccessors for Complex Numbers:\n\nc.real: Real part of the complex number.\nc.imag: Imaginary part of the complex number.\n\n\n\n\n\n\n\n\nComplex Conjugate: Use the .conjugate() method to get the complex conjugate.",
    "crumbs": [
      "Lecture 1",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Variables & Numbers</span>"
    ]
  },
  {
    "objectID": "lectures/lecture02/3_datatypes.html",
    "href": "lectures/lecture02/3_datatypes.html",
    "title": "4  Data Types in Python",
    "section": "",
    "text": "4.1 Strings\nStrings are lists of keyboard characters as well as other characters not on your keyboard. They are useful for printing results on the screen, during reading and writing of data.\nString can be concatenated using the + operator.\nAs strings are lists, each character in a string can be accessed by addressing the position in the string (see Lists section)\nStrings can also be made out of numbers.\nIf you want to obtain a number of a string, you can use what is known as type casting. Using type casting you may convert the string or any other data type into a different type if this is possible. To find out if a string is a pure number you may use the str.isnumeric method. For the above string, we may want to do a conversion to the type int by typing:\nThere are a number of methods connected to the string data type. Usually the relate to formatting or finding sub-strings. Formatting will be a topic in our next lecture. Here we just refer to one simple find example.",
    "crumbs": [
      "Lecture 2",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Types in Python</span>"
    ]
  },
  {
    "objectID": "lectures/lecture02/3_datatypes.html#lists",
    "href": "lectures/lecture02/3_datatypes.html#lists",
    "title": "4  Data Types in Python",
    "section": "4.2 Lists",
    "text": "4.2 Lists\nLists have a variety of uses. They are useful, for example, in various bookkeeping tasks that arise in computer programming. Like arrays, they are sometimes used to store data. However, lists do not have the specialized properties and tools that make arrays so powerful for scientific computing. So in general, we prefer arrays to lists for working with scientific data. For other tasks, lists work just fine and can even be preferable to arrays.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIndividual elements in a list can be accessed by the variable name and the number (index) of the list element put in square brackets. Note that the index for the elements start at 0 for the first element (left).\n\n\n\n\n\n\nIndices in Python\n\n\n\nThe first element of a list or array is accessed by the index 0. If the array has N elements, the last entries index is N-1.\n\n\n\n\n\n\n\n\nElements may be also accessed from the back by nagative indices. b[-1] denotes the last element in the list and b[-2], the element before the last.\n\n\n\n\n\n\n\n\n\n\n\n\nThe length of a list can be obtained by the len command if you need the number of elements in the list for your calculations.\n\n\n\n\n\n\nThere are powerful ways to iterate through a list and also through arrays in form of iterator. This is called list comprehension. We will talk about them later in more detail. Here is an example, which shows the powerful options you have in Python.\n\n\n\n\n\n\nIndividual elements in a list can be replaced by assigning a new value to them\n\n\n\n\n\n\n\n\n\n\n\n\nLists can be concatanated by the + operator\n\n\n\n\n\n\nA very useful feature for lists in python is the slicing of lists. Slicing means, that we access only a range of elements in the list, i.e. element 3 to 7. This is done by inserting the starting and the ending element number separated by a colon (:) in the square brackets. The index numbers can be positive or negative again.\n\n\n\n\n\n\nInserting a second colon behind the ending element index together with a thrid number allows even to select only ever second or third element from a list.\n\n\n\n\n\n\nIt is sometimes also useful to reverse a list. This can be easily done with the reverse command.\n\n\n\n\n\n\nLists may be created in different ways. An empty list can be created by assigning emtpy square brackets to a variable name. You can append elements to the list with the help of the append command which has to be added to the variable name as shown below. This way of adding a particular function, which is part of a certain variable class is part of object oriented programming.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA list of numbers can be easily created by the range() command.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLists (and also tuples below) can be multidimensional as well, i.e. for an image. The individual elements may then be addressed by supplying two indices in two square brackets.",
    "crumbs": [
      "Lecture 2",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Types in Python</span>"
    ]
  },
  {
    "objectID": "lectures/lecture02/3_datatypes.html#tuples",
    "href": "lectures/lecture02/3_datatypes.html#tuples",
    "title": "4  Data Types in Python",
    "section": "4.3 Tuples",
    "text": "4.3 Tuples\nTuples are also list, but immutable. That means, if a tuple has been once defined, it cannot be changed. Try to change an element to see the result.\n\n\n\n\n\n\nTuples may be unpacked, e.g. its values may be assigned to normal variables in the following way",
    "crumbs": [
      "Lecture 2",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Types in Python</span>"
    ]
  },
  {
    "objectID": "lectures/lecture02/3_datatypes.html#dictionaries",
    "href": "lectures/lecture02/3_datatypes.html#dictionaries",
    "title": "4  Data Types in Python",
    "section": "4.4 Dictionaries",
    "text": "4.4 Dictionaries\nDictionaries are like lists, but the elements of dictionaries are accessed in a different way than for lists. The elements of lists and arrays are numbered consecutively, and to access an element of a list or an array, you simply refer to the number corresponding to its position in the sequence. The elements of dictionaries are accessed by “keys”, which can be either strings or (arbitrary) integers (in no particular order). Dictionaries are an important part of core Python. However, we do not make much use of them in this introduction to scientific Python, so our discussion of them is limited.",
    "crumbs": [
      "Lecture 2",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Types in Python</span>"
    ]
  },
  {
    "objectID": "lectures/lecture02/3_datatypes.html#sets",
    "href": "lectures/lecture02/3_datatypes.html#sets",
    "title": "4  Data Types in Python",
    "section": "4.5 Sets",
    "text": "4.5 Sets\nSets are like lists but have immutable unique entries, which means the elements can not be changed once defined. An emtpy set is created by the set() method.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYou may add elements to a set with the add method:\nYou may also remove objects with the discard method:\n\n\n\n\n\n\nYou may also apply a variety of operation to sets checking their intersection, union or difference.",
    "crumbs": [
      "Lecture 2",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Types in Python</span>"
    ]
  },
  {
    "objectID": "lectures/lecture02/3_datatypes.html#quiz-data-types-in-python",
    "href": "lectures/lecture02/3_datatypes.html#quiz-data-types-in-python",
    "title": "4  Data Types in Python",
    "section": "4.6 Quiz: Data Types in Python",
    "text": "4.6 Quiz: Data Types in Python\nLet’s test your understanding of Python data types!\n\n\nWhat is the output of the following code?\na = [1, 2, 3]\nb = (1, 2, 3)\nprint(type(a), type(b))\n\n&lt;class 'list'&gt; &lt;class 'list'&gt;\n&lt;class 'list'&gt; &lt;class 'tuple'&gt;\n&lt;class 'tuple'&gt; &lt;class 'list'&gt;\n&lt;class 'tuple'&gt; &lt;class 'tuple'&gt;\n\nWhich of the following is mutable?\n\nList\nTuple\nString\nInteger\n\nWhat will be the output of this code?\nmy_dict = {'a': 1, 'b': 2, 'c': 3}\nprint(my_dict['b'])\n\na\n2\nb\nKeyError\n\nHow do you create an empty set in Python?\n\n{}\n[]\nset()\n()\n\nWhat is the result of 3 + 4.0?\n\n7\n7.0\n‘7.0’\nTypeError\n\n\n\n\n\n\n\n\n\nClick to reveal answers\n\n\n\n\n\n\n&lt;class 'list'&gt; &lt;class 'tuple'&gt;\nList\n2\nset()\n7.0",
    "crumbs": [
      "Lecture 2",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Types in Python</span>"
    ]
  },
  {
    "objectID": "lectures/lecture02/01-lecture02.html",
    "href": "lectures/lecture02/01-lecture02.html",
    "title": "5  Python Overview",
    "section": "",
    "text": "5.1 Functions\nFunctions are reusable blocks of code that can be executed multiple times from different parts of your program. They help in organizing code, making it more readable, and reducing redundancy. Functions can take input arguments and return output values.",
    "crumbs": [
      "Lecture 3",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Python Overview</span>"
    ]
  },
  {
    "objectID": "lectures/lecture02/01-lecture02.html#functions",
    "href": "lectures/lecture02/01-lecture02.html#functions",
    "title": "5  Python Overview",
    "section": "",
    "text": "Defining a FunctionCalling a Function\n\n\nA function in Python is defined using the def keyword followed by the name of the function, which is usually descriptive and indicates what the function does. The parameters inside the parentheses indicate what data the function expects to receive. The -&gt; symbol is used to specify the return type of the function.\nHere’s an example:\n\n\n\n\n\n\n\n\nFunctions can be called by specifying the name of the function followed by parentheses containing the arguments. The arguments passed to the function should match the number and type of parameters defined in the function. Here’s an example:",
    "crumbs": [
      "Lecture 3",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Python Overview</span>"
    ]
  },
  {
    "objectID": "lectures/lecture02/01-lecture02.html#loops",
    "href": "lectures/lecture02/01-lecture02.html#loops",
    "title": "5  Python Overview",
    "section": "5.2 Loops",
    "text": "5.2 Loops\nLoops are used to execute a block of code repeatedly. There are two main types of loops in Python: for loops and while loops.\n\nFor LoopWhile Loop\n\n\nA for loop in Python is used to iterate over a sequence (such as a list or string) and execute a block of code for each item in the sequence. Here’s an example:\n\n\n\n\n\n\n\n\nA while loop in Python is used to execute a block of code while a certain condition is met. The loop continues as long as the condition is true. Here’s an example:",
    "crumbs": [
      "Lecture 3",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Python Overview</span>"
    ]
  },
  {
    "objectID": "lectures/lecture02/01-lecture02.html#conditional-statements",
    "href": "lectures/lecture02/01-lecture02.html#conditional-statements",
    "title": "5  Python Overview",
    "section": "5.3 Conditional Statements",
    "text": "5.3 Conditional Statements\nConditional statements are used to control the flow of your program based on conditions. The main conditional statements in Python are if, else, and elif.\n\nIf StatementElse StatementElif Statement\n\n\nAn if statement in Python is used to execute a block of code if a certain condition is met. Here’s an example:\n\n\n\n\n\n\n\n\nAn else statement in Python is used to execute a block of code if the condition in an if statement is not met. Here’s an example:\n\n\n\n\n\n\n\n\nAn elif statement in Python is used to execute a block of code if the condition in an if statement is not met but under an extra condition. Here’s an example:",
    "crumbs": [
      "Lecture 3",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Python Overview</span>"
    ]
  },
  {
    "objectID": "lectures/lecture02/02-lecture02.html",
    "href": "lectures/lecture02/02-lecture02.html",
    "title": "6  Modules",
    "section": "",
    "text": "Most of the functionality in Python is provided by modules. The Python Standard Library is a large collection of modules that provides cross-platform implementations of common facilities such as access to the operating system, file I/O, string management, network communication, math, web-scraping, text manipulation, machine learning and much more.\nTo use a module in a Python module it first has to be imported. A module can be imported using the import statement. For example, to import the module math, which contains many standard mathematical functions, we can do:\n\n\n\n\n\n\nThis includes the whole module and makes it available for use later in the program. Alternatively, we can chose to import all symbols (functions and variables) in a module so that we don’t need to use the prefix “math.” every time we use something from the math module:\n\n\n\n\n\n\nThis pattern can be very convenient, but in large programs that include many modules it is often a good idea to keep the symbols from each module in their own namespaces, by using the import math pattern. This would eliminate potentially confusing problems.\n\n6.0.1 Namespaces\n\n\n\n\n\n\nNamespaces\n\n\n\nA namespace is an identifier used to organize objects, e.g. the methods and variables of a module. The prefix math. we have used in the previous section is such a namespace. You may also create your own namespace for a module. This is done by using the import math as mymath pattern.\n\n\n\n\n\n\n\n\nYou may also only import specific functions of a module.\n\n\n\n\n\n\n\n\n6.0.2 Directory of a module\nOnce a module is imported, we can list the symbols it provides using the dir function:\n\n\n\n\n\n\nAnd using the function help we can get a description of each function (almost .. not all functions have docstrings, as they are technically called, but the vast majority of functions are documented this way).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe can also use the help function directly on modules: Try\nhelp(math)\nSome very useful modules form the Python standard library are os, sys, math, shutil, re, subprocess, multiprocessing, threading.\nA complete lists of standard modules for Python 3 is available at http://docs.python.org/3/library/ .\n\n\n6.0.3 Advanced topics\n\n\n\n\n\n\nCreate Your Own Modules\n\n\n\n\n\nCreating your own modules in Python is a great way to organize your code and make it reusable. A module is simply a file containing Python definitions and statements. Here’s how you can create and use your own module:\n\n6.0.3.1 Creating a Module\nTo create a module, you just need to save your Python code in a file with a .py extension. For example, let’s create a module named mymodule.py with the following content:\n# mymodule.py\n\ndef greet(name: str) -&gt; str:\n    return f\"Hello, {name}!\"\n\ndef add(a: int, b: int) -&gt; int:\n    return a + b\n\n\n6.0.3.2 Using Your Module\nOnce you have created your module, you can import it into other Python scripts using the import statement. Here’s an example of how to use the mymodule we just created:\n# main.py\n\nimport mymodule\n\n# Use the functions from mymodule\nprint(mymodule.greet(\"Alice\"))\nprint(mymodule.add(5, 3))\n\n\n6.0.3.3 Importing Specific Functions\nYou can also import specific functions from a module using the from ... import ... syntax:\n# main.py\n\nfrom mymodule import greet, add\n\n# Use the imported functions directly\nprint(greet(\"Bob\"))\nprint(add(10, 7))\n\n\n6.0.3.4 Module Search Path\nWhen you import a module, Python searches for the module in the following locations: 1. The directory containing the input script (or the current directory if no script is specified). 2. The directories listed in the PYTHONPATH environment variable. 3. The default directory where Python is installed.\nYou can view the module search path by printing the sys.path variable:\nimport sys\nprint(sys.path)\n\n\n6.0.3.5 Creating Packages\nA package is a way of organizing related modules into a directory hierarchy. A package is simply a directory that contains a special file named __init__.py, which can be empty. Here’s an example of how to create a package:\nmypackage/\n    __init__.py\n    module1.py\n    module2.py\nYou can then import modules from the package using the dot notation:\n# main.py\n\nfrom mypackage import module1, module2\n\n# Use the functions from the modules\nprint(module1.some_function())\nprint(module2.another_function())\nCreating and using modules and packages in Python helps you organize your code better and makes it easier to maintain and reuse.\n\n\n6.0.3.6 Namespaces in Packages\nYou can also create sub-packages by adding more directories with __init__.py files. This allows you to create a hierarchical structure for your modules:\nmypackage/\n    __init__.py\n    subpackage/\n        __init__.py\n        submodule.py\nYou can then import submodules using the full package name:\n# main.py\n\nfrom mypackage.subpackage import submodule\n\n# Use the functions from the submodule\nprint(submodule.some_sub_function())",
    "crumbs": [
      "Lecture 3",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Modules</span>"
    ]
  },
  {
    "objectID": "lectures/lecture03/1_numpy.html",
    "href": "lectures/lecture03/1_numpy.html",
    "title": "7  NumPy Module",
    "section": "",
    "text": "7.1 Creating Numpy Arrays\nThere are a number of ways to initialize new numpy arrays, for example from",
    "crumbs": [
      "Lecture 4",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>NumPy Module</span>"
    ]
  },
  {
    "objectID": "lectures/lecture03/1_numpy.html#creating-numpy-arrays",
    "href": "lectures/lecture03/1_numpy.html#creating-numpy-arrays",
    "title": "7  NumPy Module",
    "section": "",
    "text": "a Python list or tuples\nusing functions that are dedicated to generating numpy arrays, such as arange, linspace, etc.\nreading data from files which will be covered in the files section\n\n\n7.1.1 From lists\nFor example, to create new vector and matrix arrays from Python lists we can use the numpy.array function.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n7.1.2 Using array-generating functions\nFor larger arrays it is inpractical to initialize the data manually, using explicit python lists. Instead we can use one of the many functions in numpy that generate arrays of different forms. Some of the more common are:\n\n\n\n\n\n\n\n\n\n\n\n\n\n7.1.2.1 linspace and logspace\nThe linspace function creates an array of N evenly spaced points between a starting point and an ending point. The form of the function is linspace(start, stop, N).If the third argument N is omitted,then N=50.\n\n\n\n\n\n\nlogspace is doing equivelent things with logaritmic spacing. Other types of array creation techniques are listed below. Try around with these commands to get a feeling what they do.\n\n\n\n\n\n\n\n\n7.1.2.2 mgrid\nmgrid generates a multi-dimensional matrix with increasing value entries, for example in columns and rows:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n7.1.2.3 diag\ndiag generates a diagonal matrix with the list supplied to it. The values can be also offset from the main diagonal.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n7.1.2.4 zeros and ones\nzeros and ones creates a matrix with the dimensions given in the argument and filled with 0 or 1.",
    "crumbs": [
      "Lecture 4",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>NumPy Module</span>"
    ]
  },
  {
    "objectID": "lectures/lecture03/1_numpy.html#manipulating-numpy-arrays",
    "href": "lectures/lecture03/1_numpy.html#manipulating-numpy-arrays",
    "title": "7  NumPy Module",
    "section": "7.2 Manipulating NumPy arrays",
    "text": "7.2 Manipulating NumPy arrays\n\n7.2.1 Slicing\nSlicing is the name for extracting part of an array by the syntax M[lower:upper:step]\n\n\n\n\n\n\n\n\n\n\n\n\nAny of the three parameters in M[lower:upper:step] can be ommited.\n\n\n\n\n\n\n\n\n\n\n\n\nNegative indices counts from the end of the array (positive index from the begining):\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIndex slicing works exactly the same way for multidimensional arrays:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDifferences\n\n\n\nSlicing can be effectively used to calculate differences for example for the calculation of derivatives. Here the position \\(y_i\\) of an object has been measured at times \\(t_i\\) and stored in an array each. We wish to calculate the average velocity at the times \\(t_{i}\\) from the arrays by\n\\[\\begin{equation}\nv_{i}=\\frac{y_i-y_{i-1}}{t_{i}-t_{i-1}}\n\\end{equation}\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n7.2.2 Reshaping\nArrays can be reshaped into any form, which contains the same number of elements.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n7.2.3 Adding a new dimension: newaxis\nWith newaxis, we can insert new dimensions in an array, for example converting a vector to a column or row matrix.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStacking and repeating arrays\n\n\n\n\n\nUsing function repeat, tile, vstack, hstack, and concatenate we can create larger vectors and matrices from smaller ones. Please try the individual functions yourself in your notebook. We wont discuss them in detail.\n\n7.2.3.1 Tile and repeat\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n7.2.3.2 Concatenate\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n7.2.3.3 Hstack and vstack",
    "crumbs": [
      "Lecture 4",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>NumPy Module</span>"
    ]
  },
  {
    "objectID": "lectures/lecture03/1_numpy.html#applying-mathematical-functions",
    "href": "lectures/lecture03/1_numpy.html#applying-mathematical-functions",
    "title": "7  NumPy Module",
    "section": "7.3 Applying mathematical functions",
    "text": "7.3 Applying mathematical functions\nAll kinds of mathematica operations can be carried out on arrays. Typically these operation act element wise as seen from the examples below.\n\n7.3.1 Operation involving one array\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n7.3.2 Operations involving multiple arrays\nVector operations enable efficient element-wise calculations where corresponding elements at matching positions are processed simultaneously. Instead of handling elements one by one, these operations work on entire arrays at once, making them particularly fast. When multiplying two vectors using these operations, the result is not a single number (as in a dot product) but rather a new array where each element is the product of the corresponding elements from the input vectors. This element-wise multiplication is just one example of vector operations, which can include addition, subtraction, and other mathematical functions.",
    "crumbs": [
      "Lecture 4",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>NumPy Module</span>"
    ]
  },
  {
    "objectID": "lectures/lecture04/04-plotting.html",
    "href": "lectures/lecture04/04-plotting.html",
    "title": "8  Plotting",
    "section": "",
    "text": "8.1 Simple Plotting\nMatplotlib offers multiple levels of functionality for creating plots. Throughout this section, we’ll primarily focus on using commands that leverage default settings. This approach simplifies the process, as Matplotlib automatically handles much of the graph layout. These high-level commands are ideal for quickly creating effective visualizations without delving into intricate details. At the end of this section, we’ll briefly touch upon more advanced techniques that provide greater control over plot elements and layout.",
    "crumbs": [
      "Lecture 4",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Plotting</span>"
    ]
  },
  {
    "objectID": "lectures/lecture04/04-plotting.html#simple-plotting",
    "href": "lectures/lecture04/04-plotting.html#simple-plotting",
    "title": "8  Plotting",
    "section": "",
    "text": "8.1.1 Anatomy of a Line Plot\nTo create a basic line plot, use the following command:\nplt.plot(x, y)\nBy default, this generates a line plot. However, you can customize the appearance by adjusting various parameters within the plot() function. For instance, you can modify it to resemble a scatter plot by changing certain arguments. The versatility of this command allows for a range of visual representations beyond simple line plots.\nLet’s create a simple line plot of the sine function over the interval [0, 4π]. We’ll use NumPy to generate the x-values and calculate the corresponding y-values. The following code snippet demonstrates this process:\n1x = np.linspace(0, 4.*np.pi, 100)\n2y = np.sin(x)\n\n3plt.figure(figsize=(4,3))\n4plt.plot(x, y)\n5plt.tight_layout()\n6plt.show()\n\n1\n\nCreate an array of 100 values between 0 and 4π.\n\n2\n\nCalculate the sine of each value in the array.\n\n3\n\ncreate a new figure\n\n4\n\nplot the data\n\n5\n\nautomatically adjust the layout\n\n6\n\nshow the figure\n\n\nHere is the code in a Python cell:\n\n\n\n\n\n\nTry to change the values of the x and y arrays and see how the plot changes.\n\n\n\n\n\n\nWhy use plt.tight_layout()\n\n\n\n\n\nplt.tight_layout() is a very useful function in Matplotlib that automatically adjusts the spacing between plot elements to prevent overlapping and ensure that all elements fit within the figure area. Here’s what it does:\n\nPadding Adjustment: It adjusts the padding between and around subplots to prevent overlapping of axis labels, titles, and other elements.\nSubplot Spacing: It optimizes the space between multiple subplots in a figure.\nText Accommodation: It ensures that all text elements (like titles, labels, and legends) fit within the figure without being cut off.\nMargin Adjustment: It adjusts the margins around the entire figure to make sure everything fits neatly.\nAutomatic Resizing: If necessary, it can slightly resize subplot areas to accommodate all elements.\nLegend Positioning: It takes into account the presence and position of legends when adjusting layouts.\n\nKey benefits of using plt.tight_layout():\n\nIt saves time in manual adjustment of plot elements.\nIt helps create more professional-looking and readable plots.\nIt’s particularly useful when creating figures with multiple subplots or when saving figures to files.\n\nYou typically call plt.tight_layout() just before plt.show() or plt.savefig(). For example:\nplt.figure()\n# ... (your plotting code here)\nplt.tight_layout()\nplt.show()\n\n\n\n\n8.1.1.1 Axis Labels\nTo enhance the clarity and interpretability of our plots, it’s crucial to provide context through proper labeling. Let’s add descriptive axis labels to our diagram, a practice that significantly improves the readability and comprehension of the data being presented.\nplt.xlabel('x-label')\nplt.ylabel('y-label')\n\n\n\n\n\n\n\n\n8.1.1.2 Legends\nplt.plot(..., label=r'$\\sin(x)$')\nplt.legend(loc='lower left')\n\n\n\n\n\n\n\n\n8.1.1.3 Plots with error bars\nWhen plotting experimental data it is customary to include error bars that indicate graphically the degree of uncertainty that exists in the measurement of each data point. The MatPlotLib function errorbar plots data with error bars attached. It can be used in a way that either replaces or augments the plot function. Both vertical and horizontal error bars can be displayed. The figure below illustrates the use of error bars.\n\n\n\n\n\n\n\n\n8.1.1.4 Saving figures\nTo save a figure to a file we can use the savefig method in the Figure class. Matplotlib can generate high-quality output in a number formats, including PNG, JPG, EPS, SVG, PGF and PDF. For scientific papers, I recommend using PDF whenever possible. (LaTeX documents compiled with pdflatex can include PDFs using the includegraphics command). In some cases, PGF can also be good alternative.",
    "crumbs": [
      "Lecture 4",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Plotting</span>"
    ]
  },
  {
    "objectID": "lectures/lecture04/04-plotting.html#other-plot-types",
    "href": "lectures/lecture04/04-plotting.html#other-plot-types",
    "title": "8  Plotting",
    "section": "8.2 Other Plot Types",
    "text": "8.2 Other Plot Types\n\n8.2.1 Scatter plot\nIf you prefer to use symbols for plotting just use the\nplt.scatter(x,y)\ncommand of pylab. Note that the scatter command requires a x and y values and you can set the marker symbol (see an overview of the marker symbols).\n\n\n\n\n\n\n\n\n8.2.2 Histograms\nA very useful plotting command is also the hist command. It generates a histogram of the data provided. A histogram is a graphical representation of the distribution of numerical data. It is an estimate of the probability distribution of a continuous variable. To construct a histogram, the first step is to “bin” the range of values—that is, divide the entire range of values into a series of intervals—and then count how many values fall into each interval. The bins are usually specified as consecutive, non-overlapping intervals of a variable. The bins must be adjacent, and are often (but not required to be) of equal size.\nWhen using the histogram function, you have flexibility in how the data is grouped. If you only provide the dataset, the function will automatically determine appropriate bins. However, you can also specify custom bins by passing an array of intervals using the syntax hist(data, bins=b), where b is your custom array of bin edges. To normalize the histogram so that the total area under it equals 1, you can set the density parameter to True. It’s worth noting that the histogram function doesn’t just create a visual representation; it also returns useful information such as the count of data points in each bin and the bin edges themselves.\n\n\n\n\n\n\nPhysics Interlude- Probability density for finding an oscillating particle\n\n\n\nLet’s integrate histogram plotting with a fundamental physics concept: the simple harmonic oscillator in one dimension. This system is described by a specific equation of motion:\n\\[\\begin{equation}\n\\ddot{x}(t) = -\\omega^2 x(t)\n\\end{equation}\\]\nFor an initial elongation \\(\\Delta x\\) at \\(t=0\\), the solution is:\n\\[\\begin{equation}\nx(t) = \\Delta x \\cos(\\omega t)\n\\end{equation}\\]\nTo calculate the probability of finding the spring at a certain elongation, we need to consider the time spent at different positions. The time \\(dt\\) spent in the interval [\\(x(t)\\), \\(x(t)+dx\\)] depends on the speed:\n\\[\\begin{equation}\nv(t) = \\frac{dx}{dt} = -\\omega \\Delta x \\sin(\\omega t)\n\\end{equation}\\]\nThe probability of finding the oscillator in a certain interval is the fraction of time spent in this interval, normalized by half the oscillation period \\(T/2\\):\n\\[\\begin{equation}\n\\frac{dt}{T/2} = \\frac{1}{T/2}\\frac{dx}{v(t)} = \\frac{1}{T/2}\\frac{-dx}{\\omega \\Delta x \\sin(\\omega t)}\n\\end{equation}\\]\nGiven that \\(\\omega = 2\\pi/T\\), we can derive the probability density:\n\\[\\begin{equation}\np(x)dx = \\frac{1}{\\pi \\Delta x}\\frac{dx}{\\sqrt{1-\\left(\\frac{x(t)}{\\Delta x}\\right)^2}}\n\\end{equation}\\]\nThis probability density reveals that the spring is more likely to be found at elongations where its speed is low. This principle extends to non-equilibrium physics, where entities moving with variable speed are more likely to be found in locations where they move slowly.\nWe can visualize this using the histogram function. By evaluating the position at equidistant times using the equation of motion and creating a histogram of these positions, we can represent the probability of finding the oscillator at certain positions. When properly normalized, this histogram will reflect the theoretical probability density we derived.\n\n\n\n\n\n\n\n\n\n\n8.2.3 Setting plotting limits and excluding data\nIf you want to zoom in to s specific region of a plot you can set the limits of the individual axes.\n\n\n\n\n\n\n\n\n8.2.4 Masked arrays\nSometimes you encounter situations, when you wish to mask some of the data of your plot, because they are not showing real data as the vertical lines in the plot above. For this purpose, you can mask the data arrays in various ways to not show up. The example below uses the\nnp.ma.masked_where()\nfunction of NumPy, which takes a condition as the first argument and what should be returned if that condition is fulfilled.\n\n\n\n\n\n\nIf you look at the resulting array, you will find, that the entries have not been removed but replaced by --, so the values are not existent and thefore not plotted.\n\n\n\n\n\n\n\nLogarithmic plots\n\n\n\n\n\nData sets can span many orders of magnitude from fractional quantities much smaller than unity to values much larger than unity. In such cases it is often useful to plot the data on logarithmic axes.\n\n8.2.5 Semi-log plots\nFor data sets that vary exponentially in the independent variable, it is often useful to use one or more logarithmic axes. Radioactive decay of unstable nuclei, for example, exhibits an exponential decrease in the number of particles emitted from the nuclei as a function of time.\nMatPlotLib provides two functions for making semi-logarithmic plots, semilogx and semilogy, for creating plots with logarithmic x and y axes, with linear y and x axes, respectively. We illustrate their use in the program below, which made the above plots.\n\n\n\n\n\n\n\n\n8.2.6 Log-log plots\nMatPlotLib can also make log-log or double-logarithmic plots using the function loglog. It is useful when both the \\(x\\) and \\(y\\) data span many orders of magnitude. Data that are described by a power law \\(y=Ax^b\\), where \\(A\\) and \\(b\\) are constants, appear as straight lines when plotted on a log-log plot. Again, the loglog function works just like the plot function but with logarithmic axes.\n\n\n\n\n\n\n\n\n\n\n\n\n8.2.7 Combined plots\nYou can combine multiple data with the same axes by stacking multiple plots.\n\n\n\n\n\n\n\n\n8.2.8 Arranging multiple plots\nOften you want to create two or more graphs and place them next to one another, generally because they are related to each other in some way.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnimations\n\n\n\n\n\nMatplotlib can also be used to create animations. The FuncAnimation class makes it easy to create animations by repeatedly calling a function to update the plot. The following example shows a simple pendulum animation.\n\n\n\n\n\n\n\n\n\n\n\n8.2.9 Simple contour plot\n\n\n\n\n\n\nPhysics Interlude\n\n\n\n\n\n\n8.3 Contour and Density Plots\nA contour plots are useful tools to study two dimensional data, meaning \\(Z(X,Y)\\). A contour plots the lines of constant value of the function \\(Z\\).\n\n\n8.4 Understanding Wave Interference\nImagine throwing two stones into a pond. Each stone creates circular waves that spread out. When these waves meet, they create interesting patterns - this is called interference. Let’s explore this using physics and Python!\n\n8.4.1 What is a Wave?\nA wave can be described mathematically. For our example, we’ll look at spherical waves (like those in the pond). Each wave has: - An amplitude (how tall the wave is) - A wavelength (distance between wave peaks) - A frequency (how fast it oscillates)\n\n\n8.4.2 Mathematical Description\nFor a single wave source, we can write: \\[\\begin{equation}\nU(r)=e^{-i\\,k r}\n\\end{equation}\\]\nWhere: - \\(k\\) is related to the wavelength (\\(k = 2\\pi/\\lambda\\)) - \\(r\\) is the distance from the source - We’ve simplified by ignoring how the wave gets smaller as it travels (\\(1/r\\) term)\n\n\n8.4.3 Two Wave Sources\nWhen we have two wave sources (like two stones dropped in the pond): 1. Each source creates its own wave 2. The waves combine where they meet 3. The total wave is the sum of both waves\n\n\n\ninterference\n\n\nMathematically: \\[\\begin{equation}\nU_{total} = e^{-i\\,k r_1} + e^{-i\\,k r_2}\n\\end{equation}\\]\nWhere \\(r_1\\) and \\(r_2\\) are the distances from each source.\n\n\n8.4.4 What We See (Intensity)\nWhat we actually see is the intensity of the combined waves:\n\\[\\begin{equation}\n\\text{Intensity} \\propto |U_{total}|^2\n\\end{equation}\\]\nThis will show us where the waves:\n\nAdd up (bright regions - constructive interference)\nCancel out (dark regions - destructive interference)\n\nLet’s create a Python program to visualize this!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n8.4.5 Color contour plot\n\n\n\n\n\n\n\n\n8.4.6 Image plot\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdvanced Plotting - Explicit Version\n\n\n\n\n\n8.5 Advanced Plotting - Explicit Version\nWhile we have so far largely relied on the default setting and the automatic arrangement of plots, there is also a way to precisely design your plot. Python provides the tools of object oriented programming and thus modules provide classes which can be instanced into objects. This explicit interfaces allows you to control all details without the automatisms of pyplot.\nThe figure below, which is taken from the matplotlib documentation website shows the sets of commands and the objects in the figure, the commands refer to. It is a nice reference, when creating a figure.\n\n\n\nanatomy of a figure\n\n\n\n8.5.1 Plots with Multiple Spines\nSometimes it is very useful to plot different quantities in the same plot with the same x-axis but with different y-axes. Here is some example, where each line plot has its own y-axis.\n\n\n\n\n\n\n\n\n8.5.2 Insets\nInsets are plots within plots using their own axes. We therefore need to create two axes systems, if we want to have a main plot and and inset.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n8.5.3 Spine axis\n\n\n\n\n\n\n\n\n8.5.4 Polar plot\n\n\n\n\n\n\n\n\n8.5.5 Text annotation\nAnnotating text in matplotlib figures can be done using the text function. It supports LaTeX formatting just like axis label texts and titles:\n\n\n\n\n\n\n\n\n8.5.6 3D Plotting\nMatplotlib was initially designed with only two-dimensional plotting in mind. Around the time of the 1.0 release, some three-dimensional plotting utilities were built on top of Matplotlib’s two-dimensional display, and the result is a convenient (if somewhat limited) set of tools for three-dimensional data visualization. Three-dimensional plots are enabled by importing the mplot3d toolkit, included with the main Matplotlib installation:\n\n\n\n\n\n\nOnce this submodule is imported, a three-dimensional axes can be created by passing the keyword projection=‘3d’ to any of the normal axes creation routines:\n\n8.5.6.1 Projection Scence\n\n\n\n\n\n\nWith this three-dimensional axes enabled, we can now plot a variety of three-dimensional plot types. Three-dimensional plotting is one of the functionalities that benefits immensely from viewing figures interactively rather than statically in the notebook; recall that to use interactive figures, you can use %matplotlib notebook rather than %matplotlib inline when running this code.\n\n\n8.5.6.2 Line Plotting in 3D\nfrom sets of (x, y, z) triples. In analogy with the more common two-dimensional plots discussed earlier, these can be created using the ax.plot3D and ax.scatter3D functions. The call signature for these is nearly identical to that of their two-dimensional counterparts, so you can refer to Simple Line Plots and Simple Scatter Plots for more information on controlling the output. Here we’ll plot a trigonometric spiral, along with some points drawn randomly near the line:\n\n\n\n\n\n\nNotice that by default, the scatter points have their transparency adjusted to give a sense of depth on the page. While the three-dimensional effect is sometimes difficult to see within a static image, an interactive view can lead to some nice intuition about the layout of the points. Use the scatter3D or the plot3D method to plot a random walk in 3-dimensions in your exercise.\n\n\n8.5.6.3 Surface Plotting\nA surface plot is like a wireframe plot, but each face of the wireframe is a filled polygon. Adding a colormap to the filled polygons can aid perception of the topology of the surface being visualized:",
    "crumbs": [
      "Lecture 4",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Plotting</span>"
    ]
  },
  {
    "objectID": "lectures/lecture04/04-plotting.html#contour-and-density-plots",
    "href": "lectures/lecture04/04-plotting.html#contour-and-density-plots",
    "title": "8  Plotting",
    "section": "8.3 Contour and Density Plots",
    "text": "8.3 Contour and Density Plots\nA contour plots are useful tools to study two dimensional data, meaning \\(Z(X,Y)\\). A contour plots the lines of constant value of the function \\(Z\\).",
    "crumbs": [
      "Lecture 4",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Plotting</span>"
    ]
  },
  {
    "objectID": "lectures/lecture04/04-plotting.html#understanding-wave-interference",
    "href": "lectures/lecture04/04-plotting.html#understanding-wave-interference",
    "title": "8  Plotting",
    "section": "8.4 Understanding Wave Interference",
    "text": "8.4 Understanding Wave Interference\nImagine throwing two stones into a pond. Each stone creates circular waves that spread out. When these waves meet, they create interesting patterns - this is called interference. Let’s explore this using physics and Python!\n\n8.4.1 What is a Wave?\nA wave can be described mathematically. For our example, we’ll look at spherical waves (like those in the pond). Each wave has: - An amplitude (how tall the wave is) - A wavelength (distance between wave peaks) - A frequency (how fast it oscillates)\n\n\n8.4.2 Mathematical Description\nFor a single wave source, we can write: \\[\\begin{equation}\nU(r)=e^{-i\\,k r}\n\\end{equation}\\]\nWhere: - \\(k\\) is related to the wavelength (\\(k = 2\\pi/\\lambda\\)) - \\(r\\) is the distance from the source - We’ve simplified by ignoring how the wave gets smaller as it travels (\\(1/r\\) term)\n\n\n8.4.3 Two Wave Sources\nWhen we have two wave sources (like two stones dropped in the pond): 1. Each source creates its own wave 2. The waves combine where they meet 3. The total wave is the sum of both waves\n\n\n\ninterference\n\n\nMathematically: \\[\\begin{equation}\nU_{total} = e^{-i\\,k r_1} + e^{-i\\,k r_2}\n\\end{equation}\\]\nWhere \\(r_1\\) and \\(r_2\\) are the distances from each source.\n\n\n8.4.4 What We See (Intensity)\nWhat we actually see is the intensity of the combined waves:\n\\[\\begin{equation}\n\\text{Intensity} \\propto |U_{total}|^2\n\\end{equation}\\]\nThis will show us where the waves:\n\nAdd up (bright regions - constructive interference)\nCancel out (dark regions - destructive interference)\n\nLet’s create a Python program to visualize this!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n8.4.5 Color contour plot\n\n\n\n\n\n\n\n\n8.4.6 Image plot",
    "crumbs": [
      "Lecture 4",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Plotting</span>"
    ]
  },
  {
    "objectID": "lectures/lecture04/04-plotting.html#advanced-plotting---explicit-version",
    "href": "lectures/lecture04/04-plotting.html#advanced-plotting---explicit-version",
    "title": "8  Plotting",
    "section": "8.5 Advanced Plotting - Explicit Version",
    "text": "8.5 Advanced Plotting - Explicit Version\nWhile we have so far largely relied on the default setting and the automatic arrangement of plots, there is also a way to precisely design your plot. Python provides the tools of object oriented programming and thus modules provide classes which can be instanced into objects. This explicit interfaces allows you to control all details without the automatisms of pyplot.\nThe figure below, which is taken from the matplotlib documentation website shows the sets of commands and the objects in the figure, the commands refer to. It is a nice reference, when creating a figure.\n\n\n\nanatomy of a figure\n\n\n\n8.5.1 Plots with Multiple Spines\nSometimes it is very useful to plot different quantities in the same plot with the same x-axis but with different y-axes. Here is some example, where each line plot has its own y-axis.\n\n\n\n\n\n\n\n\n8.5.2 Insets\nInsets are plots within plots using their own axes. We therefore need to create two axes systems, if we want to have a main plot and and inset.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n8.5.3 Spine axis\n\n\n\n\n\n\n\n\n8.5.4 Polar plot\n\n\n\n\n\n\n\n\n8.5.5 Text annotation\nAnnotating text in matplotlib figures can be done using the text function. It supports LaTeX formatting just like axis label texts and titles:\n\n\n\n\n\n\n\n\n8.5.6 3D Plotting\nMatplotlib was initially designed with only two-dimensional plotting in mind. Around the time of the 1.0 release, some three-dimensional plotting utilities were built on top of Matplotlib’s two-dimensional display, and the result is a convenient (if somewhat limited) set of tools for three-dimensional data visualization. Three-dimensional plots are enabled by importing the mplot3d toolkit, included with the main Matplotlib installation:\n\n\n\n\n\n\nOnce this submodule is imported, a three-dimensional axes can be created by passing the keyword projection=‘3d’ to any of the normal axes creation routines:\n\n8.5.6.1 Projection Scence\n\n\n\n\n\n\nWith this three-dimensional axes enabled, we can now plot a variety of three-dimensional plot types. Three-dimensional plotting is one of the functionalities that benefits immensely from viewing figures interactively rather than statically in the notebook; recall that to use interactive figures, you can use %matplotlib notebook rather than %matplotlib inline when running this code.\n\n\n8.5.6.2 Line Plotting in 3D\nfrom sets of (x, y, z) triples. In analogy with the more common two-dimensional plots discussed earlier, these can be created using the ax.plot3D and ax.scatter3D functions. The call signature for these is nearly identical to that of their two-dimensional counterparts, so you can refer to Simple Line Plots and Simple Scatter Plots for more information on controlling the output. Here we’ll plot a trigonometric spiral, along with some points drawn randomly near the line:\n\n\n\n\n\n\nNotice that by default, the scatter points have their transparency adjusted to give a sense of depth on the page. While the three-dimensional effect is sometimes difficult to see within a static image, an interactive view can lead to some nice intuition about the layout of the points. Use the scatter3D or the plot3D method to plot a random walk in 3-dimensions in your exercise.\n\n\n8.5.6.3 Surface Plotting\nA surface plot is like a wireframe plot, but each face of the wireframe is a filled polygon. Adding a colormap to the filled polygons can aid perception of the topology of the surface being visualized:",
    "crumbs": [
      "Lecture 4",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Plotting</span>"
    ]
  },
  {
    "objectID": "lectures/lecture05/1_classes.html",
    "href": "lectures/lecture05/1_classes.html",
    "title": "9  Classes and Objects",
    "section": "",
    "text": "9.1 Object oriented programming\nA very useful programming concept is object oriented programming. In all the programs we wrote till now, we have designed our program around functions i.e. blocks of statements which manipulate data. This is called the procedure-oriented way of programming.\nThere is another way of organizing your program which is to combine data and functionality and wrap it inside something called an object. This is called the object oriented programming paradigm, which will be useful especially for larger programs.",
    "crumbs": [
      "Lecture 5",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Classes and Objects</span>"
    ]
  },
  {
    "objectID": "lectures/lecture05/1_classes.html#object-oriented-programming",
    "href": "lectures/lecture05/1_classes.html#object-oriented-programming",
    "title": "9  Classes and Objects",
    "section": "",
    "text": "9.1.1 Classes and Objects\nObject-oriented programming is built upon two fundamental concepts: classes and objects.\n\nA class is a blueprint or template that defines a new type of object. Think of it as a mold that creates objects with specific characteristics and behaviors.\nObjects are specific instances of a class. They have two main components:\n\nProperties (also called attributes or fields): Variables that store data within the object\nMethods: Functions that define what the object can do\n\nProperties come in two varieties:\n\nInstance variables: Unique to each object instance (each object has its own copy)\nClass variables: Shared among all instances of the class (one copy for the entire class)\n\n\nFor example, if you had a Car class: - Instance variables might include color and mileage (unique to each car) - Class variables might include number_of_wheels (same for all cars) - Methods might include start_engine() or brake()\n\n\n9.1.2 Creating Classes\nTo define a class in Python, we use this basic syntax:\nclass ClassName:\n    # Class content goes here\nThe definition starts with the class keyword, followed by the class name, and a colon. The class content is indented and contains all properties and methods of the class.\nHere’s a minimal example:\n\n\n\n\n\n\nTo create an object (an instance) of this class:",
    "crumbs": [
      "Lecture 5",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Classes and Objects</span>"
    ]
  },
  {
    "objectID": "lectures/lecture05/1_classes.html#class-methods",
    "href": "lectures/lecture05/1_classes.html#class-methods",
    "title": "9  Classes and Objects",
    "section": "9.2 Class Methods",
    "text": "9.2 Class Methods\nMethods are functions that belong to a class. They define the behavior of the class and can operate on the class’s properties.\n\n\n\n\n\n\nUnderstanding self in Python Classes\n\n\n\nEvery method in a Python class automatically receives a special first parameter, conventionally named self. This parameter refers to the specific instance of the class that calls the method.\nKey points about self: - It’s automatically passed by Python when you call a method - It gives the method access to the instance’s properties - By convention, we name it self (though technically you could use any valid name) - You don’t include it when calling the method\nExample:\nclass Colloid:\n    def type(self):  # self is automatically provided\n        print('I am a plastic colloid')\n\n# Usage:\nparticle = Colloid()\nparticle.type()  # Notice: no argument needed for self\nIn this example, even though type() appears to take no arguments when called, it actually receives the particle object as self.\n\n\n\n\n\n\n\n\n\n9.2.1 The Constructor Method: __init__\nThe __init__ method (called the constructor) is a special method that initializes a new object when it’s created. It allows you to: - Set up initial values for the object’s properties - Perform any setup the object needs when it’s created\nThe name has double underscores (dunders) at both ends: __init__\nHere’s an example:\n\n\n\n\n\n\nUsing the class:\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nPython also provides a __del__ method (destructor) that’s called when an object is deleted. We’ll see this in action later.\n\n\n\n\n9.2.2 The String Representation: __str__ Method\nThe __str__ method defines how an object should be represented as a string. Python automatically calls this method when: - You use print(object) - You convert the object to a string using str(object)\nHere’s an example:\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe .1f format specification means the radius will be displayed with one decimal place. You can customize this string representation to show whatever information about your object is most relevant.\n\n\nLet’s see it in action:",
    "crumbs": [
      "Lecture 5",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Classes and Objects</span>"
    ]
  },
  {
    "objectID": "lectures/lecture05/1_classes.html#understanding-class-and-instance-variables",
    "href": "lectures/lecture05/1_classes.html#understanding-class-and-instance-variables",
    "title": "9  Classes and Objects",
    "section": "9.3 Understanding Class and Instance Variables",
    "text": "9.3 Understanding Class and Instance Variables\nIn Python classes, we can have two types of variables that store data:\n\n9.3.1 Class Variables (Shared Data)\n\nShared among all instances of a class\nDefined inside the class but outside any method\nAll objects share the same copy of these variables\nChanges affect all instances\nUseful for tracking data common to all instances\n\n\n\n9.3.2 Instance Variables (Individual Data)\n\nUnique to each instance/object\nUsually defined in __init__\nEach object has its own copy\nChanges only affect that specific instance\nUseful for object-specific properties\n\nHere’s a practical example:\n\n\n\n\n\n\nLet’s see how it works:\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nCommon uses for class variables:\n\nCounters (like tracking total instances)\nConstants shared by all instances\nConfiguration values for all objects",
    "crumbs": [
      "Lecture 5",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Classes and Objects</span>"
    ]
  },
  {
    "objectID": "lectures/lecture05/2_brownian_motion.html",
    "href": "lectures/lecture05/2_brownian_motion.html",
    "title": "10  Brownian Motion",
    "section": "",
    "text": "10.1 Brownian Motion",
    "crumbs": [
      "Lecture 5",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Brownian Motion</span>"
    ]
  },
  {
    "objectID": "lectures/lecture05/2_brownian_motion.html#brownian-motion",
    "href": "lectures/lecture05/2_brownian_motion.html#brownian-motion",
    "title": "10  Brownian Motion",
    "section": "",
    "text": "10.1.1 What is Brownian Motion?\nImagine a dust particle floating in water. If you look at it under a microscope, you’ll see it moving in a random, zigzag pattern. This is Brownian motion!\n\n\n10.1.2 Why Does This Happen?\nWhen we observe Brownian motion, we’re seeing the effects of countless molecular collisions. Water isn’t just a smooth, continuous fluid - it’s made up of countless tiny molecules that are in constant motion. These water molecules are continuously colliding with our particle from all directions. Each individual collision causes the particle to move just a tiny bit, barely noticeable on its own. However, when millions of these tiny collisions happen every second from random directions, they create the distinctive zigzag motion we observe.\n\n\n10.1.3 The Simplified Math Behind It\nWhen our particle moves:\n\nEach step is random in direction\nThe size of each step depends on:\n\nTemperature (warmer = more movement)\nTime between steps\nA property called the “diffusion coefficient” (D)\n\n\n\n\n10.1.4 How We Can Simulate This?\nIn Python, we can simulate these random steps using random number. These random numbers can be generated with the numpy library. Numpy provides a number of different functions that provide random numbers from different distributions. For Brownian motion, we use a special distribution called the “normal distribution”.\nstep_size = np.sqrt(2 * D * time_step)\ndx = random_number * step_size  # Random step in x direction\ndy = random_number * step_size  # Random step in y direction\n\nnew_x = old_x + dx\nnew_y = old_y + dy\nWhere:\n\nD is how easily the particle moves (diffusion coefficient)\ntime_step is how often we update the position\nrandom_number is chosen from a special “normal distribution”\n\n\n\n\n\n\n\nTip\n\n\n\nWhen simulating Brownian motion, we use np.random.normal to generate random steps following this distribution. The normal distribution is characterized by two parameters: the mean and the standard deviation. The mean is the average value, and the standard deviation is a measure of how spread out the values are. For Brownian motion, we use a standard deviation that depends on the diffusion coefficient and the time step. The standard deviation \\(\\sigma=\\sqrt{2D \\Delta t}\\) determines the typical step size, which we can use as a parameter in the normal distribution.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdvanced Mathematical Details\n\n\n\n\n\nThe Brownian motion of a colloidal particle results from collisions with surrounding solvent molecules. These collisions lead to a probability distribution described by:\n\\[\np(x,\\Delta t)=\\frac{1}{\\sqrt{4\\pi D \\Delta t}}e^{-\\frac{x^2}{4D \\Delta t}}\n\\]\nwhere: - \\(D\\) is the diffusion coefficient - \\(\\Delta t\\) is the time step - The variance is \\(\\sigma^2=2D \\Delta t\\)\nThis distribution emerges from the central limit theorem, as shown by Lindenberg and Lévy, when considering many infinitesimally small random steps.\nThe evolution of the probability density function \\(p(x,t)\\) is governed by the diffusion equation:\n\\[\n\\frac{\\partial p}{\\partial t}=D\\frac{\\partial^2 p}{\\partial x^2}\n\\]\nThis partial differential equation, also known as Fick’s second law, describes how the concentration of particles evolves over time due to diffusive processes. The Gaussian distribution above is the fundamental solution (Green’s function) of this diffusion equation, representing how an initially localized distribution spreads out over time.\nThe connection between the microscopic random motion and the macroscopic diffusion equation was first established by Einstein in his 1905 paper on Brownian motion, providing one of the earliest quantitative links between statistical mechanics and thermodynamics.",
    "crumbs": [
      "Lecture 5",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Brownian Motion</span>"
    ]
  },
  {
    "objectID": "lectures/lecture05/2_brownian_motion.html#why-use-a-class",
    "href": "lectures/lecture05/2_brownian_motion.html#why-use-a-class",
    "title": "10  Brownian Motion",
    "section": "10.2 Why Use a Class?",
    "text": "10.2 Why Use a Class?\nA class is perfect for this physics simulation because each colloidal particle:\n\nHas specific properties\n\nSize (radius)\nCurrent position\nMovement history\nDiffusion coefficient\n\nFollows certain behaviors\n\nMoves randomly (Brownian motion)\nUpdates its position over time\nKeeps track of where it’s been\n\nCan exist alongside other particles\n\nMany particles can move independently\nEach particle keeps track of its own properties\nParticles can have different sizes\n\nNeeds to track its state over time\n\nRemember previous positions\nCalculate distances moved\nMaintain its own trajectory\n\n\nThis natural mapping between real particles and code objects makes classes an ideal choice for our simulation.",
    "crumbs": [
      "Lecture 5",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Brownian Motion</span>"
    ]
  },
  {
    "objectID": "lectures/lecture05/2_brownian_motion.html#class-design",
    "href": "lectures/lecture05/2_brownian_motion.html#class-design",
    "title": "10  Brownian Motion",
    "section": "10.3 Class Design",
    "text": "10.3 Class Design\nLet’s design a Python class to simulate colloidal particles undergoing Brownian motion. This object-oriented approach will help us manage multiple particles with different properties and behaviors.\n\n10.3.1 Class-Level Properties\nThe Colloid class will maintain information shared by all particles:\n\nA counter for the total number of particles\nThe physical constant \\(k_B T/(6\\pi\\eta) = 2.2×10^{-19}\\) (combining temperature and fluid properties)\n\n\n\n10.3.2 Class Methods\nThe class will provide these shared functions:\n\nhow_many(): Reports the total number of particles\n__str__: Creates a readable description of a particle’s properties\n\n\n\n10.3.3 Instance Properties\nEach individual particle object will have:\n\nRadius (R)\nPosition history (x and y coordinates)\nUnique identifier (index)\nDiffusion coefficient (\\(D = k_B T/(6\\pi\\eta R)\\))\n\n\n\n10.3.4 Instance Methods\nEach particle will be able to:\n\nsim_trajectory(): Generate a complete motion path\nupdate(dt): Calculate one step of Brownian motion\nget_trajectory(): Return its movement history\nget_D(): Provide its diffusion coefficient\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nNote that the function sim_trajectory is actually calling the function update of the same object to generate the whole trajectory at once.",
    "crumbs": [
      "Lecture 5",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Brownian Motion</span>"
    ]
  },
  {
    "objectID": "lectures/lecture05/2_brownian_motion.html#simulating",
    "href": "lectures/lecture05/2_brownian_motion.html#simulating",
    "title": "10  Brownian Motion",
    "section": "10.4 Simulating",
    "text": "10.4 Simulating\nWith the help of this Colloid class, we would like to carry out simulations of Brownian motion of multiple particles. The simulations shall\n\ntake n=200 particles\nhave N=200 trajectory points each\nstart all at 0,0\nparticle objects should be stored in a list p_list",
    "crumbs": [
      "Lecture 5",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Brownian Motion</span>"
    ]
  },
  {
    "objectID": "lectures/lecture05/2_brownian_motion.html#plotting-the-trajectories",
    "href": "lectures/lecture05/2_brownian_motion.html#plotting-the-trajectories",
    "title": "10  Brownian Motion",
    "section": "10.5 Plotting the trajectories",
    "text": "10.5 Plotting the trajectories\nThe next step is to plot all the trajectories.",
    "crumbs": [
      "Lecture 5",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Brownian Motion</span>"
    ]
  },
  {
    "objectID": "lectures/lecture05/2_brownian_motion.html#characterizing-the-brownian-motion",
    "href": "lectures/lecture05/2_brownian_motion.html#characterizing-the-brownian-motion",
    "title": "10  Brownian Motion",
    "section": "10.6 Characterizing the Brownian motion",
    "text": "10.6 Characterizing the Brownian motion\nNow that we have a number of trajectories, we can analyze the motion of our Brownian particles.\n\n10.6.1 Calculate the particle speed\nOne way is to calculate its speed by measuring how far it traveled within a certain time \\(n\\, dt\\), where \\(dt\\) is the timestep of out simulation. We can do that as\n\\[\\begin{equation}\nv(n dt) = \\frac{&lt;\\sqrt{(x_{i+n}-x_{i})^2+(y_{i+n}-y_{i})^2}&gt;}{n\\,dt}\n\\end{equation}\\]\nThe angular brackets on the top take care of the fact that we can measure the distance traveled within a certain time \\(n\\, dt\\) several times along a trajectory.\nThese values can be used to calculate a mean speed. Note that there is not an equal amount of data pairs for all separations available. For \\(n=1\\) there are 5 distances available. For \\(n=5\\), however, only 1. This changes the statistical accuracy of the mean.\n\n\n\n\n\n\nThe result of this analysis shows, that each particle has an apparent speed which seems to increase with decreasing time of observation or which decreases with increasing time. This would mean that there is some friction at work, which slows down the particle in time, but this is apparently not true. Also an infinite speed at zero time appears to be unphysical. The correct answer is just that the speed is no good measure to characterize the motion of a Brownian particle.\n\n\n10.6.2 Calculate the particle mean squared displacement\nA better way to characterize the motion of a Brownian particle is the mean squared displacement, as we have already mentioned it in previous lectures. We may compare our simulation now to the theoretical prediction, which is\n\\[\\begin{equation}\n\\langle \\Delta r^{2}(t)\\rangle=2 d D t\n\\end{equation}\\]\nwhere \\(d\\) is the dimension of the random walk, which is \\(d=2\\) in our case.\n\n\n\n\n\n\nThe results show that the mean squared displacement of the individual particles follows on average the theoretical predictions of a linear growth in time. That means, we are able to read the diffusion coefficient from the slope of the MSD of the individual particles if recorded in a simulation or an experiment.\nYet, each individual MSD is deviating strongly from the theoretical prediction especially at large times. This is due to the fact mentioned earlier that our simulation (or experimental) data only has a limited number of data points, while the theoretical prediction is made for the limit of infinite data points.\n\n\n\n\n\n\nAnalysis of MSD data\n\n\n\nSingle particle tracking, either in the experiment or in numerical simulations can therefore only deliver an estimate of the diffusion coefficient and care should be taken when using the whole MSD to obtain the diffusion coefficient. One typically uses only a short fraction of the whole MSD data at short times.",
    "crumbs": [
      "Lecture 5",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Brownian Motion</span>"
    ]
  },
  {
    "objectID": "lectures/lecture06/1_input_output.html",
    "href": "lectures/lecture06/1_input_output.html",
    "title": "11  Input and output",
    "section": "",
    "text": "To try out all of the functions of todays notebook, we will need to use the embedded JupyterLite notebook. To use the notebook, click ob File -&gt; Open from URL and paste the following link into the input field:\nhttps://raw.githubusercontent.com/fcichos/EMPP24/refs/heads/main/seminars/1_input_output.ipynb\nTo download the data files, click ob File -&gt; Open from URL and paste the following links into the input field:\nhttps://raw.githubusercontent.com/fcichos/EMPP24/refs/heads/main/seminars/MyData.txt\nhttps://raw.githubusercontent.com/fcichos/EMPP24/refs/heads/main/seminars/2018-04-11_sds011_sensor_12253.csv\nhttps://raw.githubusercontent.com/fcichos/EMPP24/refs/heads/main/seminars/2018-04-12_sds011_sensor_12253.csv\nYou should then have 3 data files and one notebook. You can then go into fullscreen mode.\nFull Screen",
    "crumbs": [
      "Lecture 6",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Input and output</span>"
    ]
  },
  {
    "objectID": "lectures/lecture06/1_curve_fitting.html",
    "href": "lectures/lecture06/1_curve_fitting.html",
    "title": "12  Curve fitting",
    "section": "",
    "text": "12.1 Idea\nIn experimental physics, we often collect data points to understand the underlying physical phenomena. This process involves fitting a mathematical model to the experimental data.\nThe data typically comes as a series of paired points:\nEach point \\(\\{x_i, y_i\\}\\) may represent the result of multiple independent measurements. For instance, \\(y_1\\) could be the mean of several measurements \\(y_{1,j}\\):\n\\[y_1 = \\frac{1}{N}\\sum_{j=1}^N y_{1,j}\\]\nWhen these measurements have an uncertainty \\(\\sigma\\) for individual readings, the sum of all measurements has a variance of \\(N\\sigma^2\\) and a standard deviation of \\(\\sqrt{N}\\sigma\\). Consequently, the mean value has an associated error (standard deviation) known as the Standard Error of the Mean (SEOM):\n\\[\\sigma_{SEOM} = \\frac{\\sigma}{\\sqrt{N}}\\]\nThis SEOM is crucial in physics measurements.\nIt’s also important to note the definition of variance:\n\\[\\sigma_1^2 = \\frac{1}{N} \\sum_{j=1}^N (y_{1,j} - y_1)^2\\]\nThis statistical framework forms the basis for analyzing experimental data and fitting mathematical models to understand the underlying physics.",
    "crumbs": [
      "Lecture 6",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Curve fitting</span>"
    ]
  },
  {
    "objectID": "lectures/lecture06/1_curve_fitting.html#idea",
    "href": "lectures/lecture06/1_curve_fitting.html#idea",
    "title": "12  Curve fitting",
    "section": "",
    "text": "x-data\ny-data\n\n\n\n\n\\(x_{1}\\)\n\\(y_{1}\\)\n\n\n\\(x_{2}\\)\n\\(y_{2}\\)\n\n\n…\n…\n\n\n\\(x_{N}\\)\n\\(y_{N}\\)",
    "crumbs": [
      "Lecture 6",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Curve fitting</span>"
    ]
  },
  {
    "objectID": "lectures/lecture06/1_curve_fitting.html#least-squares",
    "href": "lectures/lecture06/1_curve_fitting.html#least-squares",
    "title": "12  Curve fitting",
    "section": "12.2 Least squares",
    "text": "12.2 Least squares\nIn experimental physics, we often collect data points to understand the underlying physical phenomena. To make sense of this data, we fit a mathematical model to it. One common method for fitting data is the least squares method.\n\n12.2.1 Why use least squares fitting?\nThe goal of least squares fitting is to find the set of parameters for our model that best describes the data. This is done by minimizing the differences (or residuals) between the observed data points and the model’s predictions.\n\n\n12.2.2 Gaussian uncertainty and probability\nWhen we take measurements, there is always some uncertainty. Often, this uncertainty can be modeled using a Gaussian (normal) distribution. This distribution is characterized by its mean (average value) and standard deviation (a measure of the spread of the data).\nIf we describe our data with a model function, which delivers a function value \\(f(x_{i},a)\\) for a set of parameters \\(a\\) at the position \\(x_{i}\\), the Gaussian uncertainty dictates a probability of finding a data value \\(y_{i}\\):\n\\[\\begin{equation}\np_{y_{i}}=\\frac{1}{\\sqrt{2\\pi}\\sigma_{i}}\\exp\\left(-\\frac{(y_{i}-f(x_{i},a))^2}{2\\sigma_{i}^2}\\right)\n\\end{equation}\\]\nHere, \\(\\sigma_{i}\\) represents the uncertainty in the measurement \\(y_{i}\\).\n\n\n12.2.3 Combining probabilities for multiple data points\nTo understand how well our model fits all the data points, we need to consider the combined probability of observing all the data points. This is done by multiplying the individual probabilities:\n\\[\\begin{equation}\np(y_{1},\\ldots,y_{N})=\\prod_{i=1}^{N}\\frac{1}{\\sqrt{2\\pi}\\sigma_{i}}\\exp\\left(-\\frac{(y_{i}-f(x_{i},a))^2}{2\\sigma_{i}^2}\\right)\n\\end{equation}\\]\n\n\n12.2.4 Maximizing the joint probability\nThe best fit of the model to the data is achieved when this joint probability is maximized. To simplify the calculations, we take the logarithm of the joint probability:\n\\[\\begin{equation}\n\\ln(p(y_{1},\\ldots,y_{N}))=-\\frac{1}{2}\\sum_{i=1}^{N}\\left( \\frac{y_{i}-f(x_{i},a)}{\\sigma_{i}}\\right)^2 - \\sum_{i=1}^{N}\\ln\\left( \\sigma_{i}\\sqrt{2\\pi}\\right)\n\\end{equation}\\]\nThe first term on the right side (except the factor 1/2) is the least squared deviation, also known as \\(\\chi^{2}\\):\n\\[\\begin{equation}\n\\chi^{2} =\\sum_{i=1}^{N}\\left( \\frac{y_{i}-f(x_{i},a)}{\\sigma_{i}}\\right)^2\n\\end{equation}\\]\nThe second term is just a constant value given by the uncertainties of our experimental data.",
    "crumbs": [
      "Lecture 6",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Curve fitting</span>"
    ]
  },
  {
    "objectID": "lectures/lecture06/1_curve_fitting.html#data",
    "href": "lectures/lecture06/1_curve_fitting.html#data",
    "title": "12  Curve fitting",
    "section": "12.3 Data",
    "text": "12.3 Data\nLet’s have a look at the meaning of this equation. Let’s assume we measure the trajectory of a ball that has been thrown at an angle \\(\\alpha\\) with an initial velocity \\(v_{0}\\). We have collected data points by measuring the height of the ball above the ground at equally spaced distances from the throwing person.\n\n\n\n\n    \n      \n      x\n      y\n      error\n    \n  \n\n\n\n    \n        \n        \n        \n        \n        \n        \n        \n        \n    \n    \n   \n    \n      \n  \n        \n    \n    \n  \n        \n    \n    \n  \n        \n    \n      \n  \n        \n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n        \n    \n\n\n\n\nLoading ITables v2.2.2 from the internet...\n(need help?)\n\n\n\n\n\n\n\n\nThe table above shows the measured data points \\(y_{i}\\) at the position \\(x_{i}\\) with the associated uncertainties \\(\\sigma_{i}\\).\nWe can plot the data and expect, of course, a parabola. Therefore, we model our experimental data with a parabola like\n\\[\\begin{equation}\ny = ax^2 + bx + c\n\\end{equation}\\]\nwhere the parameter \\(a\\) must be negative since the parabola is inverted.\nI have created an interactive plot with an interact widget, as this allows you to play around with the parameters. The value of \\(\\chi^2\\) is also included in the legend, so you can get an impression of how good your fit of the data is.\n\nviewof aSlider = Inputs.range([-4, 0], { label: \"a\", step: 0.01, value: -1.7 });\nviewof bSlider = Inputs.range([-2, 2], { label: \"b\", step: 0.01, value: 1.3 });\nviewof cSlider = Inputs.range([-2, 2], { label: \"c\", step: 0.01, value: 1.0 });\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfiltered = transpose(data);\n// Create the plot\n\nxValues = Array.from({ length: 100 }, (_, i) =&gt; i / 100);\nparabolaData = xValues.map(x =&gt; ({ x, y: parabola(x, aSlider, bSlider, cSlider) }));\n\n\nparabola = (x, a, b, c) =&gt; a * x**2 + b * x + c\n\ncalculateChiSquared = (data, a, b, c) =&gt; {\n  let chisq = 0\n  let x= data.map(d =&gt; d.x)\n  let y= data.map(d =&gt; d.y)\n  let err= data.map(d =&gt; d.error)\n  for (let i = 0; i &lt; x.length; i++) {\n    let y_model = parabola(x[i], a, b, c)\n    chisq += ((y[i] - y_model) / err[i])**2\n  }\n  return chisq\n}\n\nchisq = calculateChiSquared(filtered, aSlider, bSlider, cSlider)\n\nPlot.plot({\n  marks: [\n    Plot.dot(filtered, { x: \"x\", y: \"y\" }),\n    Plot.ruleY(filtered, { x: \"x\", y1: d =&gt; d.y - d.error, y2: d =&gt; d.y + d.error }),\n    Plot.line(parabolaData, { x: \"x\", y: \"y\" }),\n    Plot.text([{ x: 0.8, y: 1.5, label: `χ²: ${chisq.toFixed(2)}` }], {\n          x: \"x\",\n          y: \"y\",\n          text: \"label\",\n          dy: -10, // Adjust vertical position if needed\n          fill: \"black\", // Set text color\n          fontSize: 16\n        }),\n    Plot.frame()\n  ],\n  x: {\n    label: \"X Axis\",\n    labelAnchor: \"center\",\n    labelOffset: 35,\n    grid: true,\n    tickFormat: \".2f\", // Format ticks to 2 decimal places\n    domain: [0, 1]\n  },\n  y: {\n    label: \"Y Axis\",\n    grid: true,\n    tickFormat: \".2f\", // Format ticks to 2 decimal places\n    labelAnchor: \"center\",  // Center the label on its axis\n    labelAngle: -90,\n    labelOffset: 60,\n    domain: [0, 2],\n  },\n  width: 400,\n  height: 400,\n  marginLeft: 100,\n  marginBottom: 40,\n  style: {\n    fontSize: \"14px\",          // This sets the base font size\n    \"axis.label\": {\n      fontSize: \"18px\",        // This sets the font size for axis labels\n      fontWeight: \"bold\"       // Optionally make it bold\n    },\n    \"axis.tick\": {\n      fontSize: \"14px\"         // This sets the font size for tick labels\n    }\n  },\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe have that troubling point at the right edge with a large uncertainty. However, since the value of \\(\\chi^2\\) divides the deviation by the uncertainty \\(\\sigma_{i}\\), the weight for this point overall in the \\(\\chi^2\\) is smaller than for the other points.\n\\[\\begin{equation}\n\\chi^{2}=\\sum_{i=1}^{N}\\left( \\frac{y_{i}-f(x_{i},a)}{\\sigma_{i}}\\right)^2\n\\end{equation}\\]\nYou may simply check the effect by changing the uncertainty of the last data points in the error array.",
    "crumbs": [
      "Lecture 6",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Curve fitting</span>"
    ]
  },
  {
    "objectID": "lectures/lecture06/1_curve_fitting.html#least-square-fitting",
    "href": "lectures/lecture06/1_curve_fitting.html#least-square-fitting",
    "title": "12  Curve fitting",
    "section": "12.4 Least square fitting",
    "text": "12.4 Least square fitting\nTo find the best fit of the model to the experimental data, we use the least squares method. This method minimizes the sum of the squared differences between the observed data points and the model’s predictions.\nMathematically, we achieve this by minimizing the least squares, i.e., finding the parameters \\(a\\) that minimize the following expression:\n\\[\\begin{equation}\n\\frac{d\\chi^{2}}{da}=\\sum_{i=1}^{N}\\frac{1}{\\sigma_{i}^2}\\frac{df(x_{i},a)}{da}[y_{i}-f(x_{i},a)]=0\n\\end{equation}\\]\nThis kind of least squares minimization is done by fitting software using different types of algorithms.\n\n12.4.1 Fitting with SciPy\nLet’s do some fitting using the SciPy library, which is a powerful tool for scientific computing in Python. We will use the curve_fit method from the optimize sub-module of SciPy.\nFirst, we need to define the model function we would like to fit to the data. In this case, we will use our parabola function:\n\n\n\n\n\n\nNext, we need to provide initial guesses for the parameters. These initial guesses help the fitting algorithm start the search for the optimal parameters:\n\n\n\n\n\n\nWe then call the curve_fit function to perform the fitting:\n\n\n\n\n\n\n\n\n\n\n\n\ncurve_fit Function\n\n\n\n\n\nThe curve_fit function is used to fit a model function to data. It finds the optimal parameters for the model function that minimize the sum of the squared residuals between the observed data and the model’s predictions.\n\n12.4.2 Parameters\n\nparabola:\n\nThis is the model function that you want to fit to the data. In this case, parabola is a function that represents a quadratic equation of the form ( y = ax^2 + bx + c ).\n\nx_data:\n\nThis is the array of independent variable data points (the x-values).\n\ny_data:\n\nThis is the array of dependent variable data points (the y-values).\n\nsigma=err:\n\nThis parameter specifies the uncertainties (standard deviations) of the y-data points. The err array contains the uncertainties for each y-data point. These uncertainties are used to weight the residuals in the least squares optimization.\n\np0=init_guess:\n\nThis parameter provides the initial guesses for the parameters of the model function. The init_guess array contains the initial guesses for the parameters ( a ), ( b ), and ( c ). Providing good initial guesses can help the optimization algorithm converge more quickly and accurately.\n\nabsolute_sigma=True:\n\nThis parameter indicates whether the provided sigma values are absolute uncertainties. If absolute_sigma is set to True, the sigma values are treated as absolute uncertainties. If absolute_sigma is set to False, the sigma values are treated as relative uncertainties, and the covariance matrix of the parameters will be scaled accordingly.\n\n\n\n\n12.4.3 Return Value\nThe curve_fit function returns two values:\n\npopt:\n\nAn array containing the optimal values for the parameters of the model function that minimize the sum of the squared residuals.\n\npcov:\n\nThe covariance matrix of the optimal parameters. The diagonal elements of this matrix provide the variances of the parameter estimates, and the off-diagonal elements provide the covariances between the parameter estimates.\n\n\n\n\n\n\nThe fit variable contains the results of the fitting process. It is composed of various results, which we can split into the fitted parameters and the covariance matrix:\n\n\n\n\n\n\nThe ans variable contains the fitted parameters fit_a, fit_b, and fit_c, while the cov variable contains the covariance matrix. Let’s have a look at the fit and the \\(\\chi^{2}\\) value first:\n\n\n\n\n\n\nWe can then plot the fitted curve along with the original data points and the \\(\\chi^{2}\\) value:\n\n\n\n\n\n\n\n\n12.4.4 \\(\\chi\\)-squared value\nThe value of \\(\\chi^2\\) gives you a measure of the quality of the fit. We can judge the quality by calculating the expectation value of \\(\\chi^2\\):\n\\[\\begin{equation}\n\\langle \\chi^{2}\\rangle =\\sum_{i=1}^{N} \\frac{\\langle (y_{i}-f(x_{i},a) )^2\\rangle }{\\sigma_{i}^2}=\\sum_{i=1}^{N} \\frac{\\sigma_{i}^2}{\\sigma_{i}^2}=N\n\\end{equation}\\]\nSo, the mean of the least squared deviation increases with the number of data points. Therefore:\n\n\\(\\chi^{2} \\gg N\\) means that the fit is bad.\n\\(\\chi^{2} &lt; N\\) means that the uncertainties are wrong.\n\nThe first case may occur if you don’t have a good fit to your data, for example, if you are using the wrong model. The second case typically occurs if you don’t have accurate estimates of the uncertainties and you assume all uncertainties to be constant.\nIt is really important to have a good estimate of the uncertainties and to include them in your fit. If you include the uncertainties in your fit, it is called a weighted fit. If you don’t include the uncertainties (meaning you keep them constant), it is called an unweighted fit.\nFor our fit above, we obtain a \\(\\chi^{2}\\) which is on the order of \\(N=10\\), which tells you that I have created the data with reasonable accuracy.\n\n\n12.4.5 Residuals\nAnother way to assess the quality of the fit is by looking at the residuals. Residuals are defined as the deviation of the data from the model for the best fit:\n\\[\\begin{equation}\nr_i = y_i - f(x_{i},a)\n\\end{equation}\\]\nThe residuals can also be expressed as the percentage of the deviation of the data from the fit:\n\\[\\begin{equation}\nr_i = 100 \\left( \\frac{y_i - f(x_{i},a)}{y_i} \\right)\n\\end{equation}\\]\n\n\n12.4.6 Importance of Residuals\nResiduals are important because they provide insight into how well the model fits the data. If the residuals show only statistical fluctuations around zero, then the fit and likely also the model are good. However, if there are systematic patterns in the residuals, it may indicate that the model is not adequately capturing the underlying relationship in the data.\n\n\n12.4.7 Visualizing Residuals\nLet’s visualize the residuals to better understand their distribution. We will plot the residuals as a function of the independent variable \\(x\\).\n\n\n\n\n\n\n\n\n\n\n\n\nCommon Patterns in Residuals\n\n\n\n\n\nRandom Fluctuations Around Zero:\n\nIf the residuals are randomly scattered around zero, it suggests that the model is a good fit for the data.\n\nSystematic Patterns:\n\nIf the residuals show a systematic pattern (e.g., a trend or periodicity), it may indicate that the model is not capturing some aspect of the data. This could suggest the need for a more complex model.\n\nIncreasing or Decreasing Trends:\n\nIf the residuals increase or decrease with \\(x\\), it may indicate heteroscedasticity (non-constant variance) or that a different functional form is needed.",
    "crumbs": [
      "Lecture 6",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Curve fitting</span>"
    ]
  },
  {
    "objectID": "lectures/lecture06/1_curve_fitting.html#covariance-matrix",
    "href": "lectures/lecture06/1_curve_fitting.html#covariance-matrix",
    "title": "12  Curve fitting",
    "section": "12.5 Covariance Matrix",
    "text": "12.5 Covariance Matrix\nIn the previous sections, we discussed how to fit a model to experimental data and assess the quality of the fit using residuals. Now, let’s take a closer look at the uncertainties in the fit parameters and how they are related to each other. This is where the covariance matrix comes into play.\n\n12.5.1 Purpose of the Covariance Matrix\nThe covariance matrix provides important information about the uncertainties in the fit parameters and how these uncertainties are related to each other. It helps us understand the precision of the parameter estimates and whether the parameters are independent or correlated.\n\n\n12.5.2 Understanding Covariance\nCovariance is a measure of how much two random variables change together. If the covariance between two variables is positive, it means that they tend to increase or decrease together. If the covariance is negative, it means that one variable tends to increase when the other decreases. If the covariance is zero, it means that the variables are independent.\n\n\n12.5.3 Covariance Matrix in Curve Fitting\nWhen we fit a model to data, we obtain estimates for the parameters of the model. These estimates have uncertainties due to the measurement errors in the data. The covariance matrix quantifies these uncertainties and the relationships between them.\nFor a model with three parameters \\((a, b, c)\\), the covariance matrix is a \\(3 \\times 3\\) matrix that looks like this:\n\\[\\begin{equation}\n{\\rm cov}(p_{i}, p_{j}) =\n\\begin{bmatrix}\n\\sigma_{aa}^{2} & \\sigma_{ab}^{2} & \\sigma_{ac}^{2} \\\\\n\\sigma_{ba}^{2} & \\sigma_{bb}^{2} & \\sigma_{bc}^{2} \\\\\n\\sigma_{ca}^{2} & \\sigma_{cb}^{2} & \\sigma_{cc}^{2}\n\\end{bmatrix}\n\\end{equation}\\]\nThe diagonal elements provide the variances (squared uncertainties) of the fit parameters, while the off-diagonal elements describe the covariances between the parameters.\n\n\n12.5.4 Example\nLet’s calculate the covariance matrix for our fitted model and interpret the results.\n\n\n\n\n\n\n\n\n12.5.5 Interpreting the Covariance Matrix\nThe covariance matrix provides valuable information about the uncertainties in the fit parameters:\n\nDiagonal Elements: The diagonal elements represent the variances of the parameters. The square root of these values gives the standard deviations (uncertainties) of the parameters.\nOff-Diagonal Elements: The off-diagonal elements represent the covariances between the parameters. If these values are large, it indicates that the parameters are correlated.\n\n\n\n12.5.6 Generating Synthetic Data\nTo better understand the covariance matrix, let’s generate synthetic data and fit the model to each dataset. This will help us visualize the uncertainties in the parameters.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n12.5.7 Correlation Matrix\nTo better understand the relationships between the parameters, we can normalize the covariance matrix to obtain the correlation matrix. The correlation matrix has values between -1 and 1, where 1 indicates perfect positive correlation, -1 indicates perfect negative correlation, and 0 indicates no correlation.\n\n\n\n\n\n\n\n\n12.5.8 Visualizing the Covariance and Correlation\nLet’s visualize the covariance and correlation between the parameters using scatter plots.\n\n\n\n\n\n\nBy examining the covariance and correlation matrices, we can gain a deeper understanding of the uncertainties in the fit parameters and how they are related to each other.\n\n\n12.5.9 Improving the Model\nIf we find that the parameters are highly correlated, we might want to find a better model containing more independent parameters. For example, we can write down a different model:\n\\[\\begin{equation}\ny = a(x - b)^2 + c\n\\end{equation}\\]\nThis model also contains three parameters, but the parameter \\(b\\) directly refers to the maximum of our parabola, while the parameter \\(a\\) denotes its curvature.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe see from the covariance matrix that the new model has a smaller correlation of the parameters with each other.\n\n\n\n\n\n\nThis is also expressed by our correlation matrix.\n\n\n\n\n\n\nBy examining the covariance and correlation matrices, we can gain valuable insights into the uncertainties in the fit parameters and how to improve our model.",
    "crumbs": [
      "Lecture 6",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Curve fitting</span>"
    ]
  },
  {
    "objectID": "lectures/lecture07/1_differentiation.html",
    "href": "lectures/lecture07/1_differentiation.html",
    "title": "14  Numerical Differentiation",
    "section": "",
    "text": "14.1 First Order Derivative\nOur previous method of finding the derivative was based on the definition of the derivative itself. The derivative of a function \\(f(x)\\) at a point \\(x\\) is defined as the limit of the difference quotient as the interval \\(\\Delta x\\) goes to zero:\n\\[\nf^{\\prime}(x) = \\lim_{\\Delta x \\rightarrow 0} \\frac{f(x + \\Delta x) - f(x)}{\\Delta x}\n\\]\nIf we do not take the limit, we can approximate the derivative by:\n\\[\nf^{\\prime}_{i} \\approx \\frac{f_{i+1} - f_{i}}{\\Delta x}\n\\]\nHere, we look to the right of the current position \\(i\\) and divide by the interval \\(\\Delta x\\). It is not difficult to see that the resulting local error \\(\\delta\\) at each step is given by:\n\\[\n\\delta = f_{i+1} - f_{i} - \\Delta x f^{\\prime}(x_i) = \\frac{1}{2} \\Delta x^2 f^{\\prime \\prime}(x_i) + O(\\Delta x^3)\n\\]\nIt can be seen that the error is proportional to the square of the interval \\(\\Delta x\\). This is the reason why the method is called first order accurate. The error is of the order of \\(\\Delta x^{2}\\).\nA better expression can be found using the Taylor expansion around the position \\(x_0\\):\n\\[\nf(x) = f(x_{0}) + (x - x_0) f^{\\prime}(x) + \\frac{(x - x_0)^2}{2!} f^{\\prime\\prime}(x) + \\frac{(x - x_0)^3}{3!} f^{(3)}(x) + \\ldots\n\\]\nIn discrete notation, this gives:\n\\[\nf_{i+1} = f_{i} + \\Delta x f_{i}^{\\prime} + \\frac{\\Delta x^2}{2!} f_{i}^{\\prime\\prime} + \\frac{\\Delta x^3}{3!} f_{i}^{(3)} + \\ldots\n\\]\nThe same can be done to obtain the function value at \\(i-1\\):\n\\[\nf_{i-1} = f_{i} - \\Delta x f_{i}^{\\prime} + \\frac{\\Delta x^2}{2!} f_{i}^{\\prime\\prime} - \\frac{\\Delta x^3}{3!} f_{i}^{(3)} + \\ldots\n\\]\nSubtracting these two equations, we get:\n\\[\nf_{i+1} - f_{i-1} = 2 \\Delta x f_{i}^{\\prime} + O(\\Delta x^3)\n\\]\nsuch that the second order term in \\(\\Delta x\\) disappears. Neglecting the higher-order terms, we have\n\\[\nf^{\\prime}_{i} \\approx \\frac{f_{i+1} - f_{i-1}}{2 \\Delta x}\n\\]\nan thus have a first order derivative which is even more accurate than the one obtained from the definition of the derivative.\nWe can continue that type of derivation now to obtain higher order approximation of the first derivative with better accuracy. For that purpose you may calculate now \\(f_{i\\pm 2}\\) and combining that with \\(f_{i+1}-f_{i-1}\\) will lead to\n\\[\\begin{equation}\nf_{i}^{\\prime}=\\frac{1}{12 \\Delta x}(f_{i-2}-8f_{i-1}+8f_{i+1}-f_{i+2})\n\\end{equation}\\]\nThis can be used to give even better values for the first derivative.\nLet`s try out one of the formulas in the following code cell. We will write a function that calculates the derivative of a given function at a given position \\(x\\). The function will take the function \\(f\\) as and argument, which is new to us. We will also introduce a small interval \\(h=\\Delta x\\) which will be used to calculate the derivative. The function will return the derivative of the function at the given position \\(x\\).\nNote that the definition contains additional parameters *params which are passed to the function f. This is a general way to pass additional parameters to the function f which is used in the definition of the derivative.\nWe will try to calculate the derivative of the \\(\\sin(x)\\) function:\nWe can plot this and nicely obtain our cosine function",
    "crumbs": [
      "Lecture 7",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Numerical Differentiation</span>"
    ]
  },
  {
    "objectID": "lectures/lecture07/1_differentiation.html#first-order-derivative",
    "href": "lectures/lecture07/1_differentiation.html#first-order-derivative",
    "title": "14  Numerical Differentiation",
    "section": "",
    "text": "14.1.1 Matrix Version of the First Derivative\nIf we supply the above function with an array of positions \\(x_{i}\\) at which we would like to calculate the derivative, we obtain an array of derivative values. We can also write this procedure in a different way, which will be helpful for solving differential equations later.\nIf we consider the above finite difference formulas for a set of positions \\(x_{i}\\), we can represent the first derivative at these positions by a matrix operation as well:\n\\[\nf^{\\prime} = \\frac{1}{\\Delta x}\n\\begin{bmatrix}\n-1 & 1  & 0 & 0 & 0 & 0\\\\\n0 & -1 & 1 & 0 & 0 & 0\\\\\n0 & 0  & -1 & 1 & 0 & 0\\\\\n0 & 0  & 0  & -1 & 1 & 0\\\\\n0 & 0  & 0  &  0 & -1 & 1\\\\\n0 & 0  & 0  &  0 &  0 & -1\\\\\n\\end{bmatrix}\n\\begin{bmatrix}\nf_{1}\\\\\nf_{2}\\\\\nf_{3}\\\\\nf_{4}\\\\\nf_{5}\\\\\nf_{6}\\\\\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n\\frac{f_{2} - f_{1}}{\\Delta x}\\\\\n\\frac{f_{3} - f_{2}}{\\Delta x}\\\\\n\\frac{f_{4} - f_{3}}{\\Delta x}\\\\\n\\frac{f_{5} - f_{4}}{\\Delta x}\\\\\n\\frac{f_{6} - f_{5}}{\\Delta x}\\\\\n\\frac{0 - f_{6}}{\\Delta x}\\\\\n\\end{bmatrix}\n\\]\nNote that here we took the derivative only to the right side! Each row of the matrix, when multiplied by the vector containing the function values, gives the derivative of the function \\(f\\) at the corresponding position \\(x_{i}\\). The resulting vector represents the derivative in a certain position region.\nWe will demonstrate how to generate such a matrix with the SciPy module below.",
    "crumbs": [
      "Lecture 7",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Numerical Differentiation</span>"
    ]
  },
  {
    "objectID": "lectures/lecture07/1_differentiation.html#second-order-derivative",
    "href": "lectures/lecture07/1_differentiation.html#second-order-derivative",
    "title": "14  Numerical Differentiation",
    "section": "14.2 Second order derivative",
    "text": "14.2 Second order derivative\nWhile we did before calculate the first derivative, we can also calculate the second derivative of a function. In the previous calculations we evaluated \\(f_{i+1} - f_{i-1}\\). We can now also use the sum of both to arrive at\n\\[\\begin{equation}\nf_{i}^{\\prime\\prime}\\approx \\frac{f_{i-1}-2f_{i}+f_{i+1}}{\\Delta x^2}\n\\end{equation}\\]\nwhich gives the basic equation for calculating the second order derivative and the next order may be obtained from\n\\[\\begin{equation}\nf_{i}^{\\prime\\prime}\\approx \\frac{1}{12 \\Delta x^{2}}(-f_{i-2}+16f_{i-1}-30 f_{i}+16f_{i+1}-f_{i+2})\n\\end{equation}\\]\nwhich is again better than our previous formula, yet needs more function values to be calculated.",
    "crumbs": [
      "Lecture 7",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Numerical Differentiation</span>"
    ]
  },
  {
    "objectID": "lectures/lecture07/1_differentiation.html#scipy-module",
    "href": "lectures/lecture07/1_differentiation.html#scipy-module",
    "title": "14  Numerical Differentiation",
    "section": "14.3 SciPy Module",
    "text": "14.3 SciPy Module\nOf course, we are not the first to define some functions for calculating the derivative of functions numerically. This is already implemented in different modules. One module is the above mentioned SciPy module.\nThe SciPy module provides the method derivative, which we can call with\nderivative(f,x,dx=1.0,n=1):\nThis will calculate the n\\(th\\) derivative of the function \\(f\\) at the position \\(x\\) with a intervall \\(dx=1.0\\) (default value).\n\n\n\n\n\n\nWe also have the option to define the order parameter, which is not the order of the derivative but rather the number of points used to calculate the derivative according to our scheme earlier.\n\n\n\n\n\n\n\n14.3.1 Matrix Version\nThe SciPy module allows us to construct matrices as mentioned above. We will need the diags method from the SciPy module for that purpose.\n\n\n\n\n\n\nLet’s assume we want to calculate the derivative of the sin function at certain positions.\n\n\n\n\n\n\nThe diags function uses a set of numbers that should be distributed along the diagonals of the matrix. If you supply a list like in the example below, the numbers are distributed using the offsets as defined in the second list. The shape keyword defines the shape of the matrix. Try the example in the next cell with the .todense() suffix. This converts the otherwise unreadable sparse output to a readable matrix form.\n\n\n\n\n\n\nTo comply with our previous definition of \\(N=100\\) data points and the interval \\(\\Delta x\\), we define:\n\n\n\n\n\n\nThe derivative is then simply a matrix-vector multiplication, which is done either by np.dot(m,y) or just by the @ operator.\n\n\n\n\n\n\nLet’s plot the original function and its numerical derivative.\n\n\n\n\n\n\nCheck for yourself that the following line of code will calculate the second derivative.\n\n\n\n\n\n\nLet’s plot the original function and its second numerical derivative.\n\n\n\n\n\n\nThis demonstrates how to use the SciPy module to construct matrices for numerical differentiation and how to apply these matrices to compute first and second derivatives.\n\n\n\n\n\n\nApplications of the Matrix Method\n\n\n\n\n\nThe matrix method for computing derivatives is particularly useful in several contexts, especially in numerical analysis and computational mathematics. Here are some key applications:\n\nSolving Differential Equations:\n\nOrdinary Differential Equations (ODEs): The matrix method can be used to discretize ODEs, transforming them into a system of linear equations that can be solved using linear algebra techniques.\nPartial Differential Equations (PDEs): Similarly, PDEs can be discretized using finite difference methods, where derivatives are approximated by matrix operations. This is essential in fields like fluid dynamics, heat transfer, and electromagnetics.\n\nNumerical Differentiation:\n\nThe matrix method provides a systematic way to approximate derivatives of functions given discrete data points. This is useful in data analysis, signal processing, and any application where you need to estimate the rate of change from sampled data.\n\nStability and Accuracy Analysis:\n\nBy representing derivative operations as matrices, it becomes easier to analyze the stability and accuracy of numerical schemes. This is crucial for ensuring that numerical solutions to differential equations are reliable.\n\nOptimization Problems:\n\nIn optimization, especially in gradient-based methods, the matrix method can be used to compute gradients and Hessians efficiently. This is important in machine learning, operations research, and various engineering disciplines.\n\nFinite Element Analysis (FEA):\n\nIn FEA, the matrix method is used to approximate derivatives and integrals over complex geometries. This is widely used in structural engineering, biomechanics, and materials science.\n\nControl Theory:\n\nIn control theory, especially in the design and analysis of control systems, the matrix method can be used to model and simulate the behavior of dynamic systems.",
    "crumbs": [
      "Lecture 7",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Numerical Differentiation</span>"
    ]
  },
  {
    "objectID": "lectures/lecture08/2_integration.html",
    "href": "lectures/lecture08/2_integration.html",
    "title": "15  Numerical Integration",
    "section": "",
    "text": "15.1 Box Method (Rectangle Method)\nThe Box method is the simplest approach for numerical integration. It approximates the function in each interval \\(\\Delta x\\) with a constant value taken at the left endpoint of the interval.\n\\[\\begin{equation}\n\\int_{a}^{b} f(x) dx \\approx \\sum_{i=1}^{N} f(x_{i}) \\Delta x\n\\end{equation}\\]",
    "crumbs": [
      "Lecture 8",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Numerical Integration</span>"
    ]
  },
  {
    "objectID": "lectures/lecture08/2_integration.html#box-method-rectangle-method",
    "href": "lectures/lecture08/2_integration.html#box-method-rectangle-method",
    "title": "15  Numerical Integration",
    "section": "",
    "text": "Box Method Illustration",
    "crumbs": [
      "Lecture 8",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Numerical Integration</span>"
    ]
  },
  {
    "objectID": "lectures/lecture08/2_integration.html#trapezoid-method",
    "href": "lectures/lecture08/2_integration.html#trapezoid-method",
    "title": "15  Numerical Integration",
    "section": "15.2 Trapezoid Method",
    "text": "15.2 Trapezoid Method\n\n\n\nTrapezoid Method Illustration\n\n\nThe Trapezoid method improves upon the Box method by approximating the function with linear segments between points.\n\\[\\begin{equation}\n\\int_{a}^{b} f(x) dx \\approx \\sum_{i=1}^{N} \\frac{f(x_i) + f(x_{i-1})}{2} \\Delta x\n\\end{equation}\\]",
    "crumbs": [
      "Lecture 8",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Numerical Integration</span>"
    ]
  },
  {
    "objectID": "lectures/lecture08/2_integration.html#simpsons-method",
    "href": "lectures/lecture08/2_integration.html#simpsons-method",
    "title": "15  Numerical Integration",
    "section": "15.3 Simpson’s Method",
    "text": "15.3 Simpson’s Method\n\n\n\nSimpson’s Method Illustration\n\n\nSimpson’s method provides higher accuracy by approximating the function with parabolic segments.\n\\[\\begin{equation}\n\\int_{a}^{b} f(x) dx \\approx \\frac{\\Delta x}{3} \\sum_{i=1}^{(N-1)/2} \\left(f(x_{i-1}) + 4f(x_i) + f(x_{i+1})\\right)\n\\end{equation}\\]\n\n\n\n\n\n\n\n\n\n\n\n\nSimpson’s Rule for Numerical Integration\n\n\n\n\n\nSimpson’s Rule is a method for numerical integration that approximates the definite integral of a function by using quadratic polynomials.\n\nFor an integral \\(\\int_a^b f(x)dx\\), Simpson’s Rule fits a quadratic function through three points:\n\n\\(f(a)\\)\n\\(f(\\frac{a+b}{2})\\)\n\\(f(b)\\)\n\nLet’s define:\n\n\\(h = \\frac{b-a}{2}\\)\n\\(x_0 = a\\)\n\\(x_1 = \\frac{a+b}{2}\\)\n\\(x_2 = b\\)\n\nThe quadratic approximation has the form: \\[P(x) = Ax^2 + Bx + C\\]\nThis polynomial must satisfy: \\[f(x_0) = Ax_0^2 + Bx_0 + C\\] \\[f(x_1) = Ax_1^2 + Bx_1 + C\\] \\[f(x_2) = Ax_2^2 + Bx_2 + C\\]\nUsing Lagrange interpolation: \\[P(x) = f(x_0)L_0(x) + f(x_1)L_1(x) + f(x_2)L_2(x)\\]\nwhere \\(L_0\\), \\(L_1\\), \\(L_2\\) are the Lagrange basis functions.\n\n\n15.3.1 Final Formula\nThe integration of this polynomial leads to Simpson’s Rule:\n\\[\\int_a^b f(x)dx \\approx \\frac{h}{3}[f(a) + 4f(\\frac{a+b}{2}) + f(b)]\\]\n\n\n15.3.2 Error Term\nThe error in Simpson’s Rule is proportional to:\n\\[-\\frac{h^5}{90}f^{(4)}(\\xi)\\]\nfor some \\(\\xi \\in [a,b]\\)\n\n\n15.3.3 Composite Simpson’s Rule\nFor better accuracy, we can divide the interval into \\(n\\) subintervals (where \\(n\\) is even):\n\\[\\int_a^b f(x)dx \\approx \\frac{h}{3}[f(x_0) + 4\\sum_{i=1}^{n/2}f(x_{2i-1}) + 2\\sum_{i=1}^{n/2-1}f(x_{2i}) + f(x_n)]\\]\nwhere \\(h = \\frac{b-a}{n}\\)\nThe method is particularly effective for integrating functions that can be well-approximated by quadratic polynomials over small intervals.",
    "crumbs": [
      "Lecture 8",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Numerical Integration</span>"
    ]
  },
  {
    "objectID": "lectures/lecture08/2_integration.html#comparison-of-methods",
    "href": "lectures/lecture08/2_integration.html#comparison-of-methods",
    "title": "15  Numerical Integration",
    "section": "15.4 Comparison of Methods",
    "text": "15.4 Comparison of Methods\nLet’s compare the accuracy of all three methods:",
    "crumbs": [
      "Lecture 8",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Numerical Integration</span>"
    ]
  },
  {
    "objectID": "lectures/lecture08/2_integration.html#error-analysis",
    "href": "lectures/lecture08/2_integration.html#error-analysis",
    "title": "15  Numerical Integration",
    "section": "15.5 Error Analysis",
    "text": "15.5 Error Analysis\nThe three methods have different convergence rates:\n\nBox Method: Error ∝ \\(\\Delta x\\) (linear convergence)\nTrapezoid Method: Error ∝ \\(\\Delta x^2\\) (quadratic convergence)\nSimpson’s Method: Error ∝ \\(\\Delta x^4\\) (fourth-order convergence)\n\nThis explains why Simpson’s method typically achieves higher accuracy with fewer points. For example, doubling the number of points in Simpson’s method reduces the error by a factor of 16",
    "crumbs": [
      "Lecture 8",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Numerical Integration</span>"
    ]
  },
  {
    "objectID": "lectures/lecture08/3_solving_ODEs.html",
    "href": "lectures/lecture08/3_solving_ODEs.html",
    "title": "16  Solving ODEs",
    "section": "",
    "text": "16.1 Harmonic Oscillator",
    "crumbs": [
      "Lecture 8",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Solving ODEs</span>"
    ]
  },
  {
    "objectID": "lectures/lecture08/3_solving_ODEs.html#harmonic-oscillator",
    "href": "lectures/lecture08/3_solving_ODEs.html#harmonic-oscillator",
    "title": "16  Solving ODEs",
    "section": "",
    "text": "Physics Interlude: The harmonic oscillator\n\n\n\nWe are going to tackle as a first very simple problem, the harmonic oscillator and we will demonstrate that with the matrix (Crank-Nicholson method or implicit scheme), the Euler type integration method and using some ‘unknown’ integrator in the module SciPy.\nThe equation of motion for a classical harmonic oscillator is given\n\\[\\begin{equation}\n\\frac{\\mathrm{d}^2x}{\\mathrm{d}t^2}+\\omega^2 x=0\n\\end{equation}\\]\nThis is a second order differential equation which requires for its solution two initial conditions. The first initial condition is the initial elongation \\(x(t=0)=x_{0}\\) and the second the initial velocity \\(\\dot{x}(t=0)=v_{0}\\).",
    "crumbs": [
      "Lecture 8",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Solving ODEs</span>"
    ]
  },
  {
    "objectID": "lectures/lecture08/3_solving_ODEs.html#implicit-solution---crank-nicholson",
    "href": "lectures/lecture08/3_solving_ODEs.html#implicit-solution---crank-nicholson",
    "title": "16  Solving ODEs",
    "section": "16.2 Implicit Solution - Crank Nicholson",
    "text": "16.2 Implicit Solution - Crank Nicholson\nLets start with the matrix appraoch we have just learned about. Using the matrix version, we can transform the above equation into a system of coupled equations, which we can solve with some standard methods available from e.g. the SciPy module.\n\n16.2.1 Define Matrices\nOur matrix will consist of two parts. The first containing the second derivative and the second just the elongation. Suppose we want to calculate the position \\(x(t)\\) at 6 instances in time \\(t_{i}\\) then the matrix version of the second derivative reads as\n(\\(x_{1}=x(t_{1}), \\ldots\\)).\n\\(T=\\frac{d^2x}{dt^2}=\\frac{1}{\\delta t^2}\n\\begin{bmatrix}\n-2 & 1  & 0 & 0 & 0 & 0\\\\\n1 & -2 & 1 & 0 & 0 & 0\\\\\n0 & 1  & -2 & 1 & 0 & 0\\\\\n0 & 0  & 1  & -2 & 1 & 0\\\\\n0 & 0  & 0  &  1 & -2 & 1\\\\\n0 & 0  & 0  &  0 &  1 & -2\\\\\n\\end{bmatrix}\n\\begin{bmatrix}\nx_{1}\\\\\nx_{2}\\\\\nx_{3}\\\\\nx_{4}\\\\\nx_{5}\\\\\nx_{6}\n\\end{bmatrix}\\)\nThe second term in the equation of motion is a multiplication of the elongation \\(x(t_{i})\\) by \\(\\omega^{2}\\) and can be written as\n\\(V=\\omega^2 x=\\begin{bmatrix}\n\\omega^2  & 0  & 0 & 0 & 0 & 0\\\\\n0 & \\omega^2  & 0 & 0 & 0 & 0\\\\\n0 & 0  & \\omega^2  & 0 & 0 & 0\\\\\n0 & 0  & 0  & \\omega^2  & 0 & 0\\\\\n0 & 0  & 0  &  0 & \\omega^2  & 0\\\\\n0 & 0  & 0  &  0 &  0 & \\omega^2 \\\\\n\\end{bmatrix}\n\\begin{bmatrix}\nx_{1}\\\\\nx_{2}\\\\\nx_{3}\\\\\nx_{4}\\\\\nx_{5}\\\\\nx_{6}\n\\end{bmatrix}\\)\nThe left hand side of the would threfore contain a sum of the two matrices \\(M=T+V\\) multiplied by the vector \\(x\\). We have therfore almost all things together to solve this differential equation with the help of an implicit scheme. What we have ignored so far are the initial conditions.\n\n\n16.2.2 Use Initial Conditions\nThe matrix given for the second detivative actually implies already some initial (bounary) conditions. You probably noticed that the matrix contains incomplete coefficients for the second derivative in the first and last line. The first line contains \\((-2,1)\\), but the second derivative should contain \\((1,-2,1)\\). This \\((-2,1)\\) thus always includes the boundary condition that \\(x_{0}=0\\). To include our own initial/boundary conditions, we have to construct the matrix for the second derivative slightly differently and modify the differential equation to\n\\[\\begin{equation}\n\\frac{\\mathrm{d}^2x}{\\mathrm{d}t^2}+\\omega^2 x=b\n\\end{equation}\\]\nwhere the vector b takes care of the initial conditions.\nIf we have \\(N\\) positions in time at which we calculate the elongation \\(x\\), we have a \\(N\\times N\\) matrix of for the second derivatives. The lower \\(N-2\\) lines will contain the the coefficients for the second derivative \\((1,-2,1)\\). The first two lines supply the initial/boundary conditions.\nThe initial condition for the elongation \\(x(t=0)=x_{0}\\) is obtained when the first element of the first line is a 1. The matrix multiplication \\(M\\, x=b\\) for yields thus in the first line \\(x_{1}=b_{1}\\) and we set \\(b_{1}=x_{0}\\). The second line shall give the initial velocity. So the matrix entries of the second line contain a first derivative \\((-1,1)\\). The matrix multiplication thus yields \\(x_{2}-x_{1}=b_{2}\\). We can therefore need to set \\(b_{2}=v_{0}\\delta t\\). All of the other entries of \\(b\\) shall be set to zero according to the differential equation of the harmonic oscillator.\nOur final problem \\(M\\, x=b\\) will thus have the following shape\n\\[\\begin{equation}\n\\begin{bmatrix}\n1 & 0  & 0 & 0 & 0 & 0\\\\\n-1 & 1 & 0 & 0 & 0 & 0\\\\\n1 & -2+\\omega^2*\\delta t^2  & 1 & 0 & 0 & 0\\\\\n0 & 1  & -2+\\omega^2*\\delta t^2  & 1 & 0 & 0\\\\\n0 & 0  & 1  &  -2+\\omega^2*\\delta t^2 & 1 & 0\\\\\n0 & 0  & 0  &  1 &  -2+\\omega^2*\\delta t^2 & 1\\\\\n\\end{bmatrix}\n\\begin{bmatrix}\nx_{1}\\\\\nx_{2}\\\\\nx_{3}\\\\\nx_{4}\\\\\nx_{5}\\\\\nx_{6}\n\\end{bmatrix}=\n\\begin{bmatrix}\nx_{0}\\\\\nv_{0}\\delta t\\\\\n0\\\\\n0\\\\\n0\\\\\n0\n\\end{bmatrix}\n\\end{equation}\\]\n\n\n16.2.3 Solution\nThis is the final system of coupled equations which we can supply to any matrix solver. We will use a solver from the scipy.linalg module. Lets have a look at the details below.\nN=10\n\n(diags([-2., 1., 1.], [-1,-2, 0],\n    shape=(N, N))+diags([1], [-1], shape=(N, N))* omega**2*dt**2)",
    "crumbs": [
      "Lecture 8",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Solving ODEs</span>"
    ]
  },
  {
    "objectID": "lectures/lecture08/3_solving_ODEs.html#explicit-solution---numerical-integration",
    "href": "lectures/lecture08/3_solving_ODEs.html#explicit-solution---numerical-integration",
    "title": "16  Solving ODEs",
    "section": "16.3 Explicit Solution - Numerical Integration",
    "text": "16.3 Explicit Solution - Numerical Integration\nBefore implementing explicit numerical schemes, let’s develop a standardized approach for solving ODEs. This framework will allow us to solve different problems using various methods with minimal code modification.\nLet’s examine the free fall problem as an example:\n\\[\\begin{equation}\n\\ddot{x}= -g\n\\end{equation}\\]\nThis second-order equation can be transformed into a system of two first-order equations:\n\\[\\begin{eqnarray}\n\\dot{x} &= v \\\\\n\\dot{v} &= -g\n\\end{eqnarray}\\]\nUsing the Euler method, these equations become:\n\\[\\begin{eqnarray}\nx_{i+1} &= x_i + v_i \\Delta t \\\\\nv_{i+1} &= v_i - g\\Delta t\n\\end{eqnarray}\\]\nNote: The original equations had \\(\\dot{x}\\) and \\(\\dot{v}\\) in the right-hand side, which should be replaced with their actual values (\\(v\\) and \\(-g\\) respectively).\nThese equations can be written more compactly in vector form:\n\\[\\begin{equation}\n\\vec{y}_{i+1} = \\vec{y}_i + \\dot{\\vec{y}}_i \\Delta t\n\\end{equation}\\]\nwhere\n\\[\\begin{equation}\n\\vec{y}=\n\\begin{bmatrix}\nx \\\\\nv\n\\end{bmatrix}\n\\end{equation}\\]\nand\n\\[\\begin{equation}\n\\dot{\\vec{y}}=\n\\begin{bmatrix}\nv \\\\\n-g\n\\end{bmatrix}\n\\end{equation}\\]\nThis vector formulation allows us to separate: 1. Problem definition (specifying \\(\\dot{\\vec{y}}\\) as a function of \\(\\vec{y}\\) and \\(t\\)) 2. Solution method (implementing the numerical integration scheme)\nWe’ll explore three numerical methods:\n\nEuler Method: First-order accurate\nEuler-Cromer Method: Modified Euler method, better for oscillatory systems\nMidpoint Method: Second-order accurate\n\nMore sophisticated methods like the Runge-Kutta family offer higher accuracy but are not covered here.\n\n16.3.1 Euler Method\nThe Euler method is derived from the Taylor expansion of the solution \\(\\vec{y}(t)\\) around the current time \\(t\\):\n\\[\\begin{equation}\n\\vec{y}(t+\\Delta t)=\\vec{y}(t)+\\dot{\\vec{y}}(t)\\Delta t+\\frac{1}{2}\\ddot{\\vec{y}}(t)\\Delta t^{2}+ \\mathcal{O}(\\Delta t^3)\n\\end{equation}\\]\nThe Euler method approximates this by truncating after the first-order term:\n\\[\\begin{equation}\n\\vec{y}(t+\\Delta t) \\approx \\vec{y}(t) + \\dot{\\vec{y}}(t) \\Delta t\n\\end{equation}\\]\nFor our free fall example, this becomes:\n\\[\\begin{equation}\n\\begin{bmatrix} x_{i+1} \\\\ v_{i+1} \\end{bmatrix} =\n\\begin{bmatrix} x_i \\\\ v_i \\end{bmatrix} +\n\\begin{bmatrix} v_i \\\\ -g \\end{bmatrix} \\Delta t\n\\end{equation}\\]\nError Analysis: The method has two distinct types of errors. The local truncation error, which represents the error made in a single step, is of order \\(\\mathcal{O}(\\Delta t^2)\\). This corresponds to the first term omitted in the Taylor expansion. The global truncation error, which accumulates over the entire integration interval \\([0,\\tau]\\), is of order \\(\\mathcal{O}(\\Delta t)\\). This can be understood by considering that we take \\(N = \\tau/\\Delta t\\) steps, each contributing an error proportional to \\(\\Delta t^2\\). The total error thus scales as \\(N \\cdot \\Delta t^2 = \\tau \\Delta t\\).\nLimitations and Extensions: The method is directly applicable only to first-order systems of the form \\(\\dot{\\vec{y}} = \\vec{f}(\\vec{y},t)\\). However, this is not a fundamental limitation as higher-order equations can be converted to systems of first-order equations. For example, a second-order equation \\(\\ddot{x} = f(x,\\dot{x},t)\\) can be transformed into a system of two first-order equations by introducing the velocity as an additional variable. The resulting system becomes:\n\\[\\begin{equation}\n\\begin{bmatrix} \\dot{x} \\\\ \\dot{v} \\end{bmatrix} =\n\\begin{bmatrix} v \\\\ f(x,v,t) \\end{bmatrix}\n\\end{equation}\\]\nThis transformation allows us to apply the method to a wider class of problems while maintaining its fundamental characteristics.\n\n\n16.3.2 Euler-Cromer Method\nThe Euler-Cromer method (also known as the semi-implicit Euler method) modifies the basic Euler method by using the updated velocity when calculating the position. For a system described by position and velocity:\n\\[\\begin{equation}\n\\begin{aligned}\n\\dot{x} &= v \\\\\n\\dot{v} &= f(x,v,t)\n\\end{aligned}\n\\end{equation}\\]\nThe integration steps are:\n\\[\\begin{equation}\n\\begin{aligned}\nv_{i+1} &= v_i + f(x_i,v_i,t_i)\\Delta t \\\\\nx_{i+1} &= x_i + v_{i+1}\\Delta t\n\\end{aligned}\n\\end{equation}\\]\nFor our free fall example: \\[\\begin{equation}\n\\begin{aligned}\nv_{i+1} &= v_i - g\\Delta t \\\\\nx_{i+1} &= x_i + v_{i+1}\\Delta t\n\\end{aligned}\n\\end{equation}\\]\nEnergy Behavior: The method shows improved energy conservation for oscillatory systems compared to the standard Euler method. While the Euler method typically increases energy over time, the Euler-Cromer method exhibits small energy oscillations around the correct value.\nError Analysis: The method maintains a local truncation error of \\(\\mathcal{O}(\\Delta t^2)\\) and a global truncation error of \\(\\mathcal{O}(\\Delta t)\\). Despite having the same order of accuracy as the Euler method, it provides more stable solutions for oscillatory systems.\nAdvantages: The Euler-Cromer method represents a simple modification of the Euler method that achieves better stability for oscillatory systems without requiring additional function evaluations.\nLimitations: The method remains first-order accurate globally and is not symmetric in time. While it performs well for certain types of problems, particularly oscillatory systems, it may not be suitable for all differential equations.\nComparison with Euler Method:\n# Euler Method\nv[i+1] = v[i] + f(x[i],v[i],t[i])*dt\nx[i+1] = x[i] + v[i]*dt       # Uses old velocity\n\n# Euler-Cromer Method\nv[i+1] = v[i] + f(x[i],v[i],t[i])*dt\nx[i+1] = x[i] + v[i+1]*dt     # Uses new velocity\n\n\n16.3.3 Midpoint Method\nThe Midpoint Method (also known as the second-order Runge-Kutta method) improves upon both the Euler and Euler-Cromer methods by using the average of the derivatives at the current point and an estimated midpoint.\nFor a system of first-order differential equations:\n\\[\\begin{equation}\n\\dot{\\vec{y}} = \\vec{f}(\\vec{y},t)\n\\end{equation}\\]\nThe algorithm proceeds in two steps:\n\nCalculate an intermediate point using an Euler step to the midpoint: \\[\\begin{equation}\n\\vec{k}_1 = \\vec{f}(\\vec{y}_i,t_i)\n\\end{equation}\\] \\[\\begin{equation}\n\\vec{y}_{i+1/2} = \\vec{y}_i + \\frac{\\Delta t}{2}\\vec{k}_1\n\\end{equation}\\]\nUse the derivative at this midpoint for the full step: \\[\\begin{equation}\n\\vec{k}_2 = \\vec{f}(\\vec{y}_{i+1/2},t_i+\\Delta t/2)\n\\end{equation}\\] \\[\\begin{equation}\n\\vec{y}_{i+1} = \\vec{y}_i + \\Delta t\\vec{k}_2\n\\end{equation}\\]\n\nFor our free fall example, this becomes:\n\\[\\begin{equation}\n\\begin{aligned}\nv_{i+1/2} &= v_i - \\frac{g\\Delta t}{2} \\\\\nx_{i+1/2} &= x_i + v_i\\frac{\\Delta t}{2} \\\\\nv_{i+1} &= v_i - g\\Delta t \\\\\nx_{i+1} &= x_i + v_{i+1/2}\\Delta t\n\\end{aligned}\n\\end{equation}\\]\nError Analysis: The method achieves higher accuracy than both Euler and Euler-Cromer methods with:\n\nLocal truncation error: \\(\\mathcal{O}(\\Delta t^3)\\)\nGlobal truncation error: \\(\\mathcal{O}(\\Delta t^2)\\)\n\nImplementation:\ndef midpoint_step(y, t, dt, f):\n    # Calculate k1\n    k1 = f(y, t)\n\n    # Calculate midpoint\n    y_mid = y + 0.5 * dt * k1\n\n    # Calculate k2 at midpoint\n    k2 = f(y_mid, t + 0.5*dt)\n\n    # Full step using midpoint derivative\n    return y + dt * k2\n\n\n\n\n\n\n\n\n\n\n\n16.3.4 Putting it all together\nNow we can implement our numerical solution by combining our understanding of both the physical system and numerical methods. This implementation consists of two main parts: defining the differential equation and solving it numerically.\n\n16.3.4.1 The Definition of the Problem\nFor the simple harmonic oscillator, we start with the second-order differential equation:\n\\[\\begin{equation}\n\\frac{d^2x}{dt^2} + \\omega^2x = 0\n\\end{equation}\\]\nTo solve this numerically, we convert it to a system of first-order equations using our state vector \\(\\vec{y} = [x, v]^T\\):\n\\[\\begin{equation}\n\\frac{d}{dt}\\begin{bmatrix} x \\\\ v \\end{bmatrix} =\n\\begin{bmatrix} v \\\\ -\\omega^2x \\end{bmatrix}\n\\end{equation}\\]\nThis is implemented as: ~~~ def SHO(state, time): ““” Define the harmonic oscillator system. state[0] : position x state[1] : velocity v returns : [dx/dt, dv/dt] ““” g0 = state[1] # dx/dt = v g1 = -k/m*state[0] # dv/dt = -ω²x return np.array([g0, g1]) ~~~\nThis function defines our physical system by returning the derivatives of our state variables at any given point.\n\n\n16.3.4.2 Solving the Problem\nWith our system defined, we can implement the numerical solution using Euler’s method. The basic algorithm takes the current state and advances it by one time step:\ndef euler(y, t, dt, derivs):\n    \"\"\"\n    Perform one step of the Euler method.\n    y      : current state [x, v]\n    t      : current time\n    dt     : time step\n    derivs : function returning derivatives\n    \"\"\"\n    y_next = y + derivs(y, t) * dt\n    return y_next\nThis simple structure allows us to solve different physical problems by just changing the derivative function. For example, we can solve the free fall problem with initial conditions \\(x_0=0\\) and \\(v_0=10\\), or the harmonic oscillator with specified spring constant \\(k\\) and mass \\(m\\).\nThe key advantage of this structure lies in its flexibility. We can change the physical system by providing a different derivative function, implement various numerical methods by modifying the integration step, and explore the system behavior by adjusting parameters and initial conditions. This modular approach allows us to study a wide range of physical systems using the same basic numerical framework.",
    "crumbs": [
      "Lecture 8",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Solving ODEs</span>"
    ]
  },
  {
    "objectID": "lectures/lecture08/3_solving_ODEs.html#solving-the-harmonic-oscillator-with-scipy",
    "href": "lectures/lecture08/3_solving_ODEs.html#solving-the-harmonic-oscillator-with-scipy",
    "title": "16  Solving ODEs",
    "section": "16.4 Solving the Harmonic Oscillator with SciPy",
    "text": "16.4 Solving the Harmonic Oscillator with SciPy\nHaving explored basic numerical integration methods, we can now utilize more sophisticated tools available in SciPy. The scipy.integrate.odeint() function provides a robust and accurate integration method with several advantages over our simple implementations.\nTo use SciPy’s integrator:\nfrom scipy.integrate import odeint\nThe basic syntax is:\nsolution = odeint(derivative_function, initial_conditions, time_points)\nwhere:\n\nderivative_function defines the system (like our SHO function)\ninitial_conditions is a vector containing \\([x_0, v_0]\\)\ntime_points is an array of times at which to compute the solution\n\nThe odeint function offers several significant advantages over our simple implementations. It features adaptive step size control, which automatically adjusts the integration step size based on the local error. The function performs continuous error estimation and correction to maintain accuracy throughout the integration. It also provides various integration methods that can be selected based on the problem’s requirements. The function is capable of handling stiff equations, which are particularly challenging for simpler methods, and generally provides better numerical stability across a wide range of problems.\nFor example, to solve the harmonic oscillator:\ndef SHO(state, t, k=1.0, m=1.0):\n    x, v = state\n    return [v, -k/m * x]\n\n# Initial conditions\ny0 = [1.0, 0.0]  # x₀ = 1, v₀ = 0\nt = np.linspace(0, 10, 1000)\n\n# Solve the system\nsolution = odeint(SHO, y0, t)\nThe solution array contains:\n\nsolution[:, 0]: position values\nsolution[:, 1]: velocity values\n\nHaving understood the fundamentals of numerical integration through our implementations of Euler and other methods, we can now confidently use this more sophisticated tool for solving differential equations more accurately and efficiently.\n\n16.4.1 Setup\n\n\n\n\n\n\n\n\n16.4.2 Definition\n\n\n\n\n\n\n\n\n16.4.3 Solution\n\n\n\n\n\n\n\n\n16.4.4 Plotting",
    "crumbs": [
      "Lecture 8",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Solving ODEs</span>"
    ]
  },
  {
    "objectID": "lectures/lecture08/3_solving_ODEs.html#damped-driven-pendulum-in-scipy",
    "href": "lectures/lecture08/3_solving_ODEs.html#damped-driven-pendulum-in-scipy",
    "title": "16  Solving ODEs",
    "section": "16.5 Damped Driven Pendulum in SciPy",
    "text": "16.5 Damped Driven Pendulum in SciPy\nWrite a derivs function for a damped driven pendulum:\n\\[\\begin{equation}\n\\ddot{\\theta}=-\\frac{g}{L}\\sin(\\theta)-b \\dot{\\theta}+\\beta\\cos(\\omega t)\n\\end{equation}\\]\nUse this derivs function with the SciPy solver and plot the result for different parameters. Vary the damping parameter \\(b\\). Observe the contributions of the homogeneous and the particular solution. Plot the amplitude of the stationary solution as a function of frequency!\n\n16.5.1 Setup\n\n\n\n\n\n\n\n\n16.5.2 Definition\n\n\n\n\n\n\n\n\n16.5.3 Solution\n\n\n\n\n\n\n\n\n16.5.4 Plotting",
    "crumbs": [
      "Lecture 8",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Solving ODEs</span>"
    ]
  }
]